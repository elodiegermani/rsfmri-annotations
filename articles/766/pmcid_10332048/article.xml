<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <?properties manuscript?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-journal-id">9215515</journal-id>
      <journal-id journal-id-type="pubmed-jr-id">20498</journal-id>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>NeuroImage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">36586543</article-id>
      <article-id pub-id-type="pmc">10332048</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2022.119843</article-id>
      <article-id pub-id-type="manuscript">NIHMS1872496</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A machine learning based approach towards high-dimensional mediation analysis</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Nath</surname>
            <given-names>Tanmay</given-names>
          </name>
          <xref rid="A1" ref-type="aff">a</xref>
          <xref rid="CR1" ref-type="corresp">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Caffo</surname>
            <given-names>Brian</given-names>
          </name>
          <xref rid="A1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Wager</surname>
            <given-names>Tor</given-names>
          </name>
          <xref rid="A2" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Lindquist</surname>
            <given-names>Martin A.</given-names>
          </name>
          <xref rid="A1" ref-type="aff">a</xref>
        </contrib>
      </contrib-group>
      <aff id="A1"><label>a</label>The Department of Biostatistics, Johns Hopkins University, Baltimore, MD, USA</aff>
      <aff id="A2"><label>b</label>The Department of Psychological and Brain Sciences, Dartmouth College, Hanover, NH, USA</aff>
      <author-notes>
        <corresp id="CR1"><label>*</label>Corresponding author. <email>tnath3@jhu.edu</email> (T. Nath).</corresp>
      </author-notes>
      <pub-date pub-type="nihms-submitted">
        <day>1</day>
        <month>7</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>3</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>28</day>
        <month>12</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>10</day>
        <month>7</month>
        <year>2023</year>
      </pub-date>
      <volume>268</volume>
      <fpage>119843</fpage>
      <lpage>119843</lpage>
      <permissions>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
          <license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>)</license-p>
        </license>
      </permissions>
      <abstract id="ABS1">
        <p id="P1">Mediation analysis is used to investigate the role of intermediate variables (mediators) that lie in the path between an exposure and an outcome variable. While significant research has focused on developing methods for assessing the influence of mediators on the exposure-outcome relationship, current approaches do not easily extend to settings where the mediator is high-dimensional. These situations are becoming increasingly common with the rapid increase of new applications measuring massive numbers of variables, including brain imaging genomics, and metabolomics. In this work, we introduce a novel machine learning based method for identifying high dimensional mediators. The proposed algorithm iterates between using a machine learning model to map the high-dimensional mediators onto a lower-dimensional space, and using the predicted values as input in a standard three-variable mediation model. Hence, the machine learning model is trained to maximize the likelihood of the mediation model. Importantly, the proposed algorithm is agnostic to the machine learning mode that is used, providing significant flexibility in the types of situations where it can be used. We illustrate the proposed methodology using data from two functional Magnetic Resonance Imaging (fMRI) studies. First, using data from a task-based fMRI study of thermal pain, we combine the proposed algorithm with a deep learning model to detect distributed, network-level brain patterns mediating the relationship between stimulus intensity (temperature) and reported pain at the single trial level. Second, using resting-state fMRI data from the Human Connectome Project, we combine the proposed algorithm with a connectome-based predictive modeling approach to determine brain functional connectivity measures that mediate the relationship between fluid intelligence and working memory accuracy. In both cases, our multivariate mediation model links exposure variables (thermal pain or fluid intelligence), high dimensional brain measures (single-trial brain activation maps or resting-state brain connectivity) and behavioral outcomes (pain report or working memory accuracy) into a single unified model. Using the proposed approach, we are able to identify brain-based measures that simultaneously encode the exposure variable and correlate with the behavioral outcome.</p>
      </abstract>
      <kwd-group>
        <kwd>Machine learning</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Mediation analysis</kwd>
        <kwd>fMRI</kwd>
        <kwd>Resting-state functional connectivity</kwd>
        <kwd>Pain</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <label>1.</label>
      <title>Introduction</title>
      <p id="P2">A frequent occurrence in biological, mechanical, and information systems alike is that the relationship between two variables <inline-formula><mml:math id="M1" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M2" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula> is transmitted through a third intervening variable, or <italic toggle="yes">mediator</italic>, <inline-formula><mml:math id="M3" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula>. An example of such a relationship is illustrated in the three-variable path diagram depicted in <xref rid="F1" ref-type="fig">Fig. 1 A</xref>. For example, exposure to a drug may cause a clinical benefit via its effects on brain neurotransmitter levels. Solar energy may power an electric motor via an intermediate transformation to energy by a solar cell. Changing the position of an advertisement on a web page may influence sales of the advertised product via the position’s intermediate effects on people’s attention to the ad. In all these cases, estimating how much of the total effect of the exposure (or <italic toggle="yes">initial variable</italic>, <inline-formula><mml:math id="M4" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula>) on the outcome (or <italic toggle="yes">dependent variable</italic>, <inline-formula><mml:math id="M5" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula>) is transmitted through the mediator can help explain how the exposure influences the outcome, and thus under what conditions the relationship is likely to occur.</p>
      <p id="P3">The concept of mediation has been a staple in the behavioral sciences (<xref rid="R83" ref-type="bibr">Woodworth, 1928</xref>) for a century, and a linear model version of mediation analysis was popularized in the psychometric and behavioral sciences literature several decades ago (<xref rid="R8" ref-type="bibr">Baron and Kenny, 1986</xref>; <xref rid="R50" ref-type="bibr">MacKinnon et al., 2012</xref>). This framework has since been widely used in the social and behavioral sciences (<xref rid="R58" ref-type="bibr">Preacher and Hayes, 2008</xref>), economics, decision and policy making (<xref rid="R9" ref-type="bibr">Bickel et al., 1975</xref>; <xref rid="R27" ref-type="bibr">Goldberger, 1984</xref>), epidemiology (<xref rid="R59" ref-type="bibr">Richiardi et al., 2013</xref>), neuroscience (<xref rid="R21" ref-type="bibr">Farah, 2017</xref>; <xref rid="R74" ref-type="bibr">Vuorre and Bolger, 2018</xref>), and beyond. It has also been extended to use estimates based on modern causal modeling frameworks (<xref rid="R2" ref-type="bibr">Albert, 2008</xref>; <xref rid="R12" ref-type="bibr">Bonthrone et al., 2021</xref>; <xref rid="R32" ref-type="bibr">Holland, 1988</xref>; <xref rid="R61" ref-type="bibr">Robins and Greenland, 1992</xref>; <xref rid="R72" ref-type="bibr">VanderWeele, 2009</xref>).</p>
      <p id="P4">In most applications, the mediator variable is either univariate (<xref rid="R34" ref-type="bibr">Imai et al., 2010</xref>; <xref rid="R55" ref-type="bibr">Pearl, 2013</xref>) or low-dimensional, meaning that there are typically only one or a few mediating variables in the model (<xref rid="R35" ref-type="bibr">Imai and Yamamoto, 2013</xref>; <xref rid="R46" ref-type="bibr">Liu et al., 2022</xref>; <xref rid="R71" ref-type="bibr">VanderWeele and Vansteelandt, 2014</xref>). In practice, in many psychological, behavioral, and biological systems, there are many potential mediators, and these can be highly correlated. For example, the effects of surgery on post-operative pain may be mediated by a complex pattern of correlated gene expression changes in immune cells. The effects of an advertisement campaign on sales may be mediated by a complex pattern of measurable user data. Similarly, the effects of a hot stimulus on reported pain might be mediated by a complex pattern across inter-correlated brain regions. When the mediator space is high-dimensional, with larger numbers of mediators and multi-colinearity among them, estimating individual path coefficients in the standard way is not feasible. Potential reasons include difficulties modeling the appropriate relationship between variables in this setting (<xref rid="R11" ref-type="bibr">Blum et al., 2020</xref>), and the fact that standard estimation procedures become unstable when the number of mediators is much larger than the number of observations. However, in many cases, including those above, it may be useful or even preferred to assess the effects of a pattern across mediating variables of the same type in aggregate, without attempting to disentangle the unique causal effects of any single one. For example, the unique effect of each of 10,000 gene expression measures on post-operative pain may be difficult or impossible to estimate adequately, but a pattern that constitutes some function across the set of inter-correlated variables (e.g., a weighted average) may be both possible to estimate precisely and useful for both predictive and explanatory purposes. Such summaries are increasingly popular in genetics, neuroimaging, -omics, and beyond (<xref rid="R47" ref-type="bibr">Livshits et al., 2018</xref>; <xref rid="R54" ref-type="bibr">Parisien et al., 2017</xref>; <xref rid="R69" ref-type="bibr">Tu et al., 2016</xref>). In genetics, for example, it is now possible to measure ~1 million inter-correlated single-nucleotide polymorphisms, which individually explain &lt; 1 percent of the variance in phenotypes at best, but in aggregate can often explain much more variance. These pattern-based models have enjoyed wide applicability in machine learning, but have seldom been extended to mediation tests. Thus, with the recent growth in the number of new applications collecting data on massive numbers of variables (e.g., brain imaging, genetics, epidemiology, and public health studies), it has become important to develop mediation analysis in high-dimensional settings.</p>
      <p id="P5">As a motivating example that we continue throughout the remainder of this paper, consider the study of human brain function using functional magnetic resonance imaging (fMRI) data. Here researchers are interested in understanding the role of distributed brain measures acting as potential mediators on the relationship between an exposure (or treatment) variable and certain cognitive (or outcome) variables (<xref rid="R5" ref-type="bibr">Atlas et al., 2014</xref>; <xref rid="R20" ref-type="bibr">Dufford et al., 2021</xref>; <xref rid="R43" ref-type="bibr">Lindquist, 2012</xref>; <xref rid="R46" ref-type="bibr">Liu et al., 2022</xref>; <xref rid="R48" ref-type="bibr">Logan et al., 2021</xref>; Wager et al., 2009a; <xref rid="R77" ref-type="bibr">2008</xref>; 2009b). In this context, the mediator can be a high-dimensional image (e.g., a 3-dimensional structural brain image or brain activation map) or a set of measures of functional connectivity (e.g., a 2-dimensional connectivity matrix), while both the exposure and outcome variables are univariate. For instance, <xref rid="R14" ref-type="bibr">Brady et al. (2022)</xref> uses functional connectivity to perform mediation analysis and suggest that prenatal exposure to crime is associated with weaker neonatal limbic and frontal functional brain connectivity.</p>
      <p id="P6">Standard mediation techniques will not be directly applicable in these settings, and new approaches are required. <xref rid="R15" ref-type="bibr">Caffo et al. (2008)</xref> proposed an early approach based on expressing the multivariate images using summary measures upon which standard mediation analysis was performed. Another early approach, “mediation effect parametric mapping ” (Wager et al., 2009a; <xref rid="R77" ref-type="bibr">2008</xref>; 2009b), sought to investigate univariate mediators at each spatial location (voxel). However, this ignores the inherent relationship between voxels, instead identifying a series of univariate mediators. More recently, a number of approaches have sought to explicitly derive optimized, multivariate linear combinations of the high-dimensional mediators. <xref rid="R33" ref-type="bibr">Huang and Pan (2016)</xref> proposed a transformation model using spectral decomposition where mediation ects were estimated by placing the univariate transformed mediators into a series of regression models. A related approach, denoted the “principal directions of mediation ” (PDM) (<xref rid="R16" ref-type="bibr">Chén et al., 2018</xref>; <xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>), decomposed high dimensional mediators into multiple orthogonal mediators that together mediate the effect of an exposure variable on the outcome. The method was applied to fMRI data and used to identify brain regions that mediate the relationship between a thermal stimulus and reported pain (<xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>). Finally, <xref rid="R84" ref-type="bibr">Zhao et al. (2020)</xref> proposed a sparse principal components approach towards high-dimensional mediation analysis.</p>
      <p id="P7">In this paper we introduce a novel machine learning based method for identifying high dimensional mediators. Our proposed approach links the high dimensional mediators (e.g., brain activation maps or resting-state functional connectivity) to a standard path analysis model through a machine learning model (e.g., deep learning or support vector regression); see <xref rid="F1" ref-type="fig">Fig. 1 B</xref>. Our proposed algorithm iterates between using a machine learning model to map the high-dimensional mediators <inline-formula><mml:math id="M6" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula> onto low dimensional mediators <inline-formula><mml:math id="M7" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula>, and using the predicted values as input in a standard three-variable mediation model. Importantly, the true value of <inline-formula><mml:math id="M8" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula> is latent, and the machine learning algorithm is trained to maximize the likelihood of the underlying mediation model, rather than based on directly predicting <inline-formula><mml:math id="M9" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula>. Our proposed approach uses an iterated maximization algorithm that alternates between fitting the machine learning algorithm and the mediation model. Thus, the approach provides a means of linking exposure variables, high-dimensional brain measures, and behavioral outcomes into a single unified model. Importantly, our proposed algorithm is flexible enough to allow researchers to ‘plug in’ various different types of machine learning algorithms, depending on the type of data assumed to mediate the relationship between exposure and outcome. In this work we explore a variety of such plugins, including a deep learning model, a shallow learning model, support vector regression, and a connectome-based predictive model (<xref rid="R65" ref-type="bibr">Shen et al., 2017</xref>). Research on high-dimensional mediation analysis is in its infancy and this is to the best of our knowledge the first application of deep learning to the field.</p>
      <p id="P8">We illustrate the performance of the proposed method through a simulation study and application to two different fMRI datasets. In the first application, we use data from eight different heat pain studies (<inline-formula><mml:math id="M10" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>284</mml:mn></mml:mrow></mml:math></inline-formula>) to investigate the role of brain mediators on the generation of pain experience. Here a series of thermal stimuli were applied at various temperatures to each subject. In response, subjects gave subjective pain ratings at a specific time point following the offset of the stimulus. During the course of the experiment, brain activity in response to the thermal stimuli was measured across the entire brain using fMRI. The goal is to determine brain regions whose activity level act as potential mediators of the relationship between temperature and pain rating. In this application we use the proposed algorithm together with a deep learning model. Seven out of the eight studies (<inline-formula><mml:math id="M11" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>209</mml:mn></mml:mrow></mml:math></inline-formula>) were used as training data, and the final study (<inline-formula><mml:math id="M12" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:math></inline-formula>) was used as test data. Here the model parameters estimated in the training data are used to validate model performance in new set of individuals. <xref rid="F2" ref-type="fig">Fig. 2 A</xref> provides an overview of the proposed setup. Importantly, the test data set not only included heat pain stimuli, but also physically and emotionally aversive sounds, providing a test of whether brain mediators of pain are specific to pain or general across pain and aversive sounds. While the derived mediators should generalize to different pain data sets, they are not expected to mediate the relationship between sound levels and perceived sound intensity. We benchmark the performance of our approach against (<xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>), which used the same data to find high-dimensional brain patterns that mediate pain using the linear PDM approach, and mass-univariate mediation effect parametric mapping.</p>
      <p id="P9">In the second application, we use behavioral and resting-state fMRI (rs-fMRI) data from the Human Connectome Project (HCP) 900 release (<xref rid="R70" ref-type="bibr">Van Essen et al., 2013</xref>) to investigate the relationship between fluid intelligence and working memory, measured using performance on an N-back task. In particular, we sought to explore whether resting-state brain connectivity measures mediated the relationship between these two variables. In this application we use the proposed algorithm together with a connectome-based predictive model (<xref rid="R24" ref-type="bibr">Gao et al., 2019</xref>). For each subject we extracted the mean time series from 268 regions of the Shen atlas (<xref rid="R66" ref-type="bibr">Shen et al., 2013</xref>), and computed a connectivity matrix where each element represents the Pearson correlation between the time series from two regions. We sought to investigate whether the elements of the correlation matrix mediated the relationship between intelligence and accuracy. In total we had 798 subjects with complete data, where 70% were used for training the model and 30% for testing. <xref rid="F2" ref-type="fig">Fig. 2 B</xref> provides an overview of the proposed setup. These two examples illustrate the ability of our approach to handle different types of data and utilize different types of models, highlighting the strength and flexibility of the proposed approach.</p>
    </sec>
    <sec id="S2">
      <label>2.</label>
      <title>Methods</title>
      <sec id="S3">
        <label>2.1.</label>
        <title>Mediation model</title>
        <p id="P10">Mediation analysis is an analytic technique used to make statistical inferences on the path coefficients (see <xref rid="F1" ref-type="fig">Fig. 1</xref>), particularly on the proportion of the total effect of <inline-formula><mml:math id="M13" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> on <inline-formula><mml:math id="M14" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula> is mediated through <inline-formula><mml:math id="M15" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula>. The effects of the exposure on the outcome are decomposed into separable direct and indirect effects, representing the influence of the variables <inline-formula><mml:math id="M16" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> on <inline-formula><mml:math id="M17" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula> unmediated and mediated by <inline-formula><mml:math id="M18" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula>, respectively. Using the notation in <xref rid="F1" ref-type="fig">Fig. 1</xref>, the indirect effect is given by the product of the coefficients <inline-formula><mml:math id="M19" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M20" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and the direct effect by the coefficient <inline-formula><mml:math id="M21" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>. Together, their sum represents the total effect of <inline-formula><mml:math id="M22" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> on.</p>
        <p id="P11">Here we introduce our machine learning-based method for identifying high-dimensional mediators; see <xref rid="F1" ref-type="fig">Fig. 1 B</xref>. For <inline-formula><mml:math id="M23" display="inline"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M24" display="inline"><mml:mi>n</mml:mi></mml:math></inline-formula> denotes the number of trials, let <inline-formula><mml:math id="M25" display="inline"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M26" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denote the univariate exposure and outcome variables, respectively, and let <inline-formula><mml:math id="M27" display="inline"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> be a high-dimensional object consisting of <inline-formula><mml:math id="M28" display="inline"><mml:mi>p</mml:mi></mml:math></inline-formula> elements where <inline-formula><mml:math id="M29" display="inline"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>. Further, let <inline-formula><mml:math id="M30" display="inline"><mml:mrow><mml:mtext>Φ</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denote an arbitrary machine learning model that operates on the variables <inline-formula><mml:math id="M31" display="inline"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Our proposed approach takes the output of the algorithm <inline-formula><mml:math id="M32" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and places it into a standard 3-variable mediation model together with <inline-formula><mml:math id="M33" display="inline"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M34" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Importantly, we consider the true value of <inline-formula><mml:math id="M35" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to be a latent variable, and the machine learning model is instead trained to maximize the likelihood of the underlying mediation path analysis model (see (3)), rather than based on predicting <inline-formula><mml:math id="M36" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula>. Our proposed approach achieves this goal by using an iterated maximization algorithm that alternates between fitting the machine learning algorithm and the mediation model. Thus, all three variables <inline-formula><mml:math id="M37" display="inline"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M38" display="inline"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M39" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are part of the loss function.</p>
        <p id="P12">To elaborate, we assume that the relationship between the variables is given by two sets of equations. First, the mediator model links the exposure to the output of the machine learning model as follows:
<disp-formula id="FD1">
<label>(1)</label>
<mml:math id="M40" display="block"><mml:mrow><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M41" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the intercept, <inline-formula><mml:math id="M42" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> is the coefficient describing the exposure-to-mediator relationship, and the error term <inline-formula><mml:math id="M43" display="inline"><mml:mrow><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> Second, the outcome model links the exposure and the output of the machine learning model to the outcome as follows:
<disp-formula id="FD2">
<label>(2)</label>
<mml:math id="M44" display="block"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M45" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the intercept, <inline-formula><mml:math id="M46" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> is the coefficient representing the mediator-to-output relationship, <inline-formula><mml:math id="M47" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> is the direct effect of the exposure on the outcome, and the error term <inline-formula><mml:math id="M48" display="inline"><mml:mrow><mml:msup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Once the parameters have been estimated we can express the total effect <inline-formula><mml:math id="M49" display="inline"><mml:mi>τ</mml:mi></mml:math></inline-formula> as the sum of the direct and indirect effects as follows: <inline-formula><mml:math id="M50" display="inline"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>. This is equivalent to the decomposition obtained in a standard univariate mediation analysis (<xref rid="R8" ref-type="bibr">Baron and Kenny, 1986</xref>), and one can investigate whether there exists a significant mediation effect by testing: <inline-formula><mml:math id="M51" display="inline"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>α</mml:mi><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
        <p id="P13">We propose to jointly fit all model parameters, including those in the machine learning model, through a single unified modeling approach. Combining the error terms from <xref rid="FD1" ref-type="disp-formula">Eqs. (1)</xref> and <xref rid="FD2" ref-type="disp-formula">(2)</xref>, the global loss function contribution over all observations is given by:
<disp-formula id="FD3">
<label>(3)</label>
<mml:math id="M52" display="block"><mml:mrow><mml:mi>𝓛</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>γ</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>α</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P14">The solution to the global loss function corresponds to the maximum likelihood estimate of the three variable path model under normality assumptions.</p>
        <p id="P15">In order to estimate the model parameters we propose an iterative algorithm that alternates between fitting the machine learning model <inline-formula><mml:math id="M53" display="inline"><mml:mtext>Φ</mml:mtext></mml:math></inline-formula> and the three-variable mediation model. Let us begin by assuming that the parameters <inline-formula><mml:math id="M54" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M55" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M56" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M57" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M58" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> are known, the goal is to find an optimal solution for <xref rid="FD3" ref-type="disp-formula">Eq. (3)</xref>. Let <inline-formula><mml:math id="M59" display="inline"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M60" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>α</mml:mi></mml:mrow></mml:math></inline-formula>. Then, keeping track of only those terms that involve <inline-formula><mml:math id="M61" display="inline"><mml:mtext>Φ</mml:mtext></mml:math></inline-formula> and completing the square, <xref rid="FD3" ref-type="disp-formula">Eq. (3)</xref> becomes:
<disp-formula id="FD4">
<label>(4)</label>
<mml:math id="M62" display="block"><mml:mrow><mml:mi>𝓛</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mo>∝</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Φ</mml:mtext><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace linebreak="newline"/><mml:mo>∝</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P16">Under the assumption that <inline-formula><mml:math id="M63" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M64" display="inline"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M65" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are known, minimizing the loss <inline-formula><mml:math id="M66" display="inline"><mml:mi>𝓛</mml:mi></mml:math></inline-formula> is now equivalent to minimizing
<disp-formula id="FD5">
<label>(5)</label>
<mml:math id="M67" display="block"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M68" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. This provides an appropriate loss function to fit the machine learning algorithm. Under the assumptions discussed above, the values of <inline-formula><mml:math id="M69" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are known and thus the model can be fit using standard estimation techniques.</p>
        <p id="P17">Next, under the assumption that <inline-formula><mml:math id="M70" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is known, the parameters <inline-formula><mml:math id="M71" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M72" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M73" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M74" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M75" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> can be estimated using a standard 3-variable path analysis model (<xref rid="R8" ref-type="bibr">Baron and Kenny, 1986</xref>). This involves fitting the regression models:
<disp-formula id="FD6">
<label>(6)</label>
<mml:math id="M76" display="block"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD7">
<label>(7)</label>
<mml:math id="M77" display="block"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P18">Solving the equations provides estimates of both the direct effect <inline-formula><mml:math id="M78" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> and the indirect effect <inline-formula><mml:math id="M79" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> used to assess mediation.</p>
        <p id="P19">Initial estimates of <inline-formula><mml:math id="M80" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are computed using a given starting value for the the machine learning algorithm <inline-formula><mml:math id="M81" display="inline"><mml:mtext>Φ</mml:mtext></mml:math></inline-formula>. In the proposed framework the sign of <inline-formula><mml:math id="M82" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is not identifiable. Hence, we fix the sign so that the correlation between <inline-formula><mml:math id="M83" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M84" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is positive across observations <inline-formula><mml:math id="M85" display="inline"><mml:mi>i</mml:mi></mml:math></inline-formula> to simplify interpretation. A similar constraint is used when estimating the principal directions of mediation (<xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>) and in independent components analysis (ICA). In addition, we normalize the variable <inline-formula><mml:math id="M86" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to avoid overshooting or shrinking of the prediction while iteratively minimizing the loss function expressed in <xref rid="FD5" ref-type="disp-formula">Eq. (5)</xref>. Thus, <inline-formula><mml:math id="M87" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is known up to sign and scale. Importantly, neither of these constraints affect the total amount of variance explained by the mediators. Using the exposure variable <inline-formula><mml:math id="M88" display="inline"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, outcome <inline-formula><mml:math id="M89" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and mediator <inline-formula><mml:math id="M90" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, we fit the standard path analysis model to obtain the coefficients <inline-formula><mml:math id="M91" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M92" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M93" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M94" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M95" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>. Thereafter, we update the parameters of the machine learning model by fitting the model using <inline-formula><mml:math id="M96" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as the outcomes and <inline-formula><mml:math id="M97" display="inline"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as the predictors. The proposed approach utilizes an iterative maximization algorithm that alternates between fitting the machine learning algorithm and the path analysis model. The pseudocode for the algorithm is de- scribed in <xref rid="T1" ref-type="table">Algorithm 1</xref>.The implementation of the algorithm is available at <ext-link xlink:href="https://github.com/meet10may/deep-mediation.git" ext-link-type="uri">https://github.com/meet10may/deep-mediation.git</ext-link>.</p>
        <table-wrap position="anchor" id="T1">
          <label>Algorithm 1:</label>
          <caption>
            <p id="P20">Block maximization algorithm.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">1 Predict <inline-formula><mml:math id="M98" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>Φ</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">2 Set the sign of <inline-formula><mml:math id="M99" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> so that the correlation across observations with <inline-formula><mml:math id="M100" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is positive, i.e. if <inline-formula><mml:math id="M101" display="inline"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>; then <inline-formula><mml:math id="M102" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">3 Set <inline-formula><mml:math id="M103" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">4 Fit a path analysis model to obtain <inline-formula><mml:math id="M104" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M105" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M106" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M107" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M108" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> using the outcome <inline-formula><mml:math id="M109" display="inline"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, mediator <inline-formula><mml:math id="M110" display="inline"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and exposure variable <inline-formula><mml:math id="M111" display="inline"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">5 Create <inline-formula><mml:math id="M112" display="inline"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>θ</mml:mi></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">6 Create <inline-formula><mml:math id="M113" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>γ</mml:mi></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">7 Create <inline-formula><mml:math id="M114" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">8 Update <inline-formula><mml:math id="M115" display="inline"><mml:mtext>Φ</mml:mtext></mml:math></inline-formula> using <inline-formula><mml:math id="M116" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as the outcome and <inline-formula><mml:math id="M117" display="inline"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as the predictor.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">9 Repeat <italic toggle="yes">Steps 1 to 8</italic></td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p id="P21">It is important to note that <xref rid="T1" ref-type="table">Algorithm 1</xref> is agnostic to the choice of machine learning model. In this work, using simulated data, we show the flexibility of <xref rid="T1" ref-type="table">Algorithm 1</xref> using: (1) a deep learning model; (2) a shallow learning model; and (3) support vector regression. As a demonstration, we apply the same deep learning model to the pain data to determine brain regions mediating the relationship between input stimuli and pain ratings. Additionally, we apply a ridge regression connectome-based predictive model (<xref rid="R24" ref-type="bibr">Gao et al., 2019</xref>) to the HCP data to determine the functional networks that mediate the relationship between fluid intelligence and working memory accuracy. Below we describe each model in turn.</p>
        <sec id="S4">
          <label>2.1.1.</label>
          <title>Deep learning model</title>
          <p id="P22">We built a 3-dimensional convolutional neural network (CNN) based deep learning model that uses a residual architecture (ResNet) (<xref rid="R31" ref-type="bibr">He et al., 2016</xref>). For the application to the pain data set, the input of the CNN consists of 3-dimensional volumes of size 91 ×109×91. Each volume corresponds to the brain activation map from a single trial. The CNN architecture consists of 5 residual blocks, each followed by a max pooling layer and a fully connected layer. The max pooling layer uses a stride of 2 with a kernel size of 3. Our model is inspired by a 3D-CNN based deep learning model used for brain age prediction (<xref rid="R36" ref-type="bibr">Jónsson et al., 2019</xref>). However, our proposed model differs in two key areas. First, since we want a generalized model, we did not include information about sex and scanner type to the final layer. Second, we replaced the Batch renormalization layer with a Batch normalization layer. The convolutional part of the CNN reduces the input image from dimensions 91 × 109 × 91 to 128 feature maps of size 3 × 4 × 3. The model was trained by minimizing the mean absolute error (MAE) using Adam optimization. The final fully connected part uses these feature maps to predict the lower-dimensional mediators. A flowchart of the model is shown in <xref rid="SD1" ref-type="supplementary-material">Figure S1</xref>. The CNN architecture is implemented using Keras version 2.4.0 (<xref rid="R17" ref-type="bibr">Chollet, 2015</xref>) and Tensorflow version 2.3.1 (<xref rid="R1" ref-type="bibr">Abadi et al., 2016</xref>) as the backend. We fit the deep learning models on the Oracle cluster using NVIDIA V100 Tensor core GPU. For the simulation study, the model was altered based on the dimensions of the input images; see below for a thorough description of the simulations performed.</p>
        </sec>
        <sec id="S5">
          <label>2.1.2.</label>
          <title>Shallow learning model</title>
          <p id="P23">We used a shallow CNN-based learning model with fewer layers than the deep learning model. The model consists of two convolutional layers, each with filter size 32 and 64 respectively, with kernel size 3 and using the rectified linear unit (ReLu) activation function (<xref rid="R53" ref-type="bibr">Nair and Hinton, 2010</xref>). The convolutional layers are followed by a max pooling layer with stride 2 and a dropout layer to reduce overfitting. Thereafter, a dense layer with filter size 128 and ReLu activation function is added followed by a dropout layer with keep rate equal to 0.5 and the final output layer with no activation function. Thus, the final layer performs a linear regression on the features of the hidden layers. Similar to the deep learning model, the MAE is used as the loss function and Adam optimization is used to ensure that the architecture converges. Further details about the training process is described in <xref rid="S19" ref-type="sec">Section 2.4</xref>.The shallow learning model is used only in the simulation study for comparison purposes and to demonstrate the flexibility of our proposed approach.</p>
        </sec>
        <sec id="S6">
          <label>2.1.3.</label>
          <title>Support vector regression</title>
          <p id="P24">We used a non-linear support vector regression (SVR) using a radial basis function kernel. The python library scikit-learn (<xref rid="R56" ref-type="bibr">Pedregosa et al., 2011</xref>) was used to implement the SVR and its regularization parameter was set to 1. Similar to the shallow learning model, SVR is only used in the simulation study for comparison purposes and to demonstrate the flexibility of our proposed approach.</p>
        </sec>
        <sec id="S7">
          <label>2.1.4.</label>
          <title>Ridge regression connectome-based predictive modeling (rCPM)</title>
          <p id="P25">We used a ridge regression connectome-based predictive model (<xref rid="R24" ref-type="bibr">Gao et al., 2019</xref>), which is an approach that has proven useful for developing predictive models of brain-behavior relationships from connectivity data. Here the features are obtained from a connectivity matrix where the edge of the matrix represents the Pearson correlation between the time series from two regions. Each edge in the connectivity matrix is related to the behavioral measures using a form of linear regression and a set of edges are selected using a significance test. Thereafter, a multivariate ridge regression model is fit to evaluate the brain-behavior relationship using the selected edges. The hyper-parameter corresponding to regularization strength is tuned using a 5-fold cross-validation grid search strategy which allows for an exhaustive search over the specified grid of parameters values (<inline-formula><mml:math id="M118" display="inline"><mml:mi>λ</mml:mi></mml:math></inline-formula> is allowed to take 100 evenly spaced values between <inline-formula><mml:math id="M119" display="inline"><mml:mrow><mml:mn>5</mml:mn><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="M120" display="inline"><mml:mrow><mml:mn>5</mml:mn><mml:mi>e</mml:mi><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula>).</p>
        </sec>
      </sec>
      <sec id="S8">
        <label>2.2.</label>
        <title>Simulations</title>
        <p id="P26">We performed three simulations to evaluate the performance of the proposed algorithm. We simulated a situation in which the latent mediator scores <inline-formula><mml:math id="M121" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula> are a complex, nonlinear function of an observed set of mediator variables. To accomplish this, in our simulations, we embedded the mediator in an image whose pixels represent the values of handwritten digits. In order to create a simulated dataset, we first fixed values of <inline-formula><mml:math id="M122" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M123" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M124" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M125" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M126" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> for each simulation as described below. Next, we randomly generated input data <inline-formula><mml:math id="M127" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> using a standard normal distribution with mean 0 and standard deviation 1. Thereafter, we used the input data as an explanatory variable in the linear regression model:
<disp-formula id="FD8">
<mml:math id="M128" display="block"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M129" display="inline"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. This allowed us to generate the low-dimensional mediators <inline-formula><mml:math id="M130" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula>. In order to create a high-dimensional set of mediators <inline-formula><mml:math id="M131" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula> that encode this information in a nonlinear fashion, we computed the cumulative distribution function of <inline-formula><mml:math id="M132" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula>, which gives us a value between 0 and 1. Next, we took the first 4 digits after the decimal point and found images of these digits in the MNIST dataset (<xref rid="R42" ref-type="bibr">LeCun, 1998</xref>). We concatenate the 4 images into a larger image to create the high dimensional mediators. Next, we simulated the outcome using the linear regression model:
<disp-formula id="FD9">
<mml:math id="M133" display="block"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>γ</mml:mi><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math>
</disp-formula>
where <inline-formula><mml:math id="M134" display="inline"><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Steps for creating the dataset are summarized in <xref rid="SD1" ref-type="supplementary-material">Figure S1</xref>.</p>
        <p id="P27">Using this framework for data generation, we performed three simulations, where for each, we evaluated the performance of <xref rid="T1" ref-type="table">Algorithm 1</xref> using three different machine learning models: (1) a deep learning model; (2) a shallow learning model; and (3) support vector regression. The details of the implementation of each machine learning model are de- scribed above. The input to each of the models are the high-dimensional mediators <inline-formula><mml:math id="M135" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula> (computed using simulated data as illustrated in <xref rid="SD1" ref-type="supplementary-material">Figure S1</xref>) and <inline-formula><mml:math id="M136" display="inline"><mml:mi>d</mml:mi></mml:math></inline-formula>. The output is the model with tuned hyper-parameters that will be used for estimating the parameters of the path analysis model expressed in <xref rid="T1" ref-type="table">Algorithm 1</xref>.</p>
        <p id="P28">In Simulation 1, we sought to evaluate how the sample size effects the ability to estimate the parameters of the mediation model shown in <xref rid="SD1" ref-type="supplementary-material">Figure S1</xref>. We varied the number of observations (subjects) while keeping the dimensions of the mediator constant. We used the MNIST data with image size 28 ×28 pixels, thereby creating a high-dimensional mediator with dimensions 28 ×112, for 100, 500 and 1000 observations. The model parameters were set to <inline-formula><mml:math id="M137" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M138" display="inline"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M139" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M140" display="inline"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M141" display="inline"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M142" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
        <p id="P29">In Simulation 2, we sought to evaluate how the size of the high-dimensional mediator impacts the ability to estimate the parameters of the mediation model. We fixed the number of observations to 1000, but varied the dimensions of the MNIST data. We scaled the MNIST images to 8 ×8, 32 ×32, 64 ×64 pixels, thus changing the dimension of the high-dimensional mediator variable to 8 ×32, 32 ×128, and 64 ×256.The values of the parameters <inline-formula><mml:math id="M143" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M144" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M145" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M146" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mo>×</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> remained the same as in Simulation 1.</p>
        <p id="P30">Finally, in Simulation 3, we sought to evaluate the performance of the model in a null-setting, where there is no significant mediation effect. We removed the link between the exposure and the mediator variable by setting the value of <inline-formula><mml:math id="M147" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> to 0. The values of all other parameters remained the same as in Simulation 1. Similar to Simulation 1, we varied the number of observations (100, 500 and 1000 subjects) while keeping the dimensions of the simulated mediators constant (28 ×112).</p>
        <p id="P31">For each simulation we fit the model for each of the three machine learning methods for 20 iterations. These iterations are used for estimating the coefficients <inline-formula><mml:math id="M148" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M149" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M150" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>, and the indirect effect <inline-formula><mml:math id="M151" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>. It was noticed that the value of the coefficients converge in less than 5 iterations. This procedure was repeated 100 times for each model and simulation.</p>
        <p id="P32">For comparison purposes, we also fit the PDM approach (<xref rid="R16" ref-type="bibr">Chén et al., 2018</xref>; <xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>) to the simulated data. This approach linearly combines information across images into a smaller number of orthogonal components that are chosen based on the proportion of the indirect effect that they explain. To facilitate comparisons with the proposed approach, we only use the first PDM which corresponds to the direction (or linear combination of features) that maximizes the proportion of the indirect effect explained. Subsequent PDMs, which maximize the remaining indirect effect conditional on being orthogonal to previous PDMs, are not used in this analysis. It should also be noted that there are differences in the model specification used to generate the data and the one used in the PDM model (it assumes a linear relationship between <inline-formula><mml:math id="M152" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M153" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula>) that may affect the simulations results.</p>
      </sec>
      <sec id="S9">
        <label>2.3.</label>
        <title>Experimental data</title>
        <sec id="S10">
          <label>2.3.1.</label>
          <title>Participants</title>
          <sec id="S11">
            <title>Pain Data:</title>
            <p id="P33">The data consisted of 284 healthy participants from eight independent studies (<xref rid="R38" ref-type="bibr">Koban et al., 2019</xref>; <xref rid="R40" ref-type="bibr">Krishnan et al., 2016</xref>; <xref rid="R64" ref-type="bibr">Roy et al., 2014</xref>; <xref rid="R76" ref-type="bibr">Wager et al., 2013</xref>; <xref rid="R81" ref-type="bibr">Woo et al., 2015</xref>) of thermal pain. The sample size in each study varied between <inline-formula><mml:math id="M154" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="M155" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:math></inline-formula> subjects. All participants were recruited from the New York City and Denver/Boulder areas and provided written informed consent. The institutional review board of Columbia University and the University of Colorado Boulder approved all studies. An online questionnaire, a pain safety screening form, and an fMRI safety screening form were used to determine the eligibility of all the participants. Any participant with psychiatric, physiological or pain disorders, neurological conditions, and MRI contraindications were excluded prior to enrollment. Additionally, participants were required to have at least 30 trials (<xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>) with low variance inflation factors (&lt; 3.5), non-missing ratings, and stimulation intensity data. Based on these criteria, 18 participants were excluded from Study 8.</p>
          </sec>
          <sec id="S12">
            <title>HCP Data:</title>
            <p id="P34">The data consisted of subjects from the Human Connectome Project (HCP) 900 release (<xref rid="R70" ref-type="bibr">Van Essen et al., 2013</xref>) from the Washington University - University of Minnesota (WU-Minn HCP) Consortium. All participants gave full consent to the WU-Minn HCP Consortium, and research procedures and ethical guidelines were followed in accordance with Washington University institutional review board approval. Here resting state fMRI (rsfmri) data with <inline-formula><mml:math id="M156" display="inline"><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> polarity <inline-formula><mml:math id="M157" display="inline"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mi>I</mml:mi><mml:mo>_</mml:mo><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:msub><mml:mn>1</mml:mn><mml:mo>−</mml:mo></mml:msub><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with 1200 time-points were used. Any subject with less than 1200 time-points or with missing data (i.e., with ‘nan’ values in the time series) were excluded from the analysis. Further, any participant with a missing fluid intelligence score or accuracy measure on the working memory task were also excluded. After excluding all such participants (<inline-formula><mml:math id="M158" display="inline"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>102</mml:mn></mml:mrow></mml:math></inline-formula> exclusions), 798 subjects remained and were included in our analysis.</p>
          </sec>
        </sec>
        <sec id="S13">
          <label>2.3.2.</label>
          <title>Procedure</title>
          <sec id="S14">
            <title>Pain Data:</title>
            <p id="P35">All participants received varying levels of thermal stimuli and rated their experienced pain while they underwent fMRI scanning. The number of trials, stimulation sites, rating scales, stimulus duration and intensities, inter-trial intervals varied across the studies, but were comparable; see <xref rid="R44" ref-type="bibr">Lindquist et al. (2017)</xref> for further information. During fMRI scanning, the temperature of the heat stimulus (exposure variable) and pain rating (outcome variable) were recorded for each participant. Single trial brain activation maps were estimated using a general linear model (GLM) approach. In addition to the heat stimulus, participants in Study 8 also received an aversive sound stimuli during the fMRI scanning. The aversive sounds are taken from the the International Affective Digital Sounds database (<xref rid="R13" ref-type="bibr">Bradley and Lang, 1999</xref>). Example sounds include those of a knife scraping a plate (the single most aversive sound in the database) and emotionally aversive sounds like attacks, screaming and crying. Trials specific to aversive sounds were used to test the specificity of brain mediator patterns to thermal stimulus intensity and pain.</p>
          </sec>
          <sec id="S15">
            <title>HCP Data:</title>
            <p id="P36">In addition to extensive MRI scanning, all HCP subjects performed a battery of cognitive tasks. Here we focus on measures of fluid intelligence and working memory accuracy. Fluid intelligence, a measure of higher order relational reasoning, was assessed using a 24-item version of the Penn Progressive Matrices test (<xref rid="R10" ref-type="bibr">Bilker et al., 2012</xref>). Working memory accuracy was measured using the mean accuracy across all conditions in an n-back task, described in detail in <xref rid="R7" ref-type="bibr">Barch et al. (2013)</xref>, and consisted of values between 0–100. During fMRI scanning, four 15-minute fMRI scans (runs) with a temporal resolution of 0.72s and a spatial resolution of 2-mm isotropic were collected. Data from a single scan was used to create a resting-state connectivity matrix, described in more detail below.</p>
          </sec>
        </sec>
        <sec id="S16">
          <label>2.3.3.</label>
          <title>fMRI data processing</title>
          <sec id="S17">
            <title>Pain Data:</title>
            <p id="P37">Structural T1-weighted images were co-registered to the mean of the functional image. Thereafter, the registered image was normalized to MNI space using SPM ( <ext-link xlink:href="http://www.fil.ion.ucl.ac.uk/spm/" ext-link-type="uri">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>). Studies 1 and 6 used SPM5, while SPM8 was used for all other studies. Following initial normalization, an additional normalization step based on the genetic algorithm-based normalization (<xref rid="R4" ref-type="bibr">Atlas et al., 2010</xref>; <xref rid="R78" ref-type="bibr">Wager and Nichols, 2003</xref>) was performed in Studies 1 and 6. The first few volumes (ranging from 3–5) of each functional dataset was removed from the analysis to allow for image stabilization; see <xref rid="R44" ref-type="bibr">Lindquist et al. (2017)</xref> for more detail. Mean and standard deviation of intensity values across each slice was used to identify outlier slices. Additionally, the Mahalanobis distance was computed for slice-wise mean and standard deviation of functional volumes. After false detection rate (FDR) correction for multiple comparisons, values with a significant <inline-formula><mml:math id="M159" display="inline"><mml:mrow><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> value were considered as outliers. In total less than 1% of the total images were considered as outliers. The output of this procedure was included as nuisance covariates in subject-level models. Next, except for Study 8 (multiband data with a short TR of 480 ms), slice timing correction and motion correction was performed on the functional images using SPM. Functional images were warped to SPM’s normative atlas, interpolated to to <inline-formula><mml:math id="M160" display="inline"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>m</mml:mi><mml:msup><mml:mi>m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> voxels, and smoothed with an 8 mm FWHM Gaussian kernel.</p>
            <p id="P38">For all studies except Studies 3 and 6, a single trial design and analysis approach was used to model the data by constructing a GLM design matrix with separate regressors for each trial (<xref rid="R52" ref-type="bibr">Mumford et al., 2012</xref>; <xref rid="R60" ref-type="bibr">Rissman et al., 2010</xref>). To model the cue and rating periods for each study, boxcar regressors were convolved with the canonical hemodynamic response function (HRF). Regressors for each trial, as well as several types of nuisance covariates were also included. Trial-by trial variance inflation factors (VIF) were calculated, and any trials with VIFs exceeding 2.5 were excluded from the analyses (VIF threshold for Study 8 was 3.5 as in the primary publication). For Study 1, global outliers (trials that exceeded three standard deviations above the mean) were also excluded, and a principal component based denoising step was employed during preprocessing to minimize artifacts. This generated single trial estimates that reflect the amplitude of the fitted HRF on each trial and represent the magnitude pain-period activity for each trial in each voxel. For Studies 3 and 6, rather than using a canonical HRF, single trial analyses were based on fitting a set of three basis functions. This allowed the shape of the modeled HRF to vary across trials and voxels. This procedure differed from that used in other studies because it maintains consistency with the procedures used in the original publications (<xref rid="R4" ref-type="bibr">Atlas et al., 2010</xref>). The pain period basis set consisted of three curves shifted in time and was customized for thermal pain responses based on previous studies (<xref rid="R4" ref-type="bibr">Atlas et al., 2010</xref>; <xref rid="R45" ref-type="bibr">Lindquist et al., 2009</xref>). For Study 6, the pain anticipation period was modeled using a boxcar epoch con- volved with a canonical HRF to estimate the cue-evoked responses. This epoch was truncated at 8 s to ensure that fitted anticipatory responses were not affected by noxious stimulus-evoked activity. Similar to other Studies, the nuisance covariates were included and trials with VIFs larger than 2.5 were excluded. In Study 6 trials that were global outliers (more than 3 standard deviations above the mean) were also excluded. The fitted basis functions from the flexible single trial approach were used to reconstruct the HRF and compute the area under the curve (AUC) for each trial and in each voxel. These trial-by-trial AUC values were used as estimates of trial-level pain-period activity. Together, these single trial maps of pain-period activity were used for model development and validation. The brain activation map for each participant was z-scored for each study. The final dimensions of the maps were 91 ×109 ×91.These maps were used as the high-dimensional mediators in our analysis.</p>
          </sec>
          <sec id="S18">
            <title>HCP Data:</title>
            <p id="P39">For each subject, four 15 min rs-fMRI scans with a temporal resolution of 0.72 s and a spatial resolution of 2-mm isotropic were available. We used the preprocessed and artifact-removed rs-fMRI data provided through the HCP900-PTN data release. This data has been extensively described in multiple other publications, so we only briefly discuss it here. The preprocessing pipeline followed the procedure outlined in <xref rid="R68" ref-type="bibr">Smith et al. (2013)</xref>.Spatial preprocessing was applied using the procedure described by <xref rid="R26" ref-type="bibr">Glasser et al. (2013)</xref>.Independent component analysis (ICA), followed by FMRIBs ICA-based X-noisefier (FIX) from the FMRIB Software Library (FSL) (<xref rid="R28" ref-type="bibr">Griffanti et al., 2014</xref>), was used for structured artifact removal, removing more than 99 percent of the artifactual ICA components in the dataset.</p>
            <p id="P40">Functional parcellation of each subject’s data was performed using the Shen atlas (<xref rid="R66" ref-type="bibr">Shen et al., 2013</xref>), which consists of 268 regions. For each region, the mean time series was extracted and shifted to 0 mean and unit variance. Any subject with less than 1200 time-points or with missing data (i.e., with ‘nan’ values in the time series) were excluded from the analysis. The Pearson correlation between each regions time course was computed, resulting in a 268 ×268 correlation matrix depicting functional connectivity between regions. Since these correlation matrices are symmetric, we vectorized the lower triangle of the matrix and used these values as the high-dimensional mediator in our analysis.</p>
          </sec>
        </sec>
      </sec>
      <sec id="S19">
        <label>2.4.</label>
        <title>Model fit and training procedure</title>
        <p id="P41">The same general training procedure was used for both the simulated data and fMRI data, with the main difference lying in the number of iterations that were performed. For the simulated data Steps 1–8 of <xref rid="T1" ref-type="table">Algorithm 1</xref> was iterated 20 times, while for the fMRI data it was only iterated 10 times to reduce computational burden.</p>
        <p id="P42">In the simulation study, we evaluated the deep learning model, the shallow learning model, and support vector regression within our framework. Since the simulated data was created using MNIST data, all the layers of the deep and shallow learning models were constructed for 2D input data. For each simulation, 30% of the data was used as a vali- dation data set, allowing us to judge how well the model generalized. The parameters of the mediation model <inline-formula><mml:math id="M161" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M162" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M163" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula> were computed and compared with the ground truth value after the 20 th iteration. Both the deep and shallow learning models use the MAE as the loss function and the Adam optimization (<xref rid="R37" ref-type="bibr">Kingma and Ba, 2014</xref>) method to ensure the architecture converges. The Adam parameters are set as follows: learning rate = 0.001, decay = 10 <sup>−6</sup>, <inline-formula><mml:math id="M164" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M165" display="inline"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:mrow></mml:math></inline-formula>, and batch size = 32. The model weights were initialized using the He initialization strategy (<xref rid="R30" ref-type="bibr">He et al., 2015</xref>) and a regularization parameter (<xref rid="R41" ref-type="bibr">Krogh and Hertz, 1992</xref>) <inline-formula><mml:math id="M166" display="inline"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is added to each trainable node in the CNN.</p>
        <p id="P43">For the pain data, we combined our proposed algorithm with a deep learning model. In contrast to the stimulation study, the layers of the deep learning model were constructed for 3D input data. The first seven studies (<inline-formula><mml:math id="M167" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>209</mml:mn></mml:mrow></mml:math></inline-formula>) were used as training data, while the eighth (<inline-formula><mml:math id="M168" display="inline"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:math></inline-formula>) was used as the testing data (<xref rid="R38" ref-type="bibr">Koban et al., 2019</xref>; <xref rid="R40" ref-type="bibr">Krishnan et al., 2016</xref>; <xref rid="R64" ref-type="bibr">Roy et al., 2014</xref>; <xref rid="R76" ref-type="bibr">Wager et al., 2013</xref>; <xref rid="R81" ref-type="bibr">Woo et al., 2015</xref>). Further, 30% of the training data were used as a validation set. The validation set is used to provide insight into whether or not the model is overfitting. To further check for overfitting, we stop training the model (<xref rid="R51" ref-type="bibr">Morgan and Bourlard, 1990</xref>) if the validation error does not improve in 25 epochs and the weights with the lowest validation error were used for making the prediction in the test data.</p>
        <p id="P44">To evaluate the stability of the findings, we performed a leave-one-study out cross-validation where we alternated which of the eight studies were used as the validation dataset, while training on the remaining seven studies. In addition, we also ran multiple iterations of <inline-formula><mml:math id="M169" display="inline"><mml:mi>k</mml:mi></mml:math></inline-formula>-fold cross validation.</p>
        <p id="P45">The input data consisted of a set of processed fMRI activation maps in response to the painful stimuli registered to MNI space along with the corresponding temperature and pain report. During each epoch, training and validation data were kept separate. For each potential mediator model, we performed a multi-level mediation analysis (Wager et al., 2009c) on the test data and obtained p-values using a bootstrap approach with 5000 iterations. We chose the model with the most stable indirect effect for mediating thermal pain.</p>
        <p id="P46">Finally, we compared the results to those obtained using both mediation effect parametric mapping and the PDM approach.</p>
        <p id="P47">For the HCP data, we combined our proposed algorithm with rCPM to find potential elements that mediate the relationship between fluid intelligence and accuracy of working memory task. We used 70% of the subjects for training and 30% for testing the model. The input data consisted of a set of vectorized connectivity values along with the corresponding fluid intelligence and working memory accuracy scores. We ran Steps 1–8 of the algorithm for 10 iterations. During each iteration, we used a 5-fold cross-validation grid search strategy on the training data to tune the model hyper-parameter. Thereafter, for each iteration, we fit the model with tuned parameters to the training data. Each iteration yields a potential mediator model, and similar to the analysis used for the pain data, we performed a multi-level mediation analysis on the test data to obtain p-values using a bootstrap procedure with 5000 iterations. Finally, we chose the model with the most stable indirect effect.</p>
      </sec>
      <sec id="S20">
        <label>2.5.</label>
        <title>Model interpretation</title>
        <p id="P48">For both datasets, we used SHAP (SHapley Additive exPlanations) (<xref rid="R49" ref-type="bibr">Lundberg and Lee, 2017</xref>) to interpret the model fit. Shapley values are based on game theory which determines a ‘fair’ way to attribute the total gain to the players in a coalition game based on the individual contribution. The approach has recently been used to interpret deep learning models in a number of different medical applications (<xref rid="R63" ref-type="bibr">Rodríguez-Pérez and Bajorath, 2020</xref>; <xref rid="R67" ref-type="bibr">Singh et al., 2020</xref>; <xref rid="R73" ref-type="bibr">van der Velden et al., 2020</xref>).</p>
        <p id="P49">In our application, the goal of SHAP is to explain the prediction obtained by the deep learning model by computing the relative contribution of each feature (e.g., voxel or connectivity edge) to the prediction. The Shapley values take into account the marginal distribution of every feature to the final prediction, making sure that the contributions of these features are optimally assessed. One drawback of using Shapley values is that they are computationally expensive. However, we used the Deep Shap implementation in python (<ext-link xlink:href="https://github.com/slundberg/shap" ext-link-type="uri">https://github.com/slundberg/shap</ext-link>) which makes computation acceptable without compromising any inherent properties of the Shapley values.</p>
      </sec>
    </sec>
    <sec id="S21">
      <label>3.</label>
      <title>Results</title>
      <sec id="S22">
        <label>3.1.</label>
        <title>Simulations</title>
        <p id="P50"><xref rid="F3" ref-type="fig">Figure 3</xref> shows the results of Simulation 1. Here we investigated how increasing the number of observations influenced the performance of our approach. We kept the dimensions of the mediator constant, but allowed the number of observations to vary. Clearly, as the number of observations increase the error bars become narrower, providing more accurate estimates of <inline-formula><mml:math id="M170" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M171" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M172" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M173" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>. All three models perform roughly equivalently, though for small samples sizes the error bars for the deep learning model are somewhat larger, particularly when estimating <inline-formula><mml:math id="M174" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, indicating increased error variance. In contrast, the PDM approach shows a consistent bias in estimation of the <inline-formula><mml:math id="M175" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> coefficient which leads to a slight underestimation (overestimation) of the indirect (direct) effect. This is no doubt due to the differences in the model specification used to generate the data and the one used in the PDM model, as these biases are not present when data is generated according to the PDM model (<xref rid="R16" ref-type="bibr">Chén et al., 2018</xref>).</p>
        <p id="P51"><xref rid="F4" ref-type="fig">Figure 4</xref> shows the results of Simulation 2. Here we investigated the ability of our approach to handle increased dimensions of the mediator variable. The values of all other variables remain the same as in Simulation 1. Again, all three models perform roughly equally. Interestingly, the error bars are constant across all dimensions. This indicates that the difficulty of the estimation problem is not directly related to the size of the mediator, but rather the information content which is constant as the images are simply scaled versions of one another.</p>
        <p id="P52">Again, the PDM approach shows a consistent bias in estimation of the <inline-formula><mml:math id="M176" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> coefficient which leads to a slight underestimation (overestimation) of the indirect (direct) effect.</p>
        <p id="P53"><xref rid="F5" ref-type="fig">Figure 5</xref> shows the results of Simulation 3. Here we investigated the performance of our approach in a ‘null’ setting where the indirect effect is 0. We used the same dimension of the mediator variables as described in Simulation 1, however we changed the value of <inline-formula><mml:math id="M177" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> to be equal to 0. Each of the three models were able to handle this situation and on average found the indirect effect to be 0. Again, as the number of observations increase the error bars become narrower, providing more accurate estimates of <inline-formula><mml:math id="M178" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M179" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M180" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M181" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
        <p id="P54">Here, while the PDM approach shows a bias in estimation of both the <inline-formula><mml:math id="M182" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M183" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> coefficients, both the direct and indirect effects appear unbiased.</p>
      </sec>
      <sec id="S23">
        <label>3.2.</label>
        <title>Pain data</title>
        <p id="P55"><xref rid="T1" ref-type="table">Algorithm 1</xref> was combined with a deep learning algorithm and fit to the training data, consisting of 209 subjects with a total of 13372 trials from Studies 1–7. Each trial consisted of a temperature, a pain rating, and a 3-dimensional activation map. To validate the model fit, it was evaluated using an independent test dataset consisting of 75 subjects with a total of 2296 trials. Validation was performed by applying the trained deep learning model to the activation maps in the test dataset to obtain low-dimensional mediators. These were then placed into a standard three-variable path model together with the associated temperature and pain ratings. A multi-level mediation analysis (Wager et al., 2009c) was performed on this data set, and the significance of <inline-formula><mml:math id="M184" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M185" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M186" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> was tested using a bootstrap procedure with 5000 iterations.</p>
        <p id="P56"><xref rid="F6" ref-type="fig">Figure 6 A</xref> shows scatter plots illustrating the positive relationship between the low-dimensional mediator <inline-formula><mml:math id="M187" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula> and the input temperature, the pain ratings and the mediator, and the pain ratings and the temperature, respectively. <xref rid="F6" ref-type="fig">Fig. 6 B</xref> shows the estimated <inline-formula><mml:math id="M188" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> (stimulus intensity to brain path), <inline-formula><mml:math id="M189" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> (brain to pain report path), and <inline-formula><mml:math id="M190" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> (indirect) effects when applying the model fit to the training data. All results are significant (<inline-formula><mml:math id="M191" display="inline"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) when applied to the heat pain data, suggesting that the deep learning results are reliably related to pain and generalize across cohorts.</p>
        <p id="P57">To determine which regions are driving the mediation, Shapley values were computed for all heat pain trials in the training data set. <xref rid="F6" ref-type="fig">Figure 6 C</xref> shows the voxels with the 5% largest absolute values. Brain regions shown are commonly associated with pain processing, such as multiple cerebellar regions, anterior cingulate and surrounding medial prefrontal cortex (MPFC), posterior medial orbito-frontal cortex (OFC)/ventromedial prefrontal cortex (vmPFC), lateral prefrontal cortex (area 47, inferior frontal sulcus [IFS], area 6), multiple temporal regions (temporal pole, TA2, entorhinal cortex), hippocampus, and Bed nucleus of Stria Terminalis (BST).</p>
        <p id="P58">It should be noted that the threshold was chosen arbitrarily, though it was determined that the maps were relatively stable on the range of 3–7%. Optimally, one could determine the significance of the regions that contribute to mediation effects using a bootstrap procedure. However, combining the Shapley analysis and bootstrap is computationally quite expensive in practice.</p>
        <p id="P59">When considering the signs of the Shapley values, it is first worth noting that four different kinds of relationship are possible: (1) an increase in temperature leads to an increase in pain; (2) a decrease in temperature leads to a decrease in pain; (3) an increase in temperature leads to a decrease in pain; and (4) a decrease in temperature leads to an increase in pain. Here, type (1) is the standard, positive mediator case expected from nociceptive coding regions and type (2) represents a negative mediator, in which greater deactivation to stimulus mediates increased pain. Finally, types (3) and (4) are known as suppresor effects.</p>
        <p id="P60">Voxels shown in warm colors in <xref rid="F6" ref-type="fig">Figure 6 C</xref> correspond to those with positive values. As both <inline-formula><mml:math id="M192" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M193" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> are positive, these regions represent positive mediators. They include brain regions commonly associated with pain processing, such as the dorsal posterior and mid-insula, S2, and MCC. Brain regions with negative weights represent negative mediators and are shown in cool colors, and include prefrontal regions, medial occipital, V1/V2/V3 and left sensorimotor cortex/parietal cortex, left S1/M1, parts of cerebellum, and the right amygdala/hippocampal border. Negative mediators are those that show less activation (or deactivation) with increasing temperatures, and lower regional activation is related to higher pain ratings. These types of relationships can be expected in brain regions whose function is inhibited by nociceptive input or that are deactivated with increased pain-related processing but are not considered as suppressor effects.</p>
        <p id="P61">The test data also included trials with physically (e.g., knife on plate) and emotionally (e.g., screaming and crying) aversive sounds at three different pre-defined intensity levels. These trials were randomly inter-mixed with the heat pain trials. To test whether the results are specific for thermal pain, we applied the fitted model to these aversive non-painful stimuli. Application of the model fits on the sound data revealed no significant effects at the 0.05 significance level, see <xref rid="F6" ref-type="fig">Figure 6 B</xref>, indicating that the model does not mediate the relationship between sound intensity and intensity ratings. Thus, the results indicate a specificity to somatic pain compared to sound.</p>
        <p id="P62">To further validate the findings we performed a number of follow-up analyses. First, we performed leave-one-study out cross-validation. Here we alternated which of the eight studies were used as the validation dataset, while training on the remaining seven studies. Results can be seen in <xref rid="SD1" ref-type="supplementary-material">Figure S3</xref>. In total five of the eight pain datasets were significant when used as the test dataset. Interestingly, the three studies that were not significant (EXP, IE, and SCEBL) are the ones with the strongest psychological interventions, and the effect of pain depends strongly on these interventions. For EXP and IE, there are cues prior to pain stimulus that state whether high or low pain is coming. For SCEBL there is a cue that states how other subjects responded to the upcoming stimuli. Much of the pain response is likely linked to these cues, and therefore in each case it is not entirely surprising that the <inline-formula><mml:math id="M194" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>-pathway is non-significant. Second, we also ran multiple iterations of <inline-formula><mml:math id="M195" display="inline"><mml:mi>k</mml:mi></mml:math></inline-formula> -fold cross validation. Due to computational constraints we restricted the number of replications to 3 times. During the <inline-formula><mml:math id="M196" display="inline"><mml:mi>k</mml:mi></mml:math></inline-formula> -fold cross validation, the training dataset is split into 3 folds. <xref rid="SD1" ref-type="supplementary-material">Figure S4</xref> shows the estimated <inline-formula><mml:math id="M197" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M198" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M199" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> values obtained when applying the fitted machine learning model to the left-out fold for the pain trials. As seen in the figure, all coefficients were strongly significant.</p>
        <p id="P63">Next, we compared the results with those obtained using two competing approaches: the PDM approach and a mass univariate mediation effect parametric mapping approach. In <xref rid="SD1" ref-type="supplementary-material">Figure S5</xref> we show significant voxels obtained through both analyses. Both maps are thresholded at a false discovery rate (FDR) of <inline-formula><mml:math id="M200" display="inline"><mml:mrow><mml:mi>q</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>. The PDM approach linearly combines information across images into a smaller number of orthogonal components that are chosen based on the proportion of the indirect effect that they explain. Here we only use the first PDM which corresponds to the linear combination that maximizes the proportion of the indirect effect explained. Similar to the proposed approach, the PDM approach found mid insular-opercular areas, somatosensory S1, S2 and medial thalamus mediated the temperature-pain relationship; see <xref rid="SD1" ref-type="supplementary-material">Figure S5(a)</xref>. In contrast, mediation effect parametric mapping fits an independent mediation model on each individual voxel in the fMRI data. Thereafter, brain regions corresponding to the intersection of voxels with significant paths <inline-formula><mml:math id="M201" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M202" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M203" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> are interpreted as mediators. The mass univariate analysis found the cerebellum, posterior and midinsula, MCC, S2 and S1 were significant mediators; see <xref rid="SD1" ref-type="supplementary-material">Figure S5(b)</xref>. Comparing these results to the proposed approach found both similarities and differences. For example, both maps included somatosensory regions of MCC, mid insula, S2 and cerebellum. Additionally, negative mediators in prefrontal regions, medial occipital, S1 and right amygdala/hippocampal border region were not identified by the univariate mediation model.</p>
      </sec>
      <sec id="S24">
        <label>3.3.</label>
        <title>HCP data</title>
        <p id="P64"><xref rid="T1" ref-type="table">Algorithm 1</xref> was combined with a ridge regression connectome-based predictive model and fit to the training data, consisting of 558 subjects. Each subject’s data consisted of fluid intelligence, a 1-dimensional vectorized functional connectivity matrix, and a working memory accuracy score. To validate the results, they were applied to a test dataset consisting of 240 subjects. Validation was performed by applying the trained rCPM model to the elements of the functional connectivity matrices in the test data to obtain low-dimensional mediators. These were then placed into a standard three-variable path model together with the associated fluid intelligence and accuracy scores. A multi-level mediation analysis (Wager et al., 2009c) was performed on this data set, and the significance of <inline-formula><mml:math id="M204" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M205" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M206" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> was tested using a bootstrap procedure with 5000 iterations. Note that in practice, the mediation analysis could have been run in either direction (i.e., with working memory accuracy as the <inline-formula><mml:math id="M207" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> variable and fluid intelligence as the <inline-formula><mml:math id="M208" display="inline"><mml:mi>Y</mml:mi></mml:math></inline-formula> variable). Hence, there is no strong causal interpretation to be made here, but rather this is an example of mediation analysis can identify brain patterns jointly related to two variables that are part of the same system.</p>
        <p id="P65"><xref rid="F7" ref-type="fig">Figure 7</xref> shows the results of applying the fitted rCPM mediation model to a test data set from the HCP dataset. <xref rid="F7" ref-type="fig">Figure 7 A</xref> shows scatter plots illustrating the positive relationship between the low-dimensional mediator and fluid intelligence, accuracy and the mediator, and accuracy and fluid intelligence, respectively. <xref rid="F7" ref-type="fig">Figure 7 B</xref> shows that the effects are significant in the test dataset, indicating that the functional connectivity matrix mediates the relationship between fluid intelligence and working memory performance (accuracy) in a manner that generalizes across cohorts.</p>
        <p id="P66">Next, we determined the SHAP values in order to determine which connections are driving the mediation. <xref rid="F7" ref-type="fig">Figure 7 C</xref> shows the SHAP values in the test dataset averaged over subjects and components in each of seven pre-defined networks (<xref rid="R22" ref-type="bibr">Finn et al., 2015</xref>). Connections with positive weights are shown in warm colors. As both <inline-formula><mml:math id="M209" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M210" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula> are positive, these connections represent positive mediators. They include brain networks such as the Frontoparietal and Default Model Network, and connectivity between Frontoparietal and Medial Frontal Networks, Motor and Subcortical-Cerebellum Networks, and Motor and Visual Association Networks. Connections with negative weights rep- resent negative mediators and are shown in cool colors. They include the motor network, and connectivity between Frontoparietal and Subcortical-Cerebellum Networks, Frontoparietal and Default Mode Networks, and Default Mode and Subcortical-Cerebellum Networks. The negative weights indicate that these connections show lower values with increasing fluid intelligence, and that lower connectivity is related to higher working memory accuracy.</p>
      </sec>
    </sec>
    <sec id="S25">
      <label>4.</label>
      <title>Discussion</title>
      <p id="P67">In this work we introduce a novel analytic approach for identifying high dimensional mediators that links exposure variables, high-dimensional brain measures, and behavioral outcomes into a single unified model. Using the approach, the effects of the exposure on the outcome are decomposed into separable direct and indirect effects, repre- senting the influence of the variables <inline-formula><mml:math id="M211" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> on <inline-formula><mml:math id="M212" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula> unmediated and mediated by <inline-formula><mml:math id="M213" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula>, respectively. The indirect effect is determined by the product of the coefficients <inline-formula><mml:math id="M214" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M215" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, while the direct effect is determined by the coefficient <inline-formula><mml:math id="M216" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>; see <xref rid="F1" ref-type="fig">Fig. 1</xref> for more detail.</p>
      <p id="P68">Our approach is flexible, allowing for easy plug-and-play with different machine learning models depending on the type of data being analyzed. We demonstrate this flexibility in two applications, that necessitate using two different classes of machine learning models.</p>
      <p id="P69">In the pain application, we used the proposed approach together with a deep learning model to identify brain networks that mediate the relationship between stimulus intensity and pain reports. To interpret the results and determine which regions mediated the temperature-rating relationship we computed maps of Shaply values; see <xref rid="F6" ref-type="fig">Fig. 6</xref>. We arbitrarily chose the largest 5% Shapley values when presenting our findings, but found that the maps were relatively stable across a range from 3–7%. Optimally, one would determine the significance of the regions that contribute to mediation effects using a bootstrap procedure. However, combining Shapley analysis and the bootstrap is extremely computationally expensive in practice.</p>
      <p id="P70">Importantly, the derived mediators generalized to independent pain data, but not to aversive sound data, which indicates a degree of specificity of the model for pain. Several previous studies (<xref rid="R4" ref-type="bibr">Atlas et al., 2010</xref>; <xref rid="R5" ref-type="bibr">2014</xref>) have identified brain mediators of pain in a univariate manner by investigating each voxel separately. A shortcoming of this approach is that it can potentially miss brain regions whose contributions to pain perception are conditional on other regions. In addition, researchers have found that functional information in the brain is likely encoded in distributed patterns across neural ensembles and systems (<xref rid="R29" ref-type="bibr">Haxby et al., 2014</xref>; <xref rid="R57" ref-type="bibr">Pouget et al., 2000</xref>). This implies that brain information should ideally be treated in a multivariate fashion (<xref rid="R39" ref-type="bibr">Kriegeskorte, 2011</xref>; <xref rid="R82" ref-type="bibr">Woo et al., 2017</xref>), highlighting the importance of using multivariate brain mediators to characterize these patterns. Thus, we believe our approach provides a more comprehensive picture of pain processing in the human brain than studies that use univariate analyses, or focus solely on the stimulation-brain or brain-outcome relationships.</p>
      <p id="P71">It should be noted that the pain data was previously analyzed using the principal directions of mediation (PDM) approach (<xref rid="R25" ref-type="bibr">Geuter et al., 2020</xref>), which is an alternative method for performing high-dimensional mediation developed by our group. As both the machine learning-based approach and the PDM approach seek to estimate distributed, network-level patterns that formally mediate the relationship between stimulus intensity and pain, this allows for a convenient comparison between methods. The PDM approach linearly combines activity in different mediators into a smaller number of orthogonal components, with components ranked based upon the proportion of the indirect effect that each accounts for. In contrast, the proposed approach provides a non-linear combination of mediators as defined by the deep learning architecture. In our simulation studies, the proposed approach outperforms the PDM approach, which shows a consistent bias in its estimation of the path parameters. We hypothesize that the bias is due to the model specification used to generate the data, which assumes that a non-linear combination of mediators drive the indirect effect. We note these biases are not present when data is generated according to the PDM model (<xref rid="R16" ref-type="bibr">Chen et al., 2018</xref>). That said, we believe that the PDM approach still provides reasonably high power to detect signal even under a misspecified model. The results obtained using both methods are roughly equivalent, with both methods highlighting the same regions as mediators and providing results specific for pain vs. aversive sounds. This provides evidence that a linear combination of mediators may be driving the indirect effect in this dataset. Using the PDM results as a benchmark, we believe this provides evidence of the efficacy of our new machine-learning based approach. That said, the proposed approach has several benefits over the PDM approach. One is the aforementioned ability to study non-linear combinations of the original high-dimensional mediators. Another is its flexibility to be applied to a wide array of different data, for example, brain connectivity data.</p>
      <p id="P72">In this application we used a deep learning model to investigate its ability uncover brain regions that mediate the relationship between temperature and pain rating. In general, we believe that a simpler machine learning approach is preferable when the more complicated models do not show empirical evidence for improvement. Therefore, for completeness we repeated the analysis using both SVR and Ridge regression in place of the deep learning model. We found that the deep learning model outperformed both SVR and Ridge regression. Moreover, we did not obtain interpretable results when studying the model weights for either SVR and Ridge regression, even though both are linear models.</p>
      <p id="P73">In the application to HCP data, we used the proposed algorithm together with a connectome-based predictive model (<xref rid="R65" ref-type="bibr">Shen et al., 2017</xref>) to find elements of the resting-state connectivity matrix that mediate the relationship between fluid intelligence and working memory accuracy. The link between fluid intelligence and working memory capacity has long been established (<xref rid="R19" ref-type="bibr">Cole et al., 2012</xref>; <xref rid="R23" ref-type="bibr">Fukuda et al., 2010</xref>). In recent work, <xref rid="R6" ref-type="bibr">Avery et al. (2020)</xref> fit separate connectome-based predictive models to predict working memory performance and fluid intelligence, respectively, from whole-brain functional connectivity patterns observed in HCP participants. They found that overlap between the working memory and fluid intelligence networks were limited to connections between prefrontal, parietal, and motor regions. Additionally, <xref rid="R3" ref-type="bibr">Assem et al. (2020)</xref> have found that activity in “multiple demand ” networks (i.e. lateral and dorsomedial frontal areas, anterior insular areas, and areas along the intra-parietal sulcus regions) was robustly associated with more accurate and faster responses on a spatial working memory task and fluid intelligence. Our approach extends this approach by providing a unified model that links working memory accuracy, fluid intelligence, and functional connectivity. Using our approach, we found the strongest connections within Frontoparietal, Default Mode, and Motor networks, and between Frontoparietal, Default Mode, and Subcortical-Cerebellum networks. This evidence aligns well with findings from lesion studies that have also reported a selective relationship between fronto-parietal regions and working memory task as well as fluid cognitive abilities (<xref rid="R18" ref-type="bibr">Christodoulou et al., 2001</xref>; <xref rid="R62" ref-type="bibr">Roca et al., 2010</xref>). However, it is a further challenge to identify and interpret if these connections are statistically significant in mediating the relationship between fluid intelligence on working memory accuracy.</p>
      <p id="P74">Interpreting the indirect effect is an important part of mediation analysis. The proposed high-dimensional mediation approach can be placed into a potential outcome framework to access the conditions necessary for causal mediation analysis. In short, using potential outcomes notation, let <inline-formula><mml:math id="M217" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denote the value of the mediators if treatment <inline-formula><mml:math id="M218" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> is set to <inline-formula><mml:math id="M219" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula>. In our example, this represents the brain activation corresponding to a temperature set to a particular value.Similarly, let <inline-formula><mml:math id="M220" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denote the outcome if <inline-formula><mml:math id="M221" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula> is set to <inline-formula><mml:math id="M222" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M223" display="inline"><mml:mi mathvariant="bold-italic">M</mml:mi></mml:math></inline-formula> is set to <inline-formula><mml:math id="M224" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula>. This is the reported pain corresponding to both temperature and brain activation set to <inline-formula><mml:math id="M225" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M226" display="inline"><mml:mi>M</mml:mi></mml:math></inline-formula>, respectively. Using this notation, the natural unit indirect effect can be defined as <inline-formula><mml:math id="M227" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This corresponds to the change in pain rating that arises when brain activation is switched from <inline-formula><mml:math id="M228" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="M229" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The <inline-formula><mml:math id="M230" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>-effect represents the average in- direct effect, which is equivalent to the natural direct effect when there is no treatment-mediator interaction. In other words, when <inline-formula><mml:math id="M231" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M232" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are well defined and a series of assumptions hold, <inline-formula><mml:math id="M233" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> can be used to identify causal mediation effects. In practice, it is difficult to test whether these assumptions hold. Hence, we refrain from any causal interpretations of our results in this work. This material is discussed in the context of high-dimensional mediation in greater detail in earlier work by our group (<xref rid="R16" ref-type="bibr">Chén et al., 2018</xref>; <xref rid="R43" ref-type="bibr">Lindquist, 2012</xref>).</p>
      <p id="P75">Though our proposed framework is versatile and provides an option to test any number of machine learning models to find mediators using high dimensional data, it has its limitations. For example, the outcome of our framework depends on the performance of the underlying ma- chine learning model. This implies that one needs to build a model that is able to accurately represent the relationship between the high dimensional mediator and the outcome. A failure to yield an expected result might be linked to a poor model selection and one needs to be careful before drawing conclusions especially in clinical applications. It should be noted that problems associated with building a good machine learning model for predicting outcome is an overall challenge for the entire field that is not unique to the proposed method.</p>
      <p id="P76">In addition, there is reason to believe that there are situations where prior knowledge about the data or its acquisition plays an important role in the mediation analysis. For instance, prior knowledge about the brain function and structure couldbe a crucial factor in constraining mediation analysis. In our initial implementation, we have not considered such prior knowledge, but these factors can be incorporated into the machine learning model and thus utilized in our approach. We leave this for future research.</p>
      <p id="P77">In conclusion, we have developed a new approach for identifying high dimensional mediators. Our proposed method provides a potential way for overcoming challenges with finding mediators in high dimensional data. Our single unified deep learning method reduces the high dimensional mediator to a single latent intermediate mediation measure. Such a measure can be used to study how dimensional mediators mediate the relationship between various traits and be applied to a variety of clinical applications. We applied our method to two different types of data, thus illustrating the robustness of the method. The development of methods for dealing with high dimensional mediation is in its infancy and this is the first application of deep learning to the field.</p>
    </sec>
    <sec sec-type="supplementary-material" id="SM1">
      <title>Supplementary Material</title>
      <supplementary-material id="SD1" position="float" content-type="local-data">
        <label>1</label>
        <media xlink:href="NIHMS1872496-supplement-1.pdf" id="d64e3674" position="anchor"/>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack id="S26">
      <title>Acknowledgment</title>
      <p id="P78">Data were provided by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657), which was funded by the McDonnell Center for Systems Neuroscience at Washington University and the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research. This research was supported in part by NIH grants R01EB016061 and R01EB026549 from the National Institute of Biomedical Imaging and Bioengineering, R01MH076136 from National Institute of Mental Health, and Oracle Cloud credits and related resources provided by the Oracle for Research program. We are particularly thankful to Bryan Barker and Rajib Ghosh for providing support with the Oracle cluster.</p>
    </ack>
    <fn-group>
      <fn id="FN1">
        <p id="P81">Credit authorship contribution statement</p>
        <p id="P82">Tanmay Nath, Brian Caffo, Tor Wager and Martin Lindquist conceived the project idea. Tanmay Nath, Brian Caffo and Martin Lindquist led the simulation and building the model on real dataset. Brian Caffo and Martin Lindquist coordinated and supervised the overall research activities. Tanmay Nath, Brian Caffo, Tor Wager and Martin Lindquist contributed to the discussion of the results and wrote the paper.</p>
      </fn>
      <fn id="FN2">
        <p id="P83">Supplementary material</p>
        <p id="P84">Supplementary material associated with this article can be found, in the online version, at doi: <ext-link xlink:href="10.1016/j.neuroimage.2022.119843" ext-link-type="doi">10.1016/j.neuroimage.2022.119843</ext-link>.</p>
      </fn>
    </fn-group>
    <sec sec-type="data-availability" id="S27">
      <title>Data availability</title>
      <p id="P79">Data will be made available on request.</p>
    </sec>
    <sec sec-type="data-availability" id="S28">
      <title>Data and code availability statement</title>
      <p id="P80">We used data from two functional Magnetic Resonance Imaging (fMRI) studies. First, using data from a task-based fMRI study of thermal pain which we refer to as Pain data. Pain data consisted of 284 healthy participants from eight independent studies and can be accessed using these studies [22, 45–48]. Second, we used resting-state fMRI data from the Human Connectome Project (HCP) 900 release [34] which can be downloaded from the HCP page <ext-link xlink:href="https://www.humanconnectome.org/study/hcp-young-adult/document/900-subjects-data-release" ext-link-type="uri">https://www.humanconnectome.org/study/hcp-young-adult/document/900-subjects-data-release</ext-link>. The implementation of the algorithm is available at <ext-link xlink:href="https://github.com/meet10may/deep-mediation.git" ext-link-type="uri">https://github.com/meet10may/deep-mediation.git</ext-link>.</p>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="R1">
        <mixed-citation publication-type="confproc"><name><surname>Abadi</surname><given-names>M</given-names></name>, <name><surname>Barham</surname><given-names>P</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Davis</surname><given-names>A</given-names></name>, <name><surname>Dean</surname><given-names>J</given-names></name>, <name><surname>Devin</surname><given-names>M</given-names></name>, <name><surname>Ghemawat</surname><given-names>S</given-names></name>, <name><surname>Irving</surname><given-names>G</given-names></name>, <name><surname>Isard</surname><given-names>M</given-names></name>, <etal/>, <year>2016</year>. <source>TensorFlow: a system for large-scale machine learning</source>. In: <conf-name>12th { USENIX } Symposium on Operating Systems Design and Implementation ( { OSDI } 16)</conf-name>, pp. <fpage>265</fpage>–<lpage>283</lpage>.</mixed-citation>
      </ref>
      <ref id="R2">
        <mixed-citation publication-type="journal"><name><surname>Albert</surname><given-names>JM</given-names></name>, <year>2008</year>. <article-title>Mediation analysis via potential outcomes models</article-title>. <source>Stat. Med</source>
<volume>27</volume> (<issue>8</issue>), <fpage>1282</fpage>–<lpage>1304</lpage>.<pub-id pub-id-type="pmid">17691077</pub-id></mixed-citation>
      </ref>
      <ref id="R3">
        <mixed-citation publication-type="journal"><name><surname>Assem</surname><given-names>M</given-names></name>, <name><surname>Blank</surname><given-names>IA</given-names></name>, <name><surname>Mineroff</surname><given-names>Z</given-names></name>, <name><surname>Ademo ğlu</surname><given-names>A</given-names></name>, <name><surname>Fedorenko</surname><given-names>E</given-names></name>, <year>2020</year>. <article-title>Activity in the fronto-parietal multiple-demand network is robustly associated with individual differences in working memory and fluid intelligence</article-title>. <source>Cortex</source>
<volume>131</volume>, <fpage>1</fpage>–<lpage>16</lpage>.<pub-id pub-id-type="pmid">32777623</pub-id></mixed-citation>
      </ref>
      <ref id="R4">
        <mixed-citation publication-type="journal"><name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Bolger</surname><given-names>N</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2010</year>. <article-title>Brain mediators of predictive cue effects on perceived pain</article-title>. <source>J. Neurosci</source>
<volume>30</volume> (<issue>39</issue>), <fpage>12964</fpage>–<lpage>12977</lpage>.<pub-id pub-id-type="pmid">20881115</pub-id></mixed-citation>
      </ref>
      <ref id="R5">
        <mixed-citation publication-type="journal"><name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Bolger</surname><given-names>N</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2014</year>. <article-title>Brain mediators of the effects of noxious heat on pain</article-title>. <source>PAIN<sup>®</sup></source>
<volume>155</volume> (<issue>8</issue>), <fpage>1632</fpage>–<lpage>1648</lpage>.<pub-id pub-id-type="pmid">24845572</pub-id></mixed-citation>
      </ref>
      <ref id="R6">
        <mixed-citation publication-type="journal"><name><surname>Avery</surname><given-names>EW</given-names></name>, <name><surname>Yoo</surname><given-names>K</given-names></name>, <name><surname>Rosenberg</surname><given-names>MD</given-names></name>, <name><surname>Greene</surname><given-names>AS</given-names></name>, <name><surname>Gao</surname><given-names>S</given-names></name>, <name><surname>Na</surname><given-names>DL</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>, <name><surname>Constable</surname><given-names>TR</given-names></name>, <name><surname>Chun</surname><given-names>MM</given-names></name>, <year>2020</year>. <article-title>Distributed patterns of functional connectivity predict working memory performance in novel healthy and memory-impaired individuals</article-title>. <source>J. Cognit. Neurosci</source>
<volume>32</volume> (<issue>2</issue>), <fpage>241</fpage>–<lpage>255</lpage>.<pub-id pub-id-type="pmid">31659926</pub-id></mixed-citation>
      </ref>
      <ref id="R7">
        <mixed-citation publication-type="journal"><name><surname>Barch</surname><given-names>DM</given-names></name>, <name><surname>Burgess</surname><given-names>GC</given-names></name>, <name><surname>Harms</surname><given-names>MP</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <name><surname>Corbetta</surname><given-names>M</given-names></name>, <name><surname>Glasser</surname><given-names>MF</given-names></name>, <name><surname>Curtiss</surname><given-names>S</given-names></name>, <name><surname>Dixit</surname><given-names>S</given-names></name>, <name><surname>Feldt</surname><given-names>C</given-names></name>, <etal/>, <year>2013</year>. <article-title>Function in the human con- nectome: task-fMRI and individual differences in behavior</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>169</fpage>–<lpage>189</lpage>.<pub-id pub-id-type="pmid">23684877</pub-id></mixed-citation>
      </ref>
      <ref id="R8">
        <mixed-citation publication-type="journal"><name><surname>Baron</surname><given-names>RM</given-names></name>, <name><surname>Kenny</surname><given-names>DA</given-names></name>, <year>1986</year>. <article-title>The moderator–mediator variable distinction in social psychological research: conceptual, strategic, and statistical considerations</article-title>. <source>J. Pers. Soc. Psychol</source>
<volume>51</volume> (<issue>6</issue>), <fpage>1173</fpage>.<pub-id pub-id-type="pmid">3806354</pub-id></mixed-citation>
      </ref>
      <ref id="R9">
        <mixed-citation publication-type="journal"><name><surname>Bickel</surname><given-names>PJ</given-names></name>, <name><surname>Hammel</surname><given-names>EA</given-names></name>, <name><surname>O’Connell</surname><given-names>JW</given-names></name>, <year>1975</year>. <article-title>Sex bias in graduate admissions: data from Berkeley</article-title>. <source>Science</source>
<volume>187</volume> (<issue>4175</issue>), <fpage>398</fpage>–<lpage>404</lpage>.<pub-id pub-id-type="pmid">17835295</pub-id></mixed-citation>
      </ref>
      <ref id="R10">
        <mixed-citation publication-type="journal"><name><surname>Bilker</surname><given-names>WB</given-names></name>, <name><surname>Hansen</surname><given-names>JA</given-names></name>, <name><surname>Brensinger</surname><given-names>CM</given-names></name>, <name><surname>Richard</surname><given-names>J</given-names></name>, <name><surname>Gur</surname><given-names>RE</given-names></name>, <name><surname>Gur</surname><given-names>RC</given-names></name>, <year>2012</year>. <article-title>Development of abbreviated nine-item forms of the Raven’s standard progressive matrices test</article-title>. <source>Assessment</source>
<volume>19</volume> (<issue>3</issue>), <fpage>354</fpage>–<lpage>369</lpage>.<pub-id pub-id-type="pmid">22605785</pub-id></mixed-citation>
      </ref>
      <ref id="R11">
        <mixed-citation publication-type="journal"><name><surname>Blum</surname><given-names>MGB</given-names></name>, <name><surname>Valeri</surname><given-names>L</given-names></name>, <name><surname>François</surname><given-names>O</given-names></name>, <name><surname>Cadiou</surname><given-names>S</given-names></name>, <name><surname>Siroux</surname><given-names>V</given-names></name>, <name><surname>Lepeule</surname><given-names>J</given-names></name>, <name><surname>Slama</surname><given-names>R</given-names></name>, <year>2020</year>. <article-title>Challenges raised by mediation analysis in a high-dimension setting</article-title>. <source>Environ. Health Perspect</source>
<volume>128</volume> (<issue>5</issue>), 055001.</mixed-citation>
      </ref>
      <ref id="R12">
        <mixed-citation publication-type="journal"><name><surname>Bonthrone</surname><given-names>AF</given-names></name>, <name><surname>Dimitrova</surname><given-names>R</given-names></name>, <name><surname>Chew</surname><given-names>A</given-names></name>, <name><surname>Kelly</surname><given-names>CJ</given-names></name>, <name><surname>Cordero-Grande</surname><given-names>L</given-names></name>, <name><surname>Carney</surname><given-names>O</given-names></name>, <name><surname>Egloff</surname><given-names>A</given-names></name>, <name><surname>Hughes</surname><given-names>E</given-names></name>, <name><surname>Vecchiato</surname><given-names>K</given-names></name>, <name><surname>Simpson</surname><given-names>J</given-names></name>, <etal/>, <year>2021</year>. <article-title>Individualized brain development and cognitive outcome in infants with congenital heart disease</article-title>. <source>Brain Commun</source>. <volume>3</volume> (<issue>2</issue>), fcab046.</mixed-citation>
      </ref>
      <ref id="R13">
        <mixed-citation publication-type="book"><name><surname>Bradley</surname><given-names>MM</given-names></name>, <name><surname>Lang</surname><given-names>PJ</given-names></name>, <year>1999</year>. <source>International Affective Digitized Sounds (IADS): Stimuli, Instruction Manual and Affective Ratings. Tech. Rep. No. b-2</source>
<publisher-loc>Gainesville, FL</publisher-loc>: <publisher-name>The Center for Research in Psychophysiology, University of Florida</publisher-name>.</mixed-citation>
      </ref>
      <ref id="R14">
        <mixed-citation publication-type="journal"><name><surname>Brady</surname><given-names>RG</given-names></name>, <name><surname>Rogers</surname><given-names>CE</given-names></name>, <name><surname>Prochaska</surname><given-names>T</given-names></name>, <name><surname>Kaplan</surname><given-names>S</given-names></name>, <name><surname>Lean</surname><given-names>RE</given-names></name>, <name><surname>Smyser</surname><given-names>TA</given-names></name>, <name><surname>Shimony</surname><given-names>JS</given-names></name>, <name><surname>Slavich</surname><given-names>GM</given-names></name>, <name><surname>Warner</surname><given-names>BB</given-names></name>, <name><surname>Barch</surname><given-names>DM</given-names></name>, <etal/>, <year>2022</year>. <article-title>The effects of prenatal exposure to neighborhood crime on neonatal functional connectivity</article-title>. <source>Biol. Psychiatry</source></mixed-citation>
      </ref>
      <ref id="R15">
        <mixed-citation publication-type="journal"><name><surname>Caffo</surname><given-names>B</given-names></name>, <name><surname>Chen</surname><given-names>S</given-names></name>, <name><surname>Stewart</surname><given-names>W</given-names></name>, <name><surname>Bolla</surname><given-names>K</given-names></name>, <name><surname>Yousem</surname><given-names>D</given-names></name>, <name><surname>Davatzikos</surname><given-names>C</given-names></name>, <name><surname>Schwartz</surname><given-names>BS</given-names></name>, <year>2008</year>. <article-title>Are brain volumes based on magnetic resonance imaging mediators of the as- sociations of cumulative lead dose with cognitive function?</article-title>
<source>Am. J. Epidemiol</source>
<volume>167</volume> (<issue>4</issue>), <fpage>429</fpage>–<lpage>437</lpage>.<pub-id pub-id-type="pmid">18079133</pub-id></mixed-citation>
      </ref>
      <ref id="R16">
        <mixed-citation publication-type="journal"><name><surname>Chén</surname><given-names>OY</given-names></name>, <name><surname>Crainiceanu</surname><given-names>C</given-names></name>, <name><surname>Ogburn</surname><given-names>EL</given-names></name>, <name><surname>Caffo</surname><given-names>BS</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <year>2018</year>. <article-title>High-dimensional multivariate mediation with application to neuroimaging data</article-title>. <source>Bio- statistics</source>
<volume>19</volume> (<issue>2</issue>), <fpage>121</fpage>–<lpage>136</lpage>.</mixed-citation>
      </ref>
      <ref id="R17">
        <mixed-citation publication-type="journal"><name><surname>Chollet</surname><given-names>F</given-names></name>, <year>2015</year>. <source>Keras</source>. <comment><ext-link xlink:href="https://github.com/fchollet/keras" ext-link-type="uri">https://github.com/fchollet/keras</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R18">
        <mixed-citation publication-type="journal"><name><surname>Christodoulou</surname><given-names>C</given-names></name>, <name><surname>DeLuca</surname><given-names>J</given-names></name>, <name><surname>Ricker</surname><given-names>JH</given-names></name>, <name><surname>Madigan</surname><given-names>NK</given-names></name>, <name><surname>Bly</surname><given-names>BM</given-names></name>, <name><surname>Lange</surname><given-names>G</given-names></name>, <name><surname>Kalnin</surname><given-names>AJ</given-names></name>, <name><surname>Liu</surname><given-names>WC</given-names></name>, <name><surname>Steffener</surname><given-names>J</given-names></name>, <name><surname>Diamond</surname><given-names>BJ</given-names></name>, <etal/>, <year>2001</year>. <article-title>Functional magnetic resonance imaging of working memory impairment after traumatic brain injury</article-title>. <source>J. Neurol. Neurosurg. Psychiatry</source>
<volume>71</volume> (<issue>2</issue>), <fpage>161</fpage>–<lpage>168</lpage>.<pub-id pub-id-type="pmid">11459886</pub-id></mixed-citation>
      </ref>
      <ref id="R19">
        <mixed-citation publication-type="journal"><name><surname>Cole</surname><given-names>MW</given-names></name>, <name><surname>Yarkoni</surname><given-names>T</given-names></name>, <name><surname>Repov š</surname><given-names>G</given-names></name>, <name><surname>Anticevic</surname><given-names>A</given-names></name>, <name><surname>Braver</surname><given-names>TS</given-names></name>, <year>2012</year>. <article-title>Global connectivity of prefrontal cortex predicts cognitive control and intelligence</article-title>. <source>J. Neurosci</source>
<volume>32</volume> (<issue>26</issue>), <fpage>8988</fpage>–<lpage>8999</lpage>.<pub-id pub-id-type="pmid">22745498</pub-id></mixed-citation>
      </ref>
      <ref id="R20">
        <mixed-citation publication-type="journal"><name><surname>Dufford</surname><given-names>AJ</given-names></name>, <name><surname>Spann</surname><given-names>M</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>, <year>2021</year>. <article-title>How prenatal exposures shape the infant brain: Insights from infant neuroimaging studies</article-title>. <source>Neurosci. Biobehav. Rev</source>
<volume>131</volume>, <fpage>47</fpage>–<lpage>58</lpage>.<pub-id pub-id-type="pmid">34536461</pub-id></mixed-citation>
      </ref>
      <ref id="R21">
        <mixed-citation publication-type="journal"><name><surname>Farah</surname><given-names>MJ</given-names></name>, <year>2017</year>. <article-title>The neuroscience of socioeconomic status: correlates, causes, and consequences</article-title>. <source>Neuron</source>
<volume>96</volume> (<issue>1</issue>), <fpage>56</fpage>–<lpage>71</lpage>.<pub-id pub-id-type="pmid">28957676</pub-id></mixed-citation>
      </ref>
      <ref id="R22">
        <mixed-citation publication-type="journal"><name><surname>Finn</surname><given-names>ES</given-names></name>, <name><surname>Shen</surname><given-names>X</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>, <name><surname>Rosenberg</surname><given-names>MD</given-names></name>, <name><surname>Huang</surname><given-names>J</given-names></name>, <name><surname>Chun</surname><given-names>MM</given-names></name>, <name><surname>Pa- pademetris</surname><given-names>X</given-names></name>, <name><surname>Constable</surname><given-names>RT</given-names></name>, <year>2015</year>. <article-title>Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity</article-title>. <source>Nat. Neurosci</source>
<volume>18</volume> (<issue>11</issue>), <fpage>1664</fpage>–<lpage>1671</lpage>.<pub-id pub-id-type="pmid">26457551</pub-id></mixed-citation>
      </ref>
      <ref id="R23">
        <mixed-citation publication-type="journal"><name><surname>Fukuda</surname><given-names>K</given-names></name>, <name><surname>Vogel</surname><given-names>E</given-names></name>, <name><surname>Mayr</surname><given-names>U</given-names></name>, <name><surname>Awh</surname><given-names>E</given-names></name>, <year>2010</year>. <article-title>Quantity, not quality: the relationship between fluid intelligence and working memory capacity</article-title>. <source>Psychon. Bull. Rev</source>
<volume>17</volume> (<issue>5</issue>), <fpage>673</fpage>–<lpage>679</lpage>.<pub-id pub-id-type="pmid">21037165</pub-id></mixed-citation>
      </ref>
      <ref id="R24">
        <mixed-citation publication-type="journal"><name><surname>Gao</surname><given-names>S</given-names></name>, <name><surname>Greene</surname><given-names>AS</given-names></name>, <name><surname>Constable</surname><given-names>RT</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>, <year>2019</year>. <article-title>Combining multiple connectomes improves predictive modeling of phenotypic measures</article-title>. <source>Neuroimage</source>
<volume>201</volume>, 116038.</mixed-citation>
      </ref>
      <ref id="R25">
        <mixed-citation publication-type="journal"><name><surname>Geuter</surname><given-names>S</given-names></name>, <name><surname>Reynolds Losin</surname><given-names>EA</given-names></name>, <name><surname>Roy</surname><given-names>M</given-names></name>, <name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Schmidt</surname><given-names>L</given-names></name>, <name><surname>Krishnan</surname><given-names>A</given-names></name>, <name><surname>Koban</surname><given-names>L</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <year>2020</year>. <article-title>Multiple brain networks mediating stimulus–pain relationships in humans</article-title>. <source>Cereb. Cortex</source>
<volume>30</volume> (<issue>7</issue>), <fpage>4204</fpage>–<lpage>4219</lpage>.<pub-id pub-id-type="pmid">32219311</pub-id></mixed-citation>
      </ref>
      <ref id="R26">
        <mixed-citation publication-type="journal"><name><surname>Glasser</surname><given-names>MF</given-names></name>, <name><surname>Sotiropoulos</surname><given-names>SN</given-names></name>, <name><surname>Wilson</surname><given-names>JA</given-names></name>, <name><surname>Coalson</surname><given-names>TS</given-names></name>, <name><surname>Fischl</surname><given-names>B</given-names></name>, <name><surname>Andersson</surname><given-names>JL</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Jbabdi</surname><given-names>S</given-names></name>, <name><surname>Webster</surname><given-names>M</given-names></name>, <name><surname>Polimeni</surname><given-names>JR</given-names></name>, <etal/>, <year>2013</year>. <article-title>The minimal preprocessing pipelines for the human connectome project</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>105</fpage>–<lpage>124</lpage>.<pub-id pub-id-type="pmid">23668970</pub-id></mixed-citation>
      </ref>
      <ref id="R27">
        <mixed-citation publication-type="journal"><name><surname>Goldberger</surname><given-names>AS</given-names></name>, <year>1984</year>. <article-title>Reverse regression and salary discrimination</article-title>. <source>J. Hum. Resour</source>
<fpage>293</fpage>–<lpage>318</lpage>.</mixed-citation>
      </ref>
      <ref id="R28">
        <mixed-citation publication-type="journal"><name><surname>Griffanti</surname><given-names>L</given-names></name>, <name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <name><surname>Auerbach</surname><given-names>EJ</given-names></name>, <name><surname>Douaud</surname><given-names>G</given-names></name>, <name><surname>Sexton</surname><given-names>CE</given-names></name>, <name><surname>Zsoldos</surname><given-names>E</given-names></name>, <name><surname>Ebmeier</surname><given-names>KP</given-names></name>, <name><surname>Filippini</surname><given-names>N</given-names></name>, <name><surname>Mackay</surname><given-names>CE</given-names></name>, <etal/>, <year>2014</year>. <article-title>ICA-based artefact removal and accelerated fMRI acquisition for improved resting state network imaging</article-title>. <source>Neuroimage</source>
<volume>95</volume>, <fpage>232</fpage>–<lpage>247</lpage>.<pub-id pub-id-type="pmid">24657355</pub-id></mixed-citation>
      </ref>
      <ref id="R29">
        <mixed-citation publication-type="journal"><name><surname>Haxby</surname><given-names>JV</given-names></name>, <name><surname>Connolly</surname><given-names>AC</given-names></name>, <name><surname>Guntupalli</surname><given-names>JS</given-names></name>, <year>2014</year>. <article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title>. <source>Annu. Rev. Neurosci</source>
<volume>37</volume>, <fpage>435</fpage>–<lpage>456</lpage>.<pub-id pub-id-type="pmid">25002277</pub-id></mixed-citation>
      </ref>
      <ref id="R30">
        <mixed-citation publication-type="confproc"><name><surname>He</surname><given-names>K</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Ren</surname><given-names>S</given-names></name>, <name><surname>Sun</surname><given-names>J</given-names></name>, <year>2015</year>. <source>Delving deep into rectifiers: surpassing human-level performance on imagenet classification</source>. In: <conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name>, pp. <fpage>1026</fpage>–<lpage>1034</lpage>.</mixed-citation>
      </ref>
      <ref id="R31">
        <mixed-citation publication-type="confproc"><name><surname>He</surname><given-names>K</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Ren</surname><given-names>S</given-names></name>, <name><surname>Sun</surname><given-names>J</given-names></name>, <year>2016</year>. <source>Deep residual learning for image recognition</source>. In: <conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name>, pp. <fpage>770</fpage>–<lpage>778</lpage>.</mixed-citation>
      </ref>
      <ref id="R32">
        <mixed-citation publication-type="journal"><name><surname>Holland</surname><given-names>PW</given-names></name>, <year>1988</year>. <article-title>Causal inference, path analysis and recursive structural equations models</article-title>. <source>ETS Res. Rep. Ser</source>
<volume>1988</volume> (<issue>1</issue>), <fpage>i</fpage>–<lpage>50</lpage>.</mixed-citation>
      </ref>
      <ref id="R33">
        <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>Y-T</given-names></name>, <name><surname>Pan</surname><given-names>W-C</given-names></name>, <year>2016</year>. <article-title>Hypothesis test of mediation effect in causal mediation model with high-dimensional continuous mediators</article-title>. <source>Biometrics</source>
<volume>72</volume> (<issue>2</issue>), <fpage>402</fpage>–<lpage>413</lpage>.<pub-id pub-id-type="pmid">26414245</pub-id></mixed-citation>
      </ref>
      <ref id="R34">
        <mixed-citation publication-type="journal"><name><surname>Imai</surname><given-names>K</given-names></name>, <name><surname>Keele</surname><given-names>L</given-names></name>, <name><surname>Yamamoto</surname><given-names>T</given-names></name>, <year>2010</year>. <article-title>Identification, inference and sensitivity analysis for causal mediation effects</article-title>. <source>Stat. Sci</source>
<fpage>51</fpage>–<lpage>71</lpage>.</mixed-citation>
      </ref>
      <ref id="R35">
        <mixed-citation publication-type="journal"><name><surname>Imai</surname><given-names>K</given-names></name>, <name><surname>Yamamoto</surname><given-names>T</given-names></name>, <year>2013</year>. <article-title>Identification and sensitivity analysis for multiple causal mechanisms: revisiting evidence from framing experiments</article-title>. <source>Polit. Anal</source>
<fpage>141</fpage>–<lpage>171</lpage>.</mixed-citation>
      </ref>
      <ref id="R36">
        <mixed-citation publication-type="journal"><name><surname>Jónsson</surname><given-names>BA</given-names></name>, <name><surname>Bjornsdottir</surname><given-names>G</given-names></name>, <name><surname>Thorgeirsson</surname><given-names>TE</given-names></name>, <name><surname>Ellingsen</surname><given-names>LM</given-names></name>, <name><surname>Walters</surname><given-names>GB</given-names></name>, <name><surname>Gudbjartsson</surname><given-names>DF</given-names></name>, <name><surname>Stefansson</surname><given-names>H</given-names></name>, <name><surname>Stefansson</surname><given-names>K</given-names></name>, <name><surname>Ulfarsson</surname><given-names>MO</given-names></name>, <year>2019</year>. <article-title>Brain age prediction using deep learning uncovers associated sequence variants</article-title>. <source>Nat. Commun</source>
<volume>10</volume> (<issue>1</issue>), <fpage>1</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
      </ref>
      <ref id="R37">
        <mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>DP</given-names></name>, <name><surname>Ba</surname><given-names>J</given-names></name>, <year>2014</year>. <article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv preprint arXiv: 1412.6980</source>.</mixed-citation>
      </ref>
      <ref id="R38">
        <mixed-citation publication-type="journal"><name><surname>Koban</surname><given-names>L</given-names></name>, <name><surname>Jepma</surname><given-names>M</given-names></name>, <name><surname>López-Solà</surname><given-names>M</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2019</year>. <article-title>Different brain networks mediate the effects of social and conditioned expectations on pain</article-title>. <source>Nat. Commun</source>
<volume>10</volume> (<issue>1</issue>), <fpage>1</fpage>–<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41467-019-11934-y</pub-id>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
      </ref>
      <ref id="R39">
        <mixed-citation publication-type="journal"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <year>2011</year>. <article-title>Pattern-information analysis: from stimulus decoding to computational-model testing</article-title>. <source>Neuroimage</source>
<volume>56</volume> (<issue>2</issue>), <fpage>411</fpage>–<lpage>421</lpage>.<pub-id pub-id-type="pmid">21281719</pub-id></mixed-citation>
      </ref>
      <ref id="R40">
        <mixed-citation publication-type="journal"><name><surname>Krishnan</surname><given-names>A</given-names></name>, <name><surname>Woo</surname><given-names>C-W</given-names></name>, <name><surname>Chang</surname><given-names>LJ</given-names></name>, <name><surname>Ruzic</surname><given-names>L</given-names></name>, <name><surname>Gu</surname><given-names>X</given-names></name>, <name><surname>López-Solà</surname><given-names>M</given-names></name>, <name><surname>Jackson</surname><given-names>PL</given-names></name>, <name><surname>Pujol</surname><given-names>J</given-names></name>, <name><surname>Fan</surname><given-names>J</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2016</year>. <article-title>Somatic and vicarious pain are represented by dissociable multivariate brain patterns</article-title>. <source>Elife</source>
<volume>5</volume>, e15166. doi: <pub-id pub-id-type="doi">10.7554/eLife.15166.001</pub-id>.</mixed-citation>
      </ref>
      <ref id="R41">
        <mixed-citation publication-type="confproc"><name><surname>Krogh</surname><given-names>A</given-names></name>, <name><surname>Hertz</surname><given-names>JA</given-names></name>, <year>1992</year>. <source>A simple weight decay can improve generalization</source>. In: <conf-name>Ad- vances in Neural Information Processing Systems</conf-name>, pp. <fpage>950</fpage>–<lpage>957</lpage>.</mixed-citation>
      </ref>
      <ref id="R42">
        <mixed-citation publication-type="journal"><name><surname>LeCun</surname><given-names>Y</given-names></name>, <year>1998</year>. <source>The MNIST database of handwritten digits</source>. <comment><ext-link xlink:href="http://yann.lecun.com/exdb/mnist/" ext-link-type="uri">http://yann.lecun.com/exdb/mnist/</ext-link></comment>.</mixed-citation>
      </ref>
      <ref id="R43">
        <mixed-citation publication-type="journal"><name><surname>Lindquist</surname><given-names>MA</given-names></name>, <year>2012</year>. <article-title>Functional causal mediation analysis with an application to brain connectivity</article-title>. <source>J. Am. Stat. Assoc</source>
<volume>107</volume> (<issue>500</issue>), <fpage>1297</fpage>–<lpage>1309</lpage>.<pub-id pub-id-type="pmid">25076802</pub-id></mixed-citation>
      </ref>
      <ref id="R44">
        <mixed-citation publication-type="journal"><name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Krishnan</surname><given-names>A</given-names></name>, <name><surname>López-Solà</surname><given-names>M</given-names></name>, <name><surname>Jepma</surname><given-names>M</given-names></name>, <name><surname>Woo</surname><given-names>C-W</given-names></name>, <name><surname>Koban</surname><given-names>L</given-names></name>, <name><surname>Roy</surname><given-names>M</given-names></name>, <name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Schmidt</surname><given-names>L</given-names></name>, <name><surname>Chang</surname><given-names>LJ</given-names></name>, <etal/>, <year>2017</year>. <article-title>Group-regularized individual prediction: theory and application to pain</article-title>. <source>Neuroimage</source>
<volume>145</volume>, <fpage>274</fpage>–<lpage>287</lpage>.<pub-id pub-id-type="pmid">26592808</pub-id></mixed-citation>
      </ref>
      <ref id="R45">
        <mixed-citation publication-type="journal"><name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Loh</surname><given-names>JM</given-names></name>, <name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2009</year>. <article-title>Modeling the hemodynamic response function in fMRI: efficiency, bias and mis-modeling</article-title>. <source>Neuroimage</source>
<volume>45</volume> (<issue>1</issue>), <fpage>S187</fpage>–<lpage>S198</lpage>.<pub-id pub-id-type="pmid">19084070</pub-id></mixed-citation>
      </ref>
      <ref id="R46">
        <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>T</given-names></name>, <name><surname>Wu</surname><given-names>J</given-names></name>, <name><surname>Zhao</surname><given-names>Z</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <name><surname>Lv</surname><given-names>Y</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <name><surname>Gao</surname><given-names>F</given-names></name>, <name><surname>You</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Ji</surname><given-names>C</given-names></name>, <etal/>, <year>2022</year>. <article-title>Developmental pattern of association fibers and their interaction with associated cortical microstructures in 0–5-month-old infants</article-title>. <source>NeuroImage</source> 119525.</mixed-citation>
      </ref>
      <ref id="R47">
        <mixed-citation publication-type="journal"><name><surname>Livshits</surname><given-names>G</given-names></name>, <name><surname>Malkin</surname><given-names>I</given-names></name>, <name><surname>Bowyer</surname><given-names>RCE</given-names></name>, <name><surname>Verdi</surname><given-names>S</given-names></name>, <name><surname>Bell</surname><given-names>JT</given-names></name>, <name><surname>Menni</surname><given-names>C</given-names></name>, <name><surname>Williams</surname><given-names>FMK</given-names></name>, <name><surname>Steves</surname><given-names>CJ</given-names></name>, <year>2018</year>. <article-title>Multi-OMICS analyses of frailty and chronic widespread musculoskeletal pain suggest involvement of shared neurological pathways</article-title>. <source>Pain</source>
<volume>159</volume> (<issue>12</issue>), <fpage>2565</fpage>.<pub-id pub-id-type="pmid">30086113</pub-id></mixed-citation>
      </ref>
      <ref id="R48">
        <mixed-citation publication-type="journal"><name><surname>Logan</surname><given-names>JW</given-names></name>, <name><surname>Tan</surname><given-names>J</given-names></name>, <name><surname>Skalak</surname><given-names>M</given-names></name>, <name><surname>Fathi</surname><given-names>O</given-names></name>, <name><surname>He</surname><given-names>L</given-names></name>, <name><surname>Kline</surname><given-names>J</given-names></name>, <name><surname>Klebanoff</surname><given-names>M</given-names></name>, <name><surname>Parikh</surname><given-names>NA</given-names></name>, <year>2021</year>. <article-title>Adverse effects of perinatal illness severity on neurodevelopment are partially mediated by early brain abnormalities in infants born very preterm</article-title>. <source>J. Perinatol</source>
<volume>41</volume> (<issue>3</issue>), <fpage>519</fpage>–<lpage>527</lpage>.<pub-id pub-id-type="pmid">33028936</pub-id></mixed-citation>
      </ref>
      <ref id="R49">
        <mixed-citation publication-type="journal"><name><surname>Lundberg</surname><given-names>S</given-names></name>, <name><surname>Lee</surname><given-names>S-I</given-names></name>, <year>2017</year>. <article-title>A unified approach to interpreting model predictions</article-title>. <source>arXiv preprint arXiv: 1705.07874</source>.</mixed-citation>
      </ref>
      <ref id="R50">
        <mixed-citation publication-type="book"><name><surname>MacKinnon</surname><given-names>DP</given-names></name>, <name><surname>Cheong</surname><given-names>J</given-names></name>, <name><surname>Pirlott</surname><given-names>AG</given-names></name>, <year>2012</year>. <source>Statistical Mediation Analysis</source>. <publisher-name>American Psychological Association</publisher-name>.</mixed-citation>
      </ref>
      <ref id="R51">
        <mixed-citation publication-type="confproc"><name><surname>Morgan</surname><given-names>N</given-names></name>, <name><surname>Bourlard</surname><given-names>H</given-names></name>, <year>1990</year>. <source>Generalization and parameter estimation in feedforward nets: some experiments</source>. In: <conf-name>Advances in Neural Information Processing Systems</conf-name>, pp. <fpage>630</fpage>–<lpage>637</lpage>.</mixed-citation>
      </ref>
      <ref id="R52">
        <mixed-citation publication-type="journal"><name><surname>Mumford</surname><given-names>JA</given-names></name>, <name><surname>Turner</surname><given-names>BO</given-names></name>, <name><surname>Ashby</surname><given-names>FG</given-names></name>, <name><surname>Poldrack</surname><given-names>RA</given-names></name>, <year>2012</year>. <article-title>Deconvolving BOLD ac- tivation in event-related designs for multivoxel pattern classification analyses</article-title>. <source>Neuroimage</source>
<volume>59</volume> (<issue>3</issue>), <fpage>2636</fpage>–<lpage>2643</lpage>.<pub-id pub-id-type="pmid">21924359</pub-id></mixed-citation>
      </ref>
      <ref id="R53">
        <mixed-citation publication-type="confproc"><name><surname>Nair</surname><given-names>V</given-names></name>, <name><surname>Hinton</surname><given-names>GE</given-names></name>, <year>2010</year>. <source>Rectified linear units improve restricted Boltzmann machines</source>. In: <conf-name>Icml</conf-name>.</mixed-citation>
      </ref>
      <ref id="R54">
        <mixed-citation publication-type="journal"><name><surname>Parisien</surname><given-names>M</given-names></name>, <name><surname>Khoury</surname><given-names>S</given-names></name>, <name><surname>Chabot-Doré</surname><given-names>A-J</given-names></name>, <name><surname>Sotocinal</surname><given-names>SG</given-names></name>, <name><surname>Slade</surname><given-names>GD</given-names></name>, <name><surname>Smith</surname><given-names>SB</given-names></name>, <name><surname>Fillingim</surname><given-names>RB</given-names></name>, <name><surname>Ohrbach</surname><given-names>R</given-names></name>, <name><surname>Greenspan</surname><given-names>JD</given-names></name>, <name><surname>Maixner</surname><given-names>W</given-names></name>, <etal/>, <year>2017</year>. <article-title>Effect of human genetic variability on gene expression in dorsal root ganglia and association with pain phenotypes</article-title>. <source>Cell Rep</source>. <volume>19</volume> (<issue>9</issue>), <fpage>1940</fpage>–<lpage>1952</lpage>.<pub-id pub-id-type="pmid">28564610</pub-id></mixed-citation>
      </ref>
      <ref id="R55">
        <mixed-citation publication-type="journal"><name><surname>Pearl</surname><given-names>J</given-names></name>, <year>2013</year>. <article-title>Direct and indirect effects</article-title>. <source>arXiv preprint arXiv: 1301.2300</source>.</mixed-citation>
      </ref>
      <ref id="R56">
        <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <name><surname>Blondel</surname><given-names>M</given-names></name>, <name><surname>Prettenhofer</surname><given-names>P</given-names></name>, <name><surname>Weiss</surname><given-names>R</given-names></name>, <name><surname>Dubourg</surname><given-names>V</given-names></name>, <name><surname>Vanderplas</surname><given-names>J</given-names></name>, <name><surname>Passos</surname><given-names>A</given-names></name>, <name><surname>Cournapeau</surname><given-names>D</given-names></name>, <name><surname>Brucher</surname><given-names>M</given-names></name>, <name><surname>Perrot</surname><given-names>M</given-names></name>, <name><surname>Duchesnay</surname><given-names>E</given-names></name>, <year>2011</year>. <article-title>Scikit-learn: machine learning</article-title> in <source>Python. J. Mach. Learn. Res</source>
<volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
      </ref>
      <ref id="R57">
        <mixed-citation publication-type="journal"><name><surname>Pouget</surname><given-names>A</given-names></name>, <name><surname>Dayan</surname><given-names>P</given-names></name>, <name><surname>Zemel</surname><given-names>R</given-names></name>, <year>2000</year>. <article-title>Information processing with population codes</article-title>. <source>Nat. Rev. Neurosci</source>
<volume>1</volume> (<issue>2</issue>), <fpage>125</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">11252775</pub-id></mixed-citation>
      </ref>
      <ref id="R58">
        <mixed-citation publication-type="journal"><name><surname>Preacher</surname><given-names>KJ</given-names></name>, <name><surname>Hayes</surname><given-names>AF</given-names></name>, <year>2008</year>. <article-title>Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models</article-title>. <source>Behav. Res. Methods</source>
<volume>40</volume> (<issue>3</issue>), <fpage>879</fpage>–<lpage>891</lpage>.<pub-id pub-id-type="pmid">18697684</pub-id></mixed-citation>
      </ref>
      <ref id="R59">
        <mixed-citation publication-type="journal"><name><surname>Richiardi</surname><given-names>L</given-names></name>, <name><surname>Bellocco</surname><given-names>R</given-names></name>, <name><surname>Zugna</surname><given-names>D</given-names></name>, <year>2013</year>. <article-title>Mediation analysis in epidemiology: methods, interpretation and bias</article-title>. <source>Int. J. Epidemiol</source>
<volume>42</volume> (<issue>5</issue>), <fpage>1511</fpage>–<lpage>1519</lpage>.<pub-id pub-id-type="pmid">24019424</pub-id></mixed-citation>
      </ref>
      <ref id="R60">
        <mixed-citation publication-type="journal"><name><surname>Rissman</surname><given-names>J</given-names></name>, <name><surname>Greely</surname><given-names>HT</given-names></name>, <name><surname>Wagner</surname><given-names>AD</given-names></name>, <year>2010</year>. <article-title>Detecting individual memories through the neural decoding of memory states and past experience</article-title>. <source>Proc. Natl. Acad. Sci</source>
<volume>107</volume> (<issue>21</issue>), <fpage>9849</fpage>–<lpage>9854</lpage>.<pub-id pub-id-type="pmid">20457911</pub-id></mixed-citation>
      </ref>
      <ref id="R61">
        <mixed-citation publication-type="journal"><name><surname>Robins</surname><given-names>JM</given-names></name>, <name><surname>Greenland</surname><given-names>S</given-names></name>, <year>1992</year>. <article-title>Identifiability and exchangeability for direct and indirect effects</article-title>. <source>Epidemiology</source>
<fpage>143</fpage>–<lpage>155</lpage>.<pub-id pub-id-type="pmid">1576220</pub-id></mixed-citation>
      </ref>
      <ref id="R62">
        <mixed-citation publication-type="journal"><name><surname>Roca</surname><given-names>M</given-names></name>, <name><surname>Parr</surname><given-names>A</given-names></name>, <name><surname>Thompson</surname><given-names>R</given-names></name>, <name><surname>Woolgar</surname><given-names>A</given-names></name>, <name><surname>Torralva</surname><given-names>T</given-names></name>, <name><surname>Antoun</surname><given-names>N</given-names></name>, <name><surname>Manes</surname><given-names>F</given-names></name>, <name><surname>Dun- can</surname><given-names>J</given-names></name>, <year>2010</year>. <article-title>Executive function and fluid intelligence after frontal lobe lesions</article-title>. <source>Brain</source>
<volume>133</volume> (<issue>1</issue>), <fpage>234</fpage>–<lpage>247</lpage>.<pub-id pub-id-type="pmid">19903732</pub-id></mixed-citation>
      </ref>
      <ref id="R63">
        <mixed-citation publication-type="journal"><name><surname>Rodríguez-Pérez</surname><given-names>R</given-names></name>, <name><surname>Bajorath</surname><given-names>J</given-names></name>, <year>2020</year>. <article-title>Interpretation of machine learning models using Shapley values: application to compound potency and multi-target activity predictions</article-title>. <source>J. Comput-Aided Mol. Des</source>
<volume>34</volume> (<issue>10</issue>), <fpage>1013</fpage>–<lpage>1026</lpage>.<pub-id pub-id-type="pmid">32361862</pub-id></mixed-citation>
      </ref>
      <ref id="R64">
        <mixed-citation publication-type="journal"><name><surname>Roy</surname><given-names>M</given-names></name>, <name><surname>Shohamy</surname><given-names>D</given-names></name>, <name><surname>Daw</surname><given-names>N</given-names></name>, <name><surname>Jepma</surname><given-names>M</given-names></name>, <name><surname>Wimmer</surname><given-names>GE</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2014</year>. <article-title>Representation of aversive prediction errors in the human periaqueductal gray</article-title>. <source>Nat. Neurosci</source>
<volume>17</volume> (<issue>11</issue>), <fpage>1607</fpage>–<lpage>1612</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nn.3832</pub-id>.<pub-id pub-id-type="pmid">25282614</pub-id></mixed-citation>
      </ref>
      <ref id="R65">
        <mixed-citation publication-type="journal"><name><surname>Shen</surname><given-names>X</given-names></name>, <name><surname>Finn</surname><given-names>ES</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>, <name><surname>Rosenberg</surname><given-names>MD</given-names></name>, <name><surname>Chun</surname><given-names>MM</given-names></name>, <name><surname>Papademetris</surname><given-names>X</given-names></name>, <name><surname>Con- stable</surname><given-names>RT</given-names></name>, <year>2017</year>. <article-title>Using connectome-based predictive modeling to predict individual behavior from brain connectivity</article-title>. <source>Nat. Protocols</source>
<volume>12</volume> (<issue>3</issue>), <fpage>506</fpage>–<lpage>518</lpage>.<pub-id pub-id-type="pmid">28182017</pub-id></mixed-citation>
      </ref>
      <ref id="R66">
        <mixed-citation publication-type="journal"><name><surname>Shen</surname><given-names>X</given-names></name>, <name><surname>Tokoglu</surname><given-names>F</given-names></name>, <name><surname>Papademetris</surname><given-names>X</given-names></name>, <name><surname>Constable</surname><given-names>RT</given-names></name>, <year>2013</year>. <article-title>Groupwise whole-brain parcellation from resting-state fMRI data for network node identification</article-title>. <source>Neuroimage</source>
<volume>82</volume>, <fpage>403</fpage>–<lpage>415</lpage>.<pub-id pub-id-type="pmid">23747961</pub-id></mixed-citation>
      </ref>
      <ref id="R67">
        <mixed-citation publication-type="confproc"><name><surname>Singh</surname><given-names>A</given-names></name>, <name><surname>Mohammed</surname><given-names>AR</given-names></name>, <name><surname>Zelek</surname><given-names>J</given-names></name>, <name><surname>Lakshminarayanan</surname><given-names>V</given-names></name>, <year>2020</year>. <source>Interpretation of deep learning using attributions: application to ophthalmic diagnosis</source>. In: <conf-name>Applications of Machine Learning 2020</conf-name>, Vol. 11511. <publisher-name>International Society for Optics and Photonics</publisher-name>, p. 115110A.</mixed-citation>
      </ref>
      <ref id="R68">
        <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <name><surname>Andersson</surname><given-names>J</given-names></name>, <name><surname>Auerbach</surname><given-names>EJ</given-names></name>, <name><surname>Bijsterbosch</surname><given-names>J</given-names></name>, <name><surname>Douaud</surname><given-names>G</given-names></name>, <name><surname>Duff</surname><given-names>E</given-names></name>, <name><surname>Feinberg</surname><given-names>DA</given-names></name>, <name><surname>Griffanti</surname><given-names>L</given-names></name>, <name><surname>Harms</surname><given-names>MP</given-names></name>, <etal/>, <year>2013</year>. <article-title>Resting-state fMRI in the human connectome project</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>144</fpage>–<lpage>168</lpage>.<pub-id pub-id-type="pmid">23702415</pub-id></mixed-citation>
      </ref>
      <ref id="R69">
        <mixed-citation publication-type="journal"><name><surname>Tu</surname><given-names>Y</given-names></name>, <name><surname>Tan</surname><given-names>A</given-names></name>, <name><surname>Bai</surname><given-names>Y</given-names></name>, <name><surname>Hung</surname><given-names>YS</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <year>2016</year>. <article-title>Decoding subjective intensity of nociceptive pain from pre-stimulus and post-stimulus brain activities</article-title>. <source>Front. Comput. Neurosci</source>
<volume>10</volume>, <fpage>32</fpage>.<pub-id pub-id-type="pmid">27148029</pub-id></mixed-citation>
      </ref>
      <ref id="R70">
        <mixed-citation publication-type="journal"><name><surname>Van Essen</surname><given-names>DC</given-names></name>, <name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Barch</surname><given-names>DM</given-names></name>, <name><surname>Behrens</surname><given-names>TEJ</given-names></name>, <name><surname>Yacoub</surname><given-names>E</given-names></name>, <name><surname>Ugurbil</surname><given-names>K</given-names></name>, <name><surname>Consortium</surname><given-names>W-MH</given-names></name>, <etal/>, <year>2013</year>. <article-title>The WU-minn human connectome project: an overview</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>62</fpage>–<lpage>79</lpage>.<pub-id pub-id-type="pmid">23684880</pub-id></mixed-citation>
      </ref>
      <ref id="R71">
        <mixed-citation publication-type="journal"><name><surname>VanderWeele</surname><given-names>T</given-names></name>, <name><surname>Vansteelandt</surname><given-names>S</given-names></name>, <year>2014</year>. <article-title>Mediation analysis with multiple mediators</article-title>. <source>Epidemiol. Methods</source>
<volume>2</volume> (<issue>1</issue>), <fpage>95</fpage>–<lpage>115</lpage>.<pub-id pub-id-type="pmid">25580377</pub-id></mixed-citation>
      </ref>
      <ref id="R72">
        <mixed-citation publication-type="journal"><name><surname>VanderWeele</surname><given-names>TJ</given-names></name>, <year>2009</year>. <article-title>Marginal structural models for the estimation of direct and indirect effects</article-title>. <source>Epidemiology</source>
<fpage>18</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">19234398</pub-id></mixed-citation>
      </ref>
      <ref id="R73">
        <mixed-citation publication-type="journal"><name><surname>van der Velden</surname><given-names>BHM</given-names></name>, <name><surname>Janse</surname><given-names>MHA</given-names></name>, <name><surname>Ragusi</surname><given-names>MAA</given-names></name>, <name><surname>Loo</surname><given-names>CE</given-names></name>, <name><surname>Gilhuijs</surname><given-names>KGA</given-names></name>, <year>2020</year>. <article-title>Volumetric breast density estimation on MRI using explainable deep learning regression</article-title>. <source>Sci. Rep</source>
<volume>10</volume> (<issue>1</issue>), <fpage>1</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">31913322</pub-id></mixed-citation>
      </ref>
      <ref id="R74">
        <mixed-citation publication-type="journal"><name><surname>Vuorre</surname><given-names>M</given-names></name>, <name><surname>Bolger</surname><given-names>N</given-names></name>, <year>2018</year>. <article-title>Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience</article-title>. <source>Behav. Res. Methods</source>
<volume>50</volume> (<issue>5</issue>), <fpage>2125</fpage>–<lpage>2143</lpage>.<pub-id pub-id-type="pmid">29247385</pub-id></mixed-citation>
      </ref>
      <ref id="R75">
        <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>van Ast</surname><given-names>VA</given-names></name>, <name><surname>Hughes</surname><given-names>BL</given-names></name>, <name><surname>Davidson</surname><given-names>ML</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Ochsner</surname><given-names>KN</given-names></name>, <year>2009</year>. <article-title>Brain mediators of cardiovascular responses to social threat, Part II: Pre- frontal-subcortical pathways and relationship with anxiety</article-title>. <source>Neuroimage</source>
<volume>47</volume> (<issue>3</issue>), <fpage>836</fpage>–<lpage>851</lpage>.<pub-id pub-id-type="pmid">19465135</pub-id></mixed-citation>
      </ref>
      <ref id="R76">
        <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Roy</surname><given-names>M</given-names></name>, <name><surname>Woo</surname><given-names>C-W</given-names></name>, <name><surname>Kross</surname><given-names>E</given-names></name>, <year>2013</year>. <article-title>An fMRI-based neurologic signature of physical pain</article-title>. <source>New Engl. J. Med</source>
<volume>368</volume> (<issue>15</issue>), <fpage>1388</fpage>–<lpage>1397</lpage>. doi: <pub-id pub-id-type="doi">10.1056/NEJMoa1204471</pub-id>.<pub-id pub-id-type="pmid">23574118</pub-id></mixed-citation>
      </ref>
      <ref id="R77">
        <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Davidson</surname><given-names>ML</given-names></name>, <name><surname>Hughes</surname><given-names>BL</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Ochsner</surname><given-names>KN</given-names></name>, <year>2008</year>. <article-title>Prefrontal-subcortical pathways mediating successful emotion regulation</article-title>. <source>Neuron</source>
<volume>59</volume> (<issue>6</issue>), <fpage>1037</fpage>–<lpage>1050</lpage>.<pub-id pub-id-type="pmid">18817740</pub-id></mixed-citation>
      </ref>
      <ref id="R78">
        <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Nichols</surname><given-names>TE</given-names></name>, <year>2003</year>. <article-title>Optimization of experimental design in fMRI: a general framework using a genetic algorithm</article-title>. <source>Neuroimage</source>
<volume>18</volume> (<issue>2</issue>), <fpage>293</fpage>–<lpage>309</lpage>.<pub-id pub-id-type="pmid">12595184</pub-id></mixed-citation>
      </ref>
      <ref id="R79">
        <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Waugh</surname><given-names>CE</given-names></name>, <name><surname>Lindquist</surname><given-names>M</given-names></name>, <name><surname>Noll</surname><given-names>DC</given-names></name>, <name><surname>Fredrickson</surname><given-names>BL</given-names></name>, <name><surname>Taylor</surname><given-names>SF</given-names></name>, <year>2009</year>. <article-title>Brain mediators of cardiovascular responses to social threat: Part I: reciprocal dorsal and ventral sub-regions of the medial prefrontal cortex and heart-rate reactivity</article-title>. <source>Neuroimage</source>
<volume>47</volume> (<issue>3</issue>), <fpage>821</fpage>–<lpage>835</lpage>.<pub-id pub-id-type="pmid">19465137</pub-id></mixed-citation>
      </ref>
      <ref id="R80">
        <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Waugh</surname><given-names>CE</given-names></name>, <name><surname>Lindquist</surname><given-names>M</given-names></name>, <name><surname>Noll</surname><given-names>DC</given-names></name>, <name><surname>Fredrickson</surname><given-names>BL</given-names></name>, <name><surname>Taylor</surname><given-names>SF</given-names></name>, <year>2009</year>. <article-title>Brain mediators of cardiovascular responses to social threat: Part I: reciprocal dorsal and ventral sub-regions of the medial prefrontal cortex and heart-rate reactivity</article-title>. <source>Neuroimage</source>
<volume>47</volume> (<issue>3</issue>), <fpage>821</fpage>–<lpage>835</lpage>.<pub-id pub-id-type="pmid">19465137</pub-id></mixed-citation>
      </ref>
      <ref id="R81">
        <mixed-citation publication-type="journal"><name><surname>Woo</surname><given-names>C-W</given-names></name>, <name><surname>Roy</surname><given-names>M</given-names></name>, <name><surname>Buhle</surname><given-names>JT</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2015</year>. <article-title>Distinct brain systems mediate the effects of nociceptive input and self-regulation on pain</article-title>. <source>PLoS Biol</source>. <volume>13</volume> (<issue>1</issue>), e1002036. doi: <pub-id pub-id-type="doi">10.1371/journal.pbio.1002036</pub-id>.</mixed-citation>
      </ref>
      <ref id="R82">
        <mixed-citation publication-type="journal"><name><surname>Woo</surname><given-names>C-W</given-names></name>, <name><surname>Schmidt</surname><given-names>L</given-names></name>, <name><surname>Krishnan</surname><given-names>A</given-names></name>, <name><surname>Jepma</surname><given-names>M</given-names></name>, <name><surname>Roy</surname><given-names>M</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Atlas</surname><given-names>LY</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <year>2017</year>. <article-title>Quantifying cerebral contributions to pain beyond nociception</article-title>. <source>Nat. Commun</source>
<volume>8</volume> (<issue>1</issue>), <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">28232747</pub-id></mixed-citation>
      </ref>
      <ref id="R83">
        <mixed-citation publication-type="journal"><name><surname>Woodworth</surname><given-names>RS</given-names></name>, <year>1928</year>. <source>Dynamic psychology</source>. In: <name><surname>Murchison</surname><given-names>C</given-names></name> (Ed.), Psychologies of 1925.</mixed-citation>
      </ref>
      <ref id="R84">
        <mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>Y</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Caffo</surname><given-names>BS</given-names></name>, <year>2020</year>. <article-title>Sparse principal component based high-dimensional mediation analysis</article-title>. <source>Comput. Stat. Data Anal</source>
<volume>142</volume>, 106835.</mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig position="float" id="F1">
      <label>Fig. 1.</label>
      <caption>
        <p id="P85">(A) An overview of the standard three-variable mediation model. The variables <inline-formula><mml:math id="M234" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M235" display="inline"><mml:mi>m</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M236" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula> are all scalars along with the associated path coefficients, <inline-formula><mml:math id="M237" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M238" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M239" display="inline"><mml:mi>γ</mml:mi></mml:math></inline-formula>. (B) Schematic representation of the proposed mediation analysis framework using deep learning. Here a deep learning model links the high-dimensional mediators (brain activation maps) to a standard path analysis model used to access mediation. The output of the deep learning model is a latent intermediate mediating variable between in the input stimulus intensity(<inline-formula><mml:math id="M240" display="inline"><mml:mi>x</mml:mi></mml:math></inline-formula>) and the reported pain (<inline-formula><mml:math id="M241" display="inline"><mml:mi>y</mml:mi></mml:math></inline-formula>). The goal is to evaluate whether there is a significant indirect effect <inline-formula><mml:math id="M242" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0001" position="float"/>
    </fig>
    <fig position="float" id="F2">
      <label>Fig. 2.</label>
      <caption>
        <p id="P86">(A) Overview of Pain data. Studies 1 – 7, which comprise of 209 subjects and 13,372 trials, are used to train the deep learning model. The model is tested independently on Study 8 which consists of 75 subjects and 2,296 trials. Additionally, Study 8 not only includes the type of thermal pain stimuli used to train the model, but also aversive sounds. We tested our model and hypothesized that the estimated brain mediators of pain should generalize to the new pain dataset, but not to the sound dataset. (B) Overview of the HCP dataset. We used rs-fMRI data with <inline-formula><mml:math id="M243" display="inline"><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> polarity <inline-formula><mml:math id="M244" display="inline"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mi>I</mml:mi><mml:mo>_</mml:mo><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:msub><mml:mn>1</mml:mn><mml:mo>−</mml:mo></mml:msub><mml:mi>L</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the HCP 900 release to investigate the relationship between working memory accuracy, measured using performance on an N-back task, and fluid intelligence. We excluded subjects with missing time points. We used 70% of the selected subjects for training and 30% for testing the model.</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0002" position="float"/>
    </fig>
    <fig position="float" id="F3">
      <label>Fig. 3.</label>
      <caption>
        <p id="P87">Results of Simulation 1, where we varied the number of observations (subjects) while keeping the dimensions of mediator constant. Each violin plot shows the estimated model parameters for the training dataset using deep learning model, shallow learning model and support vector regression. The red dotted line represents the ground truth data.</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0003" position="float"/>
    </fig>
    <fig position="float" id="F4">
      <label>Fig. 4.</label>
      <caption>
        <p id="P88">Results of Simulation 2, where we varied the dimension of mediator while keeping the number of observation constant (<inline-formula><mml:math id="M245" display="inline"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math></inline-formula>). Similar to simulation 1, each violin plot shows the estimated model parameters for the training dataset using deep learning model, shallow learning model and support vector regression. The red dotted line represents the ground truth data.</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0004" position="float"/>
    </fig>
    <fig position="float" id="F5">
      <label>Fig. 5.</label>
      <caption>
        <p id="P89">Results of Simulation 3, where we varied the number of observations (subjects) and removed the effect of mediation. Similar to simulation 1, each violin plot shows the estimated model parameters for the training dataset using the deep learning model, shallow learning model and support vector regression. The red dotted line represents the ground truth data.</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0005" position="float"/>
    </fig>
    <fig position="float" id="F6">
      <label>Fig. 6.</label>
      <caption>
        <p id="P90">Validation on independent data (<inline-formula><mml:math id="M246" display="inline"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>75</mml:mn></mml:mrow></mml:math></inline-formula>). (A) Scatter plots show the relationship between the low-dimensional mediator and input temperature, pain ratings and mediator, and pain ratings and temperature of input stimuli, respectively. Lines show the least-squares fit between variables for each independent validation subject. (B) The estimated <inline-formula><mml:math id="M247" display="inline"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="M248" display="inline"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="M249" display="inline"><mml:mrow><mml:mi>α</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> values obtained when applying the fitted machine learning model to the independent validation dataset, both for the pain and sound trials. These reflect the brain increases as a function of stimulus intensity, the relationship between brain and pain controlling for stimulus intensity, and the mediation effect, respectively. Error bars indicate SEM. ∗ ∗ ∗ <inline-formula><mml:math id="M250" display="inline"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula>. All coefficients were strongly significant for heat pain but non-significant for sound, indicating specificity to pain when compared with aversive sounds. (C) Voxel maps representing the 5% largest (in absolute value) Shapley values, indicating the regions involved in mediating the relationship between stimulus intensity and pain in the independent validation dataset. The majority of identified regions are targets of pain-related ascending pathways (e.g., somatosensory S1/S2, medial thalamus, Anterior Cingulate, and mid insular-opercular areas). Some regions are not generally considered to be related to primary pain pathways but play important modulatory roles (e.g., Ventromedial Prefrontal Cortex, Cerebellum, Anterior Temporal Cortices).</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0006" position="float"/>
    </fig>
    <fig position="float" id="F7">
      <label>Fig. 7.</label>
      <caption>
        <p id="P91">Results on test data (<inline-formula><mml:math id="M251" display="inline"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>240</mml:mn></mml:mrow></mml:math></inline-formula>). (A) The high dimensional functional connectivity matrix which serves as a mediator (<inline-formula><mml:math id="M252" display="inline"><mml:mi>M</mml:mi></mml:math></inline-formula>) of the relationship between fluid intelligence (<inline-formula><mml:math id="M253" display="inline"><mml:mi>X</mml:mi></mml:math></inline-formula>) and the accuracy on the working memory task (<inline-formula><mml:math id="M254" display="inline"><mml:mi>Y</mml:mi></mml:math></inline-formula>). (B) Scatter plots show the relationship between the low-dimensional mediator <inline-formula><mml:math id="M255" display="inline"><mml:mi>z</mml:mi></mml:math></inline-formula> and fluid intelligence, accuracy and the mediator, and accuracy and fluid intelligence, respectively. Lines show the least-squares fit between variables for each test subject (<inline-formula><mml:math id="M256" display="inline"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>240</mml:mn></mml:mrow></mml:math></inline-formula>). (C) Shapley values averaged over voxels connecting each pair of large-scale networks. High connectivity within the Frontoparietal (FPN) and Default Mode Networks (DMN), and low/negative connectivity between FPN and DMN and between FPN and subcortical regions (among other connections) mediated the relationship between fluid intelligence and accuracy of working memory task. This demonstrates links between brain connectivity and both working memory performance and fluid intelligence. MF: Medial frontal, FP: Frontoparietal, DMN: Default model network, SCC: Subcortical-cerebellum, V1: Visual I, V2: Visual II, VA: Visual association. ∗ ∗ ∗ <inline-formula><mml:math id="M257" display="inline"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula> and ∗ ∗ <inline-formula><mml:math id="M258" display="inline"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      </caption>
      <graphic xlink:href="nihms-1872496-f0007" position="float"/>
    </fig>
  </floats-group>
</article>
