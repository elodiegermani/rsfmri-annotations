<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1662-4548</issn>
      <issn pub-type="epub">1662-453X</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">33013292</article-id>
      <article-id pub-id-type="pmc">7461846</article-id>
      <article-id pub-id-type="doi">10.3389/fnins.2020.00881</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A Deep Network Model on Dynamic Functional Connectivity With Applications to Gender Classification and Intelligence Prediction</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>Liangwei</given-names>
          </name>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/998448/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Su</surname>
            <given-names>Jianpo</given-names>
          </name>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/570324/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Qin</surname>
            <given-names>Jian</given-names>
          </name>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/236416/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>Dewen</given-names>
          </name>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/42723/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>Hui</given-names>
          </name>
          <xref ref-type="corresp" rid="c001">
            <sup>*</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/717165/overview"/>
        </contrib>
      </contrib-group>
      <aff><institution>College of Intelligence Science and Technology, National University of Defense Technology</institution>, <addr-line>Changsha</addr-line>, <country>China</country></aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: Xin Di, New Jersey Institute of Technology, United States</p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: Qinglin Dong, Harvard Medical School, United States; Zhao Qing, Nanjing Drum Tower Hospital, China</p>
        </fn>
        <corresp id="c001">*Correspondence: Hui Shen, <email>shenhui@nudt.edu.cn</email></corresp>
        <fn fn-type="other" id="fn004">
          <p>This article was submitted to Brain Imaging Methods, a section of the journal Frontiers in Neuroscience</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>18</day>
        <month>8</month>
        <year>2020</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2020</year>
      </pub-date>
      <volume>14</volume>
      <elocation-id>881</elocation-id>
      <history>
        <date date-type="received">
          <day>08</day>
          <month>6</month>
          <year>2020</year>
        </date>
        <date date-type="accepted">
          <day>28</day>
          <month>7</month>
          <year>2020</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2020 Fan, Su, Qin, Hu and Shen.</copyright-statement>
        <copyright-year>2020</copyright-year>
        <copyright-holder>Fan, Su, Qin, Hu and Shen</copyright-holder>
        <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Increasing evidence has suggested that the dynamic properties of functional brain networks are related to individual behaviors and cognition traits. However, current fMRI-based approaches mostly focus on statistical characteristics of the windowed correlation time course, potentially overlooking subtle time-varying patterns in dynamic functional connectivity (dFC). Here, we proposed the use of an end-to-end deep learning model that combines the convolutional neural network (CNN) and long short-term memory (LSTM) network to capture temporal and spatial features of functional connectivity sequences simultaneously. The results on a large cohort (Human Connectome Project, <italic>n</italic> = 1,050) demonstrated that our model could achieve a high classification accuracy of about 93% in a gender classification task and prediction accuracies of 0.31 and 0.49 (Pearson’s correlation coefficient) in fluid and crystallized intelligence prediction tasks, significantly outperforming previously reported models. Furthermore, we demonstrated that our model could effectively learn spatiotemporal dynamics underlying dFC with high statistical significance based on the null hypothesis estimated using surrogate data. Overall, this study suggests the advantages of a deep learning model in making full use of dynamic information in resting-state functional connectivity, and highlights the potential of time-varying connectivity patterns in improving the prediction of individualized characterization of demographics and cognition traits.</p>
      </abstract>
      <kwd-group>
        <kwd>dynamic functional connectivity (dFC)</kwd>
        <kwd>deep learning</kwd>
        <kwd>gender classification</kwd>
        <kwd>intelligence prediction</kwd>
        <kwd>resting-state functional magnetic resonance imaging</kwd>
      </kwd-group>
      <counts>
        <fig-count count="6"/>
        <table-count count="1"/>
        <equation-count count="8"/>
        <ref-count count="78"/>
        <page-count count="14"/>
        <word-count count="0"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <title>Introduction</title>
      <p>Functional organization principles in the human brain derived from resting-state functional MRI (rs-fMRI) data have been found to improve our understanding of individual cognition and behavioral differences greatly. Functional connectivity (FC) analysis based on rs-fMRI is often applied to quantify the statistical dependencies across different brain regions which are correlated over time (<xref rid="B20" ref-type="bibr">Friston, 2011</xref>). Initially, FC was assessed with the assumption that the connections remain unchanged at rest (<xref rid="B30" ref-type="bibr">Hutchison et al., 2013</xref>). Moreover, recent studies have found that FC is extremely useful in gender classification (<xref rid="B76" ref-type="bibr">Zhang et al., 2018</xref>) and individual prediction of cognition traits such as fluid intelligence (<xref rid="B19" ref-type="bibr">Finn et al., 2015</xref>).</p>
      <p>However, increasing evidence has suggested that the statistical properties of FC change over different time scales across task states (<xref rid="B17" ref-type="bibr">Elton and Gao, 2015</xref>; <xref rid="B18" ref-type="bibr">Fatima et al., 2016</xref>) and during periods of unconstrained rest (<xref rid="B6" ref-type="bibr">Chang and Glover, 2010</xref>; <xref rid="B3" ref-type="bibr">Allen et al., 2014</xref>), i.e., dynamic functional connectivity (dFC). So far, spatiotemporal patterns and dynamics of functional networks derived from rs-fMRI data have been widely studied. The evidence suggested that dynamic interactions of different functional networks were relate to specific tasks (<xref rid="B71" ref-type="bibr">Yuan et al., 2018a</xref>; <xref rid="B39" ref-type="bibr">Li et al., 2019</xref>) and brain disorders such as Alzheimer’s Disease (<xref rid="B29" ref-type="bibr">Huang et al., 2017</xref>), which motivated us to explore the spatiotemporal characteristics of functional networks based on dFC. Moreover, dFC (<xref rid="B54" ref-type="bibr">Sakoğlu et al., 2010</xref>) has been successfully applied to characterizing neuropsychiatric disorders like schizophrenia (<xref rid="B9" ref-type="bibr">Damaraju et al., 2014</xref>; <xref rid="B14" ref-type="bibr">Du et al., 2017</xref>), autism spectrum disorder (<xref rid="B78" ref-type="bibr">Zhu et al., 2016</xref>) and depression (<xref rid="B11" ref-type="bibr">Demirtaş et al., 2016</xref>). Importantly, dFC is linked to individual characteristics such as cognitive flexibility (<xref rid="B13" ref-type="bibr">Douw et al., 2016</xref>), emotions (<xref rid="B65" ref-type="bibr">Tobia et al., 2017</xref>), and age (<xref rid="B52" ref-type="bibr">Qin et al., 2015</xref>; <xref rid="B10" ref-type="bibr">Davison et al., 2016</xref>), and even the variability of dFC can be used to predict high-level cognitive performance (<xref rid="B42" ref-type="bibr">Liu et al., 2018</xref>).</p>
      <p>Although these studies discriminated individual cognitive ability or demographic characteristics based on dFC, most of them employed statistical characteristics of the original dynamic correlation series as features to achieve classification or prediction. Nevertheless, these manually selected features neglected the time-varying patterns in correlation timecourse of FC through folding temporal dimension of dFC, likely causing the loss of some useful information related to individual cognition traits. Actually, the temporal evolution of connectome-scale brain network interactions has been observed to fit well the task-fMRI data (<xref rid="B71" ref-type="bibr">Yuan et al., 2018a</xref>), suggesting the neurophysiological significance of spatiotemporal structures in functional network dynamics. Some recent studies also demonstrated the potential of temporal sequence of windowed functional correlations in predicting individual cognitive traits and demographics. For example, the time series of dFC has long-range sequential correlations that vary across the human adult lifespan (<xref rid="B4" ref-type="bibr">Battaglia et al., 2020</xref>) and specific temporal structures of several FC microstates have been reported to be subject-specific and heritable, and significantly linked to individual cognitive traits (<xref rid="B67" ref-type="bibr">Vidaurre et al., 2017</xref>). Moreover, network switching in dFC is related to task performance and sleep (<xref rid="B48" ref-type="bibr">Pedersen et al., 2018</xref>), attention (<xref rid="B44" ref-type="bibr">Madhyastha et al., 2015</xref>), schizophrenia (<xref rid="B9" ref-type="bibr">Damaraju et al., 2014</xref>), and depression (<xref rid="B77" ref-type="bibr">Zheng et al., 2017</xref>). In particular, a growing body of researches links observed patterns of non-stationary switching between FC states with aspects of the underlying neural dynamics (<xref rid="B25" ref-type="bibr">Hansen et al., 2015</xref>; <xref rid="B64" ref-type="bibr">Thompson, 2018</xref>), indicating short-term alteration in FC time series along with shifting in cognitive states. However, given that the mechanism underlying spontaneous fluctuation in resting-state dFC has not been fully understood, explicitly modeling the sequence of time-resolved FC is still a challenging task.</p>
      <p>Currently, deep learning has undergone unprecedented development in neuroscience. The advantage of an end-to-end model like deep learning is automatically extracting abstract spatial-temporal structures from neuroimaging data (<xref rid="B29" ref-type="bibr">Huang et al., 2017</xref>; <xref rid="B39" ref-type="bibr">Li et al., 2019</xref>), which has been used for discriminating complex mental disorders (<xref rid="B70" ref-type="bibr">Yan et al., 2017</xref>; <xref rid="B74" ref-type="bibr">Zeng et al., 2018</xref>) and gender classification (<xref rid="B72" ref-type="bibr">Yuan et al., 2018b</xref>). In particular, RNN models, such as long short-term memory (LSTM), can effectively extract complex and non-linear time-varying patterns underlying signals’ fluctuations in a data-driven way due to its advantages of “deep in time,” and have been successfully used in identifying autism (<xref rid="B16" ref-type="bibr">Dvornek et al., 2017</xref>) and discriminating schizophrenia (<xref rid="B69" ref-type="bibr">Yan et al., 2019</xref>) from healthy controls.</p>
      <p>In this work, we ask to what extent the dFC can be used to predict individual cognition traits including gender classification and individual prediction of fluid and crystallized intelligence, using a deep network model on the dFC time course. We proposed the use of a convolutional neural network (CNN) and LSTM framework to identify the spatial and temporal structures underlying the spontaneous fluctuation of dFC. We assumed this framework directly working on the temporal series of dFC, could avoid information reduction and make full use of high-level spatiotemporal information of dFC. This model consists of two parts. The first part includes a multi-scale 1D convolutional layer, concatenation layer, and max-pooling layer, which were designed for spatial feature extraction. The second part involves two stacked LSTM layers, which were used to detect temporal dynamics (by learning short-term sequential switching and unknown long-term/non-linear patterns) in time series of windowed correlations. Finally, the average outputs of the LSTM layer were put as the input for the final fully connected layer. We further assessed the capacity of the CNN + LSTM model on one gender classification task and two prediction tasks of individual intelligence, with comparison to support vector machine (SVM) and support vector regression (SVR) models that usually use statistical characteristics of dFC as features (<xref rid="B42" ref-type="bibr">Liu et al., 2018</xref>). Furthermore, we conducted deconvolutional computation to visualize the learned features corresponding to task-related connections in three tasks for demonstrating the validity of the network in learning dynamics of time-resolved FC.</p>
    </sec>
    <sec sec-type="materials|methods" id="S2">
      <title>Materials and Methods</title>
      <sec id="S2.SS1">
        <title>Participants and Data Acquisition</title>
        <p>The dataset was selected from the publicly available S1200 release of the Human Connectome Project dataset (HCP), including 1,206 subjects (age 22–35). The rs-fMRI data of all subjects was scanned in two sessions on two different days. Each session contains a right-left (RL) phase-encoding run and a left-right (LR) phase-encoding run. In addition, the HCP collected many behavioral measures, such as fluid intelligence and crystallized intelligence, which allows us to investigate the relationship between individual traits and their neuroimaging data. 1,050 subjects (gender: 569 females and 481 males) were left for this study by restricting subjects with at least one run and two intelligence measures.</p>
        <p>Data was acquired using a 3.0 T Siemens scanner at Washington University at St. Louis. The data acquisition parameters were as follows: repetition time (TR) = 720 ms, time echo (TE) = 33.1 ms, flip angle (FA) = 52°, resolution = 2.0 mm, field of view (FOV) = 208 × 180 mm (RO × PE), matrix size = 104 × 90 (RO × PE), slices = 72, and volumes = 1,200. More details are available in the previous literature (<xref rid="B66" ref-type="bibr">Van Essen et al., 2013</xref>).</p>
      </sec>
      <sec id="S2.SS2">
        <title>Data Preprocessing</title>
        <p>The HCP dataset was first preprocessed under the HCP minimal preprocessing pipeline, which mainly includes distortion and spatial artifact removal, motion correction, within-subject cross-modal registration, and cross-subject registration to a standard space (<xref rid="B22" ref-type="bibr">Glasser et al., 2013</xref>). In addition, standard preprocessing procedures for resting-state connectivity analysis were performed on the HCP using SPM8<sup><xref ref-type="fn" rid="footnote1">1</xref></sup>. For each subject, the fMRI images were resampled to 3 × 3 × 3 mm isotropic voxels. Next, a Gaussian filter kernel of 6 mm full width at half maximum (FWHM) was used to smooth the images spatially. Then, the images were temporally bandpass filtered from 0.01 to 0.08 Hz. Finally, to further denoise rs-fMRI data, we regressed the white matter (WM) signal, head motion, cerebrospinal fluid (CSF) signal, and their first-order deviations.</p>
      </sec>
      <sec id="S2.SS3">
        <title>Dynamic Functional Connectivity</title>
        <p>To obtain regions of interest (ROI) based bold signals, we averaged preprocessed rs-fMRI time courses of voxels within each gray matter region according to a 268-node functional atlas (<xref rid="B59" ref-type="bibr">Shen et al., 2013</xref>). Then, a sliding time window approach (<xref rid="B5" ref-type="bibr">Calhoun et al., 2014</xref>; <xref rid="B52" ref-type="bibr">Qin et al., 2015</xref>) was used to divide the ROI-based brain signals into temporal segments with a window size of 39.6 s (55 TRs), and the dFC of each region pair was calculated using Pearson correlation coefficients. As a result, a series of 268 × 268 correlation matrices were generated (<xref ref-type="fig" rid="F1">Figure 1A</xref>). Additionally, to normalize the coefficient values of correlation matrices, we applied Fisher’s <italic>z</italic>-transformation to each correlation matrix. Next, the upper triangular part of each correlation matrix was reshaped into a vector for the following analysis. Ultimately, for each run of each subject, we obtained a sliding-window correlation matrix of 230 (windows) × 35,778 (connections).</p>
        <fig id="F1" position="float">
          <label>FIGURE 1</label>
          <caption>
            <p>The flowchart of using the CNN + LSTM model to distinguish sex and predict intelligence based on dynamic functional connectivity (dFC). <bold>(A)</bold> The pipeline of calculating dFC using resting-state fMRI data and surrogate data that was generated by employing the multivariate phase randomization (MVPR) model on original BOLD signals. <bold>(B)</bold> Overview of multi-layer structure in the CNN + LSTM model. <bold>(C)</bold> The deconvolutional computation for visualizing learned spatiotemporal features in dFC from the Conv1D layers.</p>
          </caption>
          <graphic xlink:href="fnins-14-00881-g001"/>
        </fig>
      </sec>
      <sec id="S2.SS4">
        <title>dFC-Based Prediction Setup</title>
        <p>Gender and behavioral data of intelligence on high-level cognition from HCP protocol were selected, including fluid intelligence (Penn Progressive Matrices, HCP: PMAT24_A_CR) and crystallized intelligence which was measured using NIH toolbox composite scores (Crystallized Cognition Composite), combining Picture Vocabulary Test and Oral Reading Recognition Test into one score (CompGcScore) (<xref rid="B2" ref-type="bibr">Akshoomoff et al., 2013</xref>). Next, the gender and intelligence measures of subjects were predicted using the CNN + LSTM model based on dFC matrices.</p>
      </sec>
      <sec id="S2.SS5">
        <title>CNN + LSTM Model</title>
        <p>As shown in <xref ref-type="fig" rid="F1">Figure 1B</xref>, the used CNN + LSTM network is composed of three 1D convolutional layers which have three filters of different size (4, 8, and 16 time windows), one concatenation layer combining features from three convolutional layers, one max-pooling layer which was designed to down-sample, two LSTM network layers, and a fully connected layer (<xref rid="B69" ref-type="bibr">Yan et al., 2019</xref>). The model was built for both the gender classification task and cognitive performance prediction tasks. Specifically, the obtained dFC matrices were fed into the CNN + LSTM model as inputs for parameter optimization. Then, the optimized model was saved for testing and comparison.</p>
        <sec id="S2.SS5.SSS1">
          <title>Multi-Scale Convolutional Layer</title>
          <p>Although LSTM is powerful for handling temporal correlation, the major drawback of LSTM in handling spatiotemporal data was the redundancy of high-dimensional data. In addition, in the previous CNN-RNN architecture, the capability of each Conv1D layer determined by a single fixed filter size is extracting local information at only one time scale. Moreover, to adapt specific tasks, the filter length of 1D convolutional layer should be hand-picked. Therefore, multi-scale 1D convolutional layers were proposed for feature extraction because it can not only reduce spatial dimension but also account for different scales of brain activity (<xref rid="B53" ref-type="bibr">Roy et al., 2019</xref>; <xref rid="B69" ref-type="bibr">Yan et al., 2019</xref>). The architecture of multi-scale 1D convolutional layers includes multiple filters with diverse sizes in each convolutional layer. Filter lengths of 1D convolutional layers changed exponentially rather than linearly. Our experiment demonstrated that this architecture led to better performance by using different filter lengths (4, 8, and 16 time windows) in the 1D convolutional layers. Therefore, the size of the convolutional filters of three different scales 1D convolutional layers are 35,778 × 4 × 32, 35,778 × 8 × 32, 35,778 × 16 × 32, respectively. Here, we fed the dFC matrices into the multi-scale convolutional layer. As a result, outputs are three features whose sizes are 230 (time windows) × 32 (feature dimension). Then, a concatenation layer is designed to concatenate the output features in the time dimension, resulting in a feature map with a size of 230 × 96. Furthermore, a downsampling operation is performed using the max-pooling layer along the time dimension with kernel size 5 × 1, resulting in 46 × 96 features as an input of the following LSTM layers.</p>
          <p>We performed deconvolutional computation for each convolutional layer (<xref ref-type="fig" rid="F1">Figure 1C</xref>) (<xref rid="B73" ref-type="bibr">Zeiler and Fergus, 2014</xref>) to obtain the distribution of those connections with relatively high weights in discrimination. The deconvolutional results of one 1D convolutional layer were obtained for 100 randomly selected subjects. The group-level statistical strength of each functional connection was generated by computing the absolute value of its average strength across 100 randomly selected subjects (<xref rid="B76" ref-type="bibr">Zhang et al., 2018</xref>).</p>
        </sec>
        <sec id="S2.SS5.SSS2">
          <title>Two-Layer Stacked LSTM Layer</title>
          <p>Long short-term memory is one kind of RNN models, which is different from CNN because of its consideration of the temporal information. LSTM consists of an input gate, an output gate, a forget gate and a cell. The advantage of LSTM is that it has sufficient ability to solve long-term dependencies because of the interactive operation among these three gates, in contrast to general RNNs. In addition, LSTM is designed to combat vanishing/exploding gradients by using a gating mechanism. The LSTM model can be presented in the following form:</p>
          <disp-formula id="S2.E1">
            <label>(1)</label>
            <mml:math id="M1">
              <mml:mrow>
                <mml:mrow>
                  <mml:mi>F</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>o</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>r</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>g</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>g</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                </mml:mrow>
                <mml:mo>:</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>f</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mtext>Sigmoid</mml:mtext>
                    <mml:mo>⁢</mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>W</mml:mi>
                            <mml:mi>f</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>t</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>U</mml:mi>
                            <mml:mi>f</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>h</mml:mi>
                            <mml:mrow>
                              <mml:mi>t</mml:mi>
                              <mml:mo>-</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:msub>
                          <mml:mi>b</mml:mi>
                          <mml:mi>f</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="S2.E2">
            <label>(2)</label>
            <mml:math id="M2">
              <mml:mrow>
                <mml:mrow>
                  <mml:mi>I</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>n</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>p</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>u</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>g</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                </mml:mrow>
                <mml:mo>:</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>i</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mtext>Sigmoid</mml:mtext>
                    <mml:mo>⁢</mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>W</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>t</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>U</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>h</mml:mi>
                            <mml:mrow>
                              <mml:mi>t</mml:mi>
                              <mml:mo>-</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:msub>
                          <mml:mi>b</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="S2.E3">
            <label>(3)</label>
            <mml:math id="M3">
              <mml:mrow>
                <mml:mrow>
                  <mml:mi>O</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>u</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>p</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>u</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>g</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                </mml:mrow>
                <mml:mo>:</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>o</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mtext>Sigmoid</mml:mtext>
                    <mml:mo>⁢</mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>W</mml:mi>
                            <mml:mi>o</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>t</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>U</mml:mi>
                            <mml:mi>o</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>h</mml:mi>
                            <mml:mrow>
                              <mml:mi>t</mml:mi>
                              <mml:mo>-</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:msub>
                          <mml:mi>b</mml:mi>
                          <mml:mi>o</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="S2.E4">
            <label>(4)</label>
            <mml:math id="M4">
              <mml:mrow>
                <mml:mrow>
                  <mml:mi>E</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>s</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>i</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>m</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>d</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>c</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>u</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>r</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>r</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>n</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>c</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>l</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>l</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>s</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                </mml:mrow>
                <mml:mo>:</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mover accent="true">
                      <mml:mi>C</mml:mi>
                      <mml:mo stretchy="false">~</mml:mo>
                    </mml:mover>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>a</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>n</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>h</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>W</mml:mi>
                            <mml:mi>c</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>x</mml:mi>
                            <mml:mi>t</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>U</mml:mi>
                            <mml:mi>c</mml:mi>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:msub>
                            <mml:mi>h</mml:mi>
                            <mml:mrow>
                              <mml:mi>t</mml:mi>
                              <mml:mo>-</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>+</mml:mo>
                        <mml:msub>
                          <mml:mi>b</mml:mi>
                          <mml:mi>c</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="S2.E5">
            <label>(5)</label>
            <mml:math id="M5">
              <mml:mrow>
                <mml:mrow>
                  <mml:mi>C</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>l</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>l</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>s</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                </mml:mrow>
                <mml:mo>:</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>C</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>i</mml:mi>
                        <mml:mi>t</mml:mi>
                      </mml:msub>
                      <mml:mo>⊙</mml:mo>
                      <mml:msub>
                        <mml:mover accent="true">
                          <mml:mi>C</mml:mi>
                          <mml:mo stretchy="false">~</mml:mo>
                        </mml:mover>
                        <mml:mi>t</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mo>+</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>f</mml:mi>
                        <mml:mi>t</mml:mi>
                      </mml:msub>
                      <mml:mo>⊙</mml:mo>
                      <mml:msub>
                        <mml:mi>C</mml:mi>
                        <mml:mrow>
                          <mml:mi>t</mml:mi>
                          <mml:mo>-</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                      </mml:msub>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="S2.E6">
            <label>(6)</label>
            <mml:math id="M6">
              <mml:mrow>
                <mml:mrow>
                  <mml:mi>H</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>i</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>d</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>d</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>n</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>s</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>e</mml:mi>
                </mml:mrow>
                <mml:mo>:</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>h</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mo>=</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>o</mml:mi>
                      <mml:mi>t</mml:mi>
                    </mml:msub>
                    <mml:mo>⊙</mml:mo>
                    <mml:mrow>
                      <mml:mi>tanh</mml:mi>
                      <mml:mo>⁡</mml:mo>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:msub>
                          <mml:mi>C</mml:mi>
                          <mml:mi>t</mml:mi>
                        </mml:msub>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>Where <italic>W</italic><sub><italic>f</italic></sub>, <italic>W</italic><sub><italic>i</italic></sub>, <italic>W</italic><sub><italic>o</italic></sub>, and <italic>W</italic><sub><italic>c</italic></sub> are input weights; <italic>U</italic><sub><italic>f</italic></sub>, <italic>U</italic><sub><italic>i</italic></sub>, <italic>U</italic><sub><italic>o</italic></sub>, and <italic>U</italic><sub><italic>c</italic></sub> are recurrent weights; <italic>b</italic><sub><italic>f</italic></sub>, <italic>b</italic><sub><italic>i</italic></sub>, <italic>b</italic><sub><italic>o</italic></sub>, and <italic>b</italic><sub><italic>c</italic></sub> are bias weights, and ⊙ is the Hadamard product.</p>
          <p>Here, we choose two densely connected LSTM layers because it may better capture latent dynamic information than one LSTM layer. It is worth noting that densely connected LSTM layers may mitigate the vanishing or exploding gradients problem (<xref rid="B53" ref-type="bibr">Roy et al., 2019</xref>; <xref rid="B69" ref-type="bibr">Yan et al., 2019</xref>). The size of the hidden state was set as 32. Also, we averaged all of the LSTM outputs to combine all fMRI steps (<xref rid="B16" ref-type="bibr">Dvornek et al., 2017</xref>). In this way, better classification performance could be obtained through leveraging all brain activities during scanning. Then the learned features were passed to the fully connected layer. The fully connected layer can be expressed as:</p>
          <disp-formula id="S2.E7">
            <label>(7)</label>
            <mml:math id="M7">
              <mml:mrow>
                <mml:msup>
                  <mml:mi>h</mml:mi>
                  <mml:mi>l</mml:mi>
                </mml:msup>
                <mml:mo>=</mml:mo>
                <mml:mrow>
                  <mml:msup>
                    <mml:mi>b</mml:mi>
                    <mml:mi>l</mml:mi>
                  </mml:msup>
                  <mml:mo>+</mml:mo>
                  <mml:mrow>
                    <mml:msup>
                      <mml:mi>h</mml:mi>
                      <mml:mrow>
                        <mml:mi>l</mml:mi>
                        <mml:mo>-</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mo>×</mml:mo>
                    <mml:msup>
                      <mml:mi>w</mml:mi>
                      <mml:mi>l</mml:mi>
                    </mml:msup>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>Where <italic>w<sup>l</sup></italic> and <italic>b<sup>l</sup></italic> are input weight and bias weight, respectively. When the model is trained for intelligence prediction, the output of the fully connected layer is the predicted intelligence scores. However, for gender classification, another operation of Softmax was added as the last operation of this architecture.</p>
        </sec>
      </sec>
      <sec id="S2.SS6">
        <title>Training, Validation, and Testing</title>
        <p>A 10-fold cross-validation procedure was used for evaluating prediction performance. The HCP data was randomly split into training, validation, and testing sets. More specifically, we divided the 1,050 subjects into ten folds. Note that multiple runs belonging to the same subject were not split across folds (<xref rid="B26" ref-type="bibr">He et al., 2020</xref>). For every test fold, the remaining nine folds were used for training and validation. Furthermore, it has been found that head motion was correlated with behavioral measures such as fluid intelligence (<xref rid="B61" ref-type="bibr">Siegel et al., 2017</xref>). Therefore, we regressed sex, age, and motion (frame-wise displacement FD) from the intelligence. In each test fold, we estimated the regression coefficients from the training set and applied them into the test fold (<xref rid="B36" ref-type="bibr">Kong et al., 2019</xref>; <xref rid="B26" ref-type="bibr">He et al., 2020</xref>).</p>
        <p>The CNN + LSTM model was coded based on the platform of Pytorch (<xref rid="B47" ref-type="bibr">Paszke et al., 2017</xref>), and optimized with Adam optimizer to minimize the loss (<xref rid="B69" ref-type="bibr">Yan et al., 2019</xref>). The value of batch size was set as 64. The initial learning rate was 0.0001. We decreased the learning rate with weight decay rate of 10<sup>−1</sup> after each epoch. To avoid overfitting and achieve higher generalization performance, we used dropout (dropout rate = 0.5) for regulating the model parameters and early stopping to stop training according to the prediction condition of the validation data. Briefly, when training loss continued to decrease but validation loss increased, this means that the training was already overfitting, and we should stop training.</p>
      </sec>
      <sec id="S2.SS7">
        <title>Evaluation of Model Ability to Capture Dynamics of FC With Surrogate Data</title>
        <p>It was unclear whether the CNN + LSTM model concentrated on the dFC containing the sequential temporal dynamics, or just captured the static statistics of dFC. To validate the validity of the model in capture dynamic interaction information, we used initial BOLD signals to generate surrogate data as null hypothesis. The aim of surrogate data is to generate the same time probability distribution, while preserving all statistical properties of the observed data like stationary cross correlation, but to destroy the dynamics in FC time courses (<xref rid="B57" ref-type="bibr">Schreiber and Schmitz, 2000</xref>; <xref rid="B49" ref-type="bibr">Pereda et al., 2005</xref>; <xref rid="B55" ref-type="bibr">Savva et al., 2019</xref>).</p>
        <p>In this study, a multivariate phase randomization (MVPR) model (<xref rid="B51" ref-type="bibr">Prichard and Theiler, 1994</xref>) was applied by randomly shuffling the Fourier phases of the original BOLD signals such that their static FC structure could be preserved (<xref rid="B28" ref-type="bibr">Hindriks et al., 2016</xref>; <xref rid="B41" ref-type="bibr">Liégeois et al., 2017</xref>; <xref rid="B55" ref-type="bibr">Savva et al., 2019</xref>).</p>
        <disp-formula id="S2.E8">
          <label>(8)</label>
          <mml:math id="M8">
            <mml:mrow>
              <mml:mrow>
                <mml:msub>
                  <mml:mover accent="true">
                    <mml:mi>X</mml:mi>
                    <mml:mo stretchy="false">^</mml:mo>
                  </mml:mover>
                  <mml:mi>k</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mrow>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:msub>
                  <mml:mo>⁢</mml:mo>
                  <mml:msup>
                    <mml:mi>e</mml:mi>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mo>⁢</mml:mo>
                      <mml:mi mathvariant="normal">φ</mml:mi>
                    </mml:mrow>
                  </mml:msup>
                </mml:mrow>
              </mml:mrow>
              <mml:mo>,</mml:mo>
              <mml:mrow>
                <mml:mi>k</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mrow>
                  <mml:mn>1</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mn>2</mml:mn>
                  <mml:mo>,</mml:mo>
                  <mml:mi mathvariant="normal">⋯</mml:mi>
                  <mml:mo>,</mml:mo>
                  <mml:mi>n</mml:mi>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>Where <italic>X</italic> = [<italic>X</italic><sub>1</sub>,<italic>X</italic><sub>2</sub>,⋯,<italic>X</italic><sub><italic>n</italic></sub>] is the discrete Fourier transformations of original time series. <italic>n</italic> = 268 refers to the number of brain regions. φ = [φ<sub>1</sub>,φ<sub>2</sub>,⋯,φ<sub><italic>T</italic></sub>] is a uniformly distributed random phase in the range of [0,2π].</p>
        <p>Subsequently, the inverse Fourier transform is applied to <inline-formula><mml:math id="INEQ8"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">⋯</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to generate one randomized copy <inline-formula><mml:math id="INEQ9"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>. We repeated the procedure and then generated 100 surrogate copies for each subject. In addition, dFC matrices were calculated in the same way, excluding that surrogate copies instead of BOLD signals were used. For each surrogate copy of all subjects, the resulted dFC matrices were used as input of the model for gender classification with 10-fold cross-validation strategies. As a result, 100 surrogate copies were performed to estimate a distribution of accuracies under the null hypothesis of dFC.</p>
        <p>Furthermore, a statistical method was proposed to assess the existence of dFC between a pair of ROIs (<xref rid="B55" ref-type="bibr">Savva et al., 2019</xref>). Then, this statistical framework was applied to test if the CNN + LSTM model could concentrate on the ROI pairs with statistically significant dFC. For details, 250 surrogate copies of one randomly selected participant were generated with the aforementioned method to formulate the null hypothesis. This null hypothesis can be rejected when any given FC time-series exhibits dFC.</p>
      </sec>
      <sec id="S2.SS8">
        <title>Evaluation of Model Performance in Gender Classification and Intelligence Prediction Tasks</title>
        <p>As commonly seen in the recent intelligence prediction studies based on rs-fMRI data (<xref rid="B19" ref-type="bibr">Finn et al., 2015</xref>; <xref rid="B42" ref-type="bibr">Liu et al., 2018</xref>; <xref rid="B26" ref-type="bibr">He et al., 2020</xref>), the Pearson’s correlation between predicted and observed intelligence scores of all subjects across all folds was used for assessing the model performance of intelligence prediction tasks. In this study, we reported the Pearson’s correlation and mean absolute error (MAE) to evaluate our model prediction performance. In the case of gender classification, the model was evaluated with the classification accuracy. Additionally, the area under ROC curve (AUC) which is a very widely used measure of performance for classification was also reported. Furthermore, it has been revealed that chronnectome (<xref rid="B5" ref-type="bibr">Calhoun et al., 2014</xref>) could be used to identify individuals and predict individual higher cognitive performance (<xref rid="B42" ref-type="bibr">Liu et al., 2018</xref>). For comparing with the CNN + LSTM model, we used linear SVM and linear epsilon SVR models (LIBSVM toolbox in Matlab<sup><xref ref-type="fn" rid="footnote2">2</xref></sup>) based on dynamic characteristic of dFC (dFC-Str, which refers to the overall strength of dFC) (<xref rid="B42" ref-type="bibr">Liu et al., 2018</xref>), to achieve gender classification and intelligence prediction with the same 10-fold cross-validation strategies. The hyperparameter of linear SVM and linear epsilon-SVR includes the regularization parameter <italic>C</italic>, which was optimized for achieving its best performance.</p>
      </sec>
      <sec id="S2.SS9">
        <title>Control Analysis</title>
        <p>We further examined the effects of parcellation schemes and sliding window sizes on model performance. The selection of window size was controversial in previous studies (<xref rid="B35" ref-type="bibr">Kiviniemi et al., 2011</xref>; <xref rid="B32" ref-type="bibr">Jones et al., 2012</xref>; <xref rid="B30" ref-type="bibr">Hutchison et al., 2013</xref>; <xref rid="B3" ref-type="bibr">Allen et al., 2014</xref>; <xref rid="B52" ref-type="bibr">Qin et al., 2015</xref>). A smaller window size can better detect the potential low-frequency fluctuations in FC (<xref rid="B54" ref-type="bibr">Sakoğlu et al., 2010</xref>; <xref rid="B31" ref-type="bibr">Hutchison et al., 2012</xref>). It has been suggested that the window sizes from around 30–60 s can achieve the best classification and prediction performances (<xref rid="B60" ref-type="bibr">Shirer et al., 2012</xref>; <xref rid="B52" ref-type="bibr">Qin et al., 2015</xref>). In this work, three additional window sizes (60, 80, and 100 s) were used to investigate the potential impact of window width on gender classification and intelligence prediction performance. Additionally, to evaluate the effects caused by different brain parcellations, two additional parcellations were used for generating dFC matrices, including Power-264 consisting of 264 ROIs (<xref rid="B50" ref-type="bibr">Power et al., 2011</xref>), and functional brain atlas of 160 ROIs (<xref rid="B12" ref-type="bibr">Dosenbach et al., 2010</xref>). Then, we re-performed the gender classification and intelligence prediction analyses using these dFC matrices based on these parcellations.</p>
      </sec>
    </sec>
    <sec id="S3">
      <title>Results</title>
      <sec id="S3.SS1">
        <title>Performance of Gender Classification and Intelligence Prediction Tasks</title>
        <sec id="S3.SS1.SSS1">
          <title>Gender Classification Results</title>
          <p><xref ref-type="fig" rid="F2">Figure 2A</xref> shows the gender classification performance of the CNN + LSTM and SVM model. The accuracy of 93.05 ± 1.91% was obtained by using the CNN + LSTM model, which is significantly higher than that obtained using SVM (<italic>p</italic> &lt; 0.001, two-sample <italic>t</italic>-tests). Moreover, their ROC curves are shown in <xref ref-type="fig" rid="F2">Figure 2B</xref>. The CNN + LSTM model achieved an AUC of 0.9805, while the SVM achieved an AUC of 0.9195. Note that the CNN + LSTM model achieved better performance than SVM by integrating the advantages of CNN and LSTM.</p>
          <fig id="F2" position="float">
            <label>FIGURE 2</label>
            <caption>
              <p>ROC and accuracy for the gender classification task. <bold>(A)</bold> ROC curve across 10 testing folds for the CNN + LSTM and the SVM model. <bold>(B)</bold> Gender classification accuracy averaged across 10 testing folds. Bars refer to mean accuracy of all testing folds. Error bars indicate the standard error. Obviously, the CNN + LSTM model is statistically better than the SVM model (***<italic>p</italic> &lt; 0.001). <bold>(C)</bold> Accuracies of gender classification using the CNN + LSTM model on the real BOLD signals and their surrogate copies. A total of 100 surrogate data were generated by using MVPR to estimate the null distribution of classification accuracies (see section “Materials and Methods” for detail). With the mean classification accuracies as the statistic, results reveal that the classifier learned the connection dynamics with a probability of being wrong of &lt;0.001. <bold>(D)</bold> The learning curves while training the CNN + LSTM model.</p>
            </caption>
            <graphic xlink:href="fnins-14-00881-g002"/>
          </fig>
          <p>We conducted 100 times of repeated tests using 100 surrogate copies to testify whether the trained deep network discriminates genders based on dynamics in FC rather than other features such as static functional correlation across ROIs. The results are shown in <xref ref-type="fig" rid="F2">Figure 2C</xref>. As expected, empirical distributions of the accuracies scattered around 57%, suggesting the classifier performance was just better than random guessing for the surrogate copies. All the accuracies of surrogate copies fell behind that of real BOLD signals, demonstrating that the statistical significance of gender classification based on temporal dynamics in FC was high (<italic>p</italic> &lt; 0.001), so that the null hypothesis that the deep network failed in capturing spatiotemporal features of dFC could be rejected. The learning curves while training the CNN+LSTM model was shown in <xref ref-type="fig" rid="F2">Figure 2D</xref>.</p>
        </sec>
        <sec id="S3.SS1.SSS2">
          <title>Intelligence Prediction</title>
          <p><xref ref-type="fig" rid="F3">Figure 3A</xref> depicts the prediction accuracy of fluid and crystallized intelligence (Pearson’s correlation coefficient) in a 10-fold cross-validation test. The CNN + LSTM model achieved higher prediction accuracy in both tasks than the SVR model, with Pearson’s correlation <italic>r</italic> = 0.3129 for fluid intelligence and <italic>r</italic> = 0.4946 for crystallized intelligence, respectively, in contrast to SVR’s prediction accuracy of <italic>r</italic> = 0.2245 for fluid intelligence and <italic>r</italic> = 0.3889 for crystallized intelligence. The conclusions of MAE are similar, as illustrated in <xref ref-type="fig" rid="F3">Figure 3B</xref>. The MAE of 11.9561 ± 0.7412 (for crystallized intelligence) and 3.7287 ± 0.2673 (for fluid intelligence) in the CNN + LSTM model are significantly lower than those obtained using SVR (<italic>p</italic> &lt; 0.05, two-sample <italic>t</italic>-tests).</p>
          <fig id="F3" position="float">
            <label>FIGURE 3</label>
            <caption>
              <p>Prediction performance of fluid intelligence and crystallized intelligence. <bold>(A)</bold> The correlations between predicted and observed intelligence scores for the CNN + LSTM and support vector machine (SVM) models. Note that the CNN + LSTM model exhibits the highest correlation scores for both tasks. Each subject is represented by one dot, and 95% confidence interval for the best-fit line is represented by the gray area which is used to assess the predictive power of the model. <bold>(B)</bold> Comparison between mean MAE across 10 testing folds for the CNN + LSTM and the SVM model. Lower is better. Bars refer to the mean accuracy of all testing folds, and error bars refer to their standard error. Note that the CNN + LSTM model is statistically better than the SVM model (*<italic>p</italic> &lt; 0.05).</p>
            </caption>
            <graphic xlink:href="fnins-14-00881-g003"/>
          </fig>
        </sec>
      </sec>
      <sec id="S3.SS2">
        <title>Estimating the Most Discriminative Connection Features</title>
        <p>To explore the ability of the CNN + LSTM model in extracting features related to the three discriminating tasks, we used deconvolution computations to show the important functional connection features characterized with high weights. <xref ref-type="fig" rid="F4">Figure 4A</xref> shows the distributions of FC with feature weights above the threshold, which was set for an important contribution at the 75th percentile of all feature weights. Important FC features are widespread across the brain for all three discriminating tasks. However, as for gender classification, a large number of FC features above the threshold are distributed in inter-network and intra-network of frontoparietal (networks 1 and 2), default mode (network 3), and motor (network 5), especially for the default mode and motor networks. While FC features with high weights are mostly in the inter-network and intra-network of frontoparietal for fluid and crystallized intelligence tasks.</p>
        <fig id="F4" position="float">
          <label>FIGURE 4</label>
          <caption>
            <p>Connectivity patterns with high task-related weights. <bold>(A)</bold> Distributions of functional connections with feature weights that are larger than the threshold for three prediction tasks. Different brain functional networks are represented by segments of different colors, and the length of the segment refers to the total number of connections. Ribbons refer to functional connections, and the width of ribbon refers to the number of intra-network and inter-network connections. <bold>(B)</bold> Average feature weights of intra-network and inter-network connections for three tasks.</p>
          </caption>
          <graphic xlink:href="fnins-14-00881-g004"/>
        </fig>
        <p>To explore which networks had the most predictive power, average intra-network and inter-network feature weights of eight networks were calculated without thresholding. As illustrated in <xref ref-type="fig" rid="F4">Figure 4B</xref>, the default mode network (DMN) has the highest inter-network and intra-network feature weights of gender classification, especially for the inter-network. The motor and frontoparietal networks follow the default mode. The other networks have slightly low weights of intra-network and inter-network features. Additionally, patterns from fluid intelligence and crystallized intelligence predictions are very similar, i.e., the frontoparietal network has slightly higher weights than the others. However, the visual I network (network 6) has low predictive power for predicting intelligence. Intra-network and inter-network feature weights are comparable in all the networks.</p>
      </sec>
      <sec id="S3.SS3">
        <title>Identifying Significant Dynamic Connections With Surrogate Data</title>
        <p>The null hypothesis for dFC using the surrogate data was tested on one randomly selected subject, with the results indicated in <xref ref-type="fig" rid="F5">Figure 5A</xref>. The red points represent those connections exhibiting statistically significant dFC. Note that significant connections were widely distributed across the brain. To further identify if the CNN + LSTM model could capture those regions with statistically significant dynamics, we computed the distributions of averaged deconvolutional weights for all significantly dynamic and non-significantly dynamic connections. As shown in <xref ref-type="fig" rid="F5">Figures 5B,C</xref>, both the weight distributions of ROI pairs follow the approximately normal distribution. Moreover, the features with high weights cover nearly half of those connections with significant dFC. In other words, the important regions extracted by using the CNN + LSTM model carry sufficient dynamic connectivity information.</p>
        <fig id="F5" position="float">
          <label>FIGURE 5</label>
          <caption>
            <p>Statistically significant dynamic connections for one randomly selected subject. <bold>(A)</bold> Distribution of significant dynamic connections (red points) in eight networks. <bold>(B)</bold> Distribution histogram of deconvolutional weights for significant dynamic connections. <bold>(C)</bold> Distribution histogram of deconvolutional weights for non- significant dynamic connections.</p>
          </caption>
          <graphic xlink:href="fnins-14-00881-g005"/>
        </fig>
      </sec>
    </sec>
    <sec id="S4">
      <title>Discussion</title>
      <p>In this work, we used a CNN + LSTM model combining the advantages of CNN and LSTM to learn spatiotemporal information in rest-state dFC. This was the first attempt to capture the dynamic interaction information of dFC series using deep learning, which avoids information reduction and takes advantage of time-varying spatiotemporal information. More importantly, we showed that the CNN + LSTM model not only successfully achieved a high accuracy of gender classification but could significantly predict individual intelligence, including fluid and crystallized intelligence across a large-scale dataset totaling 1,050 participants. Moreover, the results of deconvolutional computation provided interpretation for extracted features. Our results suggest that the CNN + LSTM model can simultaneously learn temporal and spatial information of dFC series instead of dFC’s statistical characteristics, which could significantly improve the prediction power of individual cognition traits.</p>
      <sec id="S4.SS1">
        <title>Gender Classification and Intelligence Prediction Performance</title>
        <p><xref rid="T1" ref-type="table">Table 1</xref> summarizes the rs-fMRI based model performance of gender classification and intelligence prediction from some recent studies. <xref rid="B76" ref-type="bibr">Zhang et al. (2018)</xref> showed that with three different methods combining FC features of multiple runs from the HCP (820 subjects), the optimal classification accuracy and AUC were 85% and 0.93, respectively. <xref rid="B37" ref-type="bibr">Ktena et al. (2018)</xref> achieved a gender classification accuracy of 80% with static functional connectivity (sFC) from UK Biobank (2,500 subjects). In addition, <xref rid="B26" ref-type="bibr">He et al. (2020)</xref> reported a sex prediction accuracy of 91.6% with four different models in the UK Biobank (8,868 subjects). Our model based on dFC time series could achieve a higher accuracy of gender classification than those using the static FC feature.</p>
        <table-wrap id="T1" position="float">
          <label>TABLE 1</label>
          <caption>
            <p>Model performance of rs-fMRI based gender classification and intelligence prediction tasks in some recent studies.</p>
          </caption>
          <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
            <thead>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Author</bold>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Dataset (subs)</bold>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Methods</bold>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Types of data</bold>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Tasks</bold>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Accuracy</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Chao Zhang</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (820)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">PLSR</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender</td>
                <td valign="top" align="left" rowspan="1" colspan="1">87% (10-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Sofia Ira Ktena</td>
                <td valign="top" align="left" rowspan="1" colspan="1">UK Biobank (2,500)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">GCN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender</td>
                <td valign="top" align="left" rowspan="1" colspan="1">80% (5-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Tong He</td>
                <td valign="top" align="left" rowspan="1" colspan="1">UK Biobank (8,868)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">TML</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender</td>
                <td valign="top" align="left" rowspan="1" colspan="1">91.6% (9-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Casanova R</td>
                <td valign="top" align="left" rowspan="1" colspan="1">FCP (148)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Lasso regression</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender</td>
                <td valign="top" align="left" rowspan="1" colspan="1">62%</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Stephen M. Smith</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (131)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Linear discriminant analysis</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender</td>
                <td valign="top" align="left" rowspan="1" colspan="1">87% (LOOCV)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Susanne Weis</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (434)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">SVM</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender</td>
                <td valign="top" align="left" rowspan="1" colspan="1">75.1% (10-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Tong He</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (953)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">FNN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.297 (20-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Julien Dubois</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP(884)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Linear models</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.27 (leave-one family out)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Rajan Kashyap</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (803)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">COBE</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.25 (20-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Ru Kong</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (881)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">MS-HBM</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.22 (20-fold)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Abigail S. Greene</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (515)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">CPM</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.196 (LOOCV)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Jin Liu</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (105)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">SVR</td>
                <td valign="top" align="center" rowspan="1" colspan="1">dFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.418 (LOOCV)</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Emily S. Finn</td>
                <td valign="top" align="left" rowspan="1" colspan="1">HCP (142)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Linear regression</td>
                <td valign="top" align="center" rowspan="1" colspan="1">sFC</td>
                <td valign="top" align="left" rowspan="1" colspan="1">Fluid intelligence</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.5 (LOOCV)</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <attrib>
              <italic>All results are the best performance mentioned in the literature. CNN, convolutional neural network; GCN, graph convolutional network; PLSR, partial least squares regression; COBE, common and orthogonal basis extraction; MS-HBM, multi-session hierarchical Bayesian model; CPM, connectome-based predictive modeling; LOOCV, leave-one-subject-out cross-validation.</italic>
            </attrib>
          </table-wrap-foot>
        </table-wrap>
        <p>In the case of behavioral measures such as fluid and crystallized intelligence, combining Picture Vocabulary Test (vocabulary) and Oral Reading Recognition Test (reading) into one score, previous studies (<xref rid="B19" ref-type="bibr">Finn et al., 2015</xref>; <xref rid="B42" ref-type="bibr">Liu et al., 2018</xref>) reporting high fluid intelligence prediction accuracy were both using a leave-one-subject-out cross-validation for small samples from the HCP dataset (126 subjects and 105 subjects). Recent studies reported lower accuracies when the number of samples increased. For example, <xref rid="B26" ref-type="bibr">He et al. (2020)</xref> reported prediction accuracies (Pearson’s correlation) ranging from 0.257 to 0.297 for fluid intelligence, about from 0.25 to 0.4 for reading and approximately from 0.2 to 0.4 for vocabulary, with four different models in the HCP dataset (953 subjects). <xref rid="B15" ref-type="bibr">Dubois et al. (2018)</xref> successfully predicted fluid intelligence (<italic>r</italic> = 0.27) using linear models in the HCP dataset (884 subjects). <xref rid="B34" ref-type="bibr">Kashyap et al. (2019)</xref> reported prediction accuracies of 58 behavioral measures, including fluid intelligence (<italic>r</italic> = 0.25), reading (about <italic>r</italic> = 0.37) and vocabulary (about <italic>r</italic> = 0.39) in the HCP dataset (803 subjects).</p>
        <p>It is worthy to note that all these methods are based on the sFC, assuming that the underlying connections remain unchanged over time. Here, we applied a CNN + LSTM model to learn the spatiotemporal information of the original dFC series. Importantly, combining the multiple 1D convolutional layers of different filters can learn the spatial associations of dFC at different time scales. And the stacked LSTM layers can capture latent temporal dynamics. As mentioned earlier, we achieved a gender classification accuracy of 93.05% and prediction accuracies (Pearson’s correlation) of 0.3129 and 0.4946 for fluid intelligence and crystallized intelligence, respectively. Overall, this indicates that our model prediction performance is among the best in the literature based on the same size dataset of rs-fMRI. Further, we employed an ablation control analysis to highlight necessity of the use of the LSTM module, i.e., we only retained the multi-scale 1D convolutional layer, one concatenation layer and one fully connected layer to reperform the intelligence prediction tasks. Other parameters are consistent with the CNN + LSTM model. As shown in <xref ref-type="supplementary-material" rid="SM1">Supplementary Figure S1</xref>, the multi-scale CNN model only achieved a significantly low prediction accuracy of crystallized intelligence (Pearson’s correlation <italic>r</italic> = 0.1866) and fluid intelligence (<italic>r</italic> = 0.1277), suggesting that the LSTM greatly contributed to the prediction of individual intelligence by capturing the temporal information of dFC time series.</p>
      </sec>
      <sec id="S4.SS2">
        <title>Effectiveness Analysis Using Surrogate Data</title>
        <p>So far, many dFC studies have employed MVPR model to generate surrogate data for detecting significance of dynamics in resting-state FC (<xref rid="B28" ref-type="bibr">Hindriks et al., 2016</xref>; <xref rid="B55" ref-type="bibr">Savva et al., 2019</xref>) by preserving statistical properties of the initial data such as stationary cross-correlation, i.e., static FC structure. Given that the dynamic information is removed in the surrogate data, the null hypothesis is that the model can achieve high classification or prediction accuracy in the absence of the dFC. However, our results demonstrate that the classification performances of surrogate copies are just better than random guessing, so that the null hypothesis should be rejected (<italic>p</italic> &lt; 0.0001). Moreover, the results from the feature analysis in the model also provide further evidence supporting this deduction, i.e., the features with high weights from the 1D convolution layer covered nearly half of those connections with significant dFC, especially those connections with the highest weights. These outcomes from the surrogate data suggest that the CNN + LSTM model can sufficiently learn temporal dynamics rather than only static structure in the FC.</p>
      </sec>
      <sec id="S4.SS3">
        <title>Important Networks of Gender and Intelligence Discrimination</title>
        <p>As shown in <xref ref-type="fig" rid="F4">Figure 4</xref>, the FC features within the DMN‘, frontoparietal and motor networks had a great contribution to gender classification, especially, the DMN has the highest inter-network and intra-network feature weights, which is generally consistent with previous structural and functional MRI studies (<xref rid="B76" ref-type="bibr">Zhang et al., 2018</xref>; <xref rid="B43" ref-type="bibr">Luo et al., 2019</xref>). However, the subcortical/cerebellum and visual networks are the majority of the least discriminative functional networks.</p>
        <p>Previous researches have shown that the DMN is related to many different functions like social understanding (<xref rid="B40" ref-type="bibr">Li et al., 2014</xref>), social cognitive abilities (<xref rid="B56" ref-type="bibr">Schilbach et al., 2008</xref>; <xref rid="B45" ref-type="bibr">Mars et al., 2012</xref>), and episodic memory (<xref rid="B58" ref-type="bibr">Sestieri et al., 2011</xref>). While many studies reported sex differences in behavioral measures. For example, women perform better than men on memory tasks (<xref rid="B27" ref-type="bibr">Hedges and Nowell, 1995</xref>) as well as measures of social cognition (<xref rid="B24" ref-type="bibr">Gur et al., 2010</xref>, <xref rid="B23" ref-type="bibr">2012</xref>; <xref rid="B46" ref-type="bibr">Moore et al., 2015</xref>). These results revealed the underlying associations between the DMN and gender.</p>
        <p>Besides the DMN, there were also other networks with high contributions to the gender classification. For instance, features with high weights for gender classification are prominent in the frontoparietal and motor networks. Also, the network-level average feature weight was illustrated in <xref ref-type="fig" rid="F5">Figure 5B</xref>, indicating that the intra-network and inter-network weights of the motor and frontoparietal regions are slightly higher than other networks except for the DMN. Recent studies have also reported that most FC features within frontalparietal and sensorimotor networks are associated with gender differences (<xref rid="B75" ref-type="bibr">Zhang et al., 2016</xref>, <xref rid="B76" ref-type="bibr">2018</xref>). Additionally, the reliable gender difference in FC has been reported for the sensorimotor network (<xref rid="B68" ref-type="bibr">Weis et al., 2019</xref>).</p>
        <p>In the case of fluid intelligence and crystallized intelligence, we found stronger FC features are mostly associated with the frontoparietal network. This suggests that individual variability in intelligence is related to higher order systems that reflect individual cognitive ability than those of the primary systems. Similarly, <xref rid="B42" ref-type="bibr">Liu et al. (2018)</xref> found that dFC features of default mode, frontoparietal, and dorsal attention networks contributed predominantly to fluid intelligence and executive function. The frontoparietal network was also reported to be the most predictive of fluid intelligence (<xref rid="B19" ref-type="bibr">Finn et al., 2015</xref>). Moreover, many previous studies also reported that intelligence is related to the structural and functional properties of these networks, which are consistent with ours (<xref rid="B33" ref-type="bibr">Kanai and Rees, 2011</xref>; <xref rid="B8" ref-type="bibr">Cole et al., 2012</xref>). On the other hand, for the intelligence prediction tasks, all the networks have comparable average weights, suggesting strong evidence that more than one network accounts for the intelligence, consistent with the previous report that intelligence is related to functional coupling and structural connectivity across widespread brain regions (<xref rid="B7" ref-type="bibr">Choi et al., 2008</xref>).</p>
      </sec>
      <sec id="S4.SS4">
        <title>Effect of Parcellation Scheme and Sliding Window Width</title>
        <p>Several confounding factors, such as sliding window width and parcellation scheme, might influence prediction performance. As shown in <xref ref-type="fig" rid="F6">Figure 6</xref>, we investigated the impact of the parcellation scheme and sliding window width and found that most of the results remained robust. All the sliding window widths from 40 to 100 s could achieve a robust prediction performance, thus providing indirect evidence of dFC’s presence at different timescales (<xref rid="B55" ref-type="bibr">Savva et al., 2019</xref>). Intriguingly, the window width of 40 s achieved the best performance in gender classification and crystallized intelligence prediction tasks. The window width of 60 s in fluid intelligence prediction task achieved a slightly higher performance (<italic>r</italic> = 0.3172) than the window width of 40 s (<italic>r</italic> = 0.3129). These results suggested that the duration between 40 and 60 s could better capture dynamic information of fluctuations and decode the variability of individuals, in line with the previous findings (<xref rid="B60" ref-type="bibr">Shirer et al., 2012</xref>; <xref rid="B38" ref-type="bibr">Kucyi and Davis, 2014</xref>; <xref rid="B52" ref-type="bibr">Qin et al., 2015</xref>). However, the mean accuracies of gender classification based on the functional brain atlas of 160 ROIs and 264 ROIs were about 88 and 90.3%. The prediction accuracies of intelligence prediction tasks based on the functional brain atlas of 160 ROIs and 264 ROIs were 0.2758 and 0.3120 for fluid intelligence, 0.4283 and 0.4308 for crystallized intelligence, respectively. Reduction in gender classification and intelligence prediction accuracies compared to the 268-node functional parcellation suggests that a finer parcellation may detect more subtle individual variability and dynamics.</p>
        <fig id="F6" position="float">
          <label>FIGURE 6</label>
          <caption>
            <p>Impact of parcellation scheme and sliding window width on gender classification and intelligence prediction performance in control analysis. <bold>(A)</bold> Impact of sliding window width on gender classification. <bold>(B)</bold> Impact of parcellation scheme on gender classification. Box refers to median with 25 and 75th percentiles, and whiskers represent minimal to maximal values. <bold>(C)</bold> Impact of sliding window width on intelligence prediction. <bold>(D)</bold> Impact of parcellation scheme on intelligence prediction. The accuracy of intelligence prediction is evaluated with the Pearson’s correlation between predicted and observed intelligence scores of all subjects across all folds.</p>
          </caption>
          <graphic xlink:href="fnins-14-00881-g006"/>
        </fig>
      </sec>
      <sec id="S4.SS5">
        <title>Limitation and Conclusion</title>
        <p>Some limitations should be considered in the presented approach. Firstly, We used the gender classification task to demonstrate the effectiveness of the deep learning model, considering that gender is an accurate label and many recent studies have focused on gender classification (<xref rid="B63" ref-type="bibr">Smith et al., 2013</xref>; <xref rid="B37" ref-type="bibr">Ktena et al., 2018</xref>; <xref rid="B76" ref-type="bibr">Zhang et al., 2018</xref>). However, compared to SVM, the improvement (about 5%) of gender classification is considerate but still limited which may be caused by the ceiling effect of gender classification. A better way of evaluating the model is to extend the model to applications of individual diagnosis for typical mental disorders such as schizophrenia and depression. Many recent studies aimed to find neuroimaging-based biomarkers for disease diagnosis using deep learning techniques. For example, In our previous study (<xref rid="B74" ref-type="bibr">Zeng et al., 2018</xref>), the deep autoencoder network achieved an improvement (&gt;5.0%) in diagnosing schizophrenia across multiple imaging sites compared to other multi-site studies such as using linear classifiers (<xref rid="B62" ref-type="bibr">Skåtun et al., 2017</xref>). Furthermore, LSTM also shows potential capabilities in diagnosing disease. <xref rid="B16" ref-type="bibr">Dvornek et al. (2017)</xref> achieved a classification accuracy of 68.5% in discriminating autism spectrum disorders with LSTMs, which demonstrated a higher classification accuracy compared to previous studies (<xref rid="B21" ref-type="bibr">Ghiassian et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abraham et al., 2017</xref>). Overall, based on the findings of abnormal functional connectivities in psychiatric disorders (<xref rid="B9" ref-type="bibr">Damaraju et al., 2014</xref>; <xref rid="B70" ref-type="bibr">Yan et al., 2017</xref>; <xref rid="B74" ref-type="bibr">Zeng et al., 2018</xref>) and the potential abilities of deep learning in disease diagnosis, the CNN + LSTM model may have excellent prospects in assistant diagnosis of some mental disorders.</p>
        <p>Secondly, we applied the CNN + LSTM model to explore brain network dynamics only with rs-fMRI data. While multi-modalities fusion (e.g., combining electroencephalography measures) will be helpful for generating a more accurate model due to the higher temporal resolution of electroencephalography data relative to fMRI signals. Thirdly, interpretation of the LSTM model remains unclear but a critical field of research. We will further aim to interpret deep learning models in the future.</p>
        <p>In summary, this is the first time that original dFC series are successfully applied to discriminating individual cognitive ability or demographic characteristics such as sex, fluid, and crystallized intelligence. Furthermore, the high accuracies in these tasks indicated the effectiveness of the used model owing to the full use of the high-level spatiotemporal information of dFC. Also, the deconvolutional computation provides an interpretation of the deep learning methods. Our findings highlight that deep-chronnectome can capture the inherent dynamical interaction information of functional networks and provide the potentials for predicting individualized characterization of demographics and cognition traits.</p>
      </sec>
    </sec>
    <sec sec-type="data-availability" id="S5">
      <title>Data Availability Statement</title>
      <p>Publicly available datasets were analyzed in this study. This data can be found here: <ext-link ext-link-type="uri" xlink:href="https://www.humanconnectome.org">https://www.humanconnectome.org</ext-link>.</p>
    </sec>
    <sec id="S6">
      <title>Author Contributions</title>
      <p>DH and HS designed the study. JQ and LF performed the experiments. LF, JS, and HS discussed the results and contributed to the final manuscript. All authors contributed to the article and approved the submitted version.</p>
    </sec>
    <sec id="conf1">
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank the Human Connectome Project (HCP) for data collection and sharing. This research was supported by the National Science Foundation of China (61773391 and 61420106001).</p>
    </ack>
    <fn-group>
      <fn id="footnote1">
        <label>1</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>
        </p>
      </fn>
      <fn id="footnote2">
        <label>2</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm">http://www.csie.ntu.edu.tw/~cjlin/libsvm</ext-link>
        </p>
      </fn>
    </fn-group>
    <sec id="S8" sec-type="supplementary material">
      <title>Supplementary Material</title>
      <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fnins.2020.00881/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fnins.2020.00881/full#supplementary-material</ext-link></p>
      <supplementary-material content-type="local-data" id="SM1">
        <media xlink:href="Image_1.pdf">
          <caption>
            <p>Click here for additional data file.</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A.</given-names></name><name><surname>Milham</surname><given-names>M. P.</given-names></name><name><surname>Di Martino</surname><given-names>A.</given-names></name><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>Samaras</surname><given-names>D.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Deriving reproducible biomarkers from multi-site resting-state data: an autism-based example.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>147</volume>
<fpage>736</fpage>–<lpage>745</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.045</pub-id>
<pub-id pub-id-type="pmid">27865923</pub-id></mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akshoomoff</surname><given-names>N.</given-names></name><name><surname>Beaumont</surname><given-names>J. L.</given-names></name><name><surname>Bauer</surname><given-names>P. J.</given-names></name><name><surname>Dikmen</surname><given-names>S. S.</given-names></name><name><surname>Gershon</surname><given-names>R. C.</given-names></name><name><surname>Mungas</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>VIII. NIH Toolbox Cognition Battery (CB): composite scores of crystallized, fluid, and overall cognition.</article-title>
<source><italic>Monogr. Soc. Res Child Dev.</italic></source>
<volume>78</volume>
<fpage>119</fpage>–<lpage>132</lpage>. <pub-id pub-id-type="doi">10.1111/mono.12038</pub-id>
<pub-id pub-id-type="pmid">23952206</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>E. A.</given-names></name><name><surname>Damaraju</surname><given-names>E.</given-names></name><name><surname>Plis</surname><given-names>S. M.</given-names></name><name><surname>Erhardt</surname><given-names>E. B.</given-names></name><name><surname>Eichele</surname><given-names>T.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name></person-group> (<year>2014</year>). <article-title>Tracking whole-brain connectivity dynamics in the resting state.</article-title>
<source><italic>Cereb. Cortex</italic></source>
<volume>24</volume>
<fpage>663</fpage>–<lpage>676</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhs352</pub-id>
<pub-id pub-id-type="pmid">23146964</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battaglia</surname><given-names>D.</given-names></name><name><surname>Boudou</surname><given-names>T.</given-names></name><name><surname>Hansen</surname><given-names>E. C.</given-names></name><name><surname>Lombardo</surname><given-names>D.</given-names></name><name><surname>Chettouf</surname><given-names>S.</given-names></name><name><surname>Daffertshofer</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Dynamic functional connectivity between order and randomness and its evolution across the human adult lifespan.</article-title>
<source><italic>bioRxiv</italic></source> [Preprint]. <pub-id pub-id-type="doi">10.1101/107243</pub-id></mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Miller</surname><given-names>R.</given-names></name><name><surname>Pearlson</surname><given-names>G.</given-names></name><name><surname>Adalı</surname><given-names>T.</given-names></name></person-group> (<year>2014</year>). <article-title>The chronnectome: time-varying connectivity networks as the next frontier in fMRI data discovery.</article-title>
<source><italic>Neuron</italic></source>
<volume>84</volume>
<fpage>262</fpage>–<lpage>274</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.015</pub-id>
<pub-id pub-id-type="pmid">25374354</pub-id></mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C.</given-names></name><name><surname>Glover</surname><given-names>G. H.</given-names></name></person-group> (<year>2010</year>). <article-title>Time–frequency dynamics of resting-state brain connectivity measured with fMRI.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>50</volume>
<fpage>81</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.011</pub-id>
<pub-id pub-id-type="pmid">20006716</pub-id></mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>Y. Y.</given-names></name><name><surname>Shamosh</surname><given-names>N. A.</given-names></name><name><surname>Cho</surname><given-names>S. H.</given-names></name><name><surname>DeYoung</surname><given-names>C. G.</given-names></name><name><surname>Lee</surname><given-names>M. J.</given-names></name><name><surname>Lee</surname><given-names>J.-M.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Multiple bases of human intelligence revealed by cortical thickness and neural activation.</article-title>
<source><italic>J. Neurosci.</italic></source>
<volume>28</volume>
<fpage>10323</fpage>–<lpage>10329</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.3259-08.2008</pub-id>
<pub-id pub-id-type="pmid">18842891</pub-id></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname><given-names>M. W.</given-names></name><name><surname>Yarkoni</surname><given-names>T.</given-names></name><name><surname>Repovš</surname><given-names>G.</given-names></name><name><surname>Anticevic</surname><given-names>A.</given-names></name><name><surname>Braver</surname><given-names>T. S.</given-names></name></person-group> (<year>2012</year>). <article-title>Global connectivity of prefrontal cortex predicts cognitive control and intelligence.</article-title>
<source><italic>J. Neurosci.</italic></source>
<volume>32</volume>
<fpage>8988</fpage>–<lpage>8999</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.0536-12.2012</pub-id>
<pub-id pub-id-type="pmid">22745498</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damaraju</surname><given-names>E.</given-names></name><name><surname>Allen</surname><given-names>E.</given-names></name><name><surname>Belger</surname><given-names>A.</given-names></name><name><surname>Ford</surname><given-names>J.</given-names></name><name><surname>McEwen</surname><given-names>S.</given-names></name><name><surname>Mathalon</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Dynamic functional connectivity analysis reveals transient states of dysconnectivity in schizophrenia.</article-title>
<source><italic>Neuroimage Clin.</italic></source>
<volume>5</volume>
<fpage>298</fpage>–<lpage>308</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2014.07.003</pub-id>
<pub-id pub-id-type="pmid">25161896</pub-id></mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davison</surname><given-names>E. N.</given-names></name><name><surname>Turner</surname><given-names>B. O.</given-names></name><name><surname>Schlesinger</surname><given-names>K. J.</given-names></name><name><surname>Miller</surname><given-names>M. B.</given-names></name><name><surname>Grafton</surname><given-names>S. T.</given-names></name><name><surname>Bassett</surname><given-names>D. S.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Individual differences in dynamic functional brain connectivity across the human lifespan.</article-title>
<source><italic>PLoS Comput. biol.</italic></source>
<volume>12</volume>:<issue>e1005178</issue>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005178</pub-id>
<pub-id pub-id-type="pmid">27880785</pub-id></mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demirtaş</surname><given-names>M.</given-names></name><name><surname>Tornador</surname><given-names>C.</given-names></name><name><surname>Falcón</surname><given-names>C.</given-names></name><name><surname>López-Solà</surname><given-names>M.</given-names></name><name><surname>Hernández-Ribas</surname><given-names>R.</given-names></name><name><surname>Pujol</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Dynamic functional connectivity reveals altered variability in functional connectivity among patients with major depressive disorder.</article-title>
<source><italic>Hum Brain Map.</italic></source>
<volume>37</volume>
<fpage>2918</fpage>–<lpage>2930</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23215</pub-id>
<pub-id pub-id-type="pmid">27120982</pub-id></mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosenbach</surname><given-names>N. U. F.</given-names></name><name><surname>Nardos</surname><given-names>B.</given-names></name><name><surname>Cohen</surname><given-names>A. L.</given-names></name><name><surname>Fair</surname><given-names>D. A.</given-names></name><name><surname>Power</surname><given-names>J. D.</given-names></name><name><surname>Church</surname><given-names>J. A.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>Prediction of individual brain maturity using fMRI.</article-title>
<source><italic>Science</italic></source>
<volume>329</volume>
<fpage>1358</fpage>–<lpage>1361</lpage>. <pub-id pub-id-type="doi">10.1126/science.1194144</pub-id>
<pub-id pub-id-type="pmid">20829489</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douw</surname><given-names>L.</given-names></name><name><surname>Wakeman</surname><given-names>D. G.</given-names></name><name><surname>Tanaka</surname><given-names>N.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Stufflebeam</surname><given-names>S. M.</given-names></name></person-group> (<year>2016</year>). <article-title>State-dependent variability of dynamic functional connectivity between frontoparietal and default networks relates to cognitive flexibility.</article-title>
<source><italic>Neuroscience</italic></source>
<volume>339</volume>
<fpage>12</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroscience.2016.09.034</pub-id>
<pub-id pub-id-type="pmid">27687802</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>Y.</given-names></name><name><surname>Pearlson</surname><given-names>G. D.</given-names></name><name><surname>Lin</surname><given-names>D.</given-names></name><name><surname>Sui</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Salman</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Identifying dynamic functional connectivity biomarkers using GIG−ICA: application to schizophrenia, schizoaffective disorder, and psychotic bipolar disorder.</article-title>
<source><italic>Hum. Brain Map.</italic></source>
<volume>38</volume>
<fpage>2683</fpage>–<lpage>2708</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23553</pub-id>
<pub-id pub-id-type="pmid">28294459</pub-id></mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubois</surname><given-names>J.</given-names></name><name><surname>Galdi</surname><given-names>P.</given-names></name><name><surname>Han</surname><given-names>Y.</given-names></name><name><surname>Paul</surname><given-names>L. K.</given-names></name><name><surname>Adolphs</surname><given-names>R.</given-names></name></person-group> (<year>2018</year>). <article-title>Resting-state functional brain connectivity best predicts the personality dimension of openness to experience.</article-title>
<source><italic>Pers. Neurosci.</italic></source>
<volume>1</volume>:<issue>e6</issue>. <pub-id pub-id-type="doi">10.1017/pen.2018.8</pub-id>
<pub-id pub-id-type="pmid">30225394</pub-id></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dvornek</surname><given-names>N. C.</given-names></name><name><surname>Ventola</surname><given-names>P.</given-names></name><name><surname>Pelphrey</surname><given-names>K. A.</given-names></name><name><surname>Duncan</surname><given-names>J. S.</given-names></name></person-group> (<year>2017</year>). <source><italic>Identifying Autism from Resting-State fMRI Using Long Short-Term Memory Networks.</italic></source>
<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>, <fpage>362</fpage>–<lpage>370</lpage>.</mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elton</surname><given-names>A.</given-names></name><name><surname>Gao</surname><given-names>W.</given-names></name></person-group> (<year>2015</year>). <article-title>Task−related modulation of functional connectivity variability and its behavioral correlations.</article-title>
<source><italic>Hum. Brain Map.</italic></source>
<volume>36</volume>
<fpage>3260</fpage>–<lpage>3272</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22847</pub-id>
<pub-id pub-id-type="pmid">26015070</pub-id></mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fatima</surname><given-names>Z.</given-names></name><name><surname>Kovacevic</surname><given-names>N.</given-names></name><name><surname>Misic</surname><given-names>B.</given-names></name><name><surname>Mcintosh</surname><given-names>A. R.</given-names></name></person-group> (<year>2016</year>). <article-title>Dynamic functional connectivity shapes individual differences in associative learning.</article-title>
<source><italic>Hum. Brain Map.</italic></source>
<volume>37</volume>
<fpage>3911</fpage>–<lpage>3928</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23285</pub-id>
<pub-id pub-id-type="pmid">27353970</pub-id></mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>E. S.</given-names></name><name><surname>Shen</surname><given-names>X.</given-names></name><name><surname>Scheinost</surname><given-names>D.</given-names></name><name><surname>Rosenberg</surname><given-names>M. D.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Chun</surname><given-names>M. M.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity.</article-title>
<source><italic>Nat. Neurosci.</italic></source>
<volume>18</volume>
<fpage>1664</fpage>–<lpage>1671</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4135</pub-id>
<pub-id pub-id-type="pmid">26457551</pub-id></mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>2011</year>). <article-title>Functional and effective connectivity: a review.</article-title>
<source><italic>Brain Connect.</italic></source>
<volume>1</volume>
<fpage>13</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1089/brain.2011.0008</pub-id>
<pub-id pub-id-type="pmid">22432952</pub-id></mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghiassian</surname><given-names>S.</given-names></name><name><surname>Greiner</surname><given-names>R.</given-names></name><name><surname>Jin</surname><given-names>P.</given-names></name><name><surname>Brown</surname><given-names>M. R.</given-names></name></person-group> (<year>2016</year>). <article-title>Using functional or structural magnetic resonance images and personal characteristic data to identify ADHD and autism.</article-title>
<source><italic>PloS One</italic></source>
<volume>11</volume>:<issue>e0166934</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0166934</pub-id>
<pub-id pub-id-type="pmid">28030565</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name><name><surname>Wilson</surname><given-names>J. A.</given-names></name><name><surname>Coalson</surname><given-names>T. S.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Andersson</surname><given-names>J. L.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>The minimal preprocessing pipelines for the human connectome project.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>80</volume>
<fpage>105</fpage>–<lpage>124</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id>
<pub-id pub-id-type="pmid">23668970</pub-id></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gur</surname><given-names>R. C.</given-names></name><name><surname>Richard</surname><given-names>J.</given-names></name><name><surname>Calkins</surname><given-names>M. E.</given-names></name><name><surname>Chiavacci</surname><given-names>R.</given-names></name><name><surname>Hansen</surname><given-names>J. A.</given-names></name><name><surname>Bilker</surname><given-names>W. B.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Age group and sex differences in performance on a computerized neurocognitive battery in children age 8-21.</article-title>
<source><italic>Neuropsychology</italic></source>
<volume>26</volume>
<fpage>251</fpage>–<lpage>265</lpage>. <pub-id pub-id-type="doi">10.1037/a0026712</pub-id>
<pub-id pub-id-type="pmid">22251308</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gur</surname><given-names>R. C.</given-names></name><name><surname>Richard</surname><given-names>J.</given-names></name><name><surname>Hughett</surname><given-names>P.</given-names></name><name><surname>Calkins</surname><given-names>M. E.</given-names></name><name><surname>Macy</surname><given-names>L.</given-names></name><name><surname>Bilker</surname><given-names>W. B.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>A cognitive neuroscience-based computerized battery for efficient measurement of individual differences: standardization and initial construct validation.</article-title>
<source><italic>J. Neurosci. Methods</italic></source>
<volume>187</volume>
<fpage>254</fpage>–<lpage>262</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2009.11.017</pub-id>
<pub-id pub-id-type="pmid">19945485</pub-id></mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname><given-names>E. C.</given-names></name><name><surname>Battaglia</surname><given-names>D.</given-names></name><name><surname>Spiegler</surname><given-names>A.</given-names></name><name><surname>Deco</surname><given-names>G.</given-names></name><name><surname>Jirsa</surname><given-names>V. K.</given-names></name></person-group> (<year>2015</year>). <article-title>Functional connectivity dynamics: modeling the switching behavior of the resting state.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>105</volume>
<fpage>525</fpage>–<lpage>535</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.11.001</pub-id>
<pub-id pub-id-type="pmid">25462790</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>T.</given-names></name><name><surname>Kong</surname><given-names>R.</given-names></name><name><surname>Holmes</surname><given-names>A. J.</given-names></name><name><surname>Nguyen</surname><given-names>M.</given-names></name><name><surname>Sabuncu</surname><given-names>M. R.</given-names></name><name><surname>Eickhoff</surname><given-names>S. B.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Deep neural networks and kernel regression achieve comparable accuracies for functional connectivity prediction of behavior and demographics.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>206</volume>
<issue>116276</issue>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116276</pub-id>
<pub-id pub-id-type="pmid">31610298</pub-id></mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hedges</surname><given-names>L. V.</given-names></name><name><surname>Nowell</surname><given-names>A.</given-names></name></person-group> (<year>1995</year>). <article-title>Sex differences in mental test scores, variability, and numbers of high-scoring individuals.</article-title>
<source><italic>Science</italic></source>
<volume>269</volume>
<fpage>41</fpage>–<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1126/science.7604277</pub-id>
<pub-id pub-id-type="pmid">7604277</pub-id></mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hindriks</surname><given-names>R.</given-names></name><name><surname>Adhikari</surname><given-names>M. H.</given-names></name><name><surname>Murayama</surname><given-names>Y.</given-names></name><name><surname>Ganzetti</surname><given-names>M.</given-names></name><name><surname>Mantini</surname><given-names>D.</given-names></name><name><surname>Logothetis</surname><given-names>N. K.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Can sliding-window correlations reveal dynamic functional connectivity in resting-state fMRI? (vol 127, pg 242, 2016).</article-title>
<source><italic>Neuroimage</italic></source>
<volume>132</volume>
<fpage>115</fpage>–<lpage>115</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.02.007</pub-id>
<pub-id pub-id-type="pmid">27131042</pub-id></mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>H.</given-names></name><name><surname>Hu</surname><given-names>X.</given-names></name><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Makkie</surname><given-names>M.</given-names></name><name><surname>Dong</surname><given-names>Q.</given-names></name><name><surname>Zhao</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Modeling task fMRI data via deep convolutional autoencoder.</article-title>
<source><italic>IEEE Trans. Med. Imaging</italic></source>
<volume>37</volume>
<fpage>1551</fpage>–<lpage>1561</lpage>. <pub-id pub-id-type="doi">10.1109/tmi.2017.2715285</pub-id>
<pub-id pub-id-type="pmid">28641247</pub-id></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchison</surname><given-names>R. M.</given-names></name><name><surname>Womelsdorf</surname><given-names>T.</given-names></name><name><surname>Allen</surname><given-names>E. A.</given-names></name><name><surname>Bandettini</surname><given-names>P. A.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Corbetta</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Dynamic functional connectivity: promises, issues, and interpretations.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>80</volume>
<fpage>360</fpage>–<lpage>378</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.079</pub-id>
<pub-id pub-id-type="pmid">23707587</pub-id></mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchison</surname><given-names>R. M.</given-names></name><name><surname>Womelsdorf</surname><given-names>T.</given-names></name><name><surname>Gati</surname><given-names>J. S.</given-names></name><name><surname>Everling</surname><given-names>S.</given-names></name><name><surname>Menon</surname><given-names>R. S.</given-names></name></person-group> (<year>2012</year>). <article-title>Resting−state networks show dynamic functional connectivity in awake humans and anesthetized macaques.</article-title>
<source><italic>Hum. Brain Map.</italic></source>
<volume>34</volume>
<fpage>2154</fpage>–<lpage>2177</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22058</pub-id>
<pub-id pub-id-type="pmid">22438275</pub-id></mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>D. T.</given-names></name><name><surname>Vemuri</surname><given-names>P.</given-names></name><name><surname>Murphy</surname><given-names>M. C.</given-names></name><name><surname>Gunter</surname><given-names>J. L.</given-names></name><name><surname>Senjem</surname><given-names>M. L.</given-names></name><name><surname>Machulda</surname><given-names>M. M.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Non-stationarity in the “resting brain’s” modular architecture.</article-title>
<source><italic>PLoS One</italic></source>
<volume>7</volume>:<issue>e39731</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0039731</pub-id>
<pub-id pub-id-type="pmid">22761880</pub-id></mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanai</surname><given-names>R.</given-names></name><name><surname>Rees</surname><given-names>G.</given-names></name></person-group> (<year>2011</year>). <article-title>The structural basis of inter-individual differences in human behaviour and cognition.</article-title>
<source><italic>Nat. Rev. Neurosci.</italic></source>
<volume>12</volume>
<fpage>231</fpage>–<lpage>242</lpage>. <pub-id pub-id-type="doi">10.1038/nrn3000</pub-id>
<pub-id pub-id-type="pmid">21407245</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kashyap</surname><given-names>R.</given-names></name><name><surname>Kong</surname><given-names>R.</given-names></name><name><surname>Bhattacharjee</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Thomas Yeo</surname><given-names>B. T.</given-names></name></person-group> (<year>2019</year>). <article-title>Individual-specific fMRI-Subspaces improve functional connectivity prediction of behavior.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>189</volume>
<fpage>804</fpage>–<lpage>812</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.01.069</pub-id>
<pub-id pub-id-type="pmid">30711467</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiviniemi</surname><given-names>V.</given-names></name><name><surname>Vire</surname><given-names>T.</given-names></name><name><surname>Remes</surname><given-names>J.</given-names></name><name><surname>Elseoud</surname><given-names>A. A.</given-names></name><name><surname>Starck</surname><given-names>T.</given-names></name><name><surname>Tervonen</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>A sliding time-window ICA reveals spatial variability of the default mode network in time.</article-title>
<source><italic>Brain Connect.</italic></source>
<volume>1</volume>
<fpage>339</fpage>–<lpage>347</lpage>. <pub-id pub-id-type="doi">10.1089/brain.2011.0036</pub-id>
<pub-id pub-id-type="pmid">22432423</pub-id></mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Orban</surname><given-names>C.</given-names></name><name><surname>Sabuncu</surname><given-names>M. R.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Schaefer</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Spatial topography of individual-specific cortical networks predicts human cognition, personality, and emotion.</article-title>
<source><italic>Cereb. Cortex</italic></source>
<volume>29</volume>
<fpage>2533</fpage>–<lpage>2551</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhy123</pub-id>
<pub-id pub-id-type="pmid">29878084</pub-id></mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ktena</surname><given-names>S. I.</given-names></name><name><surname>Parisot</surname><given-names>S.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Rajchl</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Glocker</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Metric learning with spectral graph convolutions on brain connectivity networks.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>169</volume>
<fpage>431</fpage>–<lpage>442</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.12.052</pub-id>
<pub-id pub-id-type="pmid">29278772</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kucyi</surname><given-names>A.</given-names></name><name><surname>Davis</surname><given-names>K. D.</given-names></name></person-group> (<year>2014</year>). <article-title>Dynamic functional connectivity of the default mode network tracks daydreaming.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>100</volume>
<fpage>471</fpage>–<lpage>480</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.044</pub-id>
<pub-id pub-id-type="pmid">24973603</pub-id></mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Q.</given-names></name><name><surname>Dong</surname><given-names>Q.</given-names></name><name><surname>Ge</surname><given-names>F.</given-names></name><name><surname>Qiang</surname><given-names>N.</given-names></name><name><surname>Zhao</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2019</year>). “<article-title>Simultaneous spatial-temporal decomposition of connectome-scale brain networks by deep sparse recurrent auto-encoders</article-title>,” in <source><italic>Proceedings of the International Conference on Information Processing in Medical Imaging</italic></source>, (<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>579</fpage>–<lpage>591</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-20351-1_45</pub-id></mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Mai</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name></person-group> (<year>2014</year>). <article-title>The default mode network and social understanding of others: what do brain connectivity studies tell us.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>8</volume>:<issue>74</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2014.00074</pub-id>
<pub-id pub-id-type="pmid">24605094</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liégeois</surname><given-names>R.</given-names></name><name><surname>Laumann</surname><given-names>T. O.</given-names></name><name><surname>Snyder</surname><given-names>A. Z.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Yeo</surname><given-names>B. T. T.</given-names></name></person-group> (<year>2017</year>). <article-title>Interpreting temporal fluctuations in resting-state functional connectivity MRI.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>163</volume>
<fpage>437</fpage>–<lpage>455</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.09.012</pub-id>
<pub-id pub-id-type="pmid">28916180</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Liao</surname><given-names>X.</given-names></name><name><surname>Xia</surname><given-names>M.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name></person-group> (<year>2018</year>). <article-title>Chronnectome fingerprinting: identifying individuals and predicting higher cognitive functions using dynamic brain connectivity patterns.</article-title>
<source><italic>Hum. Brain Map.</italic></source>
<volume>39</volume>
<fpage>902</fpage>–<lpage>915</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23890</pub-id>
<pub-id pub-id-type="pmid">29143409</pub-id></mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>Z.</given-names></name><name><surname>Hou</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Hu</surname><given-names>D.</given-names></name></person-group> (<year>2019</year>). <article-title>Gender identification of human cortical 3-D morphology using hierarchical sparsity.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>13</volume>:<issue>e00029</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2019.00029</pub-id>
<pub-id pub-id-type="pmid">30792634</pub-id></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madhyastha</surname><given-names>T. M.</given-names></name><name><surname>Askren</surname><given-names>M. K.</given-names></name><name><surname>Boord</surname><given-names>P.</given-names></name><name><surname>Grabowski</surname><given-names>T. J.</given-names></name></person-group> (<year>2015</year>). <article-title>Dynamic connectivity at rest predicts attention task performance.</article-title>
<source><italic>Brain Connect.</italic></source>
<volume>5</volume>
<fpage>45</fpage>–<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1089/brain.2014.0248</pub-id>
<pub-id pub-id-type="pmid">25014419</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mars</surname><given-names>R.</given-names></name><name><surname>Neubert</surname><given-names>F.-X.</given-names></name><name><surname>Noonan</surname><given-names>M.</given-names></name><name><surname>Sallet</surname><given-names>J.</given-names></name><name><surname>Toni</surname><given-names>I.</given-names></name><name><surname>Rushworth</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>On the relationship between the “default mode network” and the “social brain”.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>6</volume>:<issue>e00189</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2012.00189</pub-id>
<pub-id pub-id-type="pmid">22737119</pub-id></mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>T. M.</given-names></name><name><surname>Reise</surname><given-names>S. P.</given-names></name><name><surname>Gur</surname><given-names>R. E.</given-names></name><name><surname>Hakonarson</surname><given-names>H.</given-names></name><name><surname>Gur</surname><given-names>R. C.</given-names></name></person-group> (<year>2015</year>). <article-title>Psychometric properties of the penn computerized neurocognitive battery.</article-title>
<source><italic>Neuropsychology</italic></source>
<volume>29</volume>
<fpage>235</fpage>–<lpage>246</lpage>. <pub-id pub-id-type="doi">10.1037/neu0000093</pub-id>
<pub-id pub-id-type="pmid">25180981</pub-id></mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Chintala</surname><given-names>S.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><name><surname>Yang</surname><given-names>E.</given-names></name><name><surname>DeVito</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Automatic differentiation in pytorch.</article-title>
<source><italic>NIPS-W</italic></source>.</mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedersen</surname><given-names>M.</given-names></name><name><surname>Zalesky</surname><given-names>A.</given-names></name><name><surname>Omidvarnia</surname><given-names>A.</given-names></name><name><surname>Jackson</surname><given-names>G. D.</given-names></name></person-group> (<year>2018</year>). <article-title>Brain connectivity dynamics: multilayer network switching rate predicts brain performance.</article-title>
<source><italic>bioRxiv</italic></source>
<comment>[Preprint]</comment>
<pub-id pub-id-type="doi">10.1101/403105</pub-id></mixed-citation>
      </ref>
      <ref id="B49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereda</surname><given-names>E.</given-names></name><name><surname>Quiroga</surname><given-names>R. Q.</given-names></name><name><surname>Bhattacharya</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>). <article-title>Nonlinear multivariate analysis of neurophysiological signals.</article-title>
<source><italic>Prog. Neurobiol.</italic></source>
<volume>77</volume>
<fpage>1</fpage>–<lpage>37</lpage>. <pub-id pub-id-type="doi">10.1016/j.pneurobio.2005.10.003</pub-id>
<pub-id pub-id-type="pmid">16289760</pub-id></mixed-citation>
      </ref>
      <ref id="B50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>J. D.</given-names></name><name><surname>Cohen</surname><given-names>A. L.</given-names></name><name><surname>Nelson</surname><given-names>S. M.</given-names></name><name><surname>Wig</surname><given-names>G. S.</given-names></name><name><surname>Barnes</surname><given-names>K. A.</given-names></name><name><surname>Church</surname><given-names>J. A.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Functional network organization of the human brain.</article-title>
<source><italic>Neuron</italic></source>
<volume>72</volume>
<fpage>665</fpage>–<lpage>678</lpage>.<pub-id pub-id-type="pmid">22099467</pub-id></mixed-citation>
      </ref>
      <ref id="B51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prichard</surname><given-names>D.</given-names></name><name><surname>Theiler</surname><given-names>J.</given-names></name></person-group> (<year>1994</year>). <article-title>Generating surrogate data for time series with several simultaneously measured variables.</article-title>
<source><italic>Phys. Rev. Lett.</italic></source>
<volume>73</volume>
<fpage>951</fpage>–<lpage>954</lpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.73.951</pub-id>
<pub-id pub-id-type="pmid">10057582</pub-id></mixed-citation>
      </ref>
      <ref id="B52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>S.-G.</given-names></name><name><surname>Hu</surname><given-names>D.</given-names></name><name><surname>Zeng</surname><given-names>L.-L.</given-names></name><name><surname>Fan</surname><given-names>Y.-M.</given-names></name><name><surname>Chen</surname><given-names>X.-P.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Predicting individual brain maturity using dynamic functional connectivity.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>9</volume>:<issue>e00418</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2015.00418</pub-id>
<pub-id pub-id-type="pmid">26236224</pub-id></mixed-citation>
      </ref>
      <ref id="B53">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>S.</given-names></name><name><surname>Kiral-Kornek</surname><given-names>I.</given-names></name><name><surname>Harrer</surname><given-names>S.</given-names></name></person-group> (<year>2019</year>). <source><italic>ChronoNet: A Deep Recurrent Neural Network for Abnormal EEG Identification.</italic></source>
<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>, <fpage>47</fpage>–<lpage>56</lpage>.</mixed-citation>
      </ref>
      <ref id="B54">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakoğlu</surname><given-names>Ü</given-names></name><name><surname>Pearlson</surname><given-names>G. D.</given-names></name><name><surname>Kiehl</surname><given-names>K. A.</given-names></name><name><surname>Wang</surname><given-names>Y. M.</given-names></name><name><surname>Michael</surname><given-names>A. M.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name></person-group> (<year>2010</year>). <article-title>A method for evaluating dynamic functional network connectivity and task-modulation: application to schizophrenia.</article-title>
<source><italic>MAGMA</italic></source>
<volume>23</volume>
<fpage>351</fpage>–<lpage>366</lpage>. <pub-id pub-id-type="doi">10.1007/s10334-010-0197-8</pub-id>
<pub-id pub-id-type="pmid">20162320</pub-id></mixed-citation>
      </ref>
      <ref id="B55">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savva</surname><given-names>A. D.</given-names></name><name><surname>Mitsis</surname><given-names>G. D.</given-names></name><name><surname>Matsopoulos</surname><given-names>G. K.</given-names></name></person-group> (<year>2019</year>). <article-title>Assessment of dynamic functional connectivity in resting-state fMRI using the sliding window technique.</article-title>
<source><italic>Brain Behav.</italic></source>
<volume>9</volume>:<issue>e01255</issue>. <pub-id pub-id-type="doi">10.1002/brb3.1255</pub-id>
<pub-id pub-id-type="pmid">30884215</pub-id></mixed-citation>
      </ref>
      <ref id="B56">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schilbach</surname><given-names>L.</given-names></name><name><surname>Eickhoff</surname><given-names>S. B.</given-names></name><name><surname>Rotarska-Jagiela</surname><given-names>A.</given-names></name><name><surname>Fink</surname><given-names>G. R.</given-names></name><name><surname>Vogeley</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Minds at rest? Social cognition as the default mode of cognizing and its putative relationship to the “default system” of the brain.</article-title>
<source><italic>Conscious. Cogn.</italic></source>
<volume>17</volume>
<fpage>457</fpage>–<lpage>467</lpage>. <pub-id pub-id-type="doi">10.1016/j.concog.2008.03.013</pub-id>
<pub-id pub-id-type="pmid">18434197</pub-id></mixed-citation>
      </ref>
      <ref id="B57">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreiber</surname><given-names>T.</given-names></name><name><surname>Schmitz</surname><given-names>A.</given-names></name></person-group> (<year>2000</year>). <article-title>Surrogate time series.</article-title>
<source><italic>Physica D</italic></source>
<volume>142</volume>
<fpage>346</fpage>–<lpage>382</lpage>. <pub-id pub-id-type="doi">10.1016/S0167-2789(00)00043-49</pub-id></mixed-citation>
      </ref>
      <ref id="B58">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sestieri</surname><given-names>C.</given-names></name><name><surname>Corbetta</surname><given-names>M.</given-names></name><name><surname>Romani</surname><given-names>G. L.</given-names></name><name><surname>Shulman</surname><given-names>G. L.</given-names></name></person-group> (<year>2011</year>). <article-title>Episodic memory retrieval, parietal cortex, and the default mode network: functional and topographic analyses.</article-title>
<source><italic>J. Neurosci.</italic></source>
<volume>31</volume>
<fpage>4407</fpage>–<lpage>4420</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.3335-10.2011</pub-id>
<pub-id pub-id-type="pmid">21430142</pub-id></mixed-citation>
      </ref>
      <ref id="B59">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>X.</given-names></name><name><surname>Tokoglu</surname><given-names>F.</given-names></name><name><surname>Papademetris</surname><given-names>X.</given-names></name><name><surname>Constable</surname><given-names>R. T.</given-names></name></person-group> (<year>2013</year>). <article-title>Groupwise whole-brain parcellation from resting-state fMRI data for network node identification.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>82</volume>
<fpage>403</fpage>–<lpage>415</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.081</pub-id>
<pub-id pub-id-type="pmid">23747961</pub-id></mixed-citation>
      </ref>
      <ref id="B60">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirer</surname><given-names>W.</given-names></name><name><surname>Ryali</surname><given-names>S.</given-names></name><name><surname>Rykhlevskaia</surname><given-names>E.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name><name><surname>Greicius</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>Decoding subject-driven cognitive states with whole-brain connectivity patterns.</article-title>
<source><italic>Cereb. Cortex</italic></source>
<volume>22</volume>
<fpage>158</fpage>–<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr099</pub-id>
<pub-id pub-id-type="pmid">21616982</pub-id></mixed-citation>
      </ref>
      <ref id="B61">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>J. S.</given-names></name><name><surname>Mitra</surname><given-names>A.</given-names></name><name><surname>Laumann</surname><given-names>T. O.</given-names></name><name><surname>Seitzman</surname><given-names>B. A.</given-names></name><name><surname>Raichle</surname><given-names>M.</given-names></name><name><surname>Corbetta</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Data quality influences observed links between functional connectivity and behavior.</article-title>
<source><italic>Cereb. Cortex</italic></source>
<volume>27</volume>
<fpage>4492</fpage>–<lpage>4502</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhw253</pub-id>
<pub-id pub-id-type="pmid">27550863</pub-id></mixed-citation>
      </ref>
      <ref id="B62">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skåtun</surname><given-names>K. C.</given-names></name><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>Doan</surname><given-names>N. T.</given-names></name><name><surname>Alnæs</surname><given-names>D.</given-names></name><name><surname>Córdova-Palomera</surname><given-names>A.</given-names></name><name><surname>Jönsson</surname><given-names>E. G.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Consistent functional connectivity alterations in schizophrenia spectrum disorder: a multisite study.</article-title>
<source><italic>Schizophr. Bull.</italic></source>
<volume>43</volume>
<fpage>914</fpage>–<lpage>924</lpage>. <pub-id pub-id-type="doi">10.1093/schbul/sbw145</pub-id>
<pub-id pub-id-type="pmid">27872268</pub-id></mixed-citation>
      </ref>
      <ref id="B63">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Vidaurre</surname><given-names>D.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Miller</surname><given-names>K. L.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Functional connectomics from resting-state fMRI.</article-title>
<source><italic>Trend. Cogn. Sci.</italic></source>
<volume>17</volume>, <fpage>666</fpage>–<lpage>682</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2013.09.016</pub-id>
<pub-id pub-id-type="pmid">24238796</pub-id></mixed-citation>
      </ref>
      <ref id="B64">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>G. J.</given-names></name></person-group> (<year>2018</year>). <article-title>Neural and metabolic basis of dynamic resting state fMRI.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>180</volume>
<fpage>448</fpage>–<lpage>462</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.09.010</pub-id>
<pub-id pub-id-type="pmid">28899744</pub-id></mixed-citation>
      </ref>
      <ref id="B65">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tobia</surname><given-names>M. J.</given-names></name><name><surname>Hayashi</surname><given-names>K.</given-names></name><name><surname>Ballard</surname><given-names>G.</given-names></name><name><surname>Gotlib</surname><given-names>I. H.</given-names></name><name><surname>Waugh</surname><given-names>C. E.</given-names></name></person-group> (<year>2017</year>). <article-title>Dynamic functional connectivity and individual differences in emotions during social stress.</article-title>
<source><italic>Hum. Brain Map.</italic></source>
<volume>38</volume>
<fpage>6185</fpage>–<lpage>6205</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23821</pub-id>
<pub-id pub-id-type="pmid">28940859</pub-id></mixed-citation>
      </ref>
      <ref id="B66">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>D. C.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Barch</surname><given-names>D. M.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name><name><surname>Yacoub</surname><given-names>E.</given-names></name><name><surname>Ugurbil</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>The WU-Minn human connectome project: an overview.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>80</volume>
<fpage>62</fpage>–<lpage>79</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id>
<pub-id pub-id-type="pmid">23684880</pub-id></mixed-citation>
      </ref>
      <ref id="B67">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidaurre</surname><given-names>D.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name></person-group> (<year>2017</year>). <article-title>Brain network dynamics are hierarchically organized in time.</article-title>
<source><italic>Proc. Natl. Acad. Sci. U.S.A.</italic></source>
<volume>114</volume>
<fpage>12827</fpage>–<lpage>12832</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1705120114</pub-id>
<pub-id pub-id-type="pmid">29087305</pub-id></mixed-citation>
      </ref>
      <ref id="B68">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weis</surname><given-names>S.</given-names></name><name><surname>Hodgetts</surname><given-names>S.</given-names></name><name><surname>Hausmann</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>Sex differences and menstrual cycle effects in cognitive and sensory resting state networks.</article-title>
<source><italic>Brain Cogn.</italic></source>
<volume>131</volume>
<fpage>66</fpage>–<lpage>73</lpage>. <pub-id pub-id-type="doi">10.1016/j.bandc.2017.09.003</pub-id>
<pub-id pub-id-type="pmid">29030069</pub-id></mixed-citation>
      </ref>
      <ref id="B69">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>W.</given-names></name><name><surname>Calhoun</surname><given-names>V.</given-names></name><name><surname>Song</surname><given-names>M.</given-names></name><name><surname>Cui</surname><given-names>Y.</given-names></name><name><surname>Yan</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Discriminating schizophrenia using recurrent neural network applied on time courses of multi-site FMRI data.</article-title>
<source><italic>EBioMedicine</italic></source>
<volume>47</volume>
<fpage>543</fpage>–<lpage>552</lpage>. <pub-id pub-id-type="doi">10.1016/j.ebiom.2019.08.023</pub-id>
<pub-id pub-id-type="pmid">31420302</pub-id></mixed-citation>
      </ref>
      <ref id="B70">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>W.</given-names></name><name><surname>Plis</surname><given-names>S.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Jiang</surname><given-names>R.</given-names></name><name><surname>Jiang</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Discriminating schizophrenia from normal controls using resting state functional network connectivity: a deep neural network and layer-wise relevance propagation method</article-title>,” in <source><italic>Proceedings of the 2017 IEEE 27th International Workshop on Machine Learning for Signal Processing</italic></source>, (<publisher-loc>Piscataway, NJ</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>1</fpage>–<lpage>6</lpage>.</mixed-citation>
      </ref>
      <ref id="B71">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Luo</surname><given-names>L.</given-names></name><name><surname>Dong</surname><given-names>Q.</given-names></name><name><surname>Lv</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2018a</year>). <article-title>Spatio-temporal modeling of connectome-scale brain network interactions via time-evolving graphs.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>180</volume>
<fpage>350</fpage>–<lpage>369</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.067</pub-id>
<pub-id pub-id-type="pmid">29102809</pub-id></mixed-citation>
      </ref>
      <ref id="B72">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>L.</given-names></name><name><surname>Wei</surname><given-names>X.</given-names></name><name><surname>Shen</surname><given-names>H.</given-names></name><name><surname>Zeng</surname><given-names>L.</given-names></name><name><surname>Hu</surname><given-names>D.</given-names></name></person-group> (<year>2018b</year>). <article-title>Multi-Center Brain Imaging Classification Using a Novel 3D CNN Approach.</article-title>
<source><italic>IEEE Access</italic></source>
<volume>6</volume>
<fpage>49925</fpage>–<lpage>49934</lpage>. <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2868813</pub-id></mixed-citation>
      </ref>
      <ref id="B73">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zeiler</surname><given-names>M. D.</given-names></name><name><surname>Fergus</surname><given-names>R.</given-names></name></person-group> (<year>2014</year>). <source><italic>Visualizing and Understanding Convolutional Networks.</italic></source>
<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>, <fpage>818</fpage>–<lpage>833</lpage>.</mixed-citation>
      </ref>
      <ref id="B74">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>L.-L.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Hu</surname><given-names>P.</given-names></name><name><surname>Yang</surname><given-names>B.</given-names></name><name><surname>Pu</surname><given-names>W.</given-names></name><name><surname>Shen</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Multi-site diagnostic classification of schizophrenia using discriminant deep learning with functional connectivity MRI.</article-title>
<source><italic>EBioMedicine</italic></source>
<volume>30</volume>
<fpage>74</fpage>–<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1016/j.ebiom.2018.03.017</pub-id>
<pub-id pub-id-type="pmid">29622496</pub-id></mixed-citation>
      </ref>
      <ref id="B75">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Cahill</surname><given-names>N. D.</given-names></name><name><surname>Arbabshirani</surname><given-names>M. R.</given-names></name><name><surname>White</surname><given-names>T.</given-names></name><name><surname>Baum</surname><given-names>S. A.</given-names></name><name><surname>Michael</surname><given-names>A. M.</given-names></name></person-group> (<year>2016</year>). <article-title>Sex and age effects of functional connectivity in early adulthood.</article-title>
<source><italic>Brain Connect.</italic></source>
<volume>6</volume>
<fpage>700</fpage>–<lpage>713</lpage>. <pub-id pub-id-type="doi">10.1089/brain.2016.0429</pub-id>
<pub-id pub-id-type="pmid">27527561</pub-id></mixed-citation>
      </ref>
      <ref id="B76">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Dougherty</surname><given-names>C. C.</given-names></name><name><surname>Baum</surname><given-names>S. A.</given-names></name><name><surname>White</surname><given-names>T.</given-names></name><name><surname>Michael</surname><given-names>A. M.</given-names></name></person-group> (<year>2018</year>). <article-title>Functional connectivity predicts gender: evidence for gender differences in resting brain connectivity.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>39</volume>
<fpage>1765</fpage>–<lpage>1776</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23950</pub-id>
<pub-id pub-id-type="pmid">29322586</pub-id></mixed-citation>
      </ref>
      <ref id="B77">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Bo</surname><given-names>Q.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>X.</given-names></name></person-group> (<year>2017</year>). <article-title>The dynamic characteristics of the anterior cingulate cortex in resting-state fMRI of patients with depression.</article-title>
<source><italic>J. Affect Disord</italic></source>
<volume>227</volume>
<fpage>391</fpage>–<lpage>397</lpage>. <pub-id pub-id-type="doi">10.1016/j.jad.2017.11.026</pub-id>
<pub-id pub-id-type="pmid">29154155</pub-id></mixed-citation>
      </ref>
      <ref id="B78">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Gao</surname><given-names>W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Wu</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>). “<article-title>Reveal consistent spatial-temporal patterns from dynamic functional connectivity for autism spectrum disorder identification</article-title>,” in <source><italic>Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention</italic></source>, (<publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>106</fpage>–<lpage>114</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-46720-7_13</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
