<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1662-4548</issn>
      <issn pub-type="epub">1662-453X</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">37090813</article-id>
      <article-id pub-id-type="pmc">10117439</article-id>
      <article-id pub-id-type="doi">10.3389/fnins.2023.1140801</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Discriminative analysis of schizophrenia patients using graph convolutional networks: A combined multimodal MRI and connectomics analysis</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Xiaoyi</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="fn0003" ref-type="author-notes">
<sup>†</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/2176746/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ke</surname>
            <given-names>Pengfei</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="fn0003" ref-type="author-notes">
<sup>†</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Yuanyuan</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref>
          <xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/1067301/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Jing</given-names>
          </name>
          <xref rid="aff4" ref-type="aff">
<sup>4</sup>
</xref>
          <xref rid="aff5" ref-type="aff">
<sup>5</sup>
</xref>
          <xref rid="aff6" ref-type="aff">
<sup>6</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Hehua</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref>
          <xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/1903980/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>Runlin</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>Jiayuan</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/1517234/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>Liqin</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>Guolin</given-names>
          </name>
          <xref rid="aff7" ref-type="aff">
<sup>7</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/589439/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Xiaobo</given-names>
          </name>
          <xref rid="aff8" ref-type="aff">
<sup>8</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/49858/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ning</surname>
            <given-names>Yuping</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref>
          <xref rid="aff9" ref-type="aff">
<sup>9</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/406575/overview"/>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Wu</surname>
            <given-names>Fengchun</given-names>
          </name>
          <xref rid="aff10" ref-type="aff">
<sup>10</sup>
</xref>
          <xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/1011481/overview"/>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Wu</surname>
            <given-names>Kai</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="aff5" ref-type="aff">
<sup>5</sup>
</xref>
          <xref rid="aff6" ref-type="aff">
<sup>6</sup>
</xref>
          <xref rid="aff11" ref-type="aff">
<sup>11</sup>
</xref>
          <xref rid="c002" ref-type="corresp">
<sup>*</sup>
</xref>
          <uri xlink:href="https://loop.frontiersin.org/people/71591/overview"/>
        </contrib>
      </contrib-group>
      <aff id="aff1"><sup>1</sup><institution>Department of Biomedical Engineering, School of Biomedical Sciences and Engineering, South China University of Technology, Guangzhou International Campus</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff2"><sup>2</sup><institution>Department of Emotional Disorders, The Affiliated Brain Hospital of Guangzhou Medical University</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff3"><sup>3</sup><institution>Guangdong Engineering Technology Research Center for Translational Medicine of Mental Disorders</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff4"><sup>4</sup><institution>School of Material Science and Engineering, South China University of Technology</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff5"><sup>5</sup><institution>National Engineering Research Center for Tissue Restoration and Reconstruction, South China University of Technology</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff6"><sup>6</sup><institution>Guangdong Province Key Laboratory of Biomedical Engineering, South China University of Technology</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff7"><sup>7</sup><institution>Department of Radiology, China-Japan Friendship Hospital</institution>, <addr-line>Beijing</addr-line>, <country>China</country></aff>
      <aff id="aff8"><sup>8</sup><institution>Department of Biomedical Engineering, New Jersey Institute of Technology</institution>, <addr-line>Newark, NJ</addr-line>, <country>United States</country></aff>
      <aff id="aff9"><sup>9</sup><institution>Department of Psychosomatic, The Affiliated Brain Hospital of Guangzhou Medical University</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff10"><sup>10</sup><institution>Department of Psychiatry, The Affiliated Brain Hospital of Guangzhou Medical University</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff11"><sup>11</sup><institution>Department of Nuclear Medicine and Radiology, Institute of Development, Aging and Cancer, Tohoku University</institution>, <addr-line>Sendai</addr-line>, <country>Japan</country></aff>
      <author-notes>
        <fn id="fn0001" fn-type="edited-by">
          <p>Edited by: Hongjian He, Zhejiang University, China</p>
        </fn>
        <fn id="fn0002" fn-type="edited-by">
          <p>Reviewed by: Huaiqiang Sun, Sichuan University, China; Christiane Thielemann, Aschaffenburg University of Applied Sciences, Germany</p>
        </fn>
        <corresp id="c001">*Correspondence: Fengchun Wu, <email>13580380071@163.com</email></corresp>
        <corresp id="c002">Kai Wu, <email>kaiwu@scut.edu.cn</email></corresp>
        <fn id="fn0003" fn-type="equal">
          <p><sup>†</sup>These authors have contributed equally to this work</p>
        </fn>
        <fn id="fn0004" fn-type="other">
          <p>This article was submitted to Translational Neuroscience, a section of the journal Frontiers in Neuroscience</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>30</day>
        <month>3</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2023</year>
      </pub-date>
      <volume>17</volume>
      <elocation-id>1140801</elocation-id>
      <history>
        <date date-type="received">
          <day>09</day>
          <month>1</month>
          <year>2023</year>
        </date>
        <date date-type="accepted">
          <day>10</day>
          <month>3</month>
          <year>2023</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2023 Chen, Ke, Huang, Zhou, Li, Peng, Huang, Liang, Ma, Li, Ning, Wu and Wu.</copyright-statement>
        <copyright-year>2023</copyright-year>
        <copyright-holder>Chen, Ke, Huang, Zhou, Li, Peng, Huang, Liang, Ma, Li, Ning, Wu and Wu</copyright-holder>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <sec>
          <title>Introduction</title>
          <p>Recent studies in human brain connectomics with multimodal magnetic resonance imaging (MRI) data have widely reported abnormalities in brain structure, function and connectivity associated with schizophrenia (SZ). However, most previous discriminative studies of SZ patients were based on MRI features of brain regions, ignoring the complex relationships within brain networks.</p>
        </sec>
        <sec>
          <title>Methods</title>
          <p>We applied a graph convolutional network (GCN) to discriminating SZ patients using the features of brain region and connectivity derived from a combined multimodal MRI and connectomics analysis. Structural magnetic resonance imaging (sMRI) and resting-state functional magnetic resonance imaging (rs-fMRI) data were acquired from 140 SZ patients and 205 normal controls. Eighteen types of brain graphs were constructed for each subject using 3 types of node features, 3 types of edge features, and 2 brain atlases. We investigated the performance of 18 brain graphs and used the TopK pooling layers to highlight salient brain regions (nodes in the graph).</p>
        </sec>
        <sec>
          <title>Results</title>
          <p>The GCN model, which used functional connectivity as edge features and multimodal features (sMRI + fMRI) of brain regions as node features, obtained the highest average accuracy of 95.8%, and outperformed other existing classification studies in SZ patients. In the explainability analysis, we reported that the top 10 salient brain regions, predominantly distributed in the prefrontal and occipital cortices, were mainly involved in the systems of emotion and visual processing.</p>
        </sec>
        <sec>
          <title>Discussion</title>
          <p>Our findings demonstrated that GCN with a combined multimodal MRI and connectomics analysis can effectively improve the classification of SZ at an individual level, indicating a promising direction for the diagnosis of SZ patients. The code is available at <ext-link xlink:href="https://github.com/CXY-scut/GCN-SZ.git" ext-link-type="uri">https://github.com/CXY-scut/GCN-SZ.git</ext-link>.</p>
        </sec>
      </abstract>
      <kwd-group>
        <kwd>schizophrenia</kwd>
        <kwd>graph convolutional network</kwd>
        <kwd>discriminative analysis</kwd>
        <kwd>human brain connectomics</kwd>
        <kwd>multimodal MRI</kwd>
      </kwd-group>
      <funding-group>
        <award-group>
          <funding-source id="cn1">
            <institution-wrap>
              <institution>National Key Research and Development Program of China</institution>
              <institution-id institution-id-type="doi">10.13039/501100012166</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id award-type="contract" rid="cn1">2021YFC2009400</award-id>
          <award-id award-type="contract" rid="cn1">2021YFC2009404</award-id>
        </award-group>
        <award-group>
          <funding-source id="cn2">
            <institution-wrap>
              <institution>National Natural Science Foundation of China</institution>
              <institution-id institution-id-type="doi">10.13039/501100001809</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id award-type="contract" rid="cn2">72174082</award-id>
          <award-id award-type="contract" rid="cn2">82271953</award-id>
          <award-id award-type="contract" rid="cn2">81971585</award-id>
        </award-group>
        <award-group>
          <funding-source id="cn3">Guangdong Basic and Applied Basic Research Foundation Outstanding Youth Project</funding-source>
          <award-id award-type="contract" rid="cn3">2021B1515020064</award-id>
        </award-group>
        <award-group>
          <funding-source id="cn4">
            <institution-wrap>
              <institution>Research and Development</institution>
              <institution-id institution-id-type="doi">10.13039/100006190</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id award-type="contract" rid="cn4">2018B030335001</award-id>
          <award-id award-type="contract" rid="cn4">2020B0101130020</award-id>
          <award-id award-type="contract" rid="cn4">2020B0404010002</award-id>
        </award-group>
        <award-group>
          <funding-source id="cn5">Guangdong Basic and Applied Basic Research Foundation</funding-source>
          <award-id award-type="contract" rid="cn5">2019A1515110427</award-id>
        </award-group>
        <award-group>
          <funding-source id="cn6">Science and Technology Program of Guangzhou</funding-source>
          <award-id award-type="contract" rid="cn6">201903010032</award-id>
          <award-id award-type="contract" rid="cn6">202103000032</award-id>
          <award-id award-type="contract" rid="cn6">202206060005</award-id>
          <award-id award-type="contract" rid="cn6">202206080005</award-id>
          <award-id award-type="contract" rid="cn6">202206010077</award-id>
          <award-id award-type="contract" rid="cn6">202206010034</award-id>
        </award-group>
        <award-group>
          <funding-source id="cn7">Key Laboratory Program of Guangdong Provincial Education Department</funding-source>
          <award-id award-type="contract" rid="cn7">2020KSYS001</award-id>
        </award-group>
      </funding-group>
      <counts>
        <fig-count count="5"/>
        <table-count count="6"/>
        <equation-count count="6"/>
        <ref-count count="56"/>
        <page-count count="13"/>
        <word-count count="10116"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro" id="sec1">
      <label>1.</label>
      <title>Introduction</title>
      <p>Schizophrenia (SZ), a severe and disabling psychiatric disease with visual and auditory hallucinations along with disorganized speech and thoughts as the common symptoms, has been a key focus of neuroimaging research for decades (<xref rid="ref36" ref-type="bibr">Rossler et al., 2005</xref>; <xref rid="ref41" ref-type="bibr">Tost and Meyer-Lindenberg, 2012</xref>). The diagnosis of SZ patients solely based on clinical observation may lack objectivity and accuracy because of the heterogeneous and complex clinical characteristics (<xref rid="ref41" ref-type="bibr">Tost and Meyer-Lindenberg, 2012</xref>). Magnetic resonance imaging (MRI), as an exciting noninvasive tool to study the brain, helps to model the brain functional and structural disease mechanisms of SZ (<xref rid="ref43" ref-type="bibr">van den Heuvel and Fornito, 2014</xref>; <xref rid="ref22" ref-type="bibr">Kong et al., 2021</xref>). Importantly, advances in network science and graph theory have improved our ability to study the topological organization between brain regions. Brain connectivity can be measured to generate brain “connectomics” (<xref rid="ref10" ref-type="bibr">Farras-Permanyer et al., 2015</xref>), which have been used for quantitatively analyzing regional and global network topology of the human brain (<xref rid="ref43" ref-type="bibr">van den Heuvel and Fornito, 2014</xref>; <xref rid="ref17" ref-type="bibr">Jiang et al., 2020</xref>; <xref rid="ref18" ref-type="bibr">Jo et al., 2020</xref>). Abnormalities in brain structure, function and connectivity have been widely reported in SZ patients using multimodal MRI and connectomics with structural magnetic resonance imaging (sMRI) and resting-state functional magnetic resonance imaging (rs-fMRI) data. With regard to structural brain abnormalities, SZ patients have widespread cortical thinning, a smaller cortical surface, reduced gray matter volume (GMV), and reduced white matter volume (WMV), with the largest effects observed in frontal and temporal lobe regions (<xref rid="ref44" ref-type="bibr">van Erp et al., 2018</xref>; <xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref19" ref-type="bibr">Keshavan et al., 2020</xref>). Functional brain abnormalities include significantly increased regional homogeneity (ReHo) in the striatum, the right parahippocampal gyrus, and the right middle temporal gyrus (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref28" ref-type="bibr">Li et al., 2020</xref>), significantly increased amplitude of low frequency fluctuation (ALFF) in the right fusiform gyrus and the left superior temporal gyrus (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref28" ref-type="bibr">Li et al., 2020</xref>), and significantly decreased degree centrality (DC) in the right supramarginal gyrus, the right transverse temporal gyrus and the bilateral putamen (<xref rid="ref6" ref-type="bibr">Chen et al., 2015</xref>; <xref rid="ref18" ref-type="bibr">Jo et al., 2020</xref>). The human brain is a highly interconnected network, and evidence for structural and functional abnormalities in SZ patients has developed into a dysconnectivity hypothesis (<xref rid="ref12" ref-type="bibr">Friston and Frith, 1995</xref>). More direct evidence for the dysconnectivity hypothesis comes mainly from multimodal MRI studies, which have shown widespread structural and functional dysconnectivity in brain networks in SZ (<xref rid="ref43" ref-type="bibr">van den Heuvel and Fornito, 2014</xref>; <xref rid="ref30" ref-type="bibr">Northoff and Duncan, 2016</xref>; <xref rid="ref35" ref-type="bibr">Rolls et al., 2020</xref>).</p>
      <p>In recent decades, classification studies of SZ patients have employed machine learning techniques that enable statistical inferences at the level of the individual patient (<xref rid="ref2" ref-type="bibr">Arbabshirani et al., 2017</xref>). Deep learning (<xref rid="ref15" ref-type="bibr">Hatcher and Yu, 2018</xref>; <xref rid="ref24" ref-type="bibr">Le et al., 2020</xref>), as a subfield of machine learning, can create a fully automated diagnostic process with no expert clinical intervention (<xref rid="ref34" ref-type="bibr">Qureshi et al., 2019</xref>) because of its powerful feature representation capability. However, most machine learning methods adopted in previous studies were typically based on independent neuroimaging features or connection features instead of the connectome itself (<xref rid="ref26" ref-type="bibr">Lei et al., 2022</xref>). Currently, graphs are the most commonly used representation of brain networks in neuropsychiatric disorder diagnosis. The use of graphs provides an alternative approach to capture topological information within brain networks. Network embedding (<xref rid="ref14" ref-type="bibr">Grover and Leskovec, 2016</xref>; <xref rid="ref17" ref-type="bibr">Jiang et al., 2020</xref>) approach is used to transforms the nodes of a network into a lower-dimensional representation with the network structure information. Graph convolutional networks (GCNs), proposed by <xref rid="ref21" ref-type="bibr">Kipf and Welling (2017)</xref>, was a graph embedding model that effectively combined node features with structure information during the learning process. <xref rid="ref25" ref-type="bibr">Lee et al. (2019)</xref> proposed a GCN model with a self-attention graph pooling method that achieved superior graph classification performance. <xref rid="ref26" ref-type="bibr">Lei et al. (2022)</xref> used GCN to investigate topological abnormalities of functional brain networks in SZ and achieved a higher classification accuracy (85.8%) compared with support vector machine (SVM) (80.9%). <xref rid="ref31" ref-type="bibr">Oh et al. (2022)</xref> developed the BrainNet-Global Covariance Pooling-Attention Convolutional Neural Network (BrainNet-GA CNN), which showed an accuracy of 83.13%. In addition to use MRI data for diagnosis of SZ patients, some studies used Electroencephalography (EEG) data. Compared to MRI data, EEG data has a comparatively cost and good temporal resolution, and therefore it is possible for studies used large data sets (<xref rid="ref1" ref-type="bibr">Alves et al., 2022</xref>). <xref rid="ref1" ref-type="bibr">Alves et al. (2022)</xref> built cortical networks as the input of a tuned convolutional neural network (CNN) for SZ diagnosis, and the classification performance was significantly better than using network measures to describe the network structure. <xref rid="ref5" ref-type="bibr">Chang et al. (2021)</xref> applied GCN to mismatch negativity (MMN) brain functional networks that based on EEG data and achieved an accuracy of 93.33%, which significantly outperformed the SVM classifier trained on graph-theoretic features.</p>
      <p>In our previous research, we proposed an integrated analysis of functional MRI and connectomics that considered characteristics of brain regions of interest (ROIs) and the functional connectivity between ROIs (<xref rid="ref7" ref-type="bibr">Chen et al., 2023</xref>). Specifically, we obtained an average accuracy of 92.7% based on the GCN method, which outperformed the methods that focused on features of single ROIs and the methods that only based on connectomics analysis. And the GCN method performed better than the traditional machine learning method (SVM, RF: random forest, LR: logistic regression, LDA: linear discriminant analysis and KNN: K-nearest neighbor) and the traditional deep learning method (MLP: multi-layered perceptron and CNN). The results demonstrated that taking topological relationships between ROIs into account in a combined functional MRI and connectomics analysis could effectively improve the classification performance of SZ patients. However, compared to single-modal MRI data analyses using the proposed method, multimodal MRI analyses may offer better diagnosis and prediction in SZ. Therefore, in this study, we would like to investigate multimodal MRI data based on the proposed integrated analysis method, aiming to further improve the classification performance of SZ patients. In addition, different brain parcellation schemes may have an impact on the performance of classification. To verify the robustness of the proposed method, we would like to investigate the effect of different brain atlases based on the proposed method.</p>
      <p>In this study, we applied a GCN method to the classification of SZ patients with a combined multimodal MRI and connectomics analysis. In addition, we investigated the effects of 2 brain atlases to verify the robustness of the proposed method. Furthermore, motived by the need for explainability (<xref rid="ref29" ref-type="bibr">Li X. et al., 2021</xref>), the GCN framework contained node-selection pooling layers, which highlight salient brain regions (salient nodes in the graph) to infer the important brain regions for prediction.</p>
    </sec>
    <sec sec-type="materials|methods" id="sec2">
      <label>2.</label>
      <title>Materials and methods</title>
      <sec id="sec3">
        <label>2.1.</label>
        <title>Subjects</title>
        <p>A total of 345 Chinese Han subjects were recruited from the Affiliated Brain Hospital of Guangzhou Medical University and the local community, including 140 SZ patients and 205 NCs (<xref rid="tab1" ref-type="table">Table 1</xref>). And 140 SZ patients included 61 first-episode medication-naïve SZ (FESZ) patients and 71 medicated chronic SZ (CSZ) patients. The age of the subjects was between 18–60 years and the inclusion and exclusion criteria of subjects were the same as those in our previous studies (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref22" ref-type="bibr">Kong et al., 2021</xref>; <xref rid="ref16" ref-type="bibr">Huang et al., 2022</xref>; <xref rid="ref7" ref-type="bibr">Chen et al., 2023</xref>). The SZ patients were diagnosed by veteran psychiatrists according to the structured clinical interview complying with the criteria of the Diagnostic and Statistical Manual of Mental Disorders-IV-Text Revision (DSM-IV-TR) (SCID). The Positive and Negative Syndrome Scale (PANSS) scores were over 51 and 60 for FESZ patients and CSZ patients, respectively. At least three positive symptom items with a score of at least 4 were included. In addition, the FESZ patients were recruited when they were seeking help psychotic symptoms for the first time and did not take any antipsychotic medication. And the CSZ patients were all taking antipsychotic medication and the course of disease were more than 2 years. The NCs were recruited from the local community through advertisements and group matching on demographic parameters. This study was conducted following the Declaration of Helsinki and approved by the Ethics Committee of the Affiliated Brain Hospital of Guangzhou Medical University. Each subject or their legal guardian was fully aware of the details of the experiment and signed informed consent forms before enrollment.</p>
        <table-wrap position="float" id="tab1">
          <label>Table 1</label>
          <caption>
            <p>The demographics and clinical variables of the subjects.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th align="center" valign="top" rowspan="1" colspan="1">NC (<italic>n</italic> = 205)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">SZ (<italic>n</italic> = 140)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">T(χ<sup>2</sup>)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">
<italic>p</italic>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Sex(Male/Female)</td>
                <td align="center" valign="top" rowspan="1" colspan="1">110/95</td>
                <td align="center" valign="top" rowspan="1" colspan="1">95/45</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">6.378</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">0.012</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Age</td>
                <td align="center" valign="top" rowspan="1" colspan="1">32.51 ± 8.39</td>
                <td align="char" valign="top" char="±" rowspan="1" colspan="1">34.22 ± 8.23</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">−1.870</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">0.062</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Years of Education</td>
                <td align="center" valign="top" rowspan="1" colspan="1">12.84 ± 2.83</td>
                <td align="char" valign="top" char="±" rowspan="1" colspan="1">10.69 ± 3.32</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">6.260</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">&lt; 0.001</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">PANSS-PScore</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="char" valign="top" char="±" rowspan="1" colspan="1">23.14 ± 5.25</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">PANSS-NScore</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="char" valign="top" char="±" rowspan="1" colspan="1">22.53 ± 7.48</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">PANSS-GScore</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="char" valign="top" char="±" rowspan="1" colspan="1">39.88 ± 9.59</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">PANSS-TScore</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="char" valign="top" char="±" rowspan="1" colspan="1">85.55 ± 18.55</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
                <td align="center" valign="top" rowspan="1" colspan="1">–</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p>The values are denoted as the “mean ± standard deviation.” The comparison of sex distribution was performed using the χ2 test. The comparison of age and years of education was performed using a two-sample T test. PScore: positive score; NScore: negative score; GScore: general score; TScore: total score.</p>
          </table-wrap-foot>
        </table-wrap>
        <p>The exclusion criteria for all subjects included: (1) any other psychiatric Axis I disorder that meets DSM-IV criteria, including schizoaffective disorders, intellectual disability, major depressive disorder, bipolar disorder, delirium, dementia, memory disorder, and other cognitive disorders, (2) mental disorders due to drug dependence, severe unstable somatic disease, heart disease, hypertension, definite diabetes, or thyroid diseases, (3) narrow-angle glaucoma, (4) a history of epilepsy, except for febrile convulsions, (5) alcohol dependence meeting DSM-IV-TR criteria (excluding nicotine dependence), (6) having received electroconvulsive therapy in the past 6 months, (7) any contraindications to MRI, (8) medical resource neuroleptic malignant syndrome or serious tardive dyskinesia, (9) a serious suicide attempt or an irritative state, (10) noncompliant drug administration or a lack of legal guardians, (11) lactating, pregnant, or planning to become pregnant, and (12) the NCs who had a first-or second-degree relative with a psychiatric Axis I disorder according to the DSM-IV criteria. This study was conducted following the Declaration of Helsinki and approved by the Ethics Committee of the Affiliated Brain Hospital of Guangzhou Medical University. Each subject or their legal guardian was fully aware of the details of the experiment and signed informed consent before enrollment.</p>
      </sec>
      <sec id="sec4">
        <label>2.2.</label>
        <title>Multimodal MRI data acquisition and preprocessing</title>
        <p>All MRI images were acquired using a 3.0-T Philips MR Scanner (Philips, Achieva, the Netherlands) at the Affiliated Brain Hospital of Guangzhou Medical University. During the scanning process, the subjects were instructed to rest quietly in the instrument, breathe smoothly, and keep their eyes closed but not to fall asleep. For each subject, the T1-weighted sMRI images were acquired using a magnetic preparation fast gradient-echo (MPRAGE) sequence (matrix = 256 × 256 × 188; spatial resolution = 1 × 1 × 1 mm<sup>3</sup>; echo time (TE) = 3.7 ms, repetition time (TR) = 8.2 ms, flip angle (FA) = 7°, field of view (FOV) = 256 × 256 mm<sup>2</sup>, slice thickness = 1.0 mm, and slice number = 224). The rs-fMRI images were collected using an echo-planar imaging (EPI) sequence (matrix = 64 × 64 × 36; spatial resolution = 3.4 × 3.4 × 4 mm<sup>3</sup>; TE = 30 ms; acquisition time = 2000 ms; FA = 90°; FOV = 211 × 211 mm<sup>2</sup>; slice thickness = 4.0 mm, and slice number = 36).</p>
        <p>The sMRI images were preprocessed using the SPM8 software package (<ext-link xlink:href="http://www.fil.ion.ucl.ac.uk/spm;" ext-link-type="uri">http://www.fil.ion.ucl.ac.uk/spm;</ext-link> Institute of Neurology, University College London, London, United Kingdom). Each sMRI image was segmented into three tissue maps, including gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF). The rs-fMRI images were preprocessed using SPM8 (<ext-link xlink:href="https://www.fil.ion.ucl.ac.uk/spm;" ext-link-type="uri">https://www.fil.ion.ucl.ac.uk/spm;</ext-link> Institute of Neurology, University College London) and Data Processing &amp; Analysis for Brain Imaging (DPABI; <xref rid="ref51" ref-type="bibr">Yan et al., 2016</xref>). The preprocessing steps of sMRI images and rs-fMRI images were the same as those in our previous studies (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref22" ref-type="bibr">Kong et al., 2021</xref>; <xref rid="ref16" ref-type="bibr">Huang et al., 2022</xref>; <xref rid="ref46" ref-type="bibr">Wang et al., 2022</xref>).</p>
      </sec>
      <sec id="sec5">
        <label>2.3.</label>
        <title>Brain graphs construction</title>
        <sec id="sec6">
          <label>2.3.1.</label>
          <title>Node features extraction</title>
          <p>Due to the different brain morphologies of subjects, a brain atlas was proposed to register the brain morphology to the same standard space. In this study, we used 2 brain atlases to divide the ROIs, including the automated anatomical labeling (AAL) atlas (<xref rid="ref42" ref-type="bibr">Tzourio-Mazoyer et al., 2002</xref>) with 90 ROIs and the Human Brainnetome Atlas (BNA; <xref rid="ref9" ref-type="bibr">Fan et al., 2016</xref>) with 246 ROIs. To create a brain graph, nodes were defined as ROIs, and the corresponding ROI features were defined as node features. Three sMRI measurements, including GMV, WMV and structural degree centrality (sDC), and three fMRI measurements, including ReHo, ALFF and functional degree centrality (fDC), were calculated in each ROI of the AAL and BNA atlases. The calculation methods of the ROI features used in this study were the same as those in our previous studies (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref55" ref-type="bibr">Zang et al., 2021</xref>; <xref rid="ref16" ref-type="bibr">Huang et al., 2022</xref>; <xref rid="ref46" ref-type="bibr">Wang et al., 2022</xref>).</p>
          <p>The GMV or WMV of each ROI was calculated as the average GMV or WMV of all voxels in that ROI. The ALFF method was used to measure regional spontaneous neuronal activity (<xref rid="ref54" ref-type="bibr">Zang et al., 2007</xref>). The time series of each voxel was transformed to the frequency domain with a fast Fourier transform (FFT), and the power spectrum was obtained. ALFF was calculated as the averaged square root across 0.01–0.08 Hz and then divided by the global mean ALFF for each subject for standardization. The ALFF of a ROI was represented by the average ALFF of all voxels in the ROI. The ReHo method was used to measures the functional synchronization of a voxel with its nearest neighbors (<xref rid="ref56" ref-type="bibr">Zang et al., 2004</xref>). The ReHo of each voxel was divided by the global mean ReHo, and the ReHo of a ROI was defined in the same way as ALFF analyses. The DC method was used to measure the importance/centrality of a node through the strength of connections to all other nodes (<xref rid="ref47" ref-type="bibr">Wang et al., 2015</xref>). In this study, the sDC or fDC of a given ROI was defined as the sum of its structural or functional connectivity with all other ROIs.</p>
        </sec>
        <sec id="sec7">
          <label>2.3.2.</label>
          <title>Edge features construction</title>
          <p>The brain network can be modeled as a graph consisting of brain regions as the nodes and their connectivity as the edges. The construction methods of the brain network based on MRI data were the same as those in our previous studies (<xref rid="ref22" ref-type="bibr">Kong et al., 2021</xref>; <xref rid="ref46" ref-type="bibr">Wang et al., 2022</xref>). In this section, we constructed brain connectivity matrices as edge features, including structural connectivity matrices, functional connectivity matrices and structural-functional connectivity matrices, based on sMRI and fMRI data. The flow chart of constructing the brain connectivity matrices is shown in <xref rid="fig1" ref-type="fig">Figure 1</xref>.</p>
          <fig position="float" id="fig1">
            <label>Figure 1</label>
            <caption>
              <p>Flow chart of constructing the brain network connection matrices. GMM, Gray Matter Matrix. FBM, Functional Brain Matrix. GMM-FBM, Gray Matter Matrix-Functional Brain Matrix. Similarity connectivity matrix, correlation connectivity and structural-functional connectivity matrix were all the weight fully connected adjacency matrices. The proportional quantification method was proposed to construct the sparse binary adjacency matrices, including GMM, FBM and GMM-FBM.</p>
            </caption>
            <graphic xlink:href="fnins-17-1140801-g001" position="float"/>
          </fig>
          <p>The structural brain network constructed from sMRI data was based on the GMV map cut out in the preprocessing process, so the structural connectivity matrix was defined as the gray matter matrix (GMM). The edges of the structural brain network were defined as the Kullback–Leibler (KL) divergence-based similarity (<xref rid="ref23" ref-type="bibr">Kong et al., 2014</xref>; <xref rid="ref45" ref-type="bibr">Wang et al., 2016</xref>; <xref rid="ref22" ref-type="bibr">Kong et al., 2021</xref>) measure between two ROIs of the GMV map. The functional brain network constructed from the fMRI data and the functional connectivity matrix was defined as the functional brain matrix (FBM). The edges of the functional brain network were defined as the absolute Pearson correlation coefficient between the regional mean time series. In addition, the structural-functional connectivity matrix constructed by combining sMRI and fMRI data was defined as the gray matter matrix-functional brain matrix (GMM-FBM). Specifically, the similarity matrix extracted by sMRI and the correlation connectivity matrix extracted by fMRI were normalized separately and then added to obtain the structural-functional connectivity matrix. The GMM, FBM and GMM-FBM obtained based on the AAL atlas were 90 × 90 symmetric adjacency matrices, and those obtained based on the BNA atlas were 246 × 246 symmetric adjacency matrices. According to the calculation process, the initial brain network of each subject was a complete network, where each node was connected with all the other nodes. However, considering all the correlations may incorporate the spurious and weak connections, which are most influenced by experimental noise (<xref rid="ref27" ref-type="bibr">Li L. et al., 2021</xref>). To screen more important connections, speed up the calculation of the model, and prevent the model from overfitting and oversmoothing (<xref rid="ref52" ref-type="bibr">Yao et al., 2021</xref>), we proposed a proportional quantification method to construct sparse binary networks. First, we defined the threshold as the percentile value of the edge weights, which was calculated according to the quantification parameter. Second, the edge was retained if its weight was larger than the threshold, and the weight was reset to 1. According to the characteristics of the Erdős-Rényi network, the sparsity of the fully connected network is at least <inline-formula><mml:math id="M1" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mi>N</mml:mi><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, where N is the number of nodes (<xref rid="ref8" ref-type="bibr">Erdös and Rényi, 1959</xref>; <xref rid="ref37" ref-type="bibr">Schindler et al., 2008</xref>). Therefore, we reserved the top 10 and 5% edges of the brain graph constructed based on the AAL and BNA atlases, respectively. Therefore, we obtained 6 types of adjacency matrices for each subject based on two brain atlases and two modalities of MRI data.</p>
        </sec>
        <sec id="sec8">
          <label>2.3.3.</label>
          <title>Construction of brain graphs by combining node features and edge features</title>
          <p>Each subject was represented as a brain graph that contained a feature matrix and an adjacency matrix, in which the feature matrix was regarded as node features and the adjacency matrix was regarded as edge features. For each brain atlas, there were 3 types of node features, including sMRI features (GMV, WMV and sDC), fMRI features (ReHo, ALFF and fDC) and sMRI + fMRI features (GMV, WMV, sDC, ReHo, ALFF and fDC), and 3 types of edge features, including GMM, FBM and GMM-FBM. Therefore, we can generate 9 types of brain graphs by pairwise combinations of node features and edge features for each brain atlas, which are shown in <xref rid="tab2" ref-type="table">Table 2</xref>.</p>
          <table-wrap position="float" id="tab2">
            <label>Table 2</label>
            <caption>
              <p>Nine types of brain graphs by pairwise combination of edge features and node features for each brain atlas.</p>
            </caption>
            <table frame="hsides" rules="groups">
              <thead>
                <tr>
                  <th align="left" valign="top" rowspan="1" colspan="1">Type of brain graph</th>
                  <th align="left" valign="top" rowspan="1" colspan="1">Edge features</th>
                  <th align="left" valign="top" rowspan="1" colspan="1">Node features</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">① GMM &amp; sMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">GMM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">sMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">② GMM &amp; fMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">GMM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">fMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">③ GMM &amp; sMRI + fMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">GMM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">sMRI + fMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">④ FBM &amp; sMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">FBM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">sMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">⑤ FBM &amp; fMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">FBM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">fMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">⑥ FBM &amp; sMRI + fMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">FBM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">sMRI + fMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">⑦ GMM-FBM &amp; sMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">GMM-FBM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">sMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">⑧ GMM-FBM &amp; fMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">GMM-FBM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">fMRI</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">⑨ GMM-FBM &amp; sMRI + fMRI</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">GMM-FBM</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">sMRI + fMRI</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <p>Node features of sMRI including GMV, WMV and sDC. Node features of fMRI including ReHo, ALFF and fDC. Node features of sMRI + fMRI including GMV, WMV, sDC, ReHo, ALFF and fDC.</p>
            </table-wrap-foot>
          </table-wrap>
        </sec>
      </sec>
      <sec id="sec9">
        <label>2.4.</label>
        <title>Graph convolution network algorithm</title>
        <sec id="sec10">
          <label>2.4.1.</label>
          <title>Architecture of graph convolutional network</title>
          <p>In this study, we formulated SZ diagnosis as a graph classification task and used the GCN method to discriminate SZ patients based on a combined multimodal MRI and connectomics analysis. Unlike node-level tasks, graph classification tasks need to focus on both the structure information of the graph and the characteristic information of each node. GCN, an extension of CNN in the non-European domain, can simultaneously learn node characteristic information and graph structure information. The architecture of the GCN classifier (<xref rid="fig2" ref-type="fig">Figure 2</xref>) were the same with our previous study (<xref rid="ref7" ref-type="bibr">Chen et al., 2023</xref>) that adopted the GCN framework introduced in <xref rid="ref25" ref-type="bibr">Lee et al. (2019)</xref>. The GCN classifier implemented a hierarchical pooling architecture (<xref rid="ref4" ref-type="bibr">Cangea et al., 2018</xref>; <xref rid="ref25" ref-type="bibr">Lee et al., 2019</xref>) and comprised three blocks consisting of a graph convolutional layer, a graph pooling layer and a readout layer. The fully connected layers were used after the aggregation of the readout layers to make classification decisions.</p>
          <fig position="float" id="fig2">
            <label>Figure 2</label>
            <caption>
              <p>Architecture of Graph Convolutional Networks. Input data was brain graph which consisted of 90 nodes (based on AAL atlas) or 246 nodes (based on BNA atlas), and the number of node features was 3 (sMRI features or fMRI features) or 6 (sMRI + fMRI features). The architecture of GCN comprised three blocks consisting of a graph convolutional layer, a graph pooling layer and a readout layer. The readout layers were implemented by concatenating global max-pooling with global mean-pooling. Node features were aggregated to a fixed size representation in each readout layer and then fed their summation to the fully connected layers for classification.</p>
            </caption>
            <graphic xlink:href="fnins-17-1140801-g002" position="float"/>
          </fig>
          <p>The graph convolution operation is defined as (<xref rid="ref21" ref-type="bibr">Kipf and Welling, 2017</xref>):</p>
          <disp-formula id="EQ1">
<label>(1)</label>
<mml:math id="M2" overflow="scroll"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:msup><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>
</disp-formula>
          <p>where <inline-formula><mml:math id="M3" overflow="scroll"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>ϵ</mml:mi><mml:mspace width="thickmathspace"/><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the feature matrix of the <inline-formula><mml:math id="M4" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> layer, <italic>N</italic> is the number of nodes and <inline-formula><mml:math id="M5" overflow="scroll"><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> is the feature dimension of the <inline-formula><mml:math id="M6" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> layer. <inline-formula><mml:math id="M7" overflow="scroll"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>ϵ</mml:mi><mml:mspace width="thickmathspace"/><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M8" overflow="scroll"><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are the feature matrix and the feature dimension of the <inline-formula><mml:math id="M9" overflow="scroll"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> layer, respectively. <inline-formula><mml:math id="M10" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the adjacency matrix with added self-connections, and <inline-formula><mml:math id="M11" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the identity matrix. <inline-formula><mml:math id="M12" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">˜</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:munder><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M13" overflow="scroll"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are layer-specific trainable weight matrices. <inline-formula><mml:math id="M14" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:math></inline-formula> is the activation function.</p>
          <p>After the convolution, we applied the TopK pooling method to select a portion of nodes to form a coarsened graph. The TopK pooling layer projected each node feature vector into a scalar value used as the ranking score, which considered all features (<xref rid="ref4" ref-type="bibr">Cangea et al., 2018</xref>; <xref rid="ref13" ref-type="bibr">Gao and Ji, 2021</xref>). We obtained the scalar projection vector <italic>y</italic> of each node based on a trainable projection vector <italic>p</italic> by matrix multiplication. By using the ranking scores <inline-formula><mml:math id="M15" overflow="scroll"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> of the <inline-formula><mml:math id="M16" overflow="scroll"><mml:mrow><mml:msup><mml:mi>l</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> layer, the coarsened graph is formed by computing the new adjacency matrix <italic>A</italic><sup>(<italic>l</italic> + 1)</sup> and feature matrix <italic>H</italic><sup>(<italic>l</italic> + 1)</sup>. The operation of the TopK pooling layer (<xref rid="fig3" ref-type="fig">Figure 3</xref>) was as follows:</p>
          <disp-formula id="EQ2">
<label>(2)</label>
<mml:math id="M17" overflow="scroll"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula>
          <disp-formula id="EQ3">
<label>(3)</label>
<mml:math id="M18" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>
</disp-formula>
          <disp-formula id="EQ4">
<label>(4)</label>
<mml:math id="M19" overflow="scroll"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>⊙</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>h</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>
</disp-formula>
          <disp-formula id="EQ5">
<label>(5)</label>
<mml:math id="M20" overflow="scroll"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
</disp-formula>
          <p>Here, ||.|| is the <italic>L2</italic> norm. The notation finds the indices corresponding to the largest k elements in score vector y. ⊙ is (broadcasted) element-wise multiplication, and (.)<sub>i,j</sub> is an indexing operation that takes elements at row indices i and column indices j (no indices j denotes all indices). The <italic>ratio</italic> of the graph pooling layer is the hyperparameter used to compute</p>
          <disp-formula id="E1">
<mml:math id="M25" overflow="scroll"><mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mo>.</mml:mo><mml:mi>N</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
          <fig position="float" id="fig3">
            <label>Figure 3</label>
            <caption>
              <p>Operation in the TopK pooling layer. Each node feature vector was projected into a scalar value based on a trainable projection vector.</p>
            </caption>
            <graphic xlink:href="fnins-17-1140801-g003" position="float"/>
          </fig>
          <p>The TopK pooling method improved the fusion efficiency of remote nodes by dropping nodes layer by layer, which may lead to a lack of the means to effectively merge information on all nodes. Therefore, a readout layer followed each pooling layer to aggregate multiscale global information of the graph by concatenating global max-pooling with global mean-pooling (<xref rid="ref4" ref-type="bibr">Cangea et al., 2018</xref>; <xref rid="ref50" ref-type="bibr">Xu et al., 2018</xref>; <xref rid="ref25" ref-type="bibr">Lee et al., 2019</xref>). Node features were aggregated to a fixed size representation in each readout layer and then fed their summation to the fully connected layers for classification.</p>
        </sec>
        <sec id="sec11">
          <label>2.4.2.</label>
          <title>Salient brain regions detection from pooling layer</title>
          <p>Recent findings indicated that some ROIs were more indicative of predicting SZ patients than others (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref28" ref-type="bibr">Li et al., 2020</xref>). We used the last pooling layer to identify discriminative ROIs contributing significantly to the recognition of SZ. For each subject in the training dataset, we took the first 20 ROIs retained in the last pooling layer and counted the frequency of each node. The significance score for each node was obtained by calculating the ratio of the frequency of the node to the total number of nodes (e.g., 300 training samples, 20 nodes per sample, 6,000 nodes in total).</p>
        </sec>
        <sec id="sec12">
          <label>2.4.3.</label>
          <title>Experimental setup</title>
          <p>In our experiment, we evaluated the effectiveness of our method on 345 subjects that were randomly split into two groups. The training dataset contained 300 subjects and the testing dataset contained 45 subjects. To observe the effects of different modalities of MRI data and different brain atlases on the classification performance, 18 types of brain graphs were constructed as the input data of the GCN model. We utilized the metrics of accuracy, the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, F1-score and precision to quantitatively estimate the performance. Considering that the sample size was not large and different training/testing splits lead to dramatically different rankings of models (<xref rid="ref39" ref-type="bibr">Shchur et al., 2019</xref>; <xref rid="ref11" ref-type="bibr">Flint et al., 2021</xref>; <xref rid="ref40" ref-type="bibr">Sun et al., 2023</xref>), we randomly split training and testing datasets 10 times, repeated the experiments and calculated the averaged performance for each type of brain graph. It is worth emphasizing that in our recent fMRI study (<xref rid="ref7" ref-type="bibr">Chen et al., 2023</xref>), we randomly split training and testing datasets 200 times to get the average performance and we found that the performance obtained on a single data split could be fragile and misleading, confirming the necessity of a multiple data split evaluation strategies. However, there are many models involved in this multimodal (18 types of brain graphs) study, and it would cause great computational complexity if all models repeated 200 times. In the pretest, we found that the average performance based on 10 randomly dataset splitting was basically the same as the average performance based on 200 randomly dataset splitting. Therefore, in order to reduce the computational complexity without compromising the reliability of the generalizability evaluation, we chose to randomly split training and testing datasets 10 times in this study.</p>
          <p>The parameter settings of the training procedure are shown in <xref rid="tab3" ref-type="table">Table 3</xref>. To avoid overfitting, we used the dropout technique, batch normalization (BN) and early stopping strategy. The model was implemented using the PyTorch library and the PyTorch Geometric (PyG) library.</p>
          <table-wrap position="float" id="tab3">
            <label>Table 3</label>
            <caption>
              <p>The parameter settings of the training procedure.</p>
            </caption>
            <table frame="hsides" rules="groups">
              <thead>
                <tr>
                  <th align="left" valign="top" rowspan="1" colspan="1">Parameter name</th>
                  <th align="left" valign="top" rowspan="1" colspan="1">Parameters</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Optimizer</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">Adaptive optimizer (Adam)</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Loss function</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">Cross entropy loss</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Activation function</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">ReLu</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Learning rate</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">0.0001</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Batch Size</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">30</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Dropout rate</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">0.5</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Maximum epochs</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">1,000</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Patience of early stopping</td>
                  <td align="left" valign="top" rowspan="1" colspan="1">500</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </sec>
      </sec>
    </sec>
    <sec sec-type="results" id="sec13">
      <label>3.</label>
      <title>Results</title>
      <sec id="sec14">
        <label>3.1.</label>
        <title>Classification results of different brain atlases and different MRI data</title>
        <p>Based on the construction method of the brain graph in Section 2.3, 18 types of brain graphs can be obtained by combining node features and edge features, which were used as the input graphs of the GCN classifier and the average performance is shown in <xref rid="tab4" ref-type="table">Table 4</xref>. For both the AAL and BNA atlases, the optimal classification performance was achieved when FBM was used as the edge feature and both structural and functional features of ROIs were used as node features. Specifically, the model with <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> as the input graph obtained an average accuracy of 95.8%, and the AUC, sensitivity, specificity, F1-score and precision reached 96.4, 94.8, 96.2, 94.6 and 94.6%, respectively. The model with <italic>“BNA: FBM &amp; sMRI + fMRI”</italic> as the input graph obtained an average accuracy of 94.2%, which was slightly lower than that of the AAL atlas. For brain graphs with multimodal edge features, the best performance was obtained using functional node features for the AAL atlas, while the best performance was obtained using both structural and functional node features for the BNA atlas. In addition, we compared our research with the existing SZ classification studies, which are shown in <xref rid="tab5" ref-type="table">Table 5</xref>. The GCN model with <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> as the input graph in this study showed the best accuracy.</p>
        <table-wrap position="float" id="tab4">
          <label>Table 4</label>
          <caption>
            <p>Classification results of different brain graphs and the best results are in bold.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th align="left" valign="top" rowspan="2" colspan="1">Brain Atlas</th>
                <th align="left" valign="top" rowspan="2" colspan="1">Input Graph</th>
                <th align="center" valign="top" colspan="6" rowspan="1">Performance</th>
              </tr>
              <tr>
                <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">AUC (%)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">F1-score (%)</th>
                <th align="center" valign="top" rowspan="1" colspan="1">Precision (%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" valign="middle" rowspan="9" colspan="1">AAL</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM &amp; sMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">73.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">66.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">47.6</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">89.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">56.6</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">81.6</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM &amp; fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">74.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">68.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">57.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">86.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">62.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">77.4</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM &amp; sMRI + fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">76.4</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">72.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">51.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">62.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">82.2</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">FBM &amp; sMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">71.8</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">67.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">49.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">86.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">57.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">72.7</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">FBM &amp; fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.4</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">93.6</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">87.4</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">95.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">89.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.1</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">FBM &amp; sMRI + fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">
<bold>95.8</bold>
</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">
<bold>96.4</bold>
</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">
<bold>94.8</bold>
</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">
<bold>96.2</bold>
</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">
<bold>94.6</bold>
</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">
<bold>94.6</bold>
</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM-FBM &amp; sMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">72.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">66.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">61.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">78.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">64.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">70.2</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM-FBM &amp; fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">96.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">91.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">95.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.2</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM-FBM &amp; sMRI + fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">91.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">93.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">84.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">95.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">88.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">93.7</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="9" colspan="1">BNA</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM &amp; sMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">78.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">77.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">78.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">71.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">79.5</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM &amp; fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">74.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">71.8</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">70.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">76.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">68.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">69.6</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM &amp; sMRI + fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">76.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">73.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">62.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">86.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">67.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">76.6</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">FBM &amp; sMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">75.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">71.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">63.4</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">82.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">66.4</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">72.7</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">FBM &amp; fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">89.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">95.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">90.6</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.7</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">FBM &amp; sMRI + fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">95.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.4</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.3</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM-FBM &amp; sMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">74.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">68.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">56.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">86.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">63.5</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">79.3</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM-FBM &amp; fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">90.0</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">93.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">82.2</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">95.7</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">86.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.8</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">GMM-FBM &amp; sMRI + fMRI</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">93.3</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">94.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.9</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">93.8</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">92.1</td>
                <td align="char" valign="top" char="." rowspan="1" colspan="1">91.6</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="tab5">
          <label>Table 5</label>
          <caption>
            <p>Performance comparison of the proposed method with competing methods.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th align="left" valign="top" rowspan="1" colspan="1">References</th>
                <th align="center" valign="top" rowspan="1" colspan="1">Sample Size</th>
                <th align="left" valign="top" rowspan="1" colspan="1">Input features</th>
                <th align="left" valign="top" rowspan="1" colspan="1">Classifier</th>
                <th align="center" valign="top" rowspan="1" colspan="1">Accuracy</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">
<xref rid="ref20" ref-type="bibr">Kim et al. (2020)</xref>
</td>
                <td align="char" valign="middle" char="," rowspan="1" colspan="1">SZ = 119, NC = 39</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Brain network topology properties</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">LDA</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">80.66%</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">
<xref rid="ref46" ref-type="bibr">Wang et al. (2022)</xref>
</td>
                <td align="char" valign="middle" char="," rowspan="1" colspan="1">SZ = 140, NC = 205</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Brain network topology properties</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">SVM</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">81.20%</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">
<xref rid="ref32" ref-type="bibr">Phang et al. (2020)</xref>
</td>
                <td align="char" valign="middle" char="," rowspan="1" colspan="1">SZ = 45, NC = 39</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Brain network topology properties</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">CNN</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">91.69%</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">
<xref rid="ref31" ref-type="bibr">Oh et al. (2022)</xref>
</td>
                <td align="char" valign="middle" char="," rowspan="1" colspan="1">SZ = 171, NC = 161</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Brain graph</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">BrainNet-GA CNN</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">83.13%</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">
<xref rid="ref5" ref-type="bibr">Chang et al. (2021)</xref>
</td>
                <td align="char" valign="middle" char="," rowspan="1" colspan="1">SZ = 80, NC = 32</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Brain graph</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">GCN</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">93.33%</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">Our best</td>
                <td align="char" valign="middle" char="," rowspan="1" colspan="1">SZ = 140, NC = 205</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Brain graph</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">GCN</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">95.80%</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="sec15">
        <label>3.2.</label>
        <title>Classification results of different sparsities</title>
        <p>To avoid losing the node-centralized local topology information due to graph convolution on the weighted complete graph, we proposed a proportional quantification method to construct binary brain graphs. Sparse representation-based brain graph construction methods with proportional quantification strategies could generate more robust and biologically meaningful connectivity brain graphs. We defined sparsity as the ratio of the number of preserved edges to the total number of edges. The initial sparsities of brain graphs constructed based on AAL and BNA atlases were set as 10 and 5% separately in Section 3.1. Specifically, the smaller the sparsity, the greater the brain graph focused on reflecting the topological relationships between the more strongly connected brain regions. However, a smaller sparsity means that more weak connections are discarded, which may carry the distinguishing information. In this section, we conducted comparative experiments with different sparsities for the models with single-modal edge feature and multimodal edge feature that achieved better performance in Section 3.1, and two brain atlases were investigated separately. The brain graphs included in this sparsity study were <italic>“AAL: FBM &amp; sMRI + fMRI,” “AAL: GMM-FBM &amp; fMRI,” “BNA: FBM &amp; sMRI + fMRI”</italic> and <italic>“BNA: GMM-FBM &amp; sMRI + fMRI.”</italic> We set the optimization of the sparsity in the range of 5 to 50% with a 5% interval and the results are shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>. For the AAL atlas, the optimal values were obtained when sparsity was 10% for both <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> and <italic>“AAL: GMM-FBM &amp; fMRI,”</italic> which were consistent with the initial sparsity. For the BNA atlas, the optimal sparsity of the <italic>“BNA: GMM-FBM &amp; sMRI + fMRI”</italic> model was also consistent with the initial sparsity. However, the <italic>“BNA: FBM &amp; sMRI + fMRI”</italic> model obtained the best performance using a sparsity of 10%. Although 5% was not the optimal sparsity, the <italic>“BNA: FBM &amp; sMRI + fMRI”</italic> model with 5% still obtained superior performance and achieved an accuracy of 94.2%.</p>
        <fig position="float" id="fig4">
          <label>Figure 4</label>
          <caption>
            <p>Quantitative performance of brain graphs with different sparsities. <bold>(A)</bold> Results of the <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> models, <bold>(B)</bold> Results of the <italic>“AAL: GMM-FBM &amp; fMRI”</italic> models, <bold>(C)</bold> Results of the <italic>“BNA: FBM &amp; sMRI + fMRI”</italic> models, and <bold>(D)</bold> Results of the <italic>“BNA: GMM-FBM &amp; sMRI + fMRI”</italic> models.</p>
          </caption>
          <graphic xlink:href="fnins-17-1140801-g004" position="float"/>
        </fig>
        <p>In general, the optimal sparsity was small and close to the minimum sparsity of the fully connected network (mentioned in Section 2.3.2). This may be because when combined features are adopted as node features, the combined features will provide more abundant and complementary information, resulting in less reliance of GCN on edge information. Therefore, using a larger proportion that preserved more edges of the brain graph would make the classifier tend to overfitting and thus lead to a decline in classification performance. Meanwhile, the sDC and fDC features were extracted from the edge features, which further increased the redundant information from edge features, leading to overfitting.</p>
      </sec>
      <sec id="sec16">
        <label>3.3.</label>
        <title>The results of salient brain regions</title>
        <p>For explainability analysis, the TopK graph pooling was used to estimate the contribution of each ROI to GCN classification. We calculated the average significance score across all the training individuals to reflect the contribution of each brain region. Herein, we reported the top 10 salient brain regions of the last pooling layer of the <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> model, and the results are shown in <xref rid="tab6" ref-type="table">Table 6</xref>; <xref rid="fig5" ref-type="fig">Figure 5</xref>. The results showed that the top 10 salient brain regions were mostly in the prefrontal cortex and occipital cortex, including the right medial orbitofrontal cortex (ORBmed), the right rectus gyrus (REC), the left REC, the left lingual gyrus (LING), the right cuneus (CUN), the right medial superior frontal gyrus (SFGmed), the left CUN, the right LING, the right calcarine cortex (CAL) and the right anterior cingulate gyrus (ACG). These salient brain regions were mainly involved in emotion and visual processing, which may be related to the clinical symptoms of hallucinations and mood disorders in patients with SZ.</p>
        <table-wrap position="float" id="tab6">
          <label>Table 6</label>
          <caption>
            <p>Top 10 salient brain regions of the last pooling layer of the “<italic>AAL: FBM</italic>
<italic>&amp;</italic>
<italic>sMRI + fMRI</italic>” model.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th align="left" valign="top" rowspan="1" colspan="1">No.</th>
                <th align="center" valign="top" rowspan="1" colspan="1">Score</th>
                <th align="left" valign="top" rowspan="1" colspan="1">Brain region</th>
                <th align="left" valign="top" rowspan="1" colspan="1">Cortex</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">26</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.03171</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Orbitofrontal cortex (medial).R (ORBmed.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Prefrontal</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">28</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.03160</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Rectus gyrus.R (REC.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Prefrontal</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">27</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.03140</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Rectus gyrus.L (REC.L)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Prefrontal</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">47</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02836</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Lingual gyrus.L (LING.L)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Occipital</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">46</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02814</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Cuneus.R (CUN.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Occipital</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">24</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02796</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Superior frontal gyrus (medial).R (SFGmed.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Prefrontal</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">45</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02768</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Cuneus.L (CUN.L)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Occipital</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">48</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02684</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Lingual gyrus.R (LING.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Occipital</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">44</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02665</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Calcarine cortex.R (CAL.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Occipital</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">32</td>
                <td align="char" valign="middle" char="." rowspan="1" colspan="1">0.02664</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Anterior cingulate gyrus.R (ACG.R)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Prefrontal</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <fig position="float" id="fig5">
          <label>Figure 5</label>
          <caption>
            <p>The top 10 salient brain regions based on the <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> brain graph. ORBmed.R: the right medial orbitofrontal cortex; REC.R: the right rectus gyrus; REC.L the left rectus gyrus; LING.L: the left lingual gyrus; CUN.R: the right cuneus; SFGmed.R: the right medial superior frontal gyrus; CUN.L: the left cuneus; LING.R: the right lingual gyrus; CAL.R: the right calcarine cortex; ACG.R: the right anterior cingulate gyrus. The top 10 salient brain regions predominantly distributed in the prefrontal and occipital cortices, were mainly involved in the systems of emotion and visual processing.</p>
          </caption>
          <graphic xlink:href="fnins-17-1140801-g005" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec sec-type="discussions" id="sec17">
      <label>4.</label>
      <title>Discussion</title>
      <p>In this study, we formulated SZ diagnosis as a graph classification problem using a combined multimodal MRI and connectomics analysis. For each brain atlas (AAL and BNA), there were 3 types of node features, including sMRI, fMRI and sMRI + fMRI features, and 3 types of edge features, including GMM, FBM and GMM-FBM. Therefore, we generated 9 types of brain graphs by pairwise combinations of node features and edge features for each brain atlas. Our main findings included the following: (1) the GCN model with <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> as the input graph obtained the highest average accuracy of 95.8%, which outperformed other existing SZ classification studies; (2) in the explainability analysis, the top 10 salient brain regions, predominantly distributed in the prefrontal and occipital cortices, were mainly involved in the systems of emotion and visual processing.</p>
      <p>As seen from <xref rid="tab4" ref-type="table">Table 4</xref>, the <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> model achieved the best classification performance with an average accuracy/AUC of 95.8%/96.4%, which was better than the classification performance of the <italic>“AAL: FBM &amp; sMRI”</italic> model and the <italic>“AAL: FBM &amp; fMRI”</italic> model. Similarly, when using GMM as edge features, the model using sMRI + fMRI features as node features achieved an accuracy of 76.4%, which was higher than that of sMRI or fMRI features. In addition, for the BNA atlas, when using the same edge features (FBM, GMM or GMM-FBM), the classification performance with multimodal node features was optimal. These findings suggested that the multimodal node features, which provided richer and complementary information, can improve the classification performance of SZ. <xref rid="ref46" ref-type="bibr">Wang et al. (2022)</xref> found that the classification performance with multimodal nodal attributes computed by structural and functional brain networks as the input features was significantly better than that of any single-modal nodal attributes, which was consistent with our findings. However, an abnormal finding was that the <italic>“AAL: GMM-FBM &amp; fMRI”</italic> model performed better than the <italic>“AAL: GMM-FBM &amp; sMRI + fMRI”</italic> model. We speculated that the model was less stable due to the insufficient samples and was more sensitive to different training/testing splits. Although the performance of the <italic>“AAL: GMM-FBM &amp; sMRI + fMRI”</italic> model was inconsistent with previously mentioned findings, a high accuracy (91.1%) was obtained.</p>
      <p>From the perspective of node features, we found that the fMRI features contributed more to discriminating SZ patients than the sMRI features. One evidence was that when using FBM as the edge features, the accuracy and AUC obtained using fMRI features as node features (accuracy was 92.4%, AUC was 93.6%) were significantly higher than those obtained using sMRI features as node features (accuracy was 71.8%, AUC was 67.0%). The other evidence was that when using GMM as the edge features, the performance achieved using fMRI as node features was better than that achieved using sMRI features as node features, which confirmed our finding and excluded the possibility that using the edge features and node features from the same modal MRI leads to better classification performance. <xref rid="ref55" ref-type="bibr">Zang et al. (2021)</xref> used combinations of features extracted from three modal MRI images (sMRI, DTI and fMRI) to classify SZ patients and found that the features with the highest ranking contribution to classification were mainly fMRI features, indicating that the fMRI features are more effective and conducive to classification, which was similar to our findings.</p>
      <p>From the perspective of edge features, we found that the contribution of the FBM to classification significantly exceeds that of the GMM, and the performance of the GMM-FBM were similar to that of the FBM. As shown in <xref rid="tab4" ref-type="table">Table 4</xref>, when GMM was used as edge features, the classification performance was poor regardless of which node features were selected, and the accuracy was approximately 75.0%. When using the same node features, the classification performance of using FBM or GMM-FBM as the edge features was basically higher than that of using GMM as the edge features.</p>
      <p>From the perspective of the brain atlas, we found that the results of the AAL and BNA atlases were basically consistent. The optimal classification result of the BNA atlas was also obtained when using FBM as the edge features and sMRI + fMRI features as node features, which was consistent with the AAL atlas. The highest classification accuracy of 94.2% was slightly lower than that of 95.1% for the AAL atlas.</p>
      <p><xref rid="tab5" ref-type="table">Table 5</xref> shows that our method achieved the best accuracy compared with the existing SZ classification studies. Compared with traditional machine learning methods such as the LDA algorithm of (<xref rid="ref20" ref-type="bibr">Kim et al., 2020</xref>) and the SVM algorithm of <xref rid="ref46" ref-type="bibr">Wang et al. (2022)</xref>, the results indicated that the combination of the GCN method and brain network has better classification performance than the combination of the classical classification algorithm and extracting topological properties of the brain network. The significant improvement in classification performance can be attributed to the advantages of the GCN method in the extraction of characteristics. The training process of traditional machine learning mainly relies on the prior understanding of the brain network, which requires manual selection and extraction of characteristics. These characteristics were obviously insufficient in SZ classification. However, the GCN method can automatically extract enough characteristics for classification during the training process by the backpropagation algorithm. In addition, the classification performance of the GCN method was also better than that of classical deep learning methods such as the CNN method used by (<xref rid="ref32" ref-type="bibr">Phang et al., 2020</xref>). We can simultaneously learn the relationship between different nodes and edges in the structure of the graph data, which helps to explore the complex associations and patterns between brain regions. This high-level relationship is difficult to formulate but can be represented by the nonlinear combinations in the GCN model and contribute to the final classification decision.</p>
      <p>In the explainability analysis, we reported that the top 10 salient brain regions, predominantly distributed in the prefrontal and occipital cortices, were mainly involved in the systems of emotion and visual processing. There were 4 salient brain regions from the prefrontal cortices, including the right ORBmed, the right REC, the left REC and the right ACG, which were involved in emotion processing. The medial prefrontal cortex plays an essential role in many brain functions, including cognitive processes, regulation of emotion, motivation and sociability. Lesions of the medial prefrontal cortex, leading to the impairment of these functions, have been implicated in SZ (<xref rid="ref49" ref-type="bibr">Xu et al., 2019</xref>). Moreover, there were 5 salient brain regions from the occipital cortices, including the left LING, right CUN, left CUN, right LING and right CAL, which are involved in the visual system. The structural and functional abnormalities of the occipital cortices were highly related to visual hallucinations, one of the main symptoms of SZ patients, which was consistent with previous studies (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref19" ref-type="bibr">Keshavan et al., 2020</xref>). Additionally, as shown in <xref rid="fig5" ref-type="fig">Figure 5</xref>, the salient brain regions were highly symmetrical and spatially coherent, consistent with the previous finding that ROI relevance should be distributed across the brain cortex (<xref rid="ref38" ref-type="bibr">Sebenius et al., 2021</xref>).</p>
      <p>There were three improvements in this study, compared with our previous study (<xref rid="ref7" ref-type="bibr">Chen et al., 2023</xref>). First, previous studies have indicated that multimodal MRI was more useful than that single-modal MRI data in the discriminative analyses of SZ patients (<xref rid="ref48" ref-type="bibr">Wu et al., 2018</xref>; <xref rid="ref38" ref-type="bibr">Sebenius et al., 2021</xref>; <xref rid="ref55" ref-type="bibr">Zang et al., 2021</xref>; <xref rid="ref46" ref-type="bibr">Wang et al., 2022</xref>). In this study, we computed nodal and edge features by the analysis of multimodal MRI data. Importantly, we found that combined edge features by functional MRI data with node features by multimodal MRI data (<italic>“AAL: FBM &amp; sMRI + fMRI”</italic> model) achieved the highest accuracy. Second, in addition to the AAL atlas, we also performed the analysis using the BNA atlas and demonstrated that the results using the BNA atlas were consistent with those using the AAL atlas. These findings indicated that the proposed method in this study was robust. Third, we proposed to use the TopK pooling layer to analyze the contribution of features to the classification modal. Our results indicated that the top 10 salient brain regions were mainly involved in the systems of emotion and visual processing.</p>
      <p>Several limitations need to be addressed in the present study. First, the sample size was modest. A deep neural network has a strong expression ability due to its complex structure, so more samples are needed to obtain a more stable and reliable model and to avoid overfitting. In this study, we reported more reliable generalization by repeating the experiment 10 times. However, fluctuations in generalization evaluation may still occur due to different training/testing splits, and as mentioned earlier, certain findings were inconsistent with others, and we speculated that it was related to insufficient samples. Second, we used the selected-based TopK pooling method as the explainability technique on GCN and reported the salient brain regions, which did not mean that GCN was no longer a black box. Recently, the explainability of graph neural networks on graph data has experienced rapid developments (<xref rid="ref3" ref-type="bibr">Baldassarre and Azizpour, 2019</xref>; <xref rid="ref33" ref-type="bibr">Pope et al., 2019</xref>; <xref rid="ref53" ref-type="bibr">Yuan et al., 2022</xref>). However, there is neither a unified treatment of GCN explainability methods nor a standard benchmark and testbed for evaluations. In future studies, we could perform a comparison of different explainability approaches on the GCN classifier for SZ.</p>
    </sec>
    <sec sec-type="conclusions" id="sec18">
      <label>5.</label>
      <title>Conclusion</title>
      <p>In this study, we formulated SZ diagnosis as a graph classification problem and used the GCN method to classify SZ patients based on a combined multimodal MRI and connectomics analysis. The GCN model with <italic>“AAL: FBM &amp; sMRI + fMRI”</italic> as the input graph obtained the highest average accuracy of 95.8%, which outperformed other existing SZ classification studies. In the explainability analysis, we reported the top 10 salient brain regions, predominantly distributed in the prefrontal cortex and occipital cortex that were mainly involved in emotion and visual processing. This study indicated that the GCN method based on a combined multimodal MRI and connectomics analysis was a promising method to improve the classification performance of SZ patients.</p>
    </sec>
    <sec sec-type="data-availability" id="sec19">
      <title>Data availability statement</title>
      <p>Due to the nature of this research, participants of this study did not agree for their data to be shared publicly. Requests to access the datasets should be directed to KW, <email>kaiwu@scut.edu.cn</email>.</p>
    </sec>
    <sec id="sec20">
      <title>Ethics statement</title>
      <p>The studies involving human participants were reviewed and approved by The Ethics Committee of the Affiliated Brain Hospital of Guangzhou Medical University. The patients/participants provided their written informed consent to participate in this study.</p>
    </sec>
    <sec id="sec21">
      <title>Author contributions</title>
      <p>XC and PK: conceptualization, methodology, software, investigation, visualization, formal analysis, data curation, and writing – original draft. RP: writing -review &amp; editing and formal analysis. JH, LL, YH, JZ, HL, GM, XL, and YN: writing – review &amp; editing. FW and KW: writing – review &amp; editing and funding acquisition. All authors contributed to the article and approved the submitted version.</p>
    </sec>
    <sec sec-type="funding-information" id="sec22">
      <title>Funding</title>
      <p>This work was supported by the National Key Research and Development Program of China (2021YFC2009400 and 2021YFC2009404), the National Natural Science Foundation of China (72174082, 82271953, and 81971585), Guangdong Basic and Applied Basic Research Foundation Outstanding Youth Project (2021B1515020064), the Key Research and Development Program of Guangdong (2018B030335001, 2020B0101130020, and 2020B0404010002), Guangdong Basic and Applied Basic Research Foundation (2019A1515110427), the Science and Technology Program of Guangzhou (201903010032, 202103000032, 202206060005, 202206080005, 202206010077, and 202206010034), and Key Laboratory Program of Guangdong Provincial Education Department (2020KSYS001).</p>
    </sec>
    <sec sec-type="COI-statement" id="conf1">
      <title>Conflict of interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
    <sec sec-type="disclaimer" id="sec100">
      <title>Publisher’s note</title>
      <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors thank all the people who took part in this study.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="ref1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alves</surname><given-names>C. L.</given-names></name><name><surname>Pineda</surname><given-names>A. M.</given-names></name><name><surname>Roster</surname><given-names>K.</given-names></name><name><surname>Thielemann</surname><given-names>C.</given-names></name><name><surname>Rodrigues</surname><given-names>F. A.</given-names></name></person-group> (<year>2022</year>). <article-title>EEG functional connectivity and deep learning for automatic diagnosis of brain disorders: Alzheimer’s disease and schizophrenia</article-title>. <source>J. Phys. Complex.</source>
<volume>3</volume>
<comment>025001</comment>:<fpage>13</fpage>. doi: <pub-id pub-id-type="doi">10.1088/2632-072X/ac5f8d</pub-id></mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arbabshirani</surname><given-names>M. R.</given-names></name><name><surname>Plis</surname><given-names>S.</given-names></name><name><surname>Sui</surname><given-names>J.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name></person-group> (<year>2017</year>). <article-title>Single subject prediction of brain disorders in neuroimaging: promises and pitfalls</article-title>. <source>NeuroImage</source>
<volume>145</volume>, <fpage>137</fpage>–<lpage>165</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.02.079</pub-id>, PMID: <pub-id pub-id-type="pmid">27012503</pub-id></mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassarre</surname><given-names>F.</given-names></name><name><surname>Azizpour</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). <article-title>Explainability techniques for graph convolutional networks</article-title>. <source>arXiv</source> [Preprint]: 1905.13686. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1905.13686</pub-id></mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cangea</surname><given-names>C.</given-names></name><name><surname>Velikovi</surname><given-names>P.</given-names></name><name><surname>Jovanovi</surname><given-names>N.</given-names></name><name><surname>Kipf</surname><given-names>T.</given-names></name><name><surname>Liò</surname><given-names>P.</given-names></name></person-group> (<year>2018</year>). <article-title>Owards sparse hierarchical graph classifiers</article-title>. <source>arXiv</source> [Preprint]: 1811.01287. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1811.01287</pub-id></mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>Q.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name><name><surname>Tian</surname><given-names>Q.</given-names></name><name><surname>Bo</surname><given-names>Q.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Xiong</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Classification of first-episode schizophrenia, chronic schizophrenia and healthy control based on brain network of mismatch negativity by graph neural network</article-title>. <source>IEEE Trans. Neural Syst. Rehabil. Eng.</source>
<volume>29</volume>, <fpage>1784</fpage>–<lpage>1794</lpage>. doi: <pub-id pub-id-type="doi">10.1109/TNSRE.2021.3105669</pub-id>, PMID: <pub-id pub-id-type="pmid">34406943</pub-id></mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>H. L.</given-names></name><name><surname>Wu</surname><given-names>S. H.</given-names></name><name><surname>Huang</surname><given-names>H.</given-names></name><name><surname>Zou</surname><given-names>J. L.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>Abnormal degree centrality of bilateral putamen and left superior frontal gyrus in schizophrenia with auditory hallucinations: a resting-state functional magnetic resonance imaging study</article-title>. <source>Chin. Med. J.</source>
<volume>128</volume>, <fpage>3178</fpage>–<lpage>3184</lpage>. doi: <pub-id pub-id-type="doi">10.4103/0366-6999.170269</pub-id>, PMID: <pub-id pub-id-type="pmid">26612293</pub-id></mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X. Y.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Ke</surname><given-names>P. F.</given-names></name><name><surname>Huang</surname><given-names>J. Y.</given-names></name><name><surname>Xiong</surname><given-names>D. S.</given-names></name><name><surname>Huang</surname><given-names>Y. Y.</given-names></name><etal/></person-group>. (<year>2023</year>). <article-title>Classification of schizophrenia patients using a graph convolutional network: a combined functional MRI and connectomics analysis</article-title>. <source>Biomed Signal Proc. Control</source>
<volume>80</volume>:<fpage>104293</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.bspc.2022.104293</pub-id></mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erdös</surname><given-names>P.</given-names></name><name><surname>Rényi</surname><given-names>A.</given-names></name></person-group> (<year>1959</year>). “<article-title>On random graphs i</article-title>”. <source>Publicationes Mathematicae</source>, <volume>6</volume>, <fpage>290</fpage>–<lpage>297</lpage>.</mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Zhuo</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The human Brainnetome atlas: a new brain atlas based on connectional architecture</article-title>. <source>Cereb. Cortex</source>
<volume>26</volume>, <fpage>3508</fpage>–<lpage>3526</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/bhw157</pub-id>, PMID: <pub-id pub-id-type="pmid">27230218</pub-id></mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farras-Permanyer</surname><given-names>L.</given-names></name><name><surname>Guardia-Olmos</surname><given-names>J.</given-names></name><name><surname>Pero-Cebollero</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>). <article-title>Mild cognitive impairment and fMRI studies of brain functional connectivity: the state of the art</article-title>. <source>Front. Psychol.</source>
<volume>6</volume>:<fpage>1095</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fpsyg.2015.01095</pub-id>, PMID: <pub-id pub-id-type="pmid">26300802</pub-id></mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flint</surname><given-names>C.</given-names></name><name><surname>Cearns</surname><given-names>M.</given-names></name><name><surname>Opel</surname><given-names>N.</given-names></name><name><surname>Redlich</surname><given-names>R.</given-names></name><name><surname>Mehler</surname><given-names>D. M. A.</given-names></name><name><surname>Emden</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Systematic misestimation of machine learning performance in neuroimaging studies of depression</article-title>. <source>Neuropsychopharmacology</source>
<volume>46</volume>, <fpage>1510</fpage>–<lpage>1517</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41386-021-01020-7</pub-id>, PMID: <pub-id pub-id-type="pmid">33958703</pub-id></mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Frith</surname><given-names>C. D.</given-names></name></person-group> (<year>1995</year>). <article-title>Schizophrenia: a disconnection syndrome?</article-title>
<source>Clin. Neurosci.</source>
<volume>3</volume>, <fpage>89</fpage>–<lpage>97</lpage>. PMID: <pub-id pub-id-type="pmid">7583624</pub-id></mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>H.</given-names></name><name><surname>Ji</surname><given-names>S.</given-names></name></person-group> (<year>2021</year>). <article-title>Graph U-nets</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
<volume>44</volume>, <fpage>1</fpage>–<lpage>4960</lpage>. doi: <pub-id pub-id-type="doi">10.1109/TPAMI.2021.3081010</pub-id>, PMID: <pub-id pub-id-type="pmid">33999813</pub-id></mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grover</surname><given-names>A.</given-names></name><name><surname>Leskovec</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>node2vec: scalable feature learning for networks</article-title>. <source>KDD</source>
<volume>2016</volume>, <fpage>855</fpage>–<lpage>864</lpage>. doi: <pub-id pub-id-type="doi">10.1145/2939672.2939754</pub-id>, PMID: <pub-id pub-id-type="pmid">27853626</pub-id></mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hatcher</surname><given-names>W. G.</given-names></name><name><surname>Yu</surname><given-names>W.</given-names></name></person-group> (<year>2018</year>). <article-title>A survey of deep learning: platforms, applications and emerging Rlesearch trends</article-title>. <source>IEEE Access</source>
<volume>6</volume>, <fpage>24411</fpage>–<lpage>24432</lpage>. doi: <pub-id pub-id-type="doi">10.1109/access.2018.2830661</pub-id></mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Ke</surname><given-names>P.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>S.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Xiong</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Multimodal magnetic resonance imaging reveals aberrant brain age trajectory during youth in schizophrenia patients</article-title>. <source>Front. Aging Neurosci.</source>
<volume>14</volume>:<fpage>823502</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fnagi.2022.823502</pub-id>, PMID: <pub-id pub-id-type="pmid">35309897</pub-id></mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>H.</given-names></name><name><surname>Cao</surname><given-names>P.</given-names></name><name><surname>Xu</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>J.</given-names></name><name><surname>Zaiane</surname><given-names>O.</given-names></name></person-group> (<year>2020</year>). <article-title>Hi-GCN: a hierarchical graph convolution network for graph embedding learning of brain network and brain disorders prediction</article-title>. <source>Comput. Biol. Med.</source>
<volume>127</volume>:<fpage>104096</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.compbiomed.2020.104096</pub-id>, PMID: <pub-id pub-id-type="pmid">33166800</pub-id></mixed-citation>
      </ref>
      <ref id="ref18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jo</surname><given-names>Y. T.</given-names></name><name><surname>Joo</surname><given-names>S. W.</given-names></name><name><surname>Shon</surname><given-names>S. H.</given-names></name><name><surname>Kim</surname><given-names>H.</given-names></name><name><surname>Kim</surname><given-names>Y.</given-names></name><name><surname>Lee</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Diagnosing schizophrenia with network analysis and a machine learning method</article-title>. <source>Int. J. Methods Psychiatr. Res.</source>
<volume>29</volume>:<fpage>e1818</fpage>. doi: <pub-id pub-id-type="doi">10.1002/mpr.1818</pub-id>, PMID: <pub-id pub-id-type="pmid">32022360</pub-id></mixed-citation>
      </ref>
      <ref id="ref19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keshavan</surname><given-names>M. S.</given-names></name><name><surname>Collin</surname><given-names>G.</given-names></name><name><surname>Guimond</surname><given-names>S.</given-names></name><name><surname>Kelly</surname><given-names>S.</given-names></name><name><surname>Prasad</surname><given-names>K. M.</given-names></name><name><surname>Lizano</surname><given-names>P.</given-names></name></person-group> (<year>2020</year>). <article-title>Neuroimaging in Schizophrenia</article-title>. <source>Neuroimaging Clin. N. Am.</source>
<volume>30</volume>, <fpage>73</fpage>–<lpage>83</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.nic.2019.09.007</pub-id>, PMID: <pub-id pub-id-type="pmid">31759574</pub-id></mixed-citation>
      </ref>
      <ref id="ref20">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J. Y.</given-names></name><name><surname>Lee</surname><given-names>H. S.</given-names></name><name><surname>Lee</surname><given-names>S. H.</given-names></name></person-group> (<year>2020</year>). <article-title>EEG source network for the diagnosis of schizophrenia and the identification of subtypes based on symptom severity-a machine learning approach</article-title>. <source>J. Clin. Med.</source>
<volume>9</volume>:<fpage>3934</fpage>. doi: <pub-id pub-id-type="doi">10.3390/jcm9123934</pub-id>, PMID: <pub-id pub-id-type="pmid">33291657</pub-id></mixed-citation>
      </ref>
      <ref id="ref21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kipf</surname><given-names>T. N.</given-names></name><name><surname>Welling</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>Semi-supervised classification with graph convolutional networks</article-title>. <source>arXiv</source> [Preprint]: 1609.02907. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1609.02907</pub-id></mixed-citation>
      </ref>
      <ref id="ref22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname><given-names>L. Y.</given-names></name><name><surname>Huang</surname><given-names>Y. Y.</given-names></name><name><surname>Lei</surname><given-names>B. Y.</given-names></name><name><surname>Ke</surname><given-names>P. F.</given-names></name><name><surname>Li</surname><given-names>H. H.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Divergent alterations of structural-functional connectivity couplings in first-episode and chronic schizophrenia patients</article-title>. <source>Neuroscience</source>
<volume>460</volume>, <fpage>1</fpage>–<lpage>12</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroscience.2021.02.008</pub-id>, PMID: <pub-id pub-id-type="pmid">33588002</pub-id></mixed-citation>
      </ref>
      <ref id="ref23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname><given-names>X. Z.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Huang</surname><given-names>L.</given-names></name><name><surname>Pu</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>Z.</given-names></name><name><surname>Dang</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Measuring individual morphological relationship of cortical regions</article-title>. <source>J. Neurosci. Methods</source>
<volume>237</volume>, <fpage>103</fpage>–<lpage>107</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.09.003</pub-id><pub-id pub-id-type="pmid">25220868</pub-id></mixed-citation>
      </ref>
      <ref id="ref24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>W. T.</given-names></name><name><surname>Maleki</surname><given-names>F.</given-names></name><name><surname>Romero</surname><given-names>F. P.</given-names></name><name><surname>Forghani</surname><given-names>R.</given-names></name><name><surname>Kadoury</surname><given-names>S.</given-names></name></person-group> (<year>2020</year>). <article-title>Overview of machine learning: part 2: deep learning for medical image analysis</article-title>. <source>Neuroimaging Clin. N. Am.</source>
<volume>30</volume>, <fpage>417</fpage>–<lpage>431</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.nic.2020.06.003</pub-id>, PMID: <pub-id pub-id-type="pmid">33038993</pub-id></mixed-citation>
      </ref>
      <ref id="ref25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>I.</given-names></name><name><surname>Kang</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>Self-attention graph pooling</article-title>. <source>arXiv</source> [Preprint]: 1904.08082. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1904.08082</pub-id></mixed-citation>
      </ref>
      <ref id="ref26">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lei</surname><given-names>D.</given-names></name><name><surname>Qin</surname><given-names>K.</given-names></name><name><surname>Pinaya</surname><given-names>W. H. L.</given-names></name><name><surname>Young</surname><given-names>J.</given-names></name><name><surname>Van Amelsvoort</surname><given-names>T.</given-names></name><name><surname>Marcelis</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Graph convolutional networks reveal network-level functional Dysconnectivity in schizophrenia</article-title>. <source>Schizophr. Bull.</source>
<volume>48</volume>, <fpage>881</fpage>–<lpage>892</lpage>. doi: <pub-id pub-id-type="doi">10.1093/schbul/sbac047</pub-id>, PMID: <pub-id pub-id-type="pmid">35569019</pub-id></mixed-citation>
      </ref>
      <ref id="ref27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L.</given-names></name><name><surname>Jiang</surname><given-names>H.</given-names></name><name><surname>Wen</surname><given-names>G.</given-names></name><name><surname>Cao</surname><given-names>P.</given-names></name><name><surname>Xu</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>TE-HI-GCN: an Ensemble of Transfer Hierarchical Graph Convolutional Networks for disorder diagnosis</article-title>. <source>Neuroinformatics</source>
<volume>20</volume>, <fpage>353</fpage>–<lpage>375</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s12021-021-09548-1</pub-id>, PMID: <pub-id pub-id-type="pmid">34761367</pub-id></mixed-citation>
      </ref>
      <ref id="ref28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>A.</given-names></name><name><surname>Zalesky</surname><given-names>A.</given-names></name><name><surname>Weihua</surname><given-names>Y.</given-names></name><name><surname>Howes</surname><given-names>O.</given-names></name><name><surname>Yan</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>A neuroimaging biomarker for striatal dysfunction in schizophrenia</article-title>. <source>Nat. Med.</source>
<volume>26</volume>, <fpage>558</fpage>–<lpage>565</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41591-020-0793-8</pub-id>, PMID: <pub-id pub-id-type="pmid">32251404</pub-id></mixed-citation>
      </ref>
      <ref id="ref29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Dvornek</surname><given-names>N.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Gao</surname><given-names>S.</given-names></name><name><surname>Zhuang</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>BrainGNN: interpretable brain graph neural network for fMRI analysis</article-title>. <source>Med. Image Anal.</source>
<volume>74</volume>:<fpage>102233</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.media.2021.102233</pub-id>, PMID: <pub-id pub-id-type="pmid">34655865</pub-id></mixed-citation>
      </ref>
      <ref id="ref30">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Northoff</surname><given-names>G.</given-names></name><name><surname>Duncan</surname><given-names>N. W.</given-names></name></person-group> (<year>2016</year>). <article-title>‘How do abnormalities in the brain’s spontaneous activity translate into symptoms in schizophrenia?</article-title>
<source>Prog. Neurobiol.</source>
<volume>145-146</volume>, <fpage>26</fpage>–<lpage>45</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.pneurobio.2016.08.003</pub-id>, PMID: <pub-id pub-id-type="pmid">27531135</pub-id></mixed-citation>
      </ref>
      <ref id="ref31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname><given-names>K. H.</given-names></name><name><surname>Oh</surname><given-names>I. S.</given-names></name><name><surname>Tsogt</surname><given-names>U.</given-names></name><name><surname>Shen</surname><given-names>J.</given-names></name><name><surname>Kim</surname><given-names>W. S.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Diagnosis of schizophrenia with functional connectome data: a graph-based convolutional neural network approach</article-title>. <source>BMC Neurosci.</source>
<volume>23</volume>:<fpage>5</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s12868-021-00682-9</pub-id>, PMID: <pub-id pub-id-type="pmid">35038994</pub-id></mixed-citation>
      </ref>
      <ref id="ref32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phang</surname><given-names>C. R.</given-names></name><name><surname>Noman</surname><given-names>F.</given-names></name><name><surname>Hussain</surname><given-names>H.</given-names></name><name><surname>Ting</surname><given-names>C. M.</given-names></name><name><surname>Ombao</surname><given-names>H.</given-names></name></person-group> (<year>2020</year>). <article-title>A multi-domain connectome convolutional neural network for identifying schizophrenia from EEG connectivity patterns</article-title>. <source>IEEE J. Biomed. Health Inform.</source>
<volume>24</volume>, <fpage>1333</fpage>–<lpage>1343</lpage>. doi: <pub-id pub-id-type="doi">10.1109/jbhi.2019.2941222</pub-id>, PMID: <pub-id pub-id-type="pmid">31536026</pub-id></mixed-citation>
      </ref>
      <ref id="ref33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pope</surname><given-names>P. E.</given-names></name><name><surname>Kolouri</surname><given-names>S.</given-names></name><name><surname>Rostami</surname><given-names>M.</given-names></name><name><surname>Martin</surname><given-names>C. E.</given-names></name><name><surname>Hoffmann</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). “<article-title>Explainability methods for graph convolutional neural networks</article-title>” in <source>2019 IEEE/CVF conference on computer vision and pattern recognition (CVPR)</source>, <fpage>10764</fpage>–<lpage>10773</lpage>. doi: <pub-id pub-id-type="doi">10.1109/cvpr.2019.01103</pub-id></mixed-citation>
      </ref>
      <ref id="ref34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qureshi</surname><given-names>M. N. I.</given-names></name><name><surname>Oh</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>B.</given-names></name></person-group> (<year>2019</year>). <article-title>3D-CNN based discrimination of schizophrenia using resting-state fMRI</article-title>. <source>Artif. Intell. Med.</source>
<volume>98</volume>, <fpage>10</fpage>–<lpage>17</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.artmed.2019.06.003</pub-id>, PMID: <pub-id pub-id-type="pmid">31521248</pub-id></mixed-citation>
      </ref>
      <ref id="ref35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>E. T.</given-names></name><name><surname>Cheng</surname><given-names>W.</given-names></name><name><surname>Gilson</surname><given-names>M.</given-names></name><name><surname>Gong</surname><given-names>W.</given-names></name><name><surname>Deco</surname><given-names>G.</given-names></name><name><surname>Lo</surname><given-names>C. Z.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Beyond the disconnectivity hypothesis of schizophrenia</article-title>. <source>Cereb. Cortex</source>
<volume>30</volume>, <fpage>1213</fpage>–<lpage>1233</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/bhz161</pub-id>, PMID: <pub-id pub-id-type="pmid">31381086</pub-id></mixed-citation>
      </ref>
      <ref id="ref36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossler</surname><given-names>W.</given-names></name><name><surname>Salize</surname><given-names>H. J.</given-names></name><name><surname>van Os</surname><given-names>J.</given-names></name><name><surname>Riecher-Rossler</surname><given-names>A.</given-names></name></person-group> (<year>2005</year>). <article-title>Size of burden of schizophrenia and psychotic disorders</article-title>. <source>Eur. Neuropsychopharmacol.</source>
<volume>15</volume>, <fpage>399</fpage>–<lpage>409</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.euroneuro.2005.04.009</pub-id>, PMID: <pub-id pub-id-type="pmid">15925493</pub-id></mixed-citation>
      </ref>
      <ref id="ref37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindler</surname><given-names>K. A.</given-names></name><name><surname>Bialonski</surname><given-names>S.</given-names></name><name><surname>Horstmann</surname><given-names>M. T.</given-names></name><name><surname>Elger</surname><given-names>C. E.</given-names></name><name><surname>Lehnertz</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Evolving functional network properties and synchronizability during human epileptic seizures</article-title>. <source>Chaos</source>
<volume>18</volume>:<fpage>033119</fpage>. doi: <pub-id pub-id-type="doi">10.1063/1.2966112</pub-id>, PMID: <pub-id pub-id-type="pmid">19045457</pub-id></mixed-citation>
      </ref>
      <ref id="ref38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sebenius</surname><given-names>I.</given-names></name><name><surname>Campbell</surname><given-names>A.</given-names></name><name><surname>Morgan</surname><given-names>S. E.</given-names></name><name><surname>Bullmore</surname><given-names>E. T.</given-names></name><name><surname>Lio</surname><given-names>P.</given-names></name></person-group> (<year>2021</year>). “<article-title>Multimodal graph coarsening for interpretable, MRI-based brain graph neural network</article-title>” in <source>2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)</source>, <fpage>1</fpage>–<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1109/mlsp52302.2021.9690626</pub-id></mixed-citation>
      </ref>
      <ref id="ref39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shchur</surname><given-names>O.</given-names></name><name><surname>Mumme</surname><given-names>M.</given-names></name><name><surname>Bojchevski</surname><given-names>A.</given-names></name><name><surname>Günnemann</surname><given-names>S.</given-names></name></person-group> (<year>2019</year>). <article-title>Pitfalls of graph neural network evaluation</article-title>. <source>arXiv</source> [Preprint]: 1811.05868. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1811.05868</pub-id></mixed-citation>
      </ref>
      <ref id="ref40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H.</given-names></name><name><surname>Lui</surname><given-names>S.</given-names></name><name><surname>Huang</surname><given-names>X.</given-names></name><name><surname>Sweeney</surname><given-names>J.</given-names></name><name><surname>Gong</surname><given-names>Q.</given-names></name></person-group> (<year>2023</year>). <article-title>Effects of randomness in the development of machine learning models in neuroimaging studies of schizophrenia</article-title>. <source>Schizophr. Res.</source>
<volume>252</volume>, <fpage>253</fpage>–<lpage>261</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.schres.2023.01.014</pub-id>, PMID: <pub-id pub-id-type="pmid">36682316</pub-id></mixed-citation>
      </ref>
      <ref id="ref41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tost</surname><given-names>H.</given-names></name><name><surname>Meyer-Lindenberg</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>Schizophrenia, social environment and the brain</article-title>. <source>Nat. Med.</source>
<volume>18</volume>, <fpage>211</fpage>–<lpage>213</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nm.2671</pub-id>, PMID: <pub-id pub-id-type="pmid">22310688</pub-id></mixed-citation>
      </ref>
      <ref id="ref42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name><name><surname>Landeau</surname><given-names>B.</given-names></name><name><surname>Papathanassiou</surname><given-names>D.</given-names></name><name><surname>Crivello</surname><given-names>F.</given-names></name><name><surname>Etard</surname><given-names>O.</given-names></name><name><surname>Delcroix</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2002</year>). <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>NeuroImage</source>
<volume>15</volume>, <fpage>273</fpage>–<lpage>289</lpage>. doi: <pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id>, PMID: <pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation>
      </ref>
      <ref id="ref43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>M. P.</given-names></name><name><surname>Fornito</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Brain networks in schizophrenia</article-title>. <source>Neuropsychol. Rev.</source>
<volume>24</volume>, <fpage>32</fpage>–<lpage>48</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s11065-014-9248-7</pub-id><pub-id pub-id-type="pmid">24500505</pub-id></mixed-citation>
      </ref>
      <ref id="ref44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Erp</surname><given-names>T. G. M.</given-names></name><name><surname>Walton</surname><given-names>E.</given-names></name><name><surname>Hibar</surname><given-names>D. P.</given-names></name><name><surname>Schmaal</surname><given-names>L.</given-names></name><name><surname>Jiang</surname><given-names>W.</given-names></name><name><surname>Glahn</surname><given-names>D. C.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Cortical brain abnormalities in 4474 individuals with schizophrenia and 5098 control subjects via the enhancing neuro imaging genetics through meta analysis (ENIGMA) consortium</article-title>. <source>Biol. Psychiatry</source>
<volume>84</volume>, <fpage>644</fpage>–<lpage>654</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.biopsych.2018.04.023</pub-id>, PMID: <pub-id pub-id-type="pmid">29960671</pub-id></mixed-citation>
      </ref>
      <ref id="ref45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Jin</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>Single-subject morphological brain networks: connectivity mapping, topological characterization and test-retest reliability</article-title>. <source>Brain Behav.</source>
<volume>6</volume>:<fpage>e00448</fpage>. doi: <pub-id pub-id-type="doi">10.1002/brb3.448</pub-id>, PMID: <pub-id pub-id-type="pmid">27088054</pub-id></mixed-citation>
      </ref>
      <ref id="ref46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Ke</surname><given-names>P. F.</given-names></name><name><surname>Zang</surname><given-names>J. Y.</given-names></name><name><surname>Wu</surname><given-names>F. C.</given-names></name><name><surname>Wu</surname><given-names>K.</given-names></name></person-group> (<year>2022</year>). <article-title>Discriminative analysis of schizophrenia patients using topological properties of structural and functional brain networks: a multimodal magnetic resonance imaging study</article-title>. <source>Front. Neurosci.</source>
<volume>15</volume>:<fpage>785595</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fnins.2021.785595</pub-id>, PMID: <pub-id pub-id-type="pmid">35087373</pub-id></mixed-citation>
      </ref>
      <ref id="ref47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Xia</surname><given-names>M.</given-names></name><name><surname>Liao</surname><given-names>X.</given-names></name><name><surname>Evans</surname><given-names>A.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name></person-group> (<year>2015</year>). <article-title>GRETNA: a graph theoretical network analysis toolbox for imaging connectomics</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>9</volume>:<fpage>386</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fnhum.2015.00386</pub-id>, PMID: <pub-id pub-id-type="pmid">26175682</pub-id></mixed-citation>
      </ref>
      <ref id="ref48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>F. C.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Lu</surname><given-names>X.</given-names></name><name><surname>Fang</surname><given-names>Z.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Structural and functional brain abnormalities in drug-naive, first-episode, and chronic patients with schizophrenia: a multimodal MRI study</article-title>. <source>Neuropsychiatr. Dis. Treat.</source>
<volume>14</volume>, <fpage>2889</fpage>–<lpage>2904</lpage>. doi: <pub-id pub-id-type="doi">10.2147/NDT.S174356</pub-id>, PMID: <pub-id pub-id-type="pmid">30464473</pub-id></mixed-citation>
      </ref>
      <ref id="ref49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>P.</given-names></name><name><surname>Chen</surname><given-names>A.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Xing</surname><given-names>X.</given-names></name><name><surname>Lu</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). <article-title>Medial prefrontal cortex in neurological diseases</article-title>. <source>Physiol. Genomics</source>
<volume>51</volume>, <fpage>432</fpage>–<lpage>442</lpage>. doi: <pub-id pub-id-type="doi">10.1152/physiolgenomics.00006.2019</pub-id>, PMID: <pub-id pub-id-type="pmid">31373533</pub-id></mixed-citation>
      </ref>
      <ref id="ref50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>K.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name><name><surname>Sonobe</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). <article-title>Representation learning on graphs with jumping kownledge networks</article-title>. <source>arXiv</source> [Preprint]: 1806.03536. doi: <pub-id pub-id-type="doi">10.48550/arXiv.1806.03536</pub-id></mixed-citation>
      </ref>
      <ref id="ref51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>C. G.</given-names></name><name><surname>Wang</surname><given-names>X. D.</given-names></name><name><surname>Zuo</surname><given-names>X. N.</given-names></name><name><surname>Zang</surname><given-names>Y. F.</given-names></name></person-group> (<year>2016</year>). <article-title>DPABI: Data Processing &amp; Analysis for (resting-state) brain imaging</article-title>. <source>Neuroinformatics</source>
<volume>14</volume>, <fpage>339</fpage>–<lpage>351</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s12021-016-9299-4</pub-id><pub-id pub-id-type="pmid">27075850</pub-id></mixed-citation>
      </ref>
      <ref id="ref52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>D.</given-names></name><name><surname>Sui</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>E.</given-names></name><name><surname>Jiaerken</surname><given-names>Y.</given-names></name><name><surname>Luo</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>A mutual multi-scale triplet graph convolutional network for classification of brain disorders using functional or structural connectivity</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>40</volume>, <fpage>1279</fpage>–<lpage>1289</lpage>. doi: <pub-id pub-id-type="doi">10.1109/TMI.2021.3051604</pub-id>, PMID: <pub-id pub-id-type="pmid">33444133</pub-id></mixed-citation>
      </ref>
      <ref id="ref53">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>H.</given-names></name><name><surname>Yu</surname><given-names>H.</given-names></name><name><surname>Gui</surname><given-names>S.</given-names></name><name><surname>Ji</surname><given-names>S.</given-names></name></person-group> (<year>2022</year>). <article-title>Explainability in graph neural networks: a taxonomic survey</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell.</source> PP, <fpage>1</fpage>–<lpage>19</lpage>. doi: <pub-id pub-id-type="doi">10.1109/tpami.2022.3204236</pub-id>, PMID: <pub-id pub-id-type="pmid">34941499</pub-id></mixed-citation>
      </ref>
      <ref id="ref54">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zang</surname><given-names>Y. F.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Zhu</surname><given-names>C. Z.</given-names></name><name><surname>Cao</surname><given-names>Q. J.</given-names></name><name><surname>Sui</surname><given-names>M. Q.</given-names></name><name><surname>Liang</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>Altered baseline brain activity in children with ADHD revealed by resting-state functional MRI</article-title>. <source>Brain Dev.</source>
<volume>29</volume>, <fpage>83</fpage>–<lpage>91</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.braindev.2006.07.002</pub-id>, PMID: <pub-id pub-id-type="pmid">16919409</pub-id></mixed-citation>
      </ref>
      <ref id="ref55">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zang</surname><given-names>J. Y.</given-names></name><name><surname>Huang</surname><given-names>Y. Y.</given-names></name><name><surname>Kong</surname><given-names>L. Y.</given-names></name><name><surname>Lei</surname><given-names>B.</given-names></name><name><surname>Ke</surname><given-names>P.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Effects of brain atlases and machine learning methods on the discrimination of schizophrenia patients: a multimodal MRI study</article-title>. <source>Front. Neurosci.</source>
<volume>15</volume>:<fpage>697168</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fnins.2021.697168</pub-id>, PMID: <pub-id pub-id-type="pmid">34385901</pub-id></mixed-citation>
      </ref>
      <ref id="ref56">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zang</surname><given-names>Y.</given-names></name><name><surname>Jiang</surname><given-names>T.</given-names></name><name><surname>Lu</surname><given-names>Y.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Tian</surname><given-names>L.</given-names></name></person-group> (<year>2004</year>). <article-title>Regional homogeneity approach to fMRI data analysis</article-title>. <source>NeuroImage</source>
<volume>22</volume>, <fpage>394</fpage>–<lpage>400</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2003.12.030</pub-id><pub-id pub-id-type="pmid">15110032</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
