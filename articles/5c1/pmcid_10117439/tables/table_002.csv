Parameter name,Parameters
Optimizer,Adaptive optimizer (Adam)
Loss function,Cross entropy loss
Activation function,ReLu
Learning rate,0.0001
Batch Size,30
Dropout rate,0.5
Maximum epochs,"1,000"
Patience of early stopping,500
