<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1662-4548</issn>
      <issn pub-type="epub">1662-453X</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">30323734</article-id>
      <article-id pub-id-type="pmc">6172342</article-id>
      <article-id pub-id-type="doi">10.3389/fnins.2018.00528</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>On the Extraction and Analysis of Graphs From Resting-State fMRI to Support a Correct and Robust Diagnostic Tool for Alzheimer's Disease</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Bachmann</surname>
            <given-names>Claudia</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="c001">
            <sup>*</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/455265/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Jacobs</surname>
            <given-names>Heidi I. L.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/107829/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Porta Mana</surname>
            <given-names>PierGianLuca</given-names>
          </name>
          <xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/467759/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Dillen</surname>
            <given-names>Kim</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/535195/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Richter</surname>
            <given-names>Nils</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>von Reutern</surname>
            <given-names>Boris</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Dronse</surname>
            <given-names>Julian</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Onur</surname>
            <given-names>Oezguer A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/201134/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Langen</surname>
            <given-names>Karl-Josef</given-names>
          </name>
          <xref ref-type="aff" rid="aff8">
            <sup>8</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/362963/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Fink</surname>
            <given-names>Gereon R.</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1701/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Kukolja</surname>
            <given-names>Juraj</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
          <xref ref-type="aff" rid="aff9">
            <sup>9</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/4923/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Morrison</surname>
            <given-names>Abigail</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff10">
            <sup>10</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/13504/overview"/>
        </contrib>
      </contrib-group>
      <aff id="aff1"><sup>1</sup><institution>Institute of Neuroscience and Medicine (INM-6), Institute for Advanced Simulation (IAS-6), JARA BRAIN Institute I, Jülich Research Centre</institution>, <addr-line>Jülich</addr-line>, <country>Germany</country></aff>
      <aff id="aff2"><sup>2</sup><institution>Faculty of Health, Medicine and Life Science, School for Mental Health and Neuroscience, Alzheimer Centre Limburg, Maastricht University</institution>, <addr-line>Maastricht</addr-line>, <country>Netherlands</country></aff>
      <aff id="aff3"><sup>3</sup><institution>Division of Nuclear Medicine and Molecular Imaging, Department of Radiology, Harvard Medical School, Massachusetts General Hospital</institution>, <addr-line>Boston, MA</addr-line>, <country>United States</country></aff>
      <aff id="aff4"><sup>4</sup><institution>Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, Maastricht University</institution>, <addr-line>Maastricht</addr-line>, <country>Netherlands</country></aff>
      <aff id="aff5"><sup>5</sup><institution>Kavli Institute for Systems Neuroscience, Norwegian University of Science and Technology (NTNU)</institution>, <addr-line>Trondheim</addr-line>, <country>Norway</country></aff>
      <aff id="aff6"><sup>6</sup><institution>Cognitive Neuroscience, Institute of Neuroscience and Medicine (INM-3), Jülich Research Centre</institution>, <addr-line>Jülich</addr-line>, <country>Germany</country></aff>
      <aff id="aff7"><sup>7</sup><institution>Department of Neurology, University Hospital of Cologne</institution>, <addr-line>Cologne</addr-line>, <country>Germany</country></aff>
      <aff id="aff8"><sup>8</sup><institution>Cognitive Neuroscience, Institute of Neuroscience and Medicine (INM-4), Jülich Research Centre</institution>, <addr-line>Jülich</addr-line>, <country>Germany</country></aff>
      <aff id="aff9"><sup>9</sup><institution>Department of Neurology, Helios University Hospital Wuppertal</institution>, <addr-line>Wuppertal</addr-line>, <country>Germany</country></aff>
      <aff id="aff10"><sup>10</sup><institution>Faculty of Psychology, Institute of Cognitive Neuroscience, Ruhr-University Bochum</institution>, <addr-line>Bochum</addr-line>, <country>Germany</country></aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: Athanasios Alexiou, Novel Global Community Educational Foundation (NGCEF), Australia</p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: Alessandro Giuliani, Istituto Superiore di Sanità, Italy; Rui Li, Institute of Psychology (CAS), China</p>
        </fn>
        <corresp id="c001">*Correspondence: Claudia Bachmann <email>c.bachmann@fz-juelich.de</email></corresp>
        <fn fn-type="other" id="fn001">
          <p>This article was submitted to Brain Imaging Methods, a section of the journal Frontiers in Neuroscience</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>28</day>
        <month>9</month>
        <year>2018</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2018</year>
      </pub-date>
      <volume>12</volume>
      <elocation-id>528</elocation-id>
      <history>
        <date date-type="received">
          <day>31</day>
          <month>1</month>
          <year>2018</year>
        </date>
        <date date-type="accepted">
          <day>13</day>
          <month>7</month>
          <year>2018</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2018 Bachmann, Jacobs, Porta Mana, Dillen, Richter, von Reutern, Dronse, Onur, Langen, Fink, Kukolja and Morrison.</copyright-statement>
        <copyright-year>2018</copyright-year>
        <copyright-holder>Bachmann, Jacobs, Porta Mana, Dillen, Richter, von Reutern, Dronse, Onur, Langen, Fink, Kukolja and Morrison</copyright-holder>
        <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>The diagnosis of Alzheimer's disease (AD), especially in the early stage, is still not very reliable and the development of new diagnosis tools is desirable. A diagnosis based on functional magnetic resonance imaging (fMRI) is a suitable candidate, since fMRI is non-invasive, readily available, and indirectly measures synaptic dysfunction, which can be observed even at the earliest stages of AD. However, the results of previous attempts to analyze graph properties of resting state fMRI data are contradictory, presumably caused by methodological differences in graph construction. This comprises two steps: clustering the voxels of the functional image to define the nodes of the graph, and calculating the graph's edge weights based on a functional connectivity measure of the average cluster activities. A variety of methods are available for each step, but the robustness of results to method choice, and the suitability of the methods to support a diagnostic tool, are largely unknown. To address this issue, we employ a range of commonly and rarely used clustering and edge definition methods and analyze their graph theoretic measures (graph weight, shortest path length, clustering coefficient, and weighted degree distribution and modularity) on a small data set of 26 healthy controls, 16 subjects with mild cognitive impairment (MCI) and 14 with Alzheimer's disease. We examine the results with respect to statistical significance of the mean difference in graph properties, the sensitivity of the results to model and parameter choices, and relative diagnostic power based on both a statistical model and support vector machines. We find that different combinations of graph construction techniques yield contradicting, but statistically significant, relations of graph properties between health conditions, explaining the discrepancy across previous studies, but casting doubt on such analyses as a method to gain insight into disease effects. The production of significant differences in mean graph properties turns out not to be a good predictor of future diagnostic capacity. Highest predictive power, expressed by largest negative surprise values, are achieved for both atlas-driven and data-driven clustering (Ward clustering), as long as graphs are small and clusters large, in combination with edge definitions based on correlations and mutual information transfer.</p>
      </abstract>
      <kwd-group>
        <kwd>Alzheimer's disease</kwd>
        <kwd>MCI</kwd>
        <kwd>graph theory</kwd>
        <kwd>resting-state fMRI</kwd>
        <kwd>diagnosis</kwd>
        <kwd>model by sufficiency</kwd>
        <kwd>negative surprise</kwd>
      </kwd-group>
      <funding-group>
        <award-group>
          <funding-source id="cn001">Deutsche Forschungsgemeinschaft<named-content content-type="fundref-id">10.13039/501100001659</named-content></funding-source>
          <award-id rid="cn001">JA 2336/1-1</award-id>
        </award-group>
      </funding-group>
      <counts>
        <fig-count count="13"/>
        <table-count count="4"/>
        <equation-count count="13"/>
        <ref-count count="75"/>
        <page-count count="24"/>
        <word-count count="18207"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>1. Introduction</title>
      <p>The two major challenges in Alzheimer's disease (AD) research consist in firstly, finding an effective treatment that at least slows down the disease progress, and secondly, developing diagnostic tools that can not only detect the disease at the earliest stage, during which no symptoms related to cognitive deficits are apparent (Sperling et al., <xref rid="B64" ref-type="bibr">2011</xref>), but also provide information into the progression of the disease. For the latter challenge it is particularly desirable that the tools can be deployed within the existing medical infrastructure (i.e., not requiring specialized machinery or lab procedures), such that it is feasible to scan a wide range of the elderly population. Diagnosis procedures currently in use include psychological tests, detection of abnormal concentrations of disease specific biomarkers (Amyloid-β, tau proteins) in cerebrospinal fluid and analysis of structural magnetic resonance images (MRI).</p>
      <p>Although abnormalities of Amyloid-β concentrations are proposed to be the earliest disease indicator, they are not very reliable in disease prognosis. Moreover, the changes in Amyloid-β concentrations show the strongest increase in the preclinical phase, and are thus uninformative with respect to the further progression of the disease. Tau pathology, which probably spreads along functional networks (Hoenig et al., <xref rid="B25" ref-type="bibr">2018</xref>) better predicts cognitive deficits and progression of the disease (Nelson et al., <xref rid="B46" ref-type="bibr">2012</xref>). However, the two methods measuring Amyloid-β and tau concentrations, lumbar puncture and PET are invasive (Schroeter et al., <xref rid="B59" ref-type="bibr">2009</xref>; Sperling et al., <xref rid="B64" ref-type="bibr">2011</xref>).</p>
      <p>Possibly, synaptic dysfunction, another disease marker, corresponds to the onset of AD even before Amyloid-β pathology starts. Additionally, as it gradually worsens throughout the course of the disease, it could serve as diagnostic marker for all stages of AD. Dysfunction of synapses can be indirectly measured via invasive FDG-PET and non-invasive functional MRI, which might directly be combined with structural MRI scans (Schroeter et al., <xref rid="B59" ref-type="bibr">2009</xref>; Sperling et al., <xref rid="B64" ref-type="bibr">2011</xref>). However, a diagnostic framework based on functional MRI has yet to be established.</p>
      <p>Although many fMRI studies have investigated changes of functional activity in AD (for a review see Dennis and Thompson, <xref rid="B13" ref-type="bibr">2014</xref>), there is no consensus about which information should be used. Such studies typically examine disrupted cortical connectivity, either locally, considering single brain areas (e.g., Dillen et al., <xref rid="B15" ref-type="bibr">2017</xref>) and their embedding in the network, or globally, analyzing the entire constructed brain graph and the statistics of its graph properties (Gits, <xref rid="B16" ref-type="bibr">2016</xref>).</p>
      <p>We argue that in order to develop a robust diagnosis tool applicable to all disease stages, it is preferable to consider global graph properties for the following reasons. First, global graph properties seem to be more robust across sessions; consequently, changes in these properties over time are more likely to reflect disease progression than statistical fluctuations (Telesford et al., <xref rid="B66" ref-type="bibr">2010</xref>; Wang et al., <xref rid="B69" ref-type="bibr">2014</xref>). Second, not all disease progressions follow a stereotypical pattern. Whereas structural evidence of AD is typically found predominantly in entorhinal cortex and hippocampus, in atypical cases atrophy occurs primarily in other areas, such as posterior cortex (Johnson et al., <xref rid="B30" ref-type="bibr">2012</xref>). These atypical cases might be better captured by global properties, since they make use of the entire information provided by the brain. Furthermore, analyzing the statistics of graph properties rather than comparing the properties of single nodes allows the use of data-driven brain clustering, which results in different numbers and locations of brain clusters for each individual.</p>
      <p>However, it is challenging to investigate the informativeness of global graph properties due to the innumerable methods of graph construction, comprising both the clustering of the voxels to define the graph's nodes, and the definition of functional connectivity to define its edges. Across the range of previous studies investigating graph properties in AD, a wide variety of methodological approaches for graph construction and properties assessment have been applied and are probably a major source of contradictory observations, such as the comparative length of the shortest path in AD subjects with respect to control being reported in two recent studies as both shorter (Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>) and longer (Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>).</p>
      <p>It is a further challenge to identify an appropriate evaluation method that not only enables us to compare the different graph construction methods, but also permits the results to be combined with other information indicating the probability of a particular health condition. This means that pure classifiers, although they achieve high discrimination performance (Khazaee et al., <xref rid="B33" ref-type="bibr">2015</xref>, <xref rid="B34" ref-type="bibr">2017</xref>) do not meet these requirements because they return a group membership (“AD,” “MCI,” or “control”) and not a probability that can be combined with the results of other diagnostic tests (e.g., derived from Amyloid-β concentration measures) or individual patient risk factors (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>).</p>
      <p>In this article, we address these issues by presenting a methodology for determining which combination of techniques to extract and analyze graphs from resting state fMRI data provides the best basis for a diagnosis tool, assuming a given initial data set. Here, we apply our methodology to a small data set consisting of 26 control (C) elderly patients without any indication of any form of dementia or other cognitive problems, 16 mild cognitive impaired (MCI) subjects and 14 patients suffering from Alzheimer disease (AD) (Dillen et al., <xref rid="B15" ref-type="bibr">2017</xref>). We evaluate the combinations of graph construction and analysis methods using a statistical model that partly compensates for the small data set and also yields probabilities rather than classifications, thus permitting the results to be combined with other probabilities, as discussed above. In addition, we evaluate the graph construction techniques with respect to robustness of results to method configuration parameters and similarity of results across different techniques.</p>
      <p>Note that our aim here is not to demonstrate superior classification (for which our data set is in any case too small) or to propose a particular combination of techniques as optimal (as this may vary between settings), but primarily to provide a principled way for determining an appropriate combination of techniques for a given data set, and secondarily to highlight the sensitivity of graph theoretical analysis to the details of graph construction.</p>
      <p>To understand how different methods for constructing graphs affect the resultant graph properties, and thus the ability to distinguish between patient groups, we evaluate a range of standard and non-standard methods to construct the graphs. The first step in graph construction consists in clustering adjacent voxels, such that the activity of the resulting region can be expressed by the average of time varying signal of the selected voxels (see Figure <xref ref-type="fig" rid="F1">1</xref>). The decision as to which voxels form a cluster is often based on atlases established for a standard brain with predefined brain regions. In order to map this standard atlas to the functional image or vice versa, registration algorithms are used. Problematic in this step, especially for subjects potentially suffering from neurodegenerative diseases, is the inhomogeneous shrinkage of the brain, which hampers a correct registration (Liu et al., <xref rid="B39" ref-type="bibr">2017</xref>). In addition, individual brain regions derived from standard brain templates are likely to execute several cognitive processes in parallel, such that averaging the activity across the voxels of these functional inhomogeneous regions is not justified (Marrelec and Fransson, <xref rid="B41" ref-type="bibr">2011</xref>). We therefore also include activity driven algorithms, namely region growing and selection (Lu et al., <xref rid="B40" ref-type="bibr">2003</xref>) and Ward clustering, into our evaluation.</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Overview of intermediate steps for graph construction, properties derivation and statistical analysis. Each picture illustrates the result of a processing step starting from the preprocessed functional image (far left), which is clustered into regions, used as the nodes of the graph (second image). The averaged fMRI activity of each region is then used to calculate the edges of the graph (third image) and based on the calculated graph properties (fourth image) of all graphs, the statistical analysis estimates the probability density functions (pdf) of the three health conditions (last image) that are necessary for the evaluation of diagnostic performance based on the negative surprise measure. For the first three steps of the pipeline we investigate a range of different methods, see sections 2.1, 5.3, 5.4, and 5.5 for details.</p>
        </caption>
        <graphic xlink:href="fnins-12-00528-g0001"/>
      </fig>
      <p>In the second step in graph construction, functional connectivity values are calculated based on the averaged signal of the regions. In most studies this is carried out based on the Pearson correlation coefficient, restricting the functional connectivity to non-directional connections. Here we cover a broader range of possible measures in the time domain: linear, non-linear model-free and model-based (Wang et al., <xref rid="B69" ref-type="bibr">2014</xref>) that, depending on their exact realization, result in directed or undirected graphs.</p>
      <p>We then calculate a variety of graph measures on the single nodes (weighted degree, cluster coefficient, closeness centrality), edges (weights, shortest path) and the entire graph (modularity). As several of these measures are only well-defined for binary graphs, many studies binarize the weighted graphs obtained from the previous steps into binary graphs, by setting weights above an arbitrary threshold <italic>w</italic>min to 1, and those below it to 0 (e.g., Supekar et al., <xref rid="B65" ref-type="bibr">2008</xref>). The drawback here is that there is no validation for an optimal threshold, and information that might be relevant in AD may be lost. To investigate this problem, we analyze the dependence of graph theoretic measures on <italic>w</italic>min, setting the weights below it to 0 but leaving the values above unchanged.</p>
      <p>To assess the suitability of combinations of graph construction and analysis methods to inform a diagnosis tool, we set up a statistical analysis based on a training data set of known health conditions (healthy controls, mild cognitive impairment, and Alzheimer's disease), see section 5.6. The diagnostic usefulness of the analysis pipeline is then defined as the performance of the model against a labeled test data set. A model with good performance can ultimately be employed in a clinical setting, to assess the probability that a patient has one of the three health conditions. For a more complete discussion of the development and use of the statistical model, see Porta Mana et al. (<xref rid="B53" ref-type="bibr">2018</xref>).</p>
      <p>In this study we use a statistical model constructed from the following working hypothesis: the empirical means and correlations of graph data from previous patients with a given health condition are sufficient to predict the graph data of a new patient with that same health condition. This is a partially exchangeable model by sufficiency, and the resulting likelihood is a multivariate t distribution (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>), described in section 5.6. To assess which graph constructions have the greatest predictive power, we calculate their log-probabilities or <italic>negative surprises</italic> (Bartlett, <xref rid="B3" ref-type="bibr">1952</xref>; Good, <xref rid="B17" ref-type="bibr">1956</xref>, <xref rid="B18" ref-type="bibr">1957a</xref>,<xref rid="B19" ref-type="bibr">b</xref>, <xref rid="B20" ref-type="bibr">1983</xref>). To validate this approach, we also compare the results of the negative surprise with the classification performance achieved by a support vector machine (SVM).</p>
      <p>Our results show that clustering resulting in small graphs with large clusters (Ward and atlas-based clustering) achieve highest negative surprises (and best SVM classification performance). Similarly, amongst the edge definition techniques, model-free methods (linear and non-linear correlations, mutually information transfer) obtain the highest negative surprise values. Conversely, calculating the graph's edge weights according to transfer entropy (model based) achieves limited diagnostic power but the ordering of the individuals based on their average graph properties is very robust toward the applied clustering method and choice of algorithm specific parameters. We further demonstrate that significant differences in the means of graph properties are very sensitive to method choice and to parameterization choices for a given method. Therefore such results, if taken at face value and not validated by alternate methods, may well be artifactual and not provide insight into the effects of a disease. Interestingly, the presence of significant differences in mean values of graph properties is not a reliable predictor of later diagnostic performance. In particular, atlas clustering results in only few significant differences but reaches the highest values for negative surprises and the best classification scores for the SVM. Finally, we show that the effect of setting a threshold on the graphs edge weights has only marginal effect on the negative surprise as long as threshold values are small.</p>
    </sec>
    <sec id="s2">
      <title>2. Results</title>
      <sec>
        <title>2.1. Graph construction</title>
        <sec>
          <title>2.1.1. Vertex definition by means of clustering</title>
          <p>A universal property of the clustering algorithms examined here is the existence of a control parameter that regulates how the clusters are formed, and thus preserves a certain feature (or features) of the clusters. In atlas-based clustering, the preserved features are the number of clusters and the number of voxels per cluster. In Ward clustering, the number of resulting clusters is fixed, which we violate to a small extent by deleting very small clusters. In region growing and selection (RGS), the homogeneity of each cluster is preserved. The freedom that each of the algorithms leaves to the non-regulated features can either be considered as a drawback of the algorithm, because it makes graphs less easily comparable, or as an additional feature that might even improve the diagnosis performance.</p>
          <p>Figure <xref ref-type="fig" rid="F2">2</xref> shows the number of nodes/clusters, the average number of voxels per node and the average heterogeneity of the nodes for two configurations of the RGS algorithm, four configurations of the Ward algorithm, and the atlas algorithm (see section 5.3 and Table <xref rid="T3" ref-type="table">3</xref>). Most strikingly, the node properties vary far more with respect to the clustering method chosen than with respect to the health condition.</p>
          <fig id="F2" position="float">
            <label>Figure 2</label>
            <caption>
              <p>Node properties across different clustering algorithms. For each of the seven clustering methods detailed in section 5.3 and Table <xref rid="T3" ref-type="table">3</xref>, and each subject categorized in the health conditions: control (C, blue dots), mild cognitive impairment (MCI, green dots), and Alzheimer's disease (AD, orange dots) we calculate the total number of nodes/clusters generated <bold>(Upper Panel)</bold>, the average number of voxels per node <bold>(Middle Panel)</bold>, and the average cluster heterogeneity <bold>(Lower Panel)</bold>.</p>
            </caption>
            <graphic xlink:href="fnins-12-00528-g0002"/>
          </fig>
          <p>By construction, the number of nodes for atlas clustering are the same for all individuals, and are the smallest over all the clustering methods (top panel). In Ward clustering the number of clusters is a parameter of the algorithm; it is not constant in Figure <xref ref-type="fig" rid="F2">2</xref> because we additionally include a parameter enforcing a minimum cluster size. Thus, the number of nodes for Ward clustering decreases as the minimum number of voxels per cluster <italic>p</italic> increases from 10 for “ward1” to 25 in “ward4.” In RGS clustering we do not have such restrictions and the number of clusters is defined by the voxel dynamics. A consequence of this is that the number of clusters per graph are more widely spread.</p>
          <p>The average number of voxels per cluster, shown in the middle panel of Figure <xref ref-type="fig" rid="F2">2</xref>, is unsurprisingly negatively correlated with the number of clusters. For purposes of comparison, the number of voxels for atlas clustering was first calculated for the standard space and then downscaled in proportion to the relation of the total number of voxels present in functional space to those in standard space. An inverse correlation can also be seen in the width of the distributions between the top two panels, for the non-atlas methods. In the case of RGS clustering, this can be explained by the fixation of the heterogeneity to one (see bottom panel of Figure <xref ref-type="fig" rid="F2">2</xref>), leading to quite homogeneous numbers of voxels per cluster, but to a wide range of the number of nodes, namely from 200 to 1200. Since this range is so large, it could be argued that graph properties that depend on this number would not be comparable in a meaningful fashion. In order to take care of such dependencies, we include the number of nodes in our statistical analysis (section 5.6). For Ward clustering we can observe that the numbers of nodes is inversely correlated not only with the average number of nodes and its variability, but also with the average heterogeneity and its variability. We observe the highest degree of heterogeneity for atlas clustering, presumably due to the high number of voxels per cluster.</p>
          <p>Comparing node properties between the classes of clustering methods, atlas and ward4 clustering seem to be quite similar, which suggests they might result in similar graph properties and diagnosis performance. In particular, we note that these methods reveal a much smaller heterogeneity for the MCI group than for the control and AD groups.</p>
        </sec>
        <sec>
          <title>2.1.2. Edge definition by means of functional connectivity</title>
          <p>The edges of the graphs are constructed in four different ways, described in detail in section 5.4. Linear correlations (<italic>corr</italic>) are based on the Pearson correlation coefficient; non-linear correlations (<italic>H</italic><sub>2</sub>) result from a non-linear fit of piecewise linear correlations; mutual information transfer (<italic>MIT</italic>) measures the amount of shared information between two time varying signals and transfer entropy (<italic>TE</italic>) describes in how far the future uncertainty is reduced by the preceding activity of the considered pair of nodes. As with the clustering algorithms described in the previous section, we defined differently parameterized variants of these four classes of technique (e.g., generating directed <italic>D</italic> or undirected <italic>U</italic> graphs) which are listed in Table <xref rid="T4" ref-type="table">4</xref>.</p>
          <p>For each combination of vertex (RGS, Ward or atlas) and edge definition technique (<italic>corr</italic>, <italic>H</italic><sub>2</sub>, <italic>MIT</italic>, <italic>TE</italic>), we averaged over the weights generated in each health condition for each variant of both techniques. For example, for the combination of region growing and transfer entropy (RGS <italic>TE</italic>) we averaged over all combinations of clustering implementation (RGS1 and RGS2) and edge detection (<italic>BTEU</italic>1, <italic>BTEU</italic>2, <italic>BTED</italic>1, <italic>BTED</italic>2). The results are shown in Table <xref rid="T1" ref-type="table">1</xref> and exhibit a high variability in the mean connection weights. For instance, the combination RGS <italic>TE</italic> yields a maximal mean weight of 0.158 for controls, which is three times lower than the maximum mean weight of 0.493 obtained by the RGS <italic>H</italic><sub>2</sub> combination. In particular, RGS clustering yields higher values compared with Ward and atlas clustering for model-free edge definitions (<italic>corr</italic>, <italic>H</italic><sub>2</sub>, <italic>MIT</italic>). The smallest values are obtained for <italic>TE</italic>. As a consequence, even small thresholds e.g., <italic>w</italic>min = 0.3 already cause <italic>TE</italic> graphs to disintegrate. Accordingly, not all graph properties can be calculated and used for statistical analysis, as shown in section 2.3.</p>
          <table-wrap id="T1" position="float">
            <label>Table 1</label>
            <caption>
              <p>Mean and standard deviation of edge weight across different edge definitions.</p>
            </caption>
            <table frame="hsides" rules="groups">
              <thead>
                <tr>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>Combination</bold>
                  </th>
                  <th valign="top" align="center" rowspan="1" colspan="1">
                    <bold>ŵ<sub><italic>C</italic></sub></bold>
                  </th>
                  <th valign="top" align="center" rowspan="1" colspan="1">
                    <bold>ŵ<sub><italic>MCI</italic></sub></bold>
                  </th>
                  <th valign="top" align="center" rowspan="1" colspan="1">
                    <bold>ŵ<sub><italic>AD</italic></sub></bold>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Ward <italic>corr</italic></td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.328 ± 0.021</td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.337 ± 0.04</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.315 ± 0.023</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">RGS <italic>corr</italic></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.405 ± 0.076</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.363 ± 0.049</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.397 ± 0.113</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">atlas <italic>corr</italic></td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.319 ± 0.02</td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.334 ± 0.054</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.307 ± 0.022</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Ward <italic>H</italic><sub>2</sub></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.443 ± 0.18</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.398 ± 0.081</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.414 ± 0.057</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">RGS <italic>H</italic><sub>2</sub></td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.452 ± 0.1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.471 ± 0.126</td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.493 ± 0.179</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">atlas <italic>H</italic><sub>2</sub></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.36 ± 0.057</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.352 ± 0.039</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.355 ± 0.042</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Ward <italic>MIT</italic></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.201 ± 0.004</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.2 ± 0.007</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.197 ± 0.004</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">RGS <italic>MIT</italic></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.221 ± 0.026</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.204 ± 0.011</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.218 ± 0.037</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">atlas <italic>MIT</italic></td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.196 ± 0.003</td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.197 ± 0.008</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.193 ± 0.003</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Ward <italic>TE</italic></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.163 ± 0.013</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.158 ± 0.015</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.156 ± 0.018</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">RGS <italic>TE</italic></td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.158 ± 0.026</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.149 ± 0.02</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.152 ± 0.042</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">atlas <italic>TE</italic></td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.163 ± 0.016</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">0.17 ± 0.011</td>
                  <td valign="top" align="center" style="background-color:#939598" rowspan="1" colspan="1">0.165 ± 0.011</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <p><italic>Means and standard deviations are taken across the average edge weight of every individual graph in a health condition. Highest mean edge weights for each combination across the three health conditions are highlighted in gray</italic>.</p>
            </table-wrap-foot>
          </table-wrap>
          <p>It is also notable that there is no systematic relationship between the three health conditions—for RGS <italic>corr</italic>, the control graphs have the highest mean weight, for RGS <italic>H</italic><sub>2</sub>, the AD graphs; and for atlas corr, the MCI graphs. These results demonstrate that conclusions drawn on health conditions based on weight statistics should be treated with suspicion, as the outcome can be strongly influenced by the method of calculation. A possible explanation for the higher weights generated by RGS clustering is that it produces a greater number of shorter distances compared with the other clustering techniques. However, although Figure <xref ref-type="fig" rid="F3">3</xref> does indeed confirm that edge weights become smaller with cluster distance, it does not reveal a bias to shorter weights for RGS. In fact, the converse is true: RGS clustering yields stronger long-range connections for similar graph sizes [average number of graph nodes: 379.69 ± 147.99 (RGS), 311.43 ± 33.59 (Ward); average edge weights for distances longer than 0.8: 0.25 (RGS), 0.18 (Ward)]. Therefore we conclude that connecting homogeneous clusters allows stronger long-range connections to be extracted. However, the statistics of the RGS connections has a much larger variance then the ones derived from Ward clustering. This is only partly due to the variance in the number of nodes, since even if we choose three healthy subjects with similar graph size (RGS: 297±2.16, Ward: 297.33±6.6), we still get a higher standard derivation for RGS clustering in the weight distribution (σ<sub>RGS</sub>/σ<sub>ward</sub> = 1.6).</p>
          <fig id="F3" position="float">
            <label>Figure 3</label>
            <caption>
              <p>RGS clustering yields stronger long-range connections then Ward clustering. Frequency <bold>(Upper Panel)</bold> and connection distance normalized to maximum graph distance <bold>(Lower Panel)</bold> across a range of graph edge weights calculated based on <italic>BcorrU</italic>1 for RGS1 (light gray bars) and ward2 (dark gray) clustering. Mean values and standard deviation (blue vertical lines) are calculated across single histogram values of all subjects independent of health condition.</p>
            </caption>
            <graphic xlink:href="fnins-12-00528-g0003"/>
          </fig>
          <p>In the following we will treat the distribution of edge weights as a graph property since it contains information about graph structure.</p>
        </sec>
      </sec>
      <sec>
        <title>2.2. Graph properties</title>
        <p>A recent survey by Gits (<xref rid="B16" ref-type="bibr">2016</xref>) of studies investigating graph properties in AD reveals no clear and systematic differences between heath conditions. For example, the mean clustering coefficient was found to be both significantly smaller (Supekar et al., <xref rid="B65" ref-type="bibr">2008</xref>) and larger (Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>) in AD compared to the aged-matched control group. We consider it likely that differences in methodology account for many of the contradictions. However, the stage of AD reached by the examined subject group may also play an important role. To investigate this aspect more closely, we examine the finding by Kim et al. (<xref rid="B35" ref-type="bibr">2015</xref>) that local efficiency, which corresponds to our definition of closeness centrality divided by the number of nodes in the network minus one, is increased for MCI, decreased for initial stages of AD and increased for severe AD stages with respect to the control group. The results of applying similar methods (atlas-based clustering combined with <italic>BMITU</italic>) are shown in Figure <xref ref-type="fig" rid="F4">4</xref>. The top panel shows the relationship between the health conditions when closeness centrality is calculated on the full, non-thresholded graph, which reproduces the findings of Kim et al. (<xref rid="B35" ref-type="bibr">2015</xref>), at least for initial stages of AD. However, if the measure is calculated on the graphs' rich club, i.e., the sub-graphs consisting of the nodes in the top 10% for degree, a different picture emerges, as shown in the middle panel of Figure <xref ref-type="fig" rid="F4">4</xref>. Here, AD has an increased closeness centrality with respect to both the control and mild cognitive impairment groups, which is in line with advanced AD stages in Kim et al. (<xref rid="B35" ref-type="bibr">2015</xref>).</p>
        <fig id="F4" position="float">
          <label>Figure 4</label>
          <caption>
            <p>Relationship of sub-graph properties across heath conditions is dependent on graph size. <bold>(Upper Panel)</bold> Average closeness centrality <inline-formula><mml:math id="M1"><mml:mover accent="true"><mml:mrow><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> across graph nodes for complete graphs constructed with atlas <italic>BMITU1</italic> for the different health conditions C (left), MCI (middle) and AD (right). Each dot corresponds to the graph of an individual (connected dots indicate the mean values). <bold>(Middle Panel)</bold> As in top panel, but on the basis of the rich club graphs. <bold>(Lower Panel)</bold> Difference of the averaged ward1 <italic>BMTID</italic>2 graph weights of the control group ŵ<sub><italic>C</italic></sub> and the AD group ŵ<sub><italic>AD</italic></sub> (left vertical axis, blue discs) and significance of this difference (right vertical axis, turquoise diamonds) as functions of the graph thresholding value <italic>w</italic>min. All ŵ are positive and are only calculated as long as graphs are connected (which is the case for <italic>w</italic>min &lt; 0.5). Average is taken across the weights of individual graphs. The dashed dark blue line indicates ŵ<sub>C</sub>−ŵ<sub>AD</sub> = 0; the dashed turquoise line indicates a significance level of 0.05.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0004"/>
        </fig>
        <p>More evidence that the outcome of a graph theoretical analysis can be highly sensitive toward the exact methodological implementation is given by considering the difference between the mean weights in the control and the AD conditions, and its significance (section 5.7.1), in dependence on the thresholding weight used to convert weighted graphs into simple graphs. This is illustrated in the bottom panel of Figure <xref ref-type="fig" rid="F4">4</xref>. Here, depending on where we set the threshold for considering an edge to be relevant, results having a significance level of <italic>p</italic> &lt; 0.05 can be observed for both ŵ<sub>C</sub>&gt;ŵ<sub>AD</sub> (<italic>w</italic>min∈{0.0, 0.1}) and ŵ<sub>C</sub> &lt; ŵ<sub>AD</sub> (<italic>w</italic>min∈{0.3, 0.4}).</p>
        <p>Extending this analysis, we find that contradictory significant results can be obtained for a variety of graph metrics across (and sometimes within) clustering methods. Figure <xref ref-type="fig" rid="F5">5</xref> shows the percentage of significant results obtained for health condition relationships in average edge weight, weighted degree, shortest path and clustering coefficient. Most strikingly, for most examined relationships, if significant differences are found at all, they are found in both directions, e.g., both for <inline-formula><mml:math id="M2"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>C</mml:mtext></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>MCI</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> and for <inline-formula><mml:math id="M3"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>C</mml:mtext></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>MCI</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> (weighted degree). Often a clustering algorithm favors a particular comparison direction, e.g., for the clustering coefficient, RGS clustering yields <inline-formula><mml:math id="M4"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> whereas Ward and atlas clustering yields <inline-formula><mml:math id="M5"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. However, we also find cases where significant differences are found in both directions with approximately equal frequency, such as <inline-formula><mml:math id="M6"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="M7"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for Ward clustering. In addition, we find some clustering algorithms show a systematic behavior across metrics, e.g., for RGS <inline-formula><mml:math id="M8"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with <italic>x</italic>∈{<italic>w, d, sp, clc</italic>}.</p>
        <fig id="F5" position="float">
          <label>Figure 5</label>
          <caption>
            <p>Significant relationships in graph metrics between health conditions dependent on clustering methods. Percentage of significant differences for each clustering method RGS (dark gray), Ward (light gray), and atlas (black) for different averaged graph properties: edge weight <bold>(Upper Left)</bold>, weighted degree <bold>(Upper Right)</bold>, shortest path <bold>(Lower Left)</bold> and clustering coefficient <bold>(Lower Right)</bold>. Fraction of significant differences are calculated for each health condition over all graphs constructed with the corresponding clustering including all variants in parameters, edge definition techniques, thresholds and rich club sub-graphs. The abscissa labels show which pairs of health conditions are compared (C-MCI, C-AD, MCI-AD) and the ordinate labels the direction of the significant differences (“&lt;,” “&gt;”). Significance is calculated as in the lower panel of Figure <xref ref-type="fig" rid="F4">4</xref>.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0005"/>
        </fig>
        <p>The largest number of significant differences is found for the comparison of controls with MCI, followed by the comparison of controls with AD. Only few significant differences of the means are found for AD and MCI. This relation among the groups is in line with the observed differences in heterogeneity observed for Ward and atlas clustering, for which MCI showed much lower heterogeneity and AD slightly lower values compared to controls (bottom panel of Figure <xref ref-type="fig" rid="F2">2</xref>).</p>
        <p>Focusing on the clustering methods that bring about the most significant differences comparing the entire graph properties distributions results, we find the highest fraction for RGS, followed by Ward clustering. Atlas-based clustering yields only a few significant results. Figure <xref ref-type="fig" rid="F6">6</xref> shows the breakdown of the proportion of significant results for each clustering method on the edge definition technique (shown in collated form in Figure <xref ref-type="fig" rid="F4">4</xref>). Notably, transfer entropy (<italic>TE</italic>) only rarely produces significant differences. All other edge definition methods show a similar fraction of significant comparisons. The highest number of significant comparisons across the different graph properties is generated by RGS clustering combined with <italic>MIT</italic>.</p>
        <fig id="F6" position="float">
          <label>Figure 6</label>
          <caption>
            <p>Significant relationships in graph metrics between heath conditions dependent on edge definition methods. Percentage of significant differences for each clustering technique [Ward (left), RGS (middle), atlas (right)] for each class of edge definition method clustering method [<italic>corr</italic> (dark blue), <italic>H</italic><sub>2</sub> (light blue), <italic>MIT</italic> (purple), <italic>TE</italic> (pink)] for averaged graph properties: edge weight <bold>(Upper Left)</bold>, weighted degree <bold>(Upper Right)</bold>, shortest path <bold>(Lower Left)</bold> and clustering coefficient <bold>(Lower Right)</bold>. Fraction of significant differences are calculated for each health condition over all graphs constructed with the corresponding clustering and edge techniques including all variants in parameters, thresholds and rich-club sub-graphs. Significance is calculated as in the lower panel of Figure <xref ref-type="fig" rid="F4">4</xref>.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0006"/>
        </fig>
        <p>To what extent a greater proportion of significant relationships is likely to make this graph construction method a good basis for a diagnostic tool depends on two aspects. First, the significance test is performed only on mean values, but ideally the overall distributions should overlap as little as possible. Second, the correlation between graph properties should be small in order to avoid redundant information.</p>
        <p>In this section we considered only the first moments (means) of the graph properties taken from an individual brain. However, as explained in section 5.5, we use the first four moments of the individual distributions for our statistical analysis. Since the <italic>p</italic>-value of the other moments is not calculated, its influence on the statistical analysis cannot be considered.</p>
        <p>In order to evaluate the methods based on robustness due to methodical variation, we investigate how the order of subjects (all subjects independent of their health conditions are ordered according to their average value of a certain graph property) is affected by the exact realization of the graph construction methods. Graphs constructed by methods based on similar underlying features of the data will tend to show a systematic ordering of subjects, regardless of the absolute values of the calculated graph metrics. Figure <xref ref-type="fig" rid="F7">7</xref> shows the commonalities and differences, which are illustrated with a dendrogram (see section 5.7.2) calculated on the Euclidean distance between the resulting ordered arrays of average graph weights. The continuous pink area show that graphs constructed using transfer entropy are most robust to the choice of clustering technique. Moreover, linear and non-linear correlations (dark and light blue) occupy contiguous blocks and so are most similar to each other. The leaves denoting atlas clustering (black) are rather spread out, indicating a high sensitivity of this method to the choice of edge definition.</p>
        <fig id="F7" position="float">
          <label>Figure 7</label>
          <caption>
            <p>Sensitivity of subject order to clustering and edge detection techniques. The dendrogram shows the distance of subject order, calculated by ordering all subjects according to their average graph edge weights and calculating the Euclidean distance between the resulting rank arrays. For better legibility, instead of naming the dendritic leaves, of which every leaf corresponds to a particular combination of clustering and edge definition techniques, e.g., ward2 <italic>BTED</italic>2, the top row of colors code for the class of clustering method: Ward (light gray), RGS (dark gray) and atlas (black); and the bottom row codes for the class of edge definition method: <italic>corr</italic> (dark blue), <italic>H</italic><sub>2</sub> (light blue), <italic>MIT</italic> (purple) and <italic>TE</italic> (pink).</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0007"/>
        </fig>
        <p>In this section we have shown that the relationship of graph properties between health conditions strongly depends on the methods used for graph construction. For our data we find more significant mean differences for control-AD and control-MCI then for MCI-AD. With respect to clustering and edge definition methods, the largest number of significant differences are found for RGS and Ward clustering, and for model-free edge definitions. These results show that conclusions on how graph properties change due to AD have to be drawn carefully, and ideally validated by other methods, as they can be highly sensitive to the methods used for graph construction.</p>
      </sec>
      <sec>
        <title>2.3. Evaluation of graph construction methods based on negative surprise</title>
        <p>Having examined the consequences of particular choices for clustering and edge definition techniques in the previous sections, we now evaluate their combinations by considering their ability to help a clinician to discriminate among patient groups. This discrimination is achieved by using the graph data within a statistical model, which specifies the likelihood of the graph data. The model is described in section 5.6; the likelihood is a distribution which depends on a set of parameters. In general, the kind of graph data—i.e., their construction method—and the statistical model with its parameters are interdependent: they cannot be freely varied separately. Therefore our evaluations of the predictive power of the various graph construction methods have to be understood with a caveat: they depend on our specific choice of statistical model.</p>
        <p>To quantify the discriminating power for each graph construction combination, we use a metric based on the final probabilities for the correct health conditions known as the log-probability, or <italic>negative surprise</italic> (Bartlett, <xref rid="B3" ref-type="bibr">1952</xref>; Good, <xref rid="B17" ref-type="bibr">1956</xref>, <xref rid="B18" ref-type="bibr">1957a</xref>,<xref rid="B19" ref-type="bibr">b</xref>, <xref rid="B20" ref-type="bibr">1983</xref>): a sure event, i.e., with unit probability, has surprise equal to zero; whereas an impossible event, i.e., with zero probability, has surprise equal to infinity, reflecting the fact that its occurrence would be contrary to all our expectations. A high surprise (in absolute value) therefore signals a low predictive power of the data we are using. The expectation or average of the surprises is the Shannon entropy (Shannon, <xref rid="B61" ref-type="bibr">1948</xref>; Bartlett, <xref rid="B3" ref-type="bibr">1952</xref>; McCarthy, <xref rid="B42" ref-type="bibr">1956</xref>; Bernardo, <xref rid="B6" ref-type="bibr">1979</xref>; Jaynes, <xref rid="B26" ref-type="bibr">2003</xref>: section 11.3).</p>
        <p>Another possibility, of a more decision-theoretical character, is to consider a metric based on the average utilities obtained with each particular graph-construction method. Given several possible courses of action (e.g., treat or dismiss) and their utilities or costs with respect to each health condition (e.g., treating an Alzheimer patient, dismissing a healthy patient, dismissing an Alzheimer patient, or treating a healthy one), the clinician should choose the action that maximizes the expected utility, the expectation being calculated from the final probabilities for the possible health conditions (Sox et al., <xref rid="B63" ref-type="bibr">2013</xref>). This kind of metric therefore requires not only the final probabilities—which depend on the graph-construction method—but also a table of utilities.</p>
        <p>Numerical tests show that the two kinds of metric yield similar results, at least for utility tables close to the identity (treating an ill patient and dismissing a healthy one have unit utility; the remaining combinations have zero utility). We therefore choose a metric based on the negative surprise, which is simpler and more intuitive than a utility metric.</p>
        <p>In order to have an approximate idea of the relative predictive powers of the graph-construction methods we would like to use a statistical method that can be kept the same, as much as possible, across different methods. For this reason we choose a model based on the working hypothesis of sufficiency of mean and correlations of past data, as explained in the Introduction. This model ignores any restricted range of variability of graph quantities (e.g., positive or bounded). As explained in Porta Mana et al. (<xref rid="B53" ref-type="bibr">2018</xref>), this choice is non-standard but does not entail contradictions. The model has some free parameters; their values reflect the fact that the units of measure for the graph quantities make the latter of order unity. This choice of a generic, common statistical model allows us to sidestep the demanding problem of tailoring it for the different graph quantities from our 850 graph-construction methods.</p>
        <p>Figure <xref ref-type="fig" rid="F8">8</xref> shows the obtained negative surprises for all combinations of graph construction methods except <italic>H</italic><sub>2</sub><italic>D</italic>, which is left out due to an inadequacy of the statistical model, resulting in unrealistic values between −1.26 and −0.66 with a mean and standard deviation of −0.94±0.19.</p>
        <fig id="F8" position="float">
          <label>Figure 8</label>
          <caption>
            <p>Negative surprise of the different graph construction methods. Each dot represents a specific node clustering (e.g., RGS1) and edge definition (e.g., <italic>BcorrU</italic>1). Dots are grouped together according to their main class (e.g., RGS <italic>corr</italic>). Red dots highlight the results of ward4 clustering. Negative surprise expected by chance is −1.1.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0008"/>
        </fig>
        <p>The differences in negative surprise between the different graph construction method are in general small. The best results are obtained for ward4 clustering combined with mutual information (<italic>MIT</italic>) based edge definition. Across edge definition methods, linear correlation (<italic>corr</italic>) and mutual information give the best results and transfer entropy (<italic>TE</italic>) the worst. The rather poor performance of <italic>TE</italic> edge definition is in line with the small number of significant differences found for this method (compare Figure <xref ref-type="fig" rid="F6">6</xref>). Comparing the different clustering methods, atlas and ward4 clustering give the best results, as long as the edge definition is not <italic>TE</italic>. These two clustering methods have in common a very small number of graph nodes and (correspondingly) the highest number of voxels per cluster (compare Figure <xref ref-type="fig" rid="F2">2</xref>).</p>
        <p>As explained above, the comparison of graph-construction methods can be affected by the statistical model and its parameters, especially for small datasets. As a complementary analysis we compare the negative surprises with the classification performances of a support vector machine (SVM, section 5.7.1) based on the same graph constructions. In a clinical setting, a misclassification between control and AD has more severe consequences than between MCI and AD. To avoid introducing an asymmetric misclassification penalty, we perform the classification between pairs of classes only (control-AD, C-MCI, MCI-AD).</p>
        <p>Figure <xref ref-type="fig" rid="F9">9</xref> shows the relationship between the SVM performance (measured as proportion of correct classifications) against the negative surprise. As long as <italic>TE</italic> edge definition is excluded, the two performance measures are positively correlated. In particular RGS clustering achieves low performance in both negative surprise and SVM classification. Furthermore, atlas clustering achieves a high classification performance across all edge definitions. The exact SVM classification results for each realization of graph construction method are depicted in Figure <xref ref-type="supplementary-material" rid="SM1">S2</xref> (see <xref ref-type="supplementary-material" rid="SM1">Supplemental Material</xref>).</p>
        <fig id="F9" position="float">
          <label>Figure 9</label>
          <caption>
            <p>Relationship between SVM classification performance and negative surprise. The average SVM performance achieved by each combination of clustering method and edge definition with respect to each pair of health conditions: control-AD <bold>(Upper Panel)</bold>, control -MCI <bold>(Middle Panel)</bold>, and MCI-AD <bold>(Lower Panel)</bold>, is plotted against the negative surprise calculated for all health conditions. Each marker corresponds to the averaged performance across the parameter space of a specific clustering method [atlas (black squares), Ward (dark gray octagons), RGS (light gray pentagons)] and a specific edge defintion (<italic>corr</italic>, <italic>H</italic><sub>2</sub>, <italic>MIT</italic>, <italic>TE</italic>). The regression line is calculated for all points but <italic>TE</italic> (superimposed red crosses). Pearson correlation coefficients <italic>r</italic> of the datasets are <italic>r</italic> = 0.59 <bold>(Upper Panel)</bold>, <italic>r</italic> = 0.77 <bold>(Middle Panel)</bold>, <italic>r</italic> = 0.69 <bold>(Lower Panel)</bold>.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0009"/>
        </fig>
        <p>Figure <xref ref-type="fig" rid="F10">10</xref> demonstrates that thresholding graphs has only a minor effect on the negative surprise for small thresholds up to 0.2. No systematic relationship can be observed for the effect of larger thresholds; for example, increasing the threshold to 0.4 causes a decrease in negative surprise for RGS clustering with linear correlations or mutual information, but an increase for atlas clustering with transfer entropy edge detection. Likewise, the creation of highly connected and rich club sub-graphs typically decreases the negative surprise, but in some cases increases it (e.g., RGS <italic>H</italic><sub>2</sub><italic>U</italic>). Overall the highest negative surprise (−0.66) is obtained for ward4 clustering combined with <italic>BMITU</italic>1 thresholded at <italic>w</italic>min = 0.1.</p>
        <fig id="F10" position="float">
          <label>Figure 10</label>
          <caption>
            <p>Negative surprise for different graph edge thresholds <italic>w</italic>min (<italic>w</italic>min = 0 for complete graphs, indicated by a vertical dashed line) and rich club graphs (rich) for different edge definitions: <italic>corr</italic>
<bold>(First Panel)</bold>, <italic>H</italic><sub>2</sub><italic>U</italic>
<bold>(Second Panel)</bold>, <italic>MIT</italic>
<bold>(Third Panel)</bold>, <italic>TE</italic>
<bold>(Fourth Panel)</bold> and different clustering methods Ward (light gray), RGS (dark gray) and atlas (black). Each dot is the result of averaging across all possible parameters of a general graph construction method (for <italic>w</italic>min = 0 the average across all points of a swarm in Figure <xref ref-type="fig" rid="F8">8</xref>). Since some methods yield small edge weights, some graphs become unconnected for large <italic>w</italic>min such that the statistical analysis is not conducted; no values are depicted in this case. Markers are connected for better visual comprehension.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0010"/>
        </fig>
        <p>These results suggest that the best combination of graph construction techniques to use for this data set is the atlas-based or ward4 clustering combined with linear correlation methods or mutual information transfer. Thresholding the graph edges, which might reduce experimental noise and does lower computational complexity, has only a minor effect on the predictive power, as long as threshold values are small. Reducing the graphs complexity via larger thresholds or extracting the rich-club of the graph should be done with care, since the results can change in either direction. Although transfer entropy yields lower negative surprises then the model-free functional connectivity measures, we would not conclude that this edge definition performs worse in general, since it achieves high values in SVM classification. It is very likely that our choice of statistical model is not ideal, and a more tailored choice would improve performance.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>3. Discussion</title>
      <p>In this article we have compared different techniques for constructing and analyzing graphs. By applying a statistical model, we have demonstrated a principled method for choosing a combination of techniques for a given data set. By examining the varied outcomes of the techniques, we have shown how sensitive the results of graph theoretical analyses, such as significant differences in mean properties, can be to the choice of clustering or edge definition technique.</p>
      <p>With regards to the predictive power of the graph construction techniques, measured in terms of negative surprise, we find that Ward and atlas clustering yield the highest performance of the clustering techniques, and region growing and selection clustering (RGS) the lowest. In particular, the variant of Ward clustering that produces large clusters and small numbers of nodes (ward4) achieved the highest performance values. Analogously for the edge detection methods, we find better performance for the model-free methods (linear and non-linear correlations, mutual information transfer) than for the model-based method of transfer entropy. For this particular data set, a combination of ward4 clustering with mutual information derived edges achieves best results. Therefore, we would recommend this combination as the primary target for a more narrowly focussed investigation based on a larger data set.</p>
      <p>The performances we obtain are above chance level but still far away from optimal prediction of the three health conditions. One reason for this sub-optimal prediction might lie in our choice of statistical model and its parameters. With our small data set (26 controls, 16 MCI, 14 AD) the model and its parameters have a high influence on the final probabilities, and thus on the performance (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>). We avoided tailoring the statistical model for the theoretic and practical reasons explained in section 2.3. Even if the model is not tailored, the results are consistent with the classification performance of support vector machines (see Figure <xref ref-type="fig" rid="F9">9</xref> and Figure <xref ref-type="supplementary-material" rid="SM1">S2</xref>), for the model-free edge definition techniques.</p>
      <p>It remains unclear why Ward and atlas clustering are more successful than RGS, especially in combination with model-free edge definition. One possibility is that this is related to the large variability in graph sizes generated by RGS (Figure <xref ref-type="fig" rid="F2">2</xref>). In addition, the variance of weight distributions across subjects, and the variance of the cluster distances, are much larger in RGS then in Ward clustering (Figure <xref ref-type="fig" rid="F3">3</xref>). This could be related to the variance in the number of nodes; however, choosing graphs similar in size causes even higher variances (section 2.1). Therefore we assume that the number and connectivity of the small functional units extracted by RGS are highly variable across subjects. This variance might be even higher across subjects within a health condition than across health conditions, such that changes due to AD cannot be detected. This assumption might at first glance seem to contradict the high number of significant comparisons observed (Figure <xref ref-type="fig" rid="F5">5</xref>). However, we only calculate the significance level for the means of the distributions and not their entire shape. In addition, it is likely that some graph properties correlate with the graph size, and thus that apparent significant differences in graph properties are simply reflecting significant differences in numbers of nodes detected, and do not provide further information useful for classification or understanding the nature of the disease. Further investigation is needed on this matter.</p>
      <p>The low negative surprise of transfer entropy (<italic>TE</italic>) compared with other model-free functional connectivity measures might have several reasons. The comparison of the negative surprise with the support vector machine classification suggests that a better choice of a statistical model is possible: the classification results for <italic>TE</italic> are similar to those of the model-free measures. In <italic>TE</italic> the data of a certain time interval in the past is used in order to calculate how much the uncertainty of the future is reduced. Here we use the data of the last 15 s. This time period might be poorly chosen, influencing the overall negative surprise. In addition <italic>TE</italic> is more sensitive to short recording periods than other methods, which may well also result in a reduced performance (Pereda et al., <xref rid="B51" ref-type="bibr">2005</xref>).</p>
      <p>With regards to the robustness of the graph theoretical outcomes, we discovered that relationships between mean graph properties, such as closeness centrality, edge weight or clustering coefficient (Figures <xref ref-type="fig" rid="F4">4</xref>–<xref ref-type="fig" rid="F6">6</xref>) were sensitive to choice of clustering and edge definition techniques, to parameter choices for a given technique, and to the manner in which sub-graphs were defined (thresholding value and rich club). For most relationships between graph properties <italic>X</italic>, we could find significant (<italic>p</italic> &lt; 0.05) differences in both directions, i.e., both <italic>X</italic><sub>AD</sub>&gt;<italic>X</italic><sub>C</sub> and <italic>X</italic><sub>AD</sub>&lt;<italic>X</italic><sub>C</sub>, for specific choices of clustering and edge definition technique. This strongly suggests that a degree of suspicion should be applied to studies reporting such significant differences, especially if these results are argued to give insight into how a disease affects brain properties, unless the significance level is much more compelling or the reported differences can be validated with alternate methods.</p>
      <p>We also investigated the sensitivity to method choice of the ordering of subjects according to a graph theoretic metric (Figure <xref ref-type="fig" rid="F7">7</xref>). In this analysis, transfer entropy was the most consistent. Nevertheless, the distributions of the negative surprises is as broad for transfer entropy as for other edge definitions (Figure <xref ref-type="fig" rid="F8">8</xref>). In general, the exact parameter selection within an edge definition method causes only slight changes in the negative surprise, more crucial is the exact realization of the clustering method: ward4 clustering generally achieves a better performance then ward3 clustering. These two variants differ only in the number of predefined clusters (see Supplemental Material Figure <xref ref-type="supplementary-material" rid="SM1">S1</xref>). Applying a lower threshold <italic>w</italic>min on the graph's edge weights has little effect on the negative surprise for all methods, as long as only small weights (up to 0.2) are set to zero. Thresholding higher weights or extracting the graph's rich club has unpredictable effects on the results, and so should be used with caution (Figure <xref ref-type="fig" rid="F10">10</xref>). Atlas clustering was least consistent in the subject ordering analysis, suggesting that although it may provide a good basis for a diagnostic tool, care should be taken in reporting discoveries of particular relationships in graph properties between health conditions, as these may well turn out to be critically dependent on the edge definition method used.</p>
      <p>Due to the intense computational requirements of the survey performed in this article, we recognize that it would be advantageous to develop heuristics for choosing between graph construction methods without performing the full calculation for each combination. Our results suggest that properties visible at the clustering stage, such as average heterogeneity, may give some indication of predictive performance: graph constructions that result in different degrees of heterogeneity between the health conditions seem to be more discriminable by the later steps of the calculation. More research is needed in this area, which is outside the scope of the current study. In addition, it is tempting to consider <italic>t</italic>-test results of the mean graph properties as a heuristic. Our results suggest that this approach is largely inadequate. It holds for edge definition via transfer entropy, which gives very few significant results and the negative surprise is rather small compared with the model-free edge definitions. Conversely, region growing clustering yields most significant differences but a generally poor negative surprise. This may be due to graph properties being highly correlated, and so not providing additional information to the statistical model. In addition we used the first four moments (wherever possible) in our statistical model, rather than just the mean, which may also partially account for this apparent contradiction.</p>
      <p>In addition to considering the predictive power and robustness of graph construction techniques, we can also evaluate them according to their practicality, i.e., speed of calculation and the extent to which they are easily available in established medical infrastructure and diagnostics. In general, applying graph theoretic measures to fMRI data for improving AD diagnosis makes sense, since MRI scans are already implemented in AD diagnostics for detecting structural changes such as hippocampal dystrophy caused by AD or AD-unrelated pathology (e.g., brain tumors). Softwares such as SPM (Tzourio-Mazoyer et al., <xref rid="B68" ref-type="bibr">2002</xref>) and FSL (Jenkinson et al., <xref rid="B28" ref-type="bibr">2012</xref>) are frequently used in medical research and mainly support clustering that is atlas and independent component analysis based. Ward clustering, which is the fastest of all these clustering methods, is a standard hierarchical clustering method and implemented in all standard programming softwares such as Python and Matlab. The region growing algorithm is not implemented in established softwares and is also computational very demanding. Given that it does not out-perform atlas or Ward clustering, we therefore do not recommend it. For edge definition and graph properties, several software packages are available based on Matlab (Wang et al., <xref rid="B69" ref-type="bibr">2014</xref>; Kruschwitz et al., <xref rid="B37" ref-type="bibr">2015</xref>) or Python<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref>, which provide a comprehensive range of edge definition and graph analysis methods.</p>
      <p>In general we recommend using statistical models and not pure classifiers such as support vector machines as diagnostic tools, since statistical models calculate a probability of a diagnosis rather than assign a classification, i.e., “Given the fMRI scan, person x has a 80% probability of having Alzheimer's disease,” rather than “Given the fMRI scan, person x has Alzheimer's disease.” Probabilities can be easily combined with other probabilities of other diagnostic tests (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>) such as cognitive assessment, amyloid beta and tau protein occurrence in cerebrospinal fluid, blood tests, and structural MRI<xref ref-type="fn" rid="fn0002"><sup>2</sup></xref> (Johnson et al., <xref rid="B30" ref-type="bibr">2012</xref>). This allows the medical doctor to conclude, for example: “Given the results of the cognitive test <italic>and</italic> cerebrospinal fluid analysis <italic>and</italic> structural and functional MRI scan, person x has a 95% probability of having Alzheimer's disease.” After the estimation of the probability for a disease, she has to decide on a treatment, also taking into consideration such factors as “how harmful would the treatment be for a healthy person,” which can be expressed in a utility function (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>). In addition, the statistical model used in this work allows an estimation of how much the model can be trusted, and therefore evaluate whether the sample size is sufficiently large (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>).</p>
      <sec>
        <title>3.1. Relationship to previous studies</title>
        <p>Studies focusing on the graph properties extracted from resting-state fMRI in AD and its pre-stages generally have one of two aims. The first aim is to identify significant differences in the graph properties between health conditions, and to use these to gain insight into the effects of AD on the physical brain and its cognitive processes. These studies complement the picture revealed by investigations based on structural MRI and functional changes on the basis of EEG and MEG recordings. Typically a variety of graph properties (e.g., nodal degree, clustering coefficient, averaged shortest path, local efficiency, betweenness centrality, global efficiency, small worldness) are calculated, and used to motivate an account of how disease-related modifications to these properties result in a reduced capacity to transfer and process information.</p>
        <p>However, such studies reveal entirely contradictory results. For example, the value of the clustering coefficient in AD with respect to controls has been reported to be increased, unchanged, and decreased, respectively (Supekar et al., <xref rid="B65" ref-type="bibr">2008</xref>; Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>; Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>). Analogous contradictions have been found for the comparative length of the shortest path (Supekar et al., <xref rid="B65" ref-type="bibr">2008</xref>; Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>; Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>). These contradictions could be caused by methodological differences or by not separating the different states of AD. Our results show ample evidence that the precise choice of graph construction techniques can easily account for contradictory findings, even for atlas based clustering, in which the number and size of clusters is held constant across all subjects (Figure <xref ref-type="fig" rid="F5">5</xref>). Evidence that the separation of different AD stages is relevant was provided by Kim et al. (<xref rid="B35" ref-type="bibr">2015</xref>), who demonstrated a non-monotonic behavior of global efficiency, local efficiency and betweenness centrality across different stages of AD and MCI. In our study, we could reproduce the pattern of increase and decrease of closeness centrality across conditions (Figure <xref ref-type="fig" rid="F4">4</xref>). However, we also demonstrate that the same analysis based on the rich club sub-graph yields a different pattern, and that contradictory (but significant) results can be obtained for the same graph construction techniques with different choices of threshold. We thus conclude that differences in graph properties between health conditions are currently ill-suited to provide an account of disease mechanisms in AD, unless either: (1) a specific method of graph construction can be shown to be more representative of the underlying connectivity than other methods, (2) the differences can be shown to be robust to choice of graph construction, (3) the differences can be validated by another analytical approach, or (4) the significance level is shown to be substantially more persuasive than <italic>p</italic> &lt; 0.05.</p>
        <p>The second category of studies use graph theoretical information as input for machine learning algorithms to classify the health conditions of the subjects. Note that for this purpose it is irrelevant if a difference between health conditions is not robust to method choice, as the goal is not to understand the effects of the disease but to robustly distinguish between conditions. Recent studies have reached very high performance: 100% accuracy in discriminating AD and control (Khazaee et al., <xref rid="B33" ref-type="bibr">2015</xref>), and 93% for AD, MCI and control classification (Khazaee et al., <xref rid="B34" ref-type="bibr">2017</xref>). In the latter work they extract more than two dozen local and global graph properties, resulting in roughly 3, 000 features, since each of the local properties is calculated for all brain areas. Only a small subset of features is then used for classification, e.g., in-degree of the left middle temporal gyrus. They found that the classification power of local graph measures is larger than that of the global ones. Local changes in graph properties that do not propagate to global mean values have also been reported for area specific (frontal cortices, parietal and occipital regions) synchronization levels (Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>).</p>
        <p>In this work we do not compare node-specific graph properties, because Ward and RGS clustering do not result in the same spatial location of clusters across subjects. Instead, we consider, wherever possible, the first four moments of the entire distributions of graph properties. This is more information than typically used for global measures, where often only the first moment (the mean) of a graph property distribution is taken into consideration. Nevertheless, it is still possible that considering single nodes, of which some may be more damaged by AD than others, could yield a better diagnostic performance. This requires further study in a survey considering only atlas based clustering. Again, this is out of scope of the current study, but we remark that the statistical model methodology we employ here would be equally applicable to such an investigation. The advantage of taking the entire distribution lies in the possibility of using purely data driven clustering algorithms (e.g., Ward clustering) that can be substantially faster than atlas based clustering, since they do not depend on a time and memory consuming registration of the individual brain image to standard space. In addition, the global distribution is more likely to be more robust against brain morphologic abnormalities such as brain tumors or brain shrinkage, and is more stable across recording sessions (Telesford et al., <xref rid="B66" ref-type="bibr">2010</xref>; Wang et al., <xref rid="B69" ref-type="bibr">2014</xref>). Finally, a short recording time might be expected to have a weaker influence on entire graph property distributions then on single nodes. Thus we conclude that global measures are preferable, if a good diagnostic performance can be reached. Although the goal of this work was not classification, we note that we obtain up to (80–90%) correct classification using an off-the-shelf support vector machine on leave-one-out subsets of our data for pairwise (C-AD, C-MCI, AD-MCI) comparisons. Whether global measures can reach the impressive performance shown by Khazaee et al. (<xref rid="B34" ref-type="bibr">2017</xref>) can only be investigated on a sufficiently large data set, ideally with several hundred participants.</p>
      </sec>
      <sec>
        <title>3.2. Limitations of this study</title>
        <p>In each step of the graph construction and analysis pipeline (Figure <xref ref-type="fig" rid="F1">1</xref>) we set limits to the endless space of possible methods and their corresponding parameters. Here we will shortly summarize the reasons motivating the selection of the methods examined here and the exclusion of others, given the constraint of limited computational and temporal resources. As a general principle, we aimed to include the most commonly used method(s) and additional methods that we found to be reasonable, even if they are not currently frequently used.</p>
        <p>Starting with the fMRI pre-processing, we had to decide whether to include global signal regression. The global signal (the average activity across all brain voxels) is assumed to originate partly from vascular and respiratory processes that do not represent neuronal activity. However, there is also evidence that it contains neuronal-signaling based components, since it is negatively correlated with the EEG signal and strongly correlated with the activity of the largest network in the brain (the default mode network, which plays a major role in rest state activity) when noise levels are low (Murphy and Fox, <xref rid="B44" ref-type="bibr">2017</xref>). Without global signal regression, the Pearson correlation distribution derived from the signal of all voxels, or the average activity of clustered voxels, is biased to the right such that negative values are rare and small. The correction for the global signal centers this distribution, such that negative values are much more prominent. This also changes the properties of the graphs extracted from such data, for example an increase in modularity combined with fewer unconnected nodes has been reported (Schwarz and McGonigle, <xref rid="B60" ref-type="bibr">2011</xref>; Hayasaka, <xref rid="B24" ref-type="bibr">2013</xref>).</p>
        <p>Speaking against global signal regression is the finding that correction for white matter, CSF and motions yield the most stable graph properties across sessions compared with additional applied global regression (Schwarz and McGonigle, <xref rid="B60" ref-type="bibr">2011</xref>). In diagnostics it is important to have only small variance in the outcome across different sessions if the health condition of a subject is stable, such that small changes that indicate a worsening of the health condition can be rapidly detected. Moreover, we define the edges of our graphs as the absolute values of the functional connectivity values. As the negative part of the correlation distribution is small without global regression, different possible treatment of negative correlations (taking the absolute values or setting them to zero) should have only a small influence on the resulting graph properties, at least when the underlying functional connectivity are based on correlations. Consequently, we elect not to include global signal regression in our pipeline.</p>
        <p>In the clustering step, the most commonly used method is to define clusters based on cortical regions defined by a brain atlas. We supplemented this with two data-driven clustering approaches: Ward clustering and RGS clustering. We selected Ward clustering, as it has been shown to perform better than alternative hierarchical clustering methods with respect to reproducibility and accuracy (Thirion et al., <xref rid="B67" ref-type="bibr">2014</xref>). RGS, a method derived from image processing (Lu et al., <xref rid="B40" ref-type="bibr">2003</xref>), was selected because we could adjust the method to produce functionally homogeneous clusters. In this formulation, the only free parameter of the algorithm is the minimal cluster size. For both data-driven methods, we selected parameters such that graphs did not exceed a maximal size of 1,500 nodes, due to computational limitations. We excluded clustering based on independent component analysis, because of its laborious implementation and the requirement for domain expertise to distinguish noise from activity-related components. We also excluded all clustering algorithms that do not take functional consistency into account, e.g., dividing the voxels into cuboid patches, as has been proposed for structural data (Amoroso et al., <xref rid="B1" ref-type="bibr">2017</xref>).</p>
        <p>With regards to methods for edge definition, we limit our survey to functional connectivity measures that act in the time domain and not in the frequency domain, thus omitting frequency based wavelet analysis (Supekar et al., <xref rid="B65" ref-type="bibr">2008</xref>), synchronization likelihood (Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>) and coherence (Wang et al., <xref rid="B69" ref-type="bibr">2014</xref>). The most commonly used and simplest functional connectivity measure is the Pearson correlation coefficient (e.g., Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>), which we name <italic>BCorrU</italic> in our work. We also test two additional model-free and one model-based method. A further model-based method based on Granger causality was excluded because it is too computationally expensive for larger graphs (Wang et al., <xref rid="B69" ref-type="bibr">2014</xref>).</p>
        <p>A thresholding operation is often applied to graphs extracted from fMRI, setting all values below <italic>w</italic>min to zero. The aim of this step is to reduce experimental noise, which mainly manifests in the weaker edges, and to make the computation of graph properties computationally less demanding (Bordier et al., <xref rid="B8" ref-type="bibr">2017</xref>). The threshold <italic>w</italic>min can be defined in several ways: it can be set arbitrarily, without satisfying a certain demand, or such that certain properties of the graphs are preserved, e.g., average number of edges per vertex (Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>), node density (Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>), small world behavior (Bassett et al., <xref rid="B4" ref-type="bibr">2008</xref>) or a fixed cluster coefficient. Alternatively, it can be set such that information on the network's community structure is maximized; see, e.g., Bordier et al. (<xref rid="B8" ref-type="bibr">2017</xref>). In a variant of the thresholding approach, it has been proposed to transform the edge weights by applying a power law (Schwarz and McGonigle, <xref rid="B60" ref-type="bibr">2011</xref>). In this study, for the sake of simplicity, we examine graph properties as a function of <italic>w</italic>min without targeting any specific value of a graph property. Potentially, our results would reveal a different picture if <italic>w</italic>min was optimized for each subject to attain, for example, a specific average nodal degree. However, comparison of these two different thresholding mechanisms resulted in no major difference in the relationships of graph properties between the control and AD groups (Sanz-Arigita et al., <xref rid="B56" ref-type="bibr">2010</xref>).</p>
        <p>We do not binarize our graphs (setting all values below <italic>w</italic>min to zero and those above it to one) as is frequently done (e.g., Zhao et al., <xref rid="B75" ref-type="bibr">2012</xref>), as this leads to a loss of information, and moreover some distributions of graph properties would become discrete (e.g., only ones and zeros for edge weights distributions), such that higher moments would be uninformative. The disadvantage of using weighted graphs lies in the limitation of possible graph properties. Most graph properties are well-defined for binary graphs and have been partly extended to weighted graphs. Here, we calculate the (normalized) weighted degree, shortest path, closeness centrality, clustering coefficient, and the modularity. We only investigate the most commonly used metrics and do not include more complex methods such as the minimal spanning tree (Çiftçi, <xref rid="B10" ref-type="bibr">2011</xref>).</p>
        <p>In addition to the restrictions of scope with regards to the examined techniques, a clear limitation of this study is the small data set. As our aim here is primarily to provide a methodology for evaluating and comparing analysis methods, rather than to draw conclusions on the effect of Alzheimer's disease on the graph properties of the cortex, a small data set is less problematic. Indeed, for the explorative survey carried out here, a large data set would have been prohibitively expensive with respect to computational resources. Moreover, many studies applying graph analysis to fMRI data are based on similarly sized data sets, which highlights the importance of raising awareness about the methodological artifacts we have identified.</p>
        <p>The results of our survey indicate which combinations of methods are promising in view of Alzheimer diagnosis and should be investigated further in future studies based on larger data sets. Naturally, such studies could yield some quantitatively different results to those reported here, particularly with regard to the classification performance. Nonetheless, we would like to summarize some conclusions of the work that are unlikely to change with a larger data set. First, our results show that different combinations of methods can lead to contradictory findings with regard to significant differences in mean properties (section 2.2). This effect is unlikely to be resolved by a larger sample size. Second, methods showing good robustness with respect to parameter choice for a small sample size (e.g., <italic>TE</italic> edge definition, see Figure <xref ref-type="fig" rid="F7">7</xref>), are likely to remain robust with increasing sample size. Likewise, there is no reason to assume that methods performing well in all circumstances for the small data set, e.g., Ward clustering combined with <italic>corr</italic> edge definition (section 2.3), would perform worse for larger data sets. Finally, we assert that thresholding the graphs of a large data set with a small <italic>w</italic>min (as shown in section 2.3) would similarly not result in a sudden jump in negative surprise.</p>
      </sec>
      <sec>
        <title>3.3. Application of approach to other analysis techniques</title>
        <p>We have demonstrated a systematic, quantitative approach for comparing and evaluating sequences of algorithms that result in classification of fMRI data based on the first four moments of simple graph theoretic metrics defined on the whole graph. However, the approach we present is equally well suited for assessing pipelines based on other metrics, as we briefly outline in the following.</p>
        <p>One possibility is to consider the graph properties of individual nodes, as these have been shown to be very informative (Xia et al., <xref rid="B72" ref-type="bibr">2014</xref>; Khazaee et al., <xref rid="B33" ref-type="bibr">2015</xref>; Wang et al., <xref rid="B70" ref-type="bibr">2016</xref>; Dillen et al., <xref rid="B15" ref-type="bibr">2017</xref>).</p>
        <p>This entails the use of atlas based clustering. We speculate that a global analysis of graph properties would be both faster and more robust to brain abnormalities and short recording times, and so would be the preferable approach if equivalent performance levels can be attained.</p>
        <p>A second possibility is to extend our approach to a hierarchical analysis. This could potentially be of great use, as previous studies based on PET imaging have suggested that in Alzheimer's disease, long range connections become weaker but local clustering increases (Pagani et al., <xref rid="B48" ref-type="bibr">2016</xref>, <xref rid="B49" ref-type="bibr">2017</xref>). These alterations would not be observable using the graph analyses so far considered, although we have taken the first step by calculating the modularity, which compares the ideal dissection of the given graph into modules with that of a random graph with similar edge weights.</p>
        <p>To capture the graph meta-structures it is necessary to cluster graph nodes into modules, or sub-graphs. Modules can be defined either purely functionally, such that each node (ideally) has the strongest connections to the nodes in its own cluster, and the weakest connections to nodes of other clusters, or based on anatomic structures, such that nodes in a cluster are part of large, anatomo-functionally similar brain areas. Analogous to the variety of methods for spatial clustering and edge definition investigated in this study, there are many techniques used to cluster nodes into modules (e.g., k-clustering, hierarchical clustering and spectral clustering, for a review see Schaeffer, <xref rid="B57" ref-type="bibr">2007</xref> or anatomo-functional clustering, see Pagani et al., <xref rid="B48" ref-type="bibr">2016</xref>), and likewise multiple options for analysing the characteristics of the resulting modular structure (e.g., module degree or participation coefficient; see Guimerá and Nunes Amaral, <xref rid="B23" ref-type="bibr">2005</xref>). Such a comprehensive study is outside the scope of the current work, but could well provide great insight into health condition related alterations in the global network structure of the brain.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>4. Conclusions</title>
      <p>In order to achieve a robust and successful Alzheimer's disease diagnosis based on graphs extracted from fMRI data, we recommend clustering that results in rather small graphs with large clusters. Ward clustering, in which the number of clusters can be predefined, is fast, but requires programming knowledge to implement it. Atlas clustering is well established standard fMRI analysis software applications, but it is slow and might be affected by morphologic abnormalities in the brain, such as atrophy which is a common symptom of AD.</p>
      <p>Edge weights should be calculated based on correlations or mutually information transfer, especially if a focus of the study is uncovering significant differences in mean graph properties between health conditions. We emphasize that the existence, magnitude <italic>and direction</italic> of such significant differences can be very sensitive to the methods chosen, and the parameterization of those methods, and so such findings should be reported with care, especially if a biological interpretation of said findings is claimed. Transfer entropy rarely gives significant results, but is more robust toward parameter changes in the algorithm and different clustering algorithms. Finding appropriate statistical models may be an additional challenge for this method.</p>
      <p>Weak thresholding may be used for complexity reduction as it has little effect on performance. Applying a higher threshold or extracting the rich club sub-graph (The 10% of nodes with highest degree) causes unsystematic changes in the negative surprise and should therefore be used with caution, and validated against the full graph.</p>
      <p>In summary, our quantitative evaluation and comparison of graph construction and analysis methods provides insight into how contradicting results come about in studies of graph properties of fMRI data, and identifies a number of potential methodological artifacts. Moreover, it provides a blueprint for establishing appropriate analysis pipelines, and serves as a well-founded starting point for future research on larger data sets.</p>
    </sec>
    <sec id="s5">
      <title>5. Methods</title>
      <sec>
        <title>5.1. Data acquisition</title>
        <p>The recruitment and neuropsychological assessment of the study participants is given in Dillen et al. (<xref rid="B15" ref-type="bibr">2017</xref>). Demographic information is given in Table <xref rid="T2" ref-type="table">2</xref>.</p>
        <table-wrap id="T2" position="float">
          <label>Table 2</label>
          <caption>
            <p>Demographic information of participants.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Controls</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>MCI</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>AD</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Number</td>
                <td valign="top" align="center" rowspan="1" colspan="1">26</td>
                <td valign="top" align="center" rowspan="1" colspan="1">16</td>
                <td valign="top" align="center" rowspan="1" colspan="1">14</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Age</td>
                <td valign="top" align="center" rowspan="1" colspan="1">62.38 [50, 73]</td>
                <td valign="top" align="center" rowspan="1" colspan="1">70 [55, 78]</td>
                <td valign="top" align="center" rowspan="1" colspan="1">71 [61, 78]</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Sex</td>
                <td valign="top" align="center" rowspan="1" colspan="1">10 f, 16 m</td>
                <td valign="top" align="center" rowspan="1" colspan="1">7 f, 9 m</td>
                <td valign="top" align="center" rowspan="1" colspan="1">7 f, 7 m</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Years of education</td>
                <td valign="top" align="center" rowspan="1" colspan="1">15.3 [8, 25]</td>
                <td valign="top" align="center" rowspan="1" colspan="1">12.75 [8, 21]</td>
                <td valign="top" align="center" rowspan="1" colspan="1">12.83 [7, 18]</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>Average and minimal and maximal values [min, max] are given for age and years of education; female (f), male (m)</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
        <p>Anatomical MRI and resting state fMRI (rfMRI) images were obtained from a 3T MR-Brain-PET scanner (Siemens, Erlangen, Germany) in the Memory Clinic Cologne Juelich. The parameters for the single-shot echo planar imaging sequence of the functional (T2* weighted) image are the following: TR = 3, 000ms, TE = 30ms, FA = 90°, FOV = 200 × 200mm<sup>2</sup>, matrix = 80 × 80, voxel resolution = 2.5 × 2.5 × 2.8, 50 oblique slices parallel to the infra-supratentorial line, gap = 0.28mm, interleaved, scan time = 7min. Parameters of the high-resolution T1-weighted structural image based on a magnetization-prepared rapid gradient echo sequence: TR = 2, 250ms, TE = 3.03ms, FA = 9°, FOV = 256 × 256mm<sup>2</sup>, matrix = 256 × 256, voxel resolution = 1mm isotropic, 176 sagittal slices, no gap, interleaved, scan time = 314s. For more detail see Dillen et al. (<xref rid="B15" ref-type="bibr">2017</xref>).</p>
      </sec>
      <sec>
        <title>5.2. Preprocessing of fMRI-data and extraction of cortical data</title>
        <p>Image preprocessing is accomplished using FMRIB's Software Library tools (FSL; Woolrich et al., <xref rid="B71" ref-type="bibr">2009</xref>; Jenkinson et al., <xref rid="B28" ref-type="bibr">2012</xref>). We carry out the following steps for the structural T1-weighted image: skull-stripping (Smith, <xref rid="B62" ref-type="bibr">2002</xref>) with bias field correction (Keihaninejad et al., <xref rid="B32" ref-type="bibr">2010</xref>; Leung et al., <xref rid="B38" ref-type="bibr">2011</xref>; Popescu et al., <xref rid="B52" ref-type="bibr">2012</xref>) and for the functional T2-weighted image: discarding the first 10 volumes (out of 140 each taken after 3sec), motion correction (Beckmann and Smith, <xref rid="B5" ref-type="bibr">2004</xref>), spatial smoothing using a 4 mm full width at half maximum Gaussian kernel, high-pass temporal filtering at 0.02 Hz and a six-parameter, rigid-body linear transformation procedure in MCFLIRT (Jenkinson et al., <xref rid="B27" ref-type="bibr">2002</xref>). More details can be found in Dillen et al. (<xref rid="B15" ref-type="bibr">2017</xref>), where the same preprocessing is applied. In addition we carry out white matter and cerebrospinal fluid regression (FSL regfilt, MELODIC) to the functional image in order to reduce noise.</p>
        <p>In order to extract only cortical voxels from the entire brain fMRI image, as needed for the data-driven clustering described in the next section, we first register cortical regions (frontal-, occipital-, temporal-, and insular-cortex) defined in the MNI structural atlas (Collins et al., <xref rid="B11" ref-type="bibr">1995</xref>) to the structural and then to the functional space. For this registration we apply the transformation matrix obtained from registering the entire standard brain first to the individual structural brain (linear registration with FSL/FLIRT; Jenkinson and Smith, <xref rid="B29" ref-type="bibr">2001</xref>; Jenkinson et al., <xref rid="B27" ref-type="bibr">2002</xref>) and then to the functional space (non-linear registration with Advanced Normalization Tools, ANTs; Avants et al., <xref rid="B2" ref-type="bibr">2011</xref>). In order to extract only gray matter tissue, we apply the gray matter image of the structural space (segmentation with FSL-FAST; Zhang et al., <xref rid="B74" ref-type="bibr">2001</xref>) registered to functional space as described above, as a mask to the to the functional image.</p>
      </sec>
      <sec>
        <title>5.3. Data-driven and atlas based clustering of cortical voxels</title>
        <p>In order to construct graphs we cluster cortical voxels into regions using three different methods. Two of these methods, the Ward clustering and the region growing and selection algorithm (RGS) are data driven, such that only neighboring voxels with similar activity are combined into a single region. For these algorithms the number of regions per brain and the participating voxels in a region can differ for each individual and strongly depend on predefined algorithm-specific parameters. The atlas-based cluster algorithm, in contrast, produces the same number of clusters and a constant number of voxels per region across individuals, because the individual brains are mapped onto a standard brain.</p>
        <sec>
          <title>5.3.1. Atlas-based clustering</title>
          <p>For each subject we linearly register the rfMRI image first to the structural, skull-removed image (image segmentation for skull removing with SPM8, Wellcome Department of Cognitive Neurology, London, UKFSL; linear registration with FSL/FLIRT; Jenkinson and Smith, <xref rid="B29" ref-type="bibr">2001</xref>; Jenkinson et al., <xref rid="B27" ref-type="bibr">2002</xref>) and then, through a non-linear mapping, to the MNI standard brain [non-linear registration with Advanced Normalization Tools (ANTs; Avants et al., <xref rid="B2" ref-type="bibr">2011</xref>); MNI 152 standard brain, non-linear 6th generation (Grabner et al., <xref rid="B21" ref-type="bibr">2006</xref>)]. Regions of interest (ROIs) of the resulting functional image in standard space are extracted such that they match the 94 regions identified by the Oxford lateral cortical atlas (regions have a probability above 50%) (Desikan et al., <xref rid="B14" ref-type="bibr">2006</xref>). A demonstration of how the brain is clustered according to the brain areas is given in the first panel of Figure <xref ref-type="fig" rid="F12">12</xref>.</p>
        </sec>
        <sec>
          <title>5.3.2. Ward clustering</title>
          <p>Ward clustering (Python: <italic>sklearn.cluster.AgglomerativeClustering</italic>, Pedregosa et al., <xref rid="B50" ref-type="bibr">2011</xref>) is a data-driven clustering algorithm, which is initiated by defining each voxel as a cluster and then, in each iteration step, merging the two neighboring clusters (even of different sizes) that after merging show minimal intra-cluster variance compared with all other possible variations of combining two adjacent clusters. In this way, the number of clusters is reduced by one in each iteration step. In our case the clustering stops after <italic>k</italic> clusters (Table <xref rid="T3" ref-type="table">3</xref>) are formed. Afterwards, we discard away all clusters that contain less then <italic>p</italic> voxels (Table <xref rid="T3" ref-type="table">3</xref>). An example of the outcome of Ward clustering algorithm is depicted in the second panel of Figure <xref ref-type="fig" rid="F12">12</xref>.</p>
          <table-wrap id="T3" position="float">
            <label>Table 3</label>
            <caption>
              <p>Parameters used for the different clustering algorithms.</p>
            </caption>
            <table frame="hsides" rules="groups">
              <thead>
                <tr>
                  <th rowspan="1" colspan="1"/>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>Minimal number of</bold>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>Number of</bold>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>Threshold <italic>T</italic> of Pearson</bold>
                  </th>
                </tr>
                <tr>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>Method</bold>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>voxels per cluster <italic>p</italic></bold>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>clusters <italic>k</italic></bold>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <bold>correlation coefficient</bold>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">ward1</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">10</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">5,000</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">ward2</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">25</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">5,000</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">ward3</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">10</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">2,000</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">ward4</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">25</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">2,000</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">RGS1</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">55</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">0.75</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">RGS2</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">50</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">0.75</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">atlas</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <p><italic>Ward clustering (ward), region growing and selection (RGS), atlas-based clustering (atlas)</italic>.</p>
            </table-wrap-foot>
          </table-wrap>
        </sec>
        <sec>
          <title>5.3.3. Region growing and selection</title>
          <p>The region growing and selection algorithm is a modified version of the algorithm described in Lu et al. (<xref rid="B40" ref-type="bibr">2003</xref>). Region growing implies that each voxel serves as an initial seed (center) and neighboring voxels are added iteratively if they fulfill a certain growing criteria. (Figure <xref ref-type="fig" rid="F11">11A</xref>) The condition proposed for adding a voxel to a region is based on the Pearson correlation coefficient <italic>R</italic> between the averaged time-varying signals of the pre-merged region and the signal of the voxel to be tested (Lu et al., <xref rid="B40" ref-type="bibr">2003</xref>). If this correlation is higher then a pre-defined threshold <italic>T</italic> (Table <xref rid="T3" ref-type="table">3</xref>), the voxel is merged to the region. We tighten the growth criteria by imposing a second condition that allows the merging of voxels only if, in addition to exceeding the correlation threshold, the resulting cluster is also functionally homogeneous. Here, functional homogeneity means that the time-varying signals of all voxels can be expressed as instances of a single signal with varying levels of noise. The number of independent signals in a cluster can be estimated by the spatial functional heterogeneity <italic>h</italic> (Marrelec and Fransson, <xref rid="B41" ref-type="bibr">2011</xref>):</p>
          <disp-formula id="E1">
            <label>(1)</label>
            <mml:math id="M9">
              <mml:mtable class="eqnarray" columnalign="right center left">
                <mml:mtr>
                  <mml:mtd>
                    <mml:mi>h</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>0</mml:mn>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>+</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>e</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>n</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>-</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>b</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>n</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mn>0</mml:mn>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>e</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>n</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>0</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>-</mml:mo>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>e</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>n</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>0</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>+</mml:mo>
                                <mml:mn>1</mml:mn>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                        <mml:mo>-</mml:mo>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>b</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>n</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>0</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo>-</mml:mo>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mi>b</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:msub>
                                  <mml:mrow>
                                    <mml:mi>n</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mn>0</mml:mn>
                                  </mml:mrow>
                                </mml:msub>
                                <mml:mo>+</mml:mo>
                                <mml:mn>1</mml:mn>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mfrac>
                    <mml:mo>,</mml:mo>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:math>
          </disp-formula>
          <p>where <italic>e</italic><sub><italic>n</italic></sub> are the eigenvalues of the <italic>N</italic><bold>x</bold><italic>N</italic> covariance matrix of all <italic>N</italic> time varing signals in a cluster that exceed the eigenvalues generated by the broken-stick model <italic>b</italic><sub><italic>n</italic></sub>, such that <inline-formula><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>i</mml:mi></mml:math></inline-formula>. The index <italic>n</italic><sub>0</sub> accounts for the smallest eigenvalues that fulfill this inequality equation, such that <italic>e</italic><sub><italic>n</italic><sub>0</sub></sub>&gt;<italic>b</italic><sub><italic>n</italic><sub>0</sub></sub> and <italic>e</italic><sub><italic>n</italic><sub>0+1</sub></sub>&lt;<italic>b</italic><sub><italic>n</italic><sub>0+1</sub></sub>. A value of <italic>h</italic> = 1 indicates a homogeneous cluster.</p>
          <fig id="F11" position="float">
            <label>Figure 11</label>
            <caption>
              <p>Region growing and selection algorithm. <bold>(A)</bold> Region growing, left: each voxel (colored squares) serves as center for a cluster, right: example of a growing region (purple), only adjacent voxels that fulfill the fusion criteria are added to the growing cluster. <bold>(B)</bold> Region selection. Small regions (pink) with centers overlapping with larger regions (green) get deleted (from left to right) in a iterative manner. Remaining regions can still overlap as long as their centers do not cover other regions. This illustration is in 2D for simplicity, the algorithm used for fMRI data acts in 3D following the same rules.</p>
            </caption>
            <graphic xlink:href="fnins-12-00528-g0011"/>
          </fig>
          <p>The region selection algorithm iteratively selects the largest region and deletes all clusters that have their centers in that region, excluding the possibility that centers overlap with other regions. However, clusters can still overlap (Figure <xref ref-type="fig" rid="F11">11B</xref>). Applying this framework does not guarantee that clusters remain spatially connected after deleting regions with overlapping centers. Nevertheless, a check for spatial consistency reveals that only a negligible fraction of the clusters are disrupted in that way. Finally, we took only the clusters that comprised a minimum number of voxels <italic>p</italic> (Table <xref rid="T3" ref-type="table">3</xref>). The outcome of RGS is illustrated in the last panel of Figure <xref ref-type="fig" rid="F12">12</xref>.</p>
          <fig id="F12" position="float">
            <label>Figure 12</label>
            <caption>
              <p>Clustering of the cortical functional image. Illustrated are the clustering outcome of the atlas <bold>(Upper Panel)</bold> and the Ward clustering (ward4, <bold>Middle Panel</bold>) and RGS (RGS1, <bold>Lower Panel</bold>) algorithms for frontal, sagital and horizontal brain sections (from left to right) of a randomly chosen healthy individual. Individual clusters are depicted by a randomly chosen individual color, for clustering parameters see Table <xref rid="T3" ref-type="table">3</xref>.</p>
            </caption>
            <graphic xlink:href="fnins-12-00528-g0012"/>
          </fig>
        </sec>
      </sec>
      <sec>
        <title>5.4. Edge definition</title>
        <p>A graph consists of nodes (vertices) that are connected through edges, that might be weighted or binary and directed or undirected. We construct individual brain graphs by defining nodes that represent clusters as described in section 5.3, such that the mean activity of a cluster becomes a node attribute. We presume that all graphs are fully connected and edge weights are defined in terms of functional connectivity. Since functional connectivity can be calculated in several ways, we apply a range of different connectivity measures. In Wang et al. (<xref rid="B69" ref-type="bibr">2014</xref>) many such methods are evaluated, taking the structural connectivity of a toy model as reference. As a starting point, for each proposed category of functional connectivity, measured in time, we select the analysis measurement that captures structural connectivity best. We follow this strategy for all proposed measurement categories in Wang et al. (<xref rid="B69" ref-type="bibr">2014</xref>), leaving out only Granger causality measures, due to limited computational resources. We thus use linear and non-linear correlation (<italic>corr</italic> and <italic>H</italic><sub>2</sub>) and mutual information transfer (<italic>MIT</italic>) for the model-free category and transfer entropy (<italic>TE</italic>) for the model-based category. In all groups the bivariate methods perform better then the partial ones. In conclusion we select for each of the families the bivariate implementation that can be both directed and undirected. For consistency we use the same abbreviations for the different methods as in Wang et al. (<xref rid="B69" ref-type="bibr">2014</xref>) and the same Matlab toolbox Mulan<xref ref-type="fn" rid="fn0003"><sup>3</sup></xref> which they made public. Here we provide only a short description of the applied methods and more details can be inferred from Wang et al. (<xref rid="B69" ref-type="bibr">2014</xref>).</p>
        <p>Linear correlation (<italic>corr</italic>) are measured based on the Pearson correlation coefficient (Rodgers and Nicewander, <xref rid="B55" ref-type="bibr">1988</xref>) in a pair-wise manner. For directed connectivity (<italic>BCorrD</italic>) delays of up to 5 time steps (Table <xref rid="T4" ref-type="table">4</xref>) are considered and the largest connectivity value is selected. We do not take into account time lags for undirected correlation (<italic>BCorrU</italic>).</p>
        <table-wrap id="T4" position="float">
          <label>Table 4</label>
          <caption>
            <p>Parameters of the different functional connectivity measures.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <bold>Method</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Window size</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Window overlap</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Number of bins</bold>
                </th>
                <th valign="top" align="center" rowspan="1" colspan="1">
                  <bold>Max. delay</bold>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BcorrU</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BcorrU</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BcorrD</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BcorrD</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BH</italic>2<italic>U</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">10</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BH</italic>2<italic>U</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">10</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BH</italic>2<italic>D</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">10</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BH</italic>2<italic>D</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">10</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BMITU</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BMITU</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <italic>BMITD1</italic>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BMITD</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BTEU</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BTEU</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BTED</italic>1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">130</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>BTED</italic>2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">–</td>
                <td valign="top" align="center" rowspan="1" colspan="1">5</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>Bivariate (B), undirected (U), directed (D), linear correlation (corr), non-linear correlation (H<sub>2</sub>U), mutual information entropy (MIT), transfer entropy (TE)</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
        <p>Non-linear correlations (<italic>H</italic><sub>2</sub>) are based on piece-wise linear correlations of two time signals on which the non-linear curve is fitted (da Silva et al., <xref rid="B12" ref-type="bibr">1989</xref>). Bivariate directed (<italic>BH</italic><sub>2</sub><italic>D</italic>) and bivariate undirected (<italic>BH</italic><sub>2</sub><italic>U</italic>) are defined as above for linear correlations.</p>
        <p>Mutual information indicates how much information is shared between two time varying signals by means of Shannon entropy (Grassberger et al., <xref rid="B22" ref-type="bibr">1991</xref>). For <italic>BMITD1</italic> individual histograms of two time series are contrasted to the joint histogram across different time delays. No delays are taken into account in <italic>BMITU</italic>.</p>
        <p>Transfer entropy (Schreiber, <xref rid="B58" ref-type="bibr">2000</xref>) describes how far in the past the activity of a node can reduce the uncertainty of the future activity of another node for which the past activity is also considered. Bivariate directed (<italic>BTED</italic>, Chicharro, <xref rid="B9" ref-type="bibr">2011</xref>) and bivariate undirected (<italic>BTEU</italic>) are defined as above for linear correlations.</p>
        <p>All methods were tested for a window size that comprises the whole time range (130 time points/6.5 min) and for a sliding window of 50 time points (2.5 min) with an overlap of 10 time points (0.5 min), see Table <xref rid="T4" ref-type="table">4</xref>. If the methods revealed negative weights, the absolute value was considered. The resulting graphs are directed or undirected weighted graphs with values between zero and one for all methods except non-linear correlations, where values can exceed one.</p>
        <p>Many studies transfer weighted graphs into binary ones by setting all values below a threshold <italic>w</italic><sub>min</sub> to zero and above to one e.g., Zhao et al. (<xref rid="B75" ref-type="bibr">2012</xref>). Following this strategy we also investigate the effect of setting all weights below <italic>w</italic><sub>min</sub> to zero but leaving higher weights unchanged. As far as the remaining graphs are still connected (left panels in Figure <xref ref-type="fig" rid="F13">13</xref>) and single nodes are not disconnected from the network (right panels in Figure <xref ref-type="fig" rid="F13">13</xref>) we study the disease diagnosis capacity for <italic>w</italic><sub>min</sub>∈{0.1, 0.2, …0.7, 0.8}. In addition we extract the rich club of the graphs. The rich club is a subgraph that comprises the nodes that are most strongly connected to the network. In this work we define the rich club as the 10% of nodes with highest degree.</p>
        <fig id="F13" position="float">
          <label>Figure 13</label>
          <caption>
            <p>High thresholds on graph edges cause the graphs to dissociate. <bold>(Upper Panel)</bold>, Illustration of graph with edge weights larger then 0.1 (<italic>w</italic>min&gt;0.1, <bold>Left</bold>) and larger then 0.9 (<italic>w</italic>min&gt;0.9, <bold>Right</bold>). In the according weight histograms <bold>(Lower Panel)</bold> the red bars correspond to the edges drawn in the upper graph. Edges corresponding to the black bars are not shown.</p>
          </caption>
          <graphic xlink:href="fnins-12-00528-g0013"/>
        </fig>
      </sec>
      <sec>
        <title>5.5. Graph properties</title>
        <p>This section describes the different graph properties that are either characteristics of single nodes (weighted degree, closeness centrality, cluster coefficient), of pairs of nodes (shortest path) or of the entire network (modularity). In the first two cases we get a range of values for each graph. Since we do not know, which are the important features of the resulting distributions, we take the first four moments for our statistical analysis. Because graphs based on data-driven clustering contain different number of nodes and the calculated graph properties might be dependent on the number of nodes, we also include the number of nodes in the subsequent analysis (section 5.6).</p>
        <sec>
          <title>5.5.1. Weighted degree</title>
          <p>The weighted degree deg<sub><italic>w</italic></sub> describes how strongly a node is connected to all other vertices of the network, obeying the equation:</p>
          <disp-formula id="E2">
            <label>(2)</label>
            <mml:math id="M11">
              <mml:mtable class="eqnarray" columnalign="right center left">
                <mml:mtr>
                  <mml:mtd>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mtext>deg</mml:mtext>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mi>v</mml:mi>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mstyle displaystyle="true">
                      <mml:munder class="msub">
                        <mml:mrow>
                          <mml:mo>∑</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>u</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mi>V</mml:mi>
                          <mml:mo>\</mml:mo>
                          <mml:mrow>
                            <mml:mo>{</mml:mo>
                            <mml:mrow>
                              <mml:mi>v</mml:mi>
                            </mml:mrow>
                            <mml:mo>}</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:munder>
                    </mml:mstyle>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>u</mml:mi>
                        <mml:mi>v</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:math>
          </disp-formula>
          <p>where <italic>w</italic><sub><italic>uv</italic></sub> is the weight on the edge between nodes <italic>u</italic> and <italic>v</italic> of all nodes <italic>V</italic> in the graph. This definition implies a high dependency of the weighted degree on the number of nodes in a graph. To address this problem, we normalize the weighted degree</p>
          <disp-formula id="E3">
            <label>(3)</label>
            <mml:math id="M12">
              <mml:mtable class="eqnarray" columnalign="right center left">
                <mml:mtr>
                  <mml:mtd>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mtext>deg</mml:mtext>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mi>v</mml:mi>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mtext>deg</mml:mtext>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>w</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mrow>
                            <mml:mi>v</mml:mi>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>deg</mml:mtext>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mrow>
                            <mml:mi>v</mml:mi>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                        <mml:mo>·</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>w</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mo class="qopname">max</mml:mo>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:math>
          </disp-formula>
          <p>with <italic>w</italic><sub>max</sub> being the maximal weight of the graph. The resulting values are between 0 and 1.</p>
        </sec>
        <sec>
          <title>5.5.2. Shortest path and closeness centrality</title>
          <p>The shortest path dist<sub><italic>w</italic></sub>(<italic>u, v</italic>) between a pair of nodes <italic>u</italic> and <italic>v</italic> describes the path that minimizes the sum of the weights of its participating edges. A small shortest path should indicate a strong functional connectivity, therefore we consider the inverse of the graph weights for its calculation. Its computation is carried out using Dijkstra's algorithm (Rivest et al., <xref rid="B54" ref-type="bibr">2000</xref>), which requires the weights to be positive.</p>
          <p>Based on the shortest paths of a network we calculate closeness centrality <italic>C</italic><sub><italic>w</italic></sub>(<italic>v</italic>) - a measure that indicates how strongly a node <italic>v</italic> participates in all shortest paths of the graph. It is given by:</p>
          <disp-formula id="E4">
            <label>(4)</label>
            <mml:math id="M13">
              <mml:mtable class="eqnarray" columnalign="right center left">
                <mml:mtr>
                  <mml:mtd>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>C</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mi>v</mml:mi>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mi>n</mml:mi>
                        <mml:mo>-</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mstyle displaystyle="true">
                          <mml:msub class="msub">
                            <mml:mrow>
                              <mml:mo>∑</mml:mo>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:mi>u</mml:mi>
                              <mml:mo>∈</mml:mo>
                              <mml:mi>V</mml:mi>
                              <mml:mo>\</mml:mo>
                              <mml:mrow>
                                <mml:mo>{</mml:mo>
                                <mml:mrow>
                                  <mml:mi>v</mml:mi>
                                </mml:mrow>
                                <mml:mo>}</mml:mo>
                              </mml:mrow>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mstyle>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mtext>dist</mml:mtext>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>w</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mrow>
                            <mml:mi>u</mml:mi>
                            <mml:mo>,</mml:mo>
                            <mml:mi>v</mml:mi>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:math>
          </disp-formula>
          <p>Here, <italic>n</italic> is the number of all nodes <italic>V</italic> in the graph.</p>
        </sec>
        <sec>
          <title>5.5.3. Clustering coefficient</title>
          <p>The clustering coefficient <italic>cc</italic>(<italic>v</italic>) describes to what degree the neighbors of a node <italic>v</italic> are connected among each other and with node <italic>v</italic>. Since our network is weighted, we use the Zhang-Horvath clustering coefficient (Zhang and Horvath, <xref rid="B73" ref-type="bibr">2005</xref>; Kalna and Higham, <xref rid="B31" ref-type="bibr">2007</xref>), which is an extension to the “standard” algorithm applied to binary graphs:</p>
          <disp-formula id="E5">
            <label>(5)</label>
            <mml:math id="M14">
              <mml:mrow>
                <mml:mtable>
                  <mml:mtr>
                    <mml:mtd>
                      <mml:mrow>
                        <mml:mi>c</mml:mi>
                        <mml:mi>c</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:mi>v</mml:mi>
                        <mml:mo stretchy="false">)</mml:mo>
                        <mml:mo>=</mml:mo>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:msup>
                                  <mml:mstyle mathsize="140%" displaystyle="true">
                                    <mml:mo>∑</mml:mo>
                                  </mml:mstyle>
                                  <mml:mtext>​</mml:mtext>
                                </mml:msup>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mo>≠</mml:mo>
                                <mml:mi>v</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mrow>
                                <mml:msup>
                                  <mml:mstyle mathsize="140%" displaystyle="true">
                                    <mml:mo>∑</mml:mo>
                                  </mml:mstyle>
                                  <mml:mtext>​</mml:mtext>
                                </mml:msup>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>j</mml:mi>
                                <mml:mo>≠</mml:mo>
                                <mml:mi>i</mml:mi>
                                <mml:mo>,</mml:mo>
                                <mml:mi>j</mml:mi>
                                <mml:mo>≠</mml:mo>
                                <mml:mi>v</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mover accent="true">
                                  <mml:mi>w</mml:mi>
                                  <mml:mo stretchy="true">^</mml:mo>
                                </mml:mover>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>v</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mover accent="true">
                                  <mml:mi>w</mml:mi>
                                  <mml:mo stretchy="true">^</mml:mo>
                                </mml:mover>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mi>j</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mover accent="true">
                                  <mml:mi>w</mml:mi>
                                  <mml:mo stretchy="true">^</mml:mo>
                                </mml:mover>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>j</mml:mi>
                                <mml:mi>v</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mo stretchy="true">(</mml:mo>
                                <mml:msup>
                                  <mml:mstyle mathsize="140%" displaystyle="true">
                                    <mml:mo>∑</mml:mo>
                                  </mml:mstyle>
                                  <mml:mtext>​</mml:mtext>
                                </mml:msup>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mo>≠</mml:mo>
                                <mml:mi>v</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mover accent="true">
                                  <mml:mi>w</mml:mi>
                                  <mml:mo stretchy="true">^</mml:mo>
                                </mml:mover>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>v</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:mo stretchy="true">)</mml:mo>
                            <mml:msub>
                              <mml:mrow>
                                <mml:mo stretchy="true">(</mml:mo>
                                <mml:msup>
                                  <mml:mstyle mathsize="140%" displaystyle="true">
                                    <mml:mo>∑</mml:mo>
                                  </mml:mstyle>
                                  <mml:mtext>​</mml:mtext>
                                </mml:msup>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>i</mml:mi>
                                <mml:mo>≠</mml:mo>
                                <mml:mi>v</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                            <mml:msubsup>
                              <mml:mrow>
                                <mml:mover accent="true">
                                  <mml:mi>w</mml:mi>
                                  <mml:mo stretchy="true">^</mml:mo>
                                </mml:mover>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mi>v</mml:mi>
                                <mml:mi>i</mml:mi>
                              </mml:mrow>
                              <mml:mn>2</mml:mn>
                            </mml:msubsup>
                            <mml:mo stretchy="true">)</mml:mo>
                          </mml:mrow>
                        </mml:mfrac>
                      </mml:mrow>
                    </mml:mtd>
                  </mml:mtr>
                </mml:mtable>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>for <italic>i</italic>, <italic>j</italic> neighbors of <italic>v</italic> and ŵ denoting the weights normalized by the highest weight in the network, such that 0 ≤ ŵ ≤ 1.</p>
        </sec>
        <sec>
          <title>5.5.4. Modularity</title>
          <p>A graph can be partitioned into smaller components. Modularity measures the deviation of the properties of these components as compared to the components of a random graph with the same edge weights. Accordingly, the modularity of a partition <italic>p</italic> of a network <italic>G</italic> into communities <italic>c</italic> is given by Newman (<xref rid="B47" ref-type="bibr">2004</xref>):</p>
          <disp-formula id="E6">
            <label>(6)</label>
            <mml:math id="M15">
              <mml:mtable class="eqnarray" columnalign="right center left">
                <mml:mtr>
                  <mml:mtd>
                    <mml:mi>Q</mml:mi>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>2</mml:mn>
                        <mml:mi>m</mml:mi>
                      </mml:mrow>
                    </mml:mfrac>
                    <mml:mstyle displaystyle="true">
                      <mml:munder class="msub">
                        <mml:mrow>
                          <mml:mo>∑</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                          <mml:mo>,</mml:mo>
                          <mml:mi>j</mml:mi>
                          <mml:mo>∈</mml:mo>
                          <mml:mi>V</mml:mi>
                        </mml:mrow>
                      </mml:munder>
                    </mml:mstyle>
                    <mml:mstyle mathsize="1.19em">
                      <mml:mrow/>
                    </mml:mstyle>
                    <mml:mo stretchy="true">(</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>-</mml:mo>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mtext>deg</mml:mtext>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>w</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mrow>
                            <mml:mo stretchy="false">(</mml:mo>
                            <mml:mi>i</mml:mi>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                        <mml:mo>·</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mtext>deg</mml:mtext>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>w</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mrow>
                            <mml:mi>j</mml:mi>
                          </mml:mrow>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>2</mml:mn>
                        <mml:mi>m</mml:mi>
                      </mml:mrow>
                    </mml:mfrac>
                    <mml:mstyle mathsize="1.19em">
                      <mml:mrow/>
                    </mml:mstyle>
                    <mml:mo stretchy="true">)</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>δ</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>c</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>c</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>j</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:math>
          </disp-formula>
          <p>where δ<sub><italic>c</italic><sub><italic>i</italic></sub><italic>c</italic><sub><italic>j</italic></sub></sub> is 1, if the community <italic>c</italic><sub><italic>i</italic></sub> of node <italic>i</italic> is the same as the community <italic>c</italic><sub><italic>j</italic></sub> of node <italic>j</italic>, and 0 otherwise, and <inline-formula><mml:math id="M16"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munder class="msub"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total sum of edge weights in a network. Although there are many different definitions in literature about what a community consists of, we define a community as a group of strongly interconnected nodes that make only weak connections to other communities. In addition, a node can maximally contribute to one community. Hence we want to find the partition that maximizes modularity, which is computationally very demanding, so it is important to use a very effective algorithm. We therefore use the fast algorithm by Blondel et al. (<xref rid="B7" ref-type="bibr">2008</xref>), which is implemented in the Python packages community. Unfortunately this implementation is only suitable for undirected graphs, so we investigate modularity only for these type of graphs.</p>
        </sec>
      </sec>
      <sec>
        <title>5.6. Statistical model</title>
        <p>The generated graph data is used as input for an exchangeable parametric statistical model. Let us recall that the purpose of the fMRI scan of a patient is to give the clinician a likelihood for the patient's health condition,</p>
        <disp-formula id="E7">
          <label>(7)</label>
          <mml:math id="M17">
            <mml:mrow>
              <mml:mtext>P(graph data from fMRI scan | health condition ^  prior info),</mml:mtext>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>which she combines with the likelihoods from other tests and her initial probability assignment, to obtain via Bayes's theorem a final probability for the health condition (Sox et al., <xref rid="B63" ref-type="bibr">2013</xref>):</p>
        <disp-formula id="E8">
          <label>(8)</label>
          <mml:math id="M18">
            <mml:mtable columnalign="left">
              <mml:mtr>
                <mml:mtd>
                  <mml:mover>
                    <mml:mover>
                      <mml:mrow>
                        <mml:mtext>P(health condition | results of all tests ^ prior info)</mml:mtext>
                      </mml:mrow>
                      <mml:mo stretchy="true">︷</mml:mo>
                    </mml:mover>
                    <mml:mrow>
                      <mml:mi>f</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mtext> </mml:mtext>
                      <mml:mi>p</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mi>o</mml:mi>
                      <mml:mi>b</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>b</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mi>y</mml:mi>
                    </mml:mrow>
                  </mml:mover>
                  <mml:mo>α</mml:mo>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mi>l</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>k</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>h</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>d</mml:mi>
                  <mml:mi>s</mml:mi>
                  <mml:mrow>
                    <mml:mo>{</mml:mo>
                    <mml:mtable columnalign="left">
                      <mml:mtr>
                        <mml:mtd>
                          <mml:mtext>   P(graph data from fMRI scan | health condition ^ prior info)</mml:mtext>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd>
                          <mml:mtext>×P(results of other tests | health condition </mml:mtext>
                          <mml:mo>^</mml:mo>
                          <mml:mtext> prior info)</mml:mtext>
                        </mml:mtd>
                      </mml:mtr>
                      <mml:mtr>
                        <mml:mtd>
                          <mml:mtext>×</mml:mtext>
                          <mml:mo>⋯</mml:mo>
                        </mml:mtd>
                      </mml:mtr>
                    </mml:mtable>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>                                                      </mml:mtext>
                  <mml:munder>
                    <mml:munder>
                      <mml:mrow>
                        <mml:mtext>×P(health condition | prior info).</mml:mtext>
                      </mml:mrow>
                      <mml:mo stretchy="true">︸</mml:mo>
                    </mml:munder>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mi>n</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mtext> </mml:mtext>
                      <mml:mi>p</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mi>o</mml:mi>
                      <mml:mi>b</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>b</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>l</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>t</mml:mi>
                      <mml:mi>y</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <p>The prior information also includes test results from previous patients, so that the prediction becomes more accurate and reliable, the more patients have been previously observed.</p>
        <p>The functional dependence of the likelihood on the graph data is determined by the statistical model we use, and may be different for each health condition. The statistical model is determined by additional assumptions or hypotheses. Such hypotheses and the functional form of the likelihood may depend on the particular space of graph data (e.g., real-valued, or positive, or bounded within a finite range, or combinations thereof), and therefore on the graph construction method.</p>
        <p>As explained in section 2.3, our purpose is to assess as far as possible the relative predictive power of the different graph construction methods. We therefore would like the functional dependence on the graph data space to be minimal. In the present study we adopt the working hypothesis that only the first and second empirical moments—means and correlations—of the graph data from past patients with the same health condition are relevant to make predictions about a new patient. This hypothesis is adopted for all graph construction methods. We also assume our initial knowledge of the graph data to be approximately invariant under rescalings of their values (Minka, <xref rid="B43" ref-type="bibr">2001</xref>). Finally, we do not take into account the natural range of variability (positive, bounded, etc.) of the graph data; this choice does not seem to impact the predictive power of the model (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>).</p>
        <p>These assumptions almost uniquely determine the statistical model and the likelihood (Porta Mana et al., <xref rid="B53" ref-type="bibr">2018</xref>): it turns out to be a multivariate t distribution (Minka, <xref rid="B43" ref-type="bibr">2001</xref>; Kotz and Nadarajah, <xref rid="B36" ref-type="bibr">2004</xref>; Murphy, <xref rid="B45" ref-type="bibr">2007</xref>). More precisely: select a particular health condition, e.g., Alzheimer's disease. Denote with <italic>f</italic>0 the <italic>d</italic>-dimensional vector of graph data obtained from the patient's fMRI scan via a particular graph construction method, and with (<italic>f</italic><sub><italic>i</italic></sub>) the graph data of <italic>n</italic> previous patients with the selected health condition. Then the likelihood that the present patient has the selected health condition is</p>
        <disp-formula id="E9">
          <mml:math id="M19">
            <mml:mtable columnalign="left">
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext>p</mml:mtext>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>f</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>f</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi>κ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi>δ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi>ν</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi>Δ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:mi>M</mml:mi>
                    </mml:mrow>
                    <mml:mo>]</mml:mo>
                  </mml:mrow>
                  <mml:mo>≡</mml:mo>
                  <mml:mtext>p</mml:mtext>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>f</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mi>κ</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>δ</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>ν</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>Δ</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>M</mml:mi>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>=</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mrow>
                    <mml:mo>[</mml:mo>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>f</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                        </mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mi>ν</mml:mi>
                      <mml:mo>−</mml:mo>
                      <mml:mi>d</mml:mi>
                      <mml:mo>+</mml:mo>
                      <mml:mn>1</mml:mn>
                      <mml:mo>,</mml:mo>
                      <mml:mi>δ</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:mi>κ</mml:mi>
                          <mml:mo>+</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>κ</mml:mi>
                          <mml:mrow>
                            <mml:mo>(</mml:mo>
                            <mml:mrow>
                              <mml:mi>ν</mml:mi>
                              <mml:mo>−</mml:mo>
                              <mml:mi>d</mml:mi>
                              <mml:mo>+</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                            <mml:mo>)</mml:mo>
                          </mml:mrow>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mi>Δ</mml:mi>
                    </mml:mrow>
                    <mml:mo>]</mml:mo>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <disp-formula id="E10">
          <label>(9)</label>
          <mml:math id="M20">
            <mml:mrow>
              <mml:mtable>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:mi>κ</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:msub>
                        <mml:mi>κ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mi>n</mml:mi>
                      <mml:mo>,</mml:mo>
                    </mml:mrow>
                  </mml:mtd>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:mi>ν</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:msub>
                        <mml:mi>ν</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mi>n</mml:mi>
                      <mml:mo>,</mml:mo>
                    </mml:mrow>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>with</p>
        <disp-formula id="E11">
          <label>(10)</label>
          <mml:math id="M21">
            <mml:mrow>
              <mml:mtable>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:mi>δ</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>κ</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                          <mml:msub>
                            <mml:mi>δ</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                          <mml:mo>+</mml:mo>
                          <mml:mi>n</mml:mi>
                          <mml:mover accent="true">
                            <mml:mi>f</mml:mi>
                            <mml:mo>¯</mml:mo>
                          </mml:mover>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>κ</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                          <mml:mo>+</mml:mo>
                          <mml:mi>n</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mo>,</mml:mo>
                      <mml:mtext> </mml:mtext>
                      <mml:mi>Δ</mml:mi>
                      <mml:mo>=</mml:mo>
                      <mml:msub>
                        <mml:mi>Δ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo>+</mml:mo>
                      <mml:mi>n</mml:mi>
                      <mml:mtext>Cov</mml:mtext>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mi>f</mml:mi>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                  </mml:mtd>
                </mml:mtr>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:mo>+</mml:mo>
                      <mml:mfrac>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>κ</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                          <mml:mi>n</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>κ</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                          <mml:mo>+</mml:mo>
                          <mml:mi>n</mml:mi>
                        </mml:mrow>
                      </mml:mfrac>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mover accent="true">
                        <mml:mi>f</mml:mi>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                      <mml:mo>−</mml:mo>
                      <mml:msub>
                        <mml:mi>δ</mml:mi>
                        <mml:mn>0</mml:mn>
                      </mml:msub>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:msup>
                        <mml:mrow>
                          <mml:mo stretchy="false">(</mml:mo>
                          <mml:mover accent="true">
                            <mml:mi>f</mml:mi>
                            <mml:mo>¯</mml:mo>
                          </mml:mover>
                          <mml:mo>−</mml:mo>
                          <mml:msub>
                            <mml:mi>δ</mml:mi>
                            <mml:mn>0</mml:mn>
                          </mml:msub>
                          <mml:mo stretchy="false">)</mml:mo>
                        </mml:mrow>
                        <mml:mi>⊤</mml:mi>
                      </mml:msup>
                      <mml:mo>,</mml:mo>
                    </mml:mrow>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>where t is a multivariate t distribution with ν−<italic>d</italic>+1 degrees of freedom, mean δ, and scale matrix <inline-formula><mml:math id="M22"><mml:mfrac><mml:mrow><mml:mi>κ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>κ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>Δ</mml:mi></mml:math></inline-formula>, and</p>
        <disp-formula id="E12">
          <label>(11)</label>
          <mml:math id="M23">
            <mml:mrow>
              <mml:mtable>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mrow>
                      <mml:mover accent="true">
                        <mml:mi>f</mml:mi>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                      <mml:mo>:</mml:mo>
                      <mml:mtext> </mml:mtext>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mn>1</mml:mn>
                        <mml:mi>n</mml:mi>
                      </mml:mfrac>
                      <mml:mstyle displaystyle="true">
                        <mml:msub>
                          <mml:mo>∑</mml:mo>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mi>f</mml:mi>
                            <mml:mi>i</mml:mi>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mstyle>
                      <mml:mo>,</mml:mo>
                      <mml:mtext> </mml:mtext>
                      <mml:mo> </mml:mo>
                      <mml:mtext>Cov</mml:mtext>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mi>f</mml:mi>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mo>:</mml:mo>
                      <mml:mtext> </mml:mtext>
                      <mml:mo>=</mml:mo>
                      <mml:mfrac>
                        <mml:mn>1</mml:mn>
                        <mml:mi>n</mml:mi>
                      </mml:mfrac>
                    </mml:mrow>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
              <mml:msup>
                <mml:mrow>
                  <mml:mstyle displaystyle="true">
                    <mml:msub>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:msub>
                        <mml:mi>f</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:mo>−</mml:mo>
                      <mml:mover accent="true">
                        <mml:mi>f</mml:mi>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:msub>
                        <mml:mi>f</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                      <mml:mo>−</mml:mo>
                      <mml:mover accent="true">
                        <mml:mi>f</mml:mi>
                        <mml:mo>¯</mml:mo>
                      </mml:mover>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                  </mml:mstyle>
                </mml:mrow>
                <mml:mi>⊤</mml:mi>
              </mml:msup>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <p>are the empirical mean and covariance matrix of the previous graph data.</p>
        <p>The parameters κ0, ν0, δ0, Δ0 should reflect our initial knowledge of the graph parameters. For the reasons explained above and in section 2.3, we fix one set of values identically for all graph construction methods: κ = 1, (δ0)<sub><italic>a</italic></sub> = 0.5, Δ0 = 2.5<italic>I</italic>, where <italic>I</italic> is the identity matrix. These values yield an initial distribution (before any data from previous patients) centered on positive values of unit order of magnitude, as all the graph data indeed are for each graph construction method.</p>
      </sec>
      <sec>
        <title>5.7. Supportive evaluation measures of graph construction methods</title>
        <sec>
          <title>5.7.1. Significance test</title>
          <p>We measure the significance level of the mean values of a graph property distribution between pairs of the three healthy conditions (control-AD, control-MCI, MCI-AD) based on the Student's <italic>t</italic>-test, if variances are equal (<italic>F</italic>-test), and Welch's <italic>t</italic>-test otherwise. The underlying null hypothesis is that the means of the two data arrays are assumed to be equal, which is rejected for <italic>p</italic>-values smaller then 0.05.</p>
        </sec>
        <sec>
          <title>5.7.2. Dendrograms of subject order</title>
          <p>Subjects indexed from 1 to 56 (total number of participants) across all health conditions are ordered according to the mean values of a given graph property distribution. The indices of the ordering (the rank) calculated for each graph construction method is then used in order to construct the dendrogram. In the dendrogram, the Euclidean distance between two indices arrays is indicated by the height of the top of the U-link linking the two arrays. In addition, arrays with a small distance are clustered together.</p>
        </sec>
        <sec>
          <title>5.7.3. Support vector machines</title>
          <p>For all complete graphs constructed by all different graph construction methods, we apply a support vector classification (Python: <italic>sklearn.svm.SVC</italic>) on each pair of health conditions (control-AD, control-MCI, MCI-AD). Hereby we choose the graph properties such that the performance of the algorithm maximizes. We use the default parameters and do not optimize performance by varying the kernel coefficient or the penalty parameter of the error term.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s6">
      <title>Ethics statement</title>
      <p>This study was part of a larger study, which was approved by the local ethics committee, in accordance with the declaration of Helsinki and performed after informed written consent of each participant. Healthy participants were reimbursed. AD patients were not reimbursed since imaging was part of their diagnostic procedures. We did, however, pay for and organize their traveling costs and lunch.</p>
    </sec>
    <sec id="s7">
      <title>Author contributions</title>
      <p>CB constructed the graphs and calculated and analyzed the graph properties. She also applied the statistical analysis, formulated together with PP, to the data. KD, HJ, NR, BvR, JD, OO, K-JL, GF and JK contributed to the conception of the study design and recruited patients. KD, NR, BvR, and JD organized and performed fMRI scanning. KD and HJ applied primary preprocessing to the fMRI data. The manuscript was written by CB, AM, and PP, with additional editing by HJ and JK.</p>
      <sec>
        <title>Conflict of interest statement</title>
        <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>PP thanks Mari &amp; Miri for continuous encouragement, affection, and support; the kind staff at Iris; and Buster Keaton and Saitama for filling life with awe and inspiration. We are grateful to Simone Buttler for her important help with regard to the calculation of graph properties, and Fahad Khalid and Andreas Müller of the SimLab Neuroscience at the Jülich Supercomputing Center for their expertise in graph visualization. We also acknowledge the support and expert advice by Alper Yegenoglu, Paulina Dabrowska, and Dr. Jyotika Bahuguna. We would like to thank Dr. Gabriele Stoffels, Dr. Christian Filss, and Nathalie Judov for their assistance and generous support. We also acknowledge the technical support and advice of Prof. Dr. Hans Herzog, Dr. Elena Rota Kops, Lutz Tellmann, and Dr. Daniel Pflugfelder. Finally, we are grateful to Kornelia Frey, Suzanne Schaden, and Silke Frensch for their important help in data acquisition. Thanks are extended to Prof. Dr. Nadim Jon Shah for support with the MRI.</p>
    </ack>
    <fn-group>
      <fn id="fn0001">
        <p><sup>1</sup><ext-link ext-link-type="uri" xlink:href="https://github.com/dpisner453/PyNets">https://github.com/dpisner453/PyNets</ext-link>.</p>
      </fn>
      <fn id="fn0002">
        <p><sup>2</sup><ext-link ext-link-type="uri" xlink:href="https://www.alz.org/research/diagnostic_criteria/">https://www.alz.org/research/diagnostic_criteria/</ext-link>.</p>
      </fn>
      <fn id="fn0003">
        <p><sup>3</sup><ext-link ext-link-type="uri" xlink:href="https://github.com/HuifangWang/MULAN">https://github.com/HuifangWang/MULAN</ext-link>.</p>
      </fn>
    </fn-group>
    <fn-group>
      <fn fn-type="financial-disclosure">
        <p><bold>Funding.</bold> We acknowledge partial support by the Helmholtz Alliance through the Initiative and Networking Fund of the Helmholtz Association and the Helmholtz Portfolio theme Supercomputing and Modeling for the Human Brain and the German Research Foundation (DFG; grant DI 1721/3-1 [KFO219-TP9]). This work was also supported by a DFG individual grant JA 2336/1-1 (HJ) and by a grant of the Marga and Walter Boll Foundation, Kerpen, Germany, to GF and JK.</p>
      </fn>
    </fn-group>
    <sec sec-type="supplementary-material" id="s10">
      <title>Supplementary material</title>
      <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fnins.2018.00528/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fnins.2018.00528/full#supplementary-material</ext-link></p>
      <supplementary-material content-type="local-data" id="SM1">
        <media xlink:href="Data_Sheet_1.pdf">
          <caption>
            <p>Click here for additional data file.</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amoroso</surname><given-names>N.</given-names></name><name><surname>La Rocca</surname><given-names>M.</given-names></name><name><surname>Bruno</surname><given-names>S.</given-names></name><name><surname>Maggipinto</surname><given-names>T.</given-names></name><name><surname>Monaco</surname><given-names>A.</given-names></name><name><surname>Bellotti</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Brain structural connectivity atrophy in Alzheimer's disease</article-title>. <source>arXiv 1709.02369</source> [preprint].</mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>B. B.</given-names></name><name><surname>Tustison</surname><given-names>N. J.</given-names></name><name><surname>Song</surname><given-names>G.</given-names></name><name><surname>Cook</surname><given-names>P. A.</given-names></name><name><surname>Klein</surname><given-names>A.</given-names></name><name><surname>Gee</surname><given-names>J. C.</given-names></name></person-group> (<year>2011</year>). <article-title>A reproducible evaluation of ANTS similarity metric performance in brain image registration</article-title>. <source>Neuroimage</source>
<volume>54</volume>, <fpage>2033</fpage>–<lpage>2044</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.09.025</pub-id><pub-id pub-id-type="pmid">20851191</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>M. S.</given-names></name></person-group> (<year>1952</year>). <article-title>The statistical significance of odd bits of information</article-title>. <source>Biometrika</source>
<volume>39</volume>, <fpage>228</fpage>–<lpage>237</lpage>. <pub-id pub-id-type="doi">10.2307/2334019</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bassett</surname><given-names>D. S.</given-names></name><name><surname>Bullmore</surname><given-names>E.</given-names></name><name><surname>Verchinski</surname><given-names>B. A.</given-names></name><name><surname>Mattay</surname><given-names>V. S.</given-names></name><name><surname>Weinberger</surname><given-names>D. R.</given-names></name><name><surname>Meyer-Lindenberg</surname><given-names>A.</given-names></name></person-group> (<year>2008</year>). <article-title>Hierarchical organization of human cortical networks in health and schizophrenia</article-title>. <source>J. Neurosci</source>
<volume>28</volume>, <fpage>9239</fpage>–<lpage>9248</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1929-08.2008</pub-id><pub-id pub-id-type="pmid">18784304</pub-id></mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2004</year>). <article-title>Probabilistic independent component analysis for functional magnetic resonance imaging</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>23</volume>, <fpage>137</fpage>–<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2003.822821</pub-id><pub-id pub-id-type="pmid">14964560</pub-id></mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernardo</surname><given-names>J.-M.</given-names></name></person-group> (<year>1979</year>). <article-title>Expected information as expected utility</article-title>. <source>Ann. Stat.</source>
<volume>7</volume>, <fpage>686</fpage>–<lpage>690</lpage>.</mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname><given-names>V. D.</given-names></name><name><surname>Guillaume</surname><given-names>J.-L.</given-names></name><name><surname>Lambiotte</surname><given-names>R.</given-names></name><name><surname>Lefebvre</surname><given-names>E.</given-names></name></person-group> (<year>2008</year>). <article-title>Fast unfolding of communities in large networks</article-title>. <source>J. Stat. Mech.</source>
<volume>10</volume>:<fpage>P10008</fpage>
<pub-id pub-id-type="doi">10.1088/1742-5468/2008/10/P10008</pub-id></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bordier</surname><given-names>C.</given-names></name><name><surname>Nicolini</surname><given-names>C.</given-names></name><name><surname>Bifone</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Graph analysis and modularity of brain functional connectivity networks: searching for the optimal threshold</article-title>. <source>Front. Neurosci.</source>
<volume>11</volume>:<fpage>441</fpage>
<pub-id pub-id-type="doi">10.3389/fnins.2017.00441</pub-id><pub-id pub-id-type="pmid">28824364</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chicharro</surname><given-names>D.</given-names></name></person-group> (<year>2011</year>). <article-title>On the spectral formulation of Granger causality</article-title>. <source>Biol. Cybern.</source>
<volume>105</volume>, <fpage>331</fpage>–<lpage>347</lpage>. <pub-id pub-id-type="doi">10.1007/s00422-011-0469-z</pub-id><pub-id pub-id-type="pmid">22249416</pub-id></mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Çiftçi</surname><given-names>K.</given-names></name></person-group> (<year>2011</year>). <article-title>Minimum spanning tree reflects the alterations of the default mode network during Alzheimer's disease</article-title>. <source>Ann. Biomed. Eng.</source>
<volume>39</volume>, <fpage>1493</fpage>–<lpage>1504</lpage>. <pub-id pub-id-type="doi">10.1007/s10439-011-0258-9</pub-id><pub-id pub-id-type="pmid">21286814</pub-id></mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>D. L.</given-names></name><name><surname>Holmes</surname><given-names>C. J.</given-names></name><name><surname>Peters</surname><given-names>T. M.</given-names></name><name><surname>Evans</surname><given-names>A. C.</given-names></name></person-group> (<year>1995</year>). <article-title>Automatic 3-D model-based neuroanatomical segmentation</article-title>. <source>Hum. Brain Mapp.</source>
<volume>3</volume>, <fpage>190</fpage>–<lpage>208</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.460030304</pub-id></mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>da Silva</surname><given-names>F. L.</given-names></name><name><surname>Pijn</surname><given-names>J. P.</given-names></name><name><surname>Boeijinga</surname><given-names>P.</given-names></name></person-group> (<year>1989</year>). <article-title>Interdependence of EEG signals: linear vs. nonlinear associations and the significance of time delays and phase shifts</article-title>. <source>Brain Topogr.</source>
<volume>2</volume>, <fpage>9</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">2641479</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dennis</surname><given-names>E. L.</given-names></name><name><surname>Thompson</surname><given-names>P. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Functional brain connectivity using fMRI in aging and Alzheimer's disease</article-title>. <source>Neuropsychol. Rev.</source>
<volume>24</volume>, <fpage>49</fpage>–<lpage>62</lpage>. <pub-id pub-id-type="doi">10.1007/s11065-014-9249-6</pub-id><pub-id pub-id-type="pmid">24562737</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname><given-names>R. S.</given-names></name><name><surname>Ségonne</surname><given-names>F.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Quinn</surname><given-names>B. T.</given-names></name><name><surname>Dickerson</surname><given-names>B. C.</given-names></name><name><surname>Blacker</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>Neuroimage</source>
<volume>31</volume>, <fpage>968</fpage>–<lpage>980</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><pub-id pub-id-type="pmid">16530430</pub-id></mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dillen</surname><given-names>K. N.</given-names></name><name><surname>Jacobs</surname><given-names>H. I. L.</given-names></name><name><surname>Kukolja</surname><given-names>J.</given-names></name><name><surname>Richter</surname><given-names>N.</given-names></name><name><surname>von Reutern</surname><given-names>B.</given-names></name><name><surname>Onur</surname><given-names>O. A.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Functional disintegration of the default mode network in prodromal Alzheimer's disease</article-title>. <source>J. Alzheimer. Dis.</source>
<volume>59</volume>, <fpage>169</fpage>–<lpage>187</lpage>. <pub-id pub-id-type="doi">10.3233/JAD-161120</pub-id><pub-id pub-id-type="pmid">28598839</pub-id></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gits</surname><given-names>H. C.</given-names></name></person-group> (<year>2016</year>). <article-title>Relating connectivity and graph analysis to cognitive function in Alzheimer's disease</article-title>. <source>Michigan J. Med.</source>
<volume>1</volume>, <fpage>45</fpage>–<lpage>65</lpage>. <pub-id pub-id-type="doi">10.3998/mjm.13761231.0001.111</pub-id></mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Good</surname><given-names>I. J.</given-names></name></person-group> (<year>1956</year>). <article-title>The surprise index for the multivariate normal distribution</article-title>. <source>Ann. Math. Stat.</source>
<volume>27</volume>, <fpage>1130</fpage>–<lpage>1135</lpage>.</mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Good</surname><given-names>I. J.</given-names></name></person-group> (<year>1957a</year>). <article-title>The appropriate mathematical tools for describing and measuring uncertainty</article-title>, in <source>Good Thinking: The Foundations of Probability and Its Applications</source>, Chap. 16 (<publisher-loc>Minneapolis, MN</publisher-loc>: <publisher-name>University of Minnesota Press</publisher-name>), <fpage>173</fpage>–<lpage>177</lpage>. First publ. 1957.</mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Good</surname><given-names>I. J.</given-names></name></person-group> (<year>1957b</year>). <article-title>Corrections to “The surprise index for the multivariate normal distribution.”</article-title>
<source>Ann. Math. Stat</source>. <volume>28</volume>:<fpage>1055</fpage>.</mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Good</surname><given-names>I. J.</given-names></name></person-group> (<year>1983</year>). <source>Good Thinking: The Foundations of Probability and Its Applications</source>. <publisher-loc>Minneapolis, MN</publisher-loc>: <publisher-name>University of Minnesota Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grabner</surname><given-names>G.</given-names></name><name><surname>Janke</surname><given-names>A. L.</given-names></name><name><surname>Budge</surname><given-names>M. M.</given-names></name><name><surname>Smith</surname><given-names>D.</given-names></name><name><surname>Pruessner</surname><given-names>J.</given-names></name><name><surname>Collins</surname><given-names>D. L.</given-names></name></person-group> (<year>2006</year>). <article-title>Symmetric atlasing and model based segmentation: an application to the hippocampus in older adults</article-title>. <source>Med. Image Comput. Comput. Assist. Interv</source>
<volume>9</volume>, <fpage>58</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1007/11866763_8</pub-id><pub-id pub-id-type="pmid">17354756</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grassberger</surname><given-names>P.</given-names></name><name><surname>Schreiber</surname><given-names>T.</given-names></name><name><surname>Schaffrath</surname><given-names>C.</given-names></name></person-group> (<year>1991</year>). <article-title>Nonlinear time sequence analysis</article-title>. <source>Int. J. Bifurcation Chaos</source>
<volume>1</volume>, <fpage>521</fpage>–<lpage>547</lpage>. <pub-id pub-id-type="doi">10.1142/S0218127491000403</pub-id></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guimerá</surname><given-names>R.</given-names></name><name><surname>Nunes Amaral</surname><given-names>L. A.</given-names></name></person-group> (<year>2005</year>). <article-title>Functional cartography of complex metabolic networks</article-title>. <source>Nature</source>
<volume>433</volume>, <fpage>895</fpage>–<lpage>900</lpage>. <pub-id pub-id-type="doi">10.1038/nature03288</pub-id><pub-id pub-id-type="pmid">15729348</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayasaka</surname><given-names>S.</given-names></name></person-group> (<year>2013</year>). <article-title>Functional connectivity networks with and without global signal correction</article-title>. <source>Front. Hum. Neurosci.</source>
<volume>7</volume>:<fpage>880</fpage>. <pub-id pub-id-type="doi">10.3389/fnhum.2013.00880</pub-id><pub-id pub-id-type="pmid">24385961</pub-id></mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoenig</surname><given-names>M. C.</given-names></name><name><surname>Bischof</surname><given-names>G. N.</given-names></name><name><surname>Seemiller</surname><given-names>J.</given-names></name><name><surname>Hammes</surname><given-names>J.</given-names></name><name><surname>Kukolja</surname><given-names>J.</given-names></name><name><surname>Onur</surname><given-names>O. A.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Networks of tau distribution in Alzheimer's disease</article-title>. <source>Brain</source>
<volume>141</volume>, <fpage>568</fpage>–<lpage>581</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awx353</pub-id><pub-id pub-id-type="pmid">29315361</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Jaynes</surname><given-names>E. T.</given-names></name></person-group> (<year>2003</year>). <source>Probability Theory: The Logic of Science. Cambridge: Cambridge University Press</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://archive.org/details/XQUHIUXHIQUHIQXUIHX2">https://archive.org/details/XQUHIUXHIQUHIQXUIHX2</ext-link>, <ext-link ext-link-type="uri" xlink:href="http://www-biba.inrialpes.fr/Jaynes/prob.html">http://www-biba.inrialpes.fr/Jaynes/prob.html</ext-link></mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Bannister</surname><given-names>P.</given-names></name><name><surname>Brady</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>). <article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>. <source>Neuroimage</source>
<volume>17</volume>, <fpage>825</fpage>–<lpage>841</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2012</year>). <article-title>FSL</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>782</fpage>–<lpage>790</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><pub-id pub-id-type="pmid">21979382</pub-id></mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>S.</given-names></name></person-group> (<year>2001</year>). <article-title>A global optimisation method for robust affine registration of brain images</article-title>. <source>Med. Image Anal.</source>
<volume>5</volume>, <fpage>143</fpage>–<lpage>156</lpage>. <pub-id pub-id-type="doi">10.1016/S1361-8415(01)00036-6</pub-id><pub-id pub-id-type="pmid">11516708</pub-id></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>K. A.</given-names></name><name><surname>Fox</surname><given-names>N. C.</given-names></name><name><surname>Sperling</surname><given-names>R. A.</given-names></name><name><surname>Klunk</surname><given-names>W. E.</given-names></name></person-group> (<year>2012</year>). <article-title>Brain imaging in Alzheimer disease</article-title>. <source>Cold Spring Harb. Perspect. Med.</source>
<volume>2</volume>:<fpage>a006213</fpage>. <pub-id pub-id-type="doi">10.1101/cshperspect.a006213</pub-id><pub-id pub-id-type="pmid">22474610</pub-id></mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalna</surname><given-names>G.</given-names></name><name><surname>Higham</surname><given-names>D. J.</given-names></name></person-group> (<year>2007</year>). <article-title>A clustering coefficient for weighted networks, with application to gene expression data</article-title>. <source>AI Commun.</source>
<volume>20</volume>, <fpage>263</fpage>–<lpage>271</lpage>.</mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keihaninejad</surname><given-names>S.</given-names></name><name><surname>Heckemann</surname><given-names>R. A.</given-names></name><name><surname>Fagiolo</surname><given-names>G.</given-names></name><name><surname>Symms</surname><given-names>M. R.</given-names></name><name><surname>Hajnal</surname><given-names>J. V.</given-names></name><name><surname>Hammers</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>A robust method to estimate the intracranial volume across MRI field strengths (1.5T and 3T)</article-title>. <source>Neuroimage</source>
<volume>50</volume>, <fpage>1427</fpage>–<lpage>1437</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.064</pub-id><pub-id pub-id-type="pmid">20114082</pub-id></mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khazaee</surname><given-names>A.</given-names></name><name><surname>Ebrahimzadeh</surname><given-names>A.</given-names></name><name><surname>Babajani-Feremi</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>Identifying patients with Alzheimer's disease using resting-state fMRI and graph theory</article-title>. <source>Clin. Neurophysiol.</source>
<volume>126</volume>, <fpage>2132</fpage>–<lpage>2141</lpage>. <pub-id pub-id-type="doi">10.1016/j.clinph.2015.02.060</pub-id><pub-id pub-id-type="pmid">25907414</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khazaee</surname><given-names>A.</given-names></name><name><surname>Ebrahimzadeh</surname><given-names>A.</given-names></name><name><surname>Babajani-Feremi</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Classification of patients with MCI and AD from healthy controls using directed graph measures of resting-state fMRI</article-title>. <source>Behav. Brain Res.</source>
<volume>322</volume>, <fpage>339</fpage>–<lpage>350</lpage>. <pub-id pub-id-type="doi">10.1016/j.bbr.2016.06.043</pub-id><pub-id pub-id-type="pmid">27345822</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>H.</given-names></name><name><surname>Yoo</surname><given-names>K.</given-names></name><name><surname>Na</surname><given-names>D. L.</given-names></name><name><surname>Seo</surname><given-names>S. W.</given-names></name><name><surname>Jeong</surname><given-names>J.</given-names></name><name><surname>Jeong</surname><given-names>Y.</given-names></name></person-group> (<year>2015</year>). <article-title>Non-monotonic reorganization of brain networks with Alzheimer's disease progression</article-title>. <source>Front. Aging Neurosci.</source>
<volume>7</volume>:<fpage>111</fpage>. <pub-id pub-id-type="doi">10.3389/fnagi.2015.00111</pub-id><pub-id pub-id-type="pmid">26106325</pub-id></mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kotz</surname><given-names>S.</given-names></name><name><surname>Nadarajah</surname><given-names>S.</given-names></name></person-group> (<year>2004</year>). <source>Multivariate <italic>t</italic> Distributions and Their Applications</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruschwitz</surname><given-names>J. D.</given-names></name><name><surname>List</surname><given-names>D.</given-names></name><name><surname>Waller</surname><given-names>L.</given-names></name><name><surname>Rubinov</surname><given-names>M.</given-names></name><name><surname>Walter</surname><given-names>H.</given-names></name></person-group> (<year>2015</year>). <article-title>GraphVar: a user-friendly toolbox for comprehensive graph analyses of functional brain connectivity</article-title>. <source>J. Neurosci. Methods</source>
<volume>245</volume>, <fpage>107</fpage>–<lpage>115</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.02.021</pub-id><pub-id pub-id-type="pmid">25725332</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leung</surname><given-names>K. K.</given-names></name><name><surname>Barnes</surname><given-names>J.</given-names></name><name><surname>Modat</surname><given-names>M.</given-names></name><name><surname>Ridgway</surname><given-names>G. R.</given-names></name><name><surname>Bartlett</surname><given-names>J. W.</given-names></name><name><surname>Fox</surname><given-names>N. C.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Brain MAPS: an automated, accurate and robust brain extraction technique using a template library</article-title>. <source>Neuroimage</source>
<volume>55</volume>, <fpage>1091</fpage>–<lpage>1108</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.12.067</pub-id><pub-id pub-id-type="pmid">21195780</pub-id></mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Gerraty</surname><given-names>R. T.</given-names></name><name><surname>Grinband</surname><given-names>J.</given-names></name><name><surname>Parker</surname><given-names>D.</given-names></name><name><surname>Razlighi</surname><given-names>Q. R.</given-names></name></person-group> (<year>2017</year>). <article-title>Brain atrophy can introduce age-related differences in BOLD response</article-title>. <source>Hum. Brain Mapp.</source>
<volume>38</volume>, <fpage>3402</fpage>–<lpage>3414</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23597</pub-id></mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Y.</given-names></name><name><surname>Jiang</surname><given-names>T.</given-names></name><name><surname>Zang</surname><given-names>Y.</given-names></name></person-group> (<year>2003</year>). <article-title>Region growing method for the analysis of functional MRI data</article-title>. <source>Neuroimage</source>
<volume>20</volume>, <fpage>455</fpage>–<lpage>465</lpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(03)00352-5</pub-id><pub-id pub-id-type="pmid">14527606</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marrelec</surname><given-names>G.</given-names></name><name><surname>Fransson</surname><given-names>P.</given-names></name></person-group> (<year>2011</year>). <article-title>Assessing the influence of different ROI selection strategies on functional connectivity analyses of fMRI data acquired during steady-state conditions</article-title>. <source>PLOS ONE</source>
<volume>6</volume>:<fpage>e14788</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0014788</pub-id><pub-id pub-id-type="pmid">21533283</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCarthy</surname><given-names>J.</given-names></name></person-group> (<year>1956</year>). <article-title>Measures of the value of information</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>42</volume>, <fpage>654</fpage>–<lpage>655</lpage>. <pub-id pub-id-type="pmid">16589926</pub-id></mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Minka</surname><given-names>T.</given-names></name></person-group> (<year>2001</year>). <source>Inferring a Gaussian Distribution</source>. Tech. rep., MIT Media Lab, <publisher-loc>Cambridge, MA</publisher-loc> Available online at: <ext-link ext-link-type="uri" xlink:href="http://research.microsoft.com/en-us/um/people/minka/papers/Firstpubl.1998">http://research.microsoft.com/en-us/um/people/minka/papers/Firstpubl.1998</ext-link></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K.</given-names></name><name><surname>Fox</surname><given-names>M. D.</given-names></name></person-group> (<year>2017</year>). <article-title>Towards a consensus regarding global signal regression for resting state functional connectivity MRI</article-title>. <source>Neuroimage</source>
<volume>154</volume>, <fpage>169</fpage>–<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.11.052</pub-id><pub-id pub-id-type="pmid">27888059</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K. P.</given-names></name></person-group> (<year>2007</year>). <source>Conjugate Bayesian Analysis of the Gaussian Distribution</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://thaines.com/content/misc/gaussian_conjugate_prior_cheat_sheet.pdf">http://thaines.com/content/misc/gaussian_conjugate_prior_cheat_sheet.pdf</ext-link></mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>P. T.</given-names></name><name><surname>Alafuzoff</surname><given-names>I.</given-names></name><name><surname>Bigio</surname><given-names>E. H.</given-names></name><name><surname>Bouras</surname><given-names>C.</given-names></name><name><surname>Braak</surname><given-names>H.</given-names></name><name><surname>Cairns</surname><given-names>N. J.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Correlation of Alzheimer disease neuropathologic changes with cognitive status: a review of the literature</article-title>. <source>J. Neuropathol. Exp. Neurol.</source>
<volume>71</volume>, <fpage>362</fpage>–<lpage>381</lpage>. <pub-id pub-id-type="doi">10.1097/NEN.0b013e31825018f7</pub-id><pub-id pub-id-type="pmid">22487856</pub-id></mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>M. E. J.</given-names></name></person-group> (<year>2004</year>). <article-title>Analysis of weighted networks</article-title>. <source>Phys. Rev. E</source>
<volume>70</volume>:<fpage>056131</fpage>
<pub-id pub-id-type="doi">10.1103/PhysRevE.70.056131</pub-id></mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pagani</surname><given-names>M.</given-names></name><name><surname>Giuliani</surname><given-names>A.</given-names></name><name><surname>Öberg</surname><given-names>J.</given-names></name><name><surname>Chincarini</surname><given-names>A.</given-names></name><name><surname>Morbelli</surname><given-names>S.</given-names></name><name><surname>Brugnolo</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Predicting the transition from normal aging to Alzheimer's disease: a statistical mechanistic evaluation of FDG-PET data</article-title>. <source>Neuroimage</source>
<volume>141</volume>, <fpage>282</fpage>–<lpage>290</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.07.043</pub-id><pub-id pub-id-type="pmid">27453158</pub-id></mixed-citation>
      </ref>
      <ref id="B49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pagani</surname><given-names>M.</given-names></name><name><surname>Giuliani</surname><given-names>A.</given-names></name><name><surname>Öberg</surname><given-names>J.</given-names></name><name><surname>De Carli</surname><given-names>F.</given-names></name><name><surname>Morbelli</surname><given-names>S.</given-names></name><name><surname>Girtler</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Progressive disintegration of brain networking from normal aging to Alzheimer disease: analysis of independent components of 18F-FDG PET data</article-title>. <source>J. Nucl. Med.</source>
<volume>58</volume>, <fpage>1132</fpage>–<lpage>1139</lpage>. <pub-id pub-id-type="doi">10.2967/jnumed.116.184309</pub-id><pub-id pub-id-type="pmid">28280223</pub-id></mixed-citation>
      </ref>
      <ref id="B50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Scikit-learn: machine learning in Python</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
      </ref>
      <ref id="B51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereda</surname><given-names>E.</given-names></name><name><surname>Quiroga</surname><given-names>R. Q.</given-names></name><name><surname>Bhattacharya</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>). <article-title>Nonlinear multivariate analysis of neurophysiological signals</article-title>. <source>Prog. Neurobiol.</source>
<volume>77</volume>, <fpage>1</fpage>–<lpage>37</lpage>. <pub-id pub-id-type="doi">10.1016/j.pneurobio.2005.10.003</pub-id><pub-id pub-id-type="pmid">16289760</pub-id></mixed-citation>
      </ref>
      <ref id="B52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popescu</surname><given-names>V.</given-names></name><name><surname>Battaglini</surname><given-names>M.</given-names></name><name><surname>Hoogstrate</surname><given-names>W. S.</given-names></name><name><surname>Verfaillie</surname><given-names>S. C. J.</given-names></name><name><surname>Sluimer</surname><given-names>I. C.</given-names></name><name><surname>van Schijndel</surname><given-names>R. A.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Optimizing parameter choice for FSL-Brain Extraction Tool (BET) on 3D T1 images in multiple sclerosis</article-title>. <source>Neuroimage</source>
<volume>61</volume>, <fpage>1484</fpage>–<lpage>1494</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.074</pub-id><pub-id pub-id-type="pmid">22484407</pub-id></mixed-citation>
      </ref>
      <ref id="B53">
        <mixed-citation publication-type="thesis"><person-group person-group-type="author"><name><surname>Porta Mana</surname><given-names>P. G. L.</given-names></name><name><surname>Bachmann</surname><given-names>C.</given-names></name><name><surname>Morrison</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>Inferring health conditions from fMRI-graph data</article-title>. <source>Open Science Framework. arXiv:1803.02626</source> [preprint]. <pub-id pub-id-type="doi">10.31219/osf.io/r2huz</pub-id></mixed-citation>
      </ref>
      <ref id="B54">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rivest</surname><given-names>R. L.</given-names></name><name><surname>Leiserson</surname><given-names>C. E.</given-names></name><name><surname>Cormen</surname><given-names>T. H.</given-names></name></person-group> (<year>2000</year>). <source>Introduction to Algorithms (MIT Electrical Engineering and Computer Science Series.)</source>
<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B55">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodgers</surname><given-names>J. L.</given-names></name><name><surname>Nicewander</surname><given-names>W. A.</given-names></name></person-group> (<year>1988</year>). <article-title>Thirteen ways to look at the correlation coefficient</article-title>. <source>Am. Stat.</source>
<volume>42</volume>, <fpage>59</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1080/00031305.1988.10475524</pub-id></mixed-citation>
      </ref>
      <ref id="B56">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanz-Arigita</surname><given-names>E. J.</given-names></name><name><surname>Schoonheim</surname><given-names>M. M.</given-names></name><name><surname>Damoiseaux</surname><given-names>J. S.</given-names></name><name><surname>Rombouts</surname><given-names>S. A.</given-names></name><name><surname>Maris</surname><given-names>E.</given-names></name><name><surname>Barkhof</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Loss of “small-world” networks in Alzheimer's disease: graph analysis of fMRI resting-state functional connectivity</article-title>. <source>PLOS ONE</source>
<volume>5</volume>:<fpage>e13788</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0013788</pub-id><pub-id pub-id-type="pmid">21072180</pub-id></mixed-citation>
      </ref>
      <ref id="B57">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>S. E.</given-names></name></person-group> (<year>2007</year>). <article-title>Graph clustering</article-title>. <source>Comput. Sci. Rev.</source>
<volume>1</volume>, <fpage>27</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1016/j.cosrev.2007.05.001</pub-id></mixed-citation>
      </ref>
      <ref id="B58">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreiber</surname><given-names>T.</given-names></name></person-group> (<year>2000</year>). <article-title>Measuring information transfer</article-title>. <source>Phys. Rev. Lett.</source>
<volume>85</volume>, <fpage>461</fpage>–<lpage>464</lpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.85.461</pub-id><pub-id pub-id-type="pmid">10991308</pub-id></mixed-citation>
      </ref>
      <ref id="B59">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeter</surname><given-names>M. L.</given-names></name><name><surname>Stein</surname><given-names>T.</given-names></name><name><surname>Maslowski</surname><given-names>N.</given-names></name><name><surname>Neumann</surname><given-names>J.</given-names></name></person-group> (<year>2009</year>). <article-title>Neural correlates of Alzheimer's disease and mild cognitive impairment: a systematic and quantitative meta-analysis involving 1,351 patients</article-title>. <source>Neuroimage</source>
<volume>47</volume>, <fpage>1196</fpage>–<lpage>1206</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.05.037</pub-id><pub-id pub-id-type="pmid">19463961</pub-id></mixed-citation>
      </ref>
      <ref id="B60">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>A. J.</given-names></name><name><surname>McGonigle</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Negative edges and soft thresholding in complex network analysis of resting state functional connectivity data</article-title>. <source>Neuroimage</source>
<volume>55</volume>, <fpage>1032</fpage>–<lpage>1146</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.12.047</pub-id><pub-id pub-id-type="pmid">21194570</pub-id></mixed-citation>
      </ref>
      <ref id="B61">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>C. E.</given-names></name></person-group> (<year>1948</year>). <article-title>A mathematical theory of communication</article-title>. <source>Bell Syst. Tech. J.</source>
<volume>27</volume>, <fpage>379</fpage>–<lpage>423</lpage>, <fpage>623</fpage>–<lpage>656</lpage>.</mixed-citation>
      </ref>
      <ref id="B62">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2002</year>). <article-title>Fast robust automated brain extraction</article-title>. <source>Hum. Brain Mapp.</source>
<volume>17</volume>, <fpage>143</fpage>–<lpage>155</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.10062</pub-id><pub-id pub-id-type="pmid">12391568</pub-id></mixed-citation>
      </ref>
      <ref id="B63">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sox</surname><given-names>H. C.</given-names></name><name><surname>Higgins</surname><given-names>M. C.</given-names></name><name><surname>Owens</surname><given-names>D. K.</given-names></name></person-group> (<year>2013</year>). <source>Medical Decision Making</source>, <edition>2nd Edn</edition>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B64">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sperling</surname><given-names>R. A.</given-names></name><name><surname>Aisen</surname><given-names>P. S.</given-names></name><name><surname>Beckett</surname><given-names>L. A.</given-names></name><name><surname>Bennett</surname><given-names>D. A.</given-names></name><name><surname>Craft</surname><given-names>S.</given-names></name><name><surname>Fagan</surname><given-names>A. M.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Toward defining the preclinical stages of Alzheimer's disease: recommendations from the National Institute on Aging-Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease</article-title>. <source>Alzheimer. Dement.</source>
<volume>7</volume>, <fpage>280</fpage>–<lpage>292</lpage>. <pub-id pub-id-type="doi">10.1016/j.jalz.2011.03.003</pub-id><pub-id pub-id-type="pmid">21514248</pub-id></mixed-citation>
      </ref>
      <ref id="B65">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Supekar</surname><given-names>K.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name><name><surname>Rubin</surname><given-names>D.</given-names></name><name><surname>Musen</surname><given-names>M.</given-names></name><name><surname>Greicius</surname><given-names>M. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Network analysis of intrinsic functional brain connectivity in Alzheimer's disease</article-title>. <source>PLOS Comput. Biol.</source>
<volume>4</volume>:<fpage>e1000100</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000100</pub-id><pub-id pub-id-type="pmid">18584043</pub-id></mixed-citation>
      </ref>
      <ref id="B66">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Telesford</surname><given-names>Q. K.</given-names></name><name><surname>Morgan</surname><given-names>A. R.</given-names></name><name><surname>Hayasaka</surname><given-names>S.</given-names></name><name><surname>Simpson</surname><given-names>S. L.</given-names></name><name><surname>Barret</surname><given-names>W.</given-names></name><name><surname>Kraft</surname><given-names>R. A.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Reproducibility of graph metrics in fMRI networks</article-title>. <source>Front. Neuroinformat.</source>
<volume>4</volume>:<fpage>117</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2010.00117</pub-id><pub-id pub-id-type="pmid">21165174</pub-id></mixed-citation>
      </ref>
      <ref id="B67">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Dohmatob</surname><given-names>E.</given-names></name><name><surname>Poline</surname><given-names>J.-B.</given-names></name></person-group> (<year>2014</year>). <article-title>Which fMRI clustering gives good brain parcellations?</article-title>
<source>Front. Neurosci.</source>
<volume>8</volume>:<fpage>167</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2014.00167</pub-id><pub-id pub-id-type="pmid">25071425</pub-id></mixed-citation>
      </ref>
      <ref id="B68">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name><name><surname>Landeau</surname><given-names>B.</given-names></name><name><surname>Papathanassiou</surname><given-names>D.</given-names></name><name><surname>Crivello</surname><given-names>F.</given-names></name><name><surname>Etard</surname><given-names>O.</given-names></name><name><surname>Delcroix</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2002</year>). <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>Neuroimage</source>
<volume>15</volume>, <fpage>273</fpage>–<lpage>289</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id><pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation>
      </ref>
      <ref id="B69">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H. E.</given-names></name><name><surname>Bénar</surname><given-names>C. G.</given-names></name><name><surname>Quilichini</surname><given-names>P. P.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Jirsa</surname><given-names>V. K.</given-names></name><name><surname>Bernard</surname><given-names>C.</given-names></name></person-group> (<year>2014</year>). <article-title>A systematic framework for functional connectivity measures</article-title>. <source>Front. Neurosci.</source>
<volume>8</volume>:<fpage>405</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2014.00405</pub-id><pub-id pub-id-type="pmid">25538556</pub-id></mixed-citation>
      </ref>
      <ref id="B70">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Han</surname><given-names>Y.</given-names></name><name><surname>Song</surname><given-names>H.</given-names></name><name><surname>Guo</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name></person-group> (<year>2016</year>). <article-title>Differentially disrupted functional connectivity of the subregions of the amygdala in Alzheimer's disease</article-title>. <source>J. X-Ray Sci. Technol.</source>
<volume>24</volume>, <fpage>329</fpage>–<lpage>342</lpage>. <pub-id pub-id-type="doi">10.3233/XST-160556</pub-id><pub-id pub-id-type="pmid">27002909</pub-id></mixed-citation>
      </ref>
      <ref id="B71">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>M. W.</given-names></name><name><surname>Jbabdi</surname><given-names>S.</given-names></name><name><surname>Patenaude</surname><given-names>B.</given-names></name><name><surname>Chappell</surname><given-names>M.</given-names></name><name><surname>Makni</surname><given-names>S.</given-names></name><name><surname>Behrens</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>Bayesian analysis of neuroimaging data in FSL</article-title>. <source>Neuroimage</source>
<volume>45</volume>, <fpage>S173</fpage>–<lpage>S186</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.10.055</pub-id><pub-id pub-id-type="pmid">19059349</pub-id></mixed-citation>
      </ref>
      <ref id="B72">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>M.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Dai</surname><given-names>Z.</given-names></name><name><surname>Liang</surname><given-names>X.</given-names></name><name><surname>Song</surname><given-names>H.</given-names></name><name><surname>Shu</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Differentially disrupted functional connectivity in posteromedial cortical subregions in Alzheimer's disease</article-title>. <source>J. Alzheimers Dis.</source>
<volume>39</volume>, <fpage>527</fpage>–<lpage>543</lpage>. <pub-id pub-id-type="doi">10.3233/JAD-131583</pub-id><pub-id pub-id-type="pmid">24217277</pub-id></mixed-citation>
      </ref>
      <ref id="B73">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>B.</given-names></name><name><surname>Horvath</surname><given-names>S.</given-names></name></person-group> (<year>2005</year>). <article-title>A general framework for weighted gene co-expression network analysis</article-title>. <source>Stat. Appl. Genet. Mol. Biol.</source> 4:Article17. <pub-id pub-id-type="doi">10.2202/1544-6115.1128</pub-id><pub-id pub-id-type="pmid">16646834</pub-id></mixed-citation>
      </ref>
      <ref id="B74">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Brady</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>S.</given-names></name></person-group> (<year>2001</year>). <article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>20</volume>, <fpage>45</fpage>–<lpage>57</lpage>. <pub-id pub-id-type="doi">10.1109/42.906424</pub-id><pub-id pub-id-type="pmid">11293691</pub-id></mixed-citation>
      </ref>
      <ref id="B75">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>X.</given-names></name><name><surname>Lui</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>B.</given-names></name><name><surname>Xi</surname><given-names>Q.</given-names></name><name><surname>Guo</surname><given-names>Q.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Disrupted small-world brain networks in moderate Alzheimer's disease: a resting-state fMRI study</article-title>. <source>PLOS ONE</source>
<volume>7</volume>:<fpage>e33540</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0033540</pub-id><pub-id pub-id-type="pmid">22457774</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
