<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" article-type="research-article">
  <?properties open_access?>
  <?properties manuscript?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-journal-id">9215515</journal-id>
      <journal-id journal-id-type="pubmed-jr-id">20498</journal-id>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>NeuroImage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">33878383</article-id>
      <article-id pub-id-type="pmc">8456451</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2021.118069</article-id>
      <article-id pub-id-type="manuscript">NIHMS1722730</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Brain network mechanisms of visual shape completion</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Keane</surname>
            <given-names>Brian P.</given-names>
          </name>
          <xref ref-type="aff" rid="A1">a</xref>
          <xref ref-type="aff" rid="A2">b</xref>
          <xref rid="CR1" ref-type="corresp">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Barch</surname>
            <given-names>Deanna M.</given-names>
          </name>
          <xref ref-type="aff" rid="A3">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Mill</surname>
            <given-names>Ravi D.</given-names>
          </name>
          <xref ref-type="aff" rid="A4">d</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Silverstein</surname>
            <given-names>Steven M.</given-names>
          </name>
          <xref ref-type="aff" rid="A1">a</xref>
          <xref ref-type="aff" rid="A2">b</xref>
          <xref ref-type="aff" rid="A5">e</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Krekelberg</surname>
            <given-names>Bart</given-names>
          </name>
          <xref ref-type="aff" rid="A4">d</xref>
          <xref rid="FN1" ref-type="author-notes">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Cole</surname>
            <given-names>Michael W.</given-names>
          </name>
          <xref ref-type="aff" rid="A4">d</xref>
          <xref rid="FN1" ref-type="author-notes">1</xref>
        </contrib>
      </contrib-group>
      <aff id="A1"><label>a</label>University Behavioral Health Care, Department of Psychiatry, and Center for Cognitive Science, Rutgers, The State University of New Jersey, Piscataway, NJ 08854, USA</aff>
      <aff id="A2"><label>b</label>Departments of Psychiatry and Neuroscience, University of Rochester Medical Center, 601 Elmwood Ave, Rochester, NY 14642, USA</aff>
      <aff id="A3"><label>c</label>Departments of Psychological &amp; Brain Sciences, Psychiatry, and Radiology, Washington University in St. Louis, One Brookings Drive, St. Louis, MO 63130, USA</aff>
      <aff id="A4"><label>d</label>Center for Molecular and Behavioral Neuroscience, Rutgers, The State University of New Jersey, 197 University Ave 07102, USA</aff>
      <aff id="A5"><label>e</label>Department of Ophthalmology, University of Rochester Medical Center, 601 Elmwood Ave, Rochester, NY, USA</aff>
      <author-notes>
        <fn fn-type="other" id="FN1">
          <label>1</label>
          <p id="P1">Co-senior authors.</p>
        </fn>
        <fn fn-type="con" id="FN2">
          <p id="P2">Credit author statement</p>
          <p id="P3"><italic>Author contributions:</italic> Conceptualization – BPK, DMB, MWC; Data acquisition – BPK; Formal analysis–BPK, RDM, MWC, DMB; Funding acquisition–BPK; Resources–MWC, BK, SMS; Software–RDM, MWC, BPK; Supervision–MWC; Visualization–BPK, RDM, MWC; First draft – BPK; Review &amp; editing–BPK, RDM, MWC, DMB, BK, SMS.</p>
        </fn>
        <corresp id="CR1"><label>*</label>Corresponding author. <email>brian_keane@urmc.rochester.edu</email> (B.P. Keane).</corresp>
      </author-notes>
      <pub-date pub-type="nihms-submitted">
        <day>20</day>
        <month>8</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>18</day>
        <month>4</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>8</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>22</day>
        <month>9</month>
        <year>2021</year>
      </pub-date>
      <volume>236</volume>
      <fpage>118069</fpage>
      <lpage>118069</lpage>
      <!--elocation-id from pubmed: 10.1016/j.neuroimage.2021.118069-->
      <permissions>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
          <license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>)</license-p>
        </license>
      </permissions>
      <abstract id="ABS1">
        <p id="P4">Visual shape completion recovers object shape, size, and number from spatially segregated edges. Despite being extensively investigated, the process’s underlying brain regions, networks, and functional connections are still not well understood. To shed light on the topic, we scanned (fMRI) healthy adults during rest and during a task in which they discriminated pac-man configurations that formed or failed to form completed shapes (illusory and fragmented condition, respectively). Task activation differences (illusory-fragmented), resting-state functional connectivity, and multivariate patterns were identified on the cortical surface using 360 predefined parcels and 12 functional networks composed of such parcels. Brain activity flow mapping (ActFlow) was used to evaluate the likely involvement of resting-state connections for shape completion. We identified 36 differentially-active parcels including a posterior temporal region, PH, whose activity was consistent across 95% of observers. Significant task regions primarily occupied the secondary visual network but also incorporated the frontoparietal dorsal attention, default mode, and cingulo-opercular networks. Each parcel’s task activation difference could be modeled via its resting-state connections with the remaining parcels (<italic>r</italic>=.62, <italic>p</italic>&lt;10<sup>−9</sup>), suggesting that such connections undergird shape completion. Functional connections from the dorsal attention network were key in modelling task activation differences in the secondary visual network. Dorsal attention and frontoparietal connections could also model activations in the remaining networks. Taken together, these results suggest that shape completion relies upon a sparsely distributed but densely interconnected network coalition that is centered in the secondary visual network, coordinated by the dorsal attention network, and inclusive of at least three other networks.</p>
      </abstract>
      <kwd-group>
        <kwd>Secondary visual network</kwd>
        <kwd>Dorsal attention network</kwd>
        <kwd>Frontoparietal network</kwd>
        <kwd>Resting-state functional connectivity</kwd>
        <kwd>Area PH</kwd>
        <kwd>Kanizsa shapes</kwd>
        <kwd>Subjective contours</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <label>1.</label>
      <title>Introduction</title>
      <p id="P5">Visual shape completion plays a fundamental role in normal seeing, extracting object shape, size, position, and numerosity from the relative alignments and orientations of spatially segregated edges. Converging evidence from human and non-human primates suggests that the process relies upon V4, LO, V2, and V1, with feedback cascading from the former to the latter two regions. For example, transcranial magnetic stimulation applied earlier to LO (100–122 ms) or later over V1/V2 (160–182 ms) worsened discrimination of completed shapes (<xref rid="R78" ref-type="bibr">Wokke et al., 2013</xref>). Multielectrode array recordings of V4 revealed differential activity for completed shapes within ~150 ms, which could plausibly precede low-level visual activations (<xref rid="R11" ref-type="bibr">Cox et al., 2013</xref>). In single-cell recordings, deep layer V2 cells responded ~100 ms post-stimulus onset and deep layer V1 cells responded ~120–190 ms (<xref rid="R38" ref-type="bibr">Lee and Nguyen, 2001</xref>). In addition to feed-back, long-range horizontal excitatory connections between V1 pyramidal cells also bolster edge integration (<xref rid="R26" ref-type="bibr">Iacaruso et al., 2017</xref>). These four regions —V1, V2, V4, and LO —have been termed the “classical” regions of shape completion (<xref rid="R29" ref-type="bibr">Keane, 2018</xref>) given their inter-connectedness and well-established role in the process. <sup><xref ref-type="fn" rid="FN7">1</xref></sup></p>
      <p id="P6">What other regions participate in shape completion? At present there is no consensus (M. M. <xref rid="R49" ref-type="bibr">Murray and Herrmann, 2013</xref>; <xref rid="R64" ref-type="bibr">Seghier and Vuilleumier, 2006</xref>). Fusiform gyrus, V3A, and V3B/KO have been implicated (<xref rid="R42" ref-type="bibr">Mendola et al., 1999</xref>; M. <xref rid="R47" ref-type="bibr">Murray et al., 2002</xref>), although the last region has been found mainly, but not exclusively, with dynamic illusory contour stimuli (<xref rid="R36" ref-type="bibr">Kruggel et al., 2001</xref>). In a magnetoencephalography (MEG) study, adults passively viewing briefly-presented pac-man stimuli (30 ms) exhibited more orbitofrontal (OFC) activation relative to a control stimulus 340 ms post stimulus onset (<xref rid="R23" ref-type="bibr">Halgren et al., 2003</xref>). The OFC effect has not been replicated perhaps because older fMRI studies had coarser spatial resolution, more partial voluming, and thus more signal drop-out near the sinuses (due to magnetic field inhomogeneities). Other studies reported activation in the frontal or posterior parietal cortices for illusory “Kanizsa” shapes, but in certain instances there was no control condition or the effects did not eclipse those found for a control condition (<xref rid="R14" ref-type="bibr">Doniger et al., 2002</xref>; <xref rid="R16" ref-type="bibr">Foxe et al., 2005</xref>; M. M. <xref rid="R48" ref-type="bibr">Murray et al., 2004</xref>). A more recent review of illusory contour perception did not report any role for frontal/prefrontal or frontoparietal cortex (M. M. <xref rid="R49" ref-type="bibr">Murray and Herrmann, 2013</xref>). Finally, many of the studies that searched for shape completion effects across cortex invoked MEG, EEG, or lower-resolution MRI, and thus had limited ability to locate activations with spatial precision.</p>
      <p id="P7">Another unanswered question pertains to the functional connections and large-scale networks of shape completion. A search of relevant key terms on PubMed retrieved 892 items on shape completion but the list dwindled to zero when either “functional connectivity” or “functional network” was conjoined to the search. <sup>2</sup> Couching a process in terms of its encompassing network is useful. It allows for a better interpretation of co-modulated regions that fall within that same network. It allows functional interactions to be understood in a larger context and motivates further tests on how the networks interact. Finally, because net-works are much larger functional units and much more readily aligned between subjects, network-based results are easier to generalize across subjects (<xref rid="R28" ref-type="bibr">Ji et al., 2019</xref>).</p>
      <p id="P8">There are good reasons to document the neural basis of shape completion. The process is phylogenetically primitive and ontogenetically early, underscoring its importance for normal seeing (<xref rid="R51" ref-type="bibr">Nieder, 2002</xref>; <xref rid="R72" ref-type="bibr">Valenza and Bulf, 2010</xref>). Moreover, shape completion deficits arise during brain injury (<xref rid="R75" ref-type="bibr">Vuilleumier et al., 2001</xref>), developmental agnosia (<xref rid="R17" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>), sight restoration (<xref rid="R53" ref-type="bibr">Ostrovsky et al., 2009</xref>), and neuropsychiatric illness (<xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>). Knowing the neural basis of shape completion constitutes a first step for developing novel pharmacologic or stimulation-based interventions.</p>
      <p id="P9">We investigated the brain network mechanisms of shape completion with four task scans and one resting-state scan. Our ability to detect effects was augmented by having used a higher spatial resolution (voxel = 2.4 mm iso) to reduce signal drop-out near the ventral surface, a cortex-wide surface-based analysis to improve anatomical accuracy (<xref rid="R19" ref-type="bibr">Glasser et al., 2013</xref>), and a parcellation scheme to non-arbitrarily segregate cortex into a manageable number of functional units. In the task scans, participants discriminated pac-man configurations that formed or failed to form visually completed shapes (illusory and fragmented condition, respectively) (<xref rid="R61" ref-type="bibr">Ringach and Shapley, 1996</xref>). Shape completion was operationalized as the difference in performance or activation between the two conditions. This so-called “fat/thin” task was chosen because it has been extensively investigated via psychophysics, fMRI, EEG, and TMS and because it relies upon the classical brain regions just mentioned (<xref rid="R20" ref-type="bibr">Gold et al., 2000</xref>; <xref rid="R31" ref-type="bibr">Keane et al., 2007</xref>; <xref rid="R39" ref-type="bibr">Maertens et al., 2008</xref>; M. M. <xref rid="R50" ref-type="bibr">Murray et al., 2006</xref>; <xref rid="R56" ref-type="bibr">Pillow and Rubin, 2002</xref>; <xref rid="R78" ref-type="bibr">Wokke et al., 2013</xref>). The resting-state scan data allowed us to compute the resting-state functional connectivity (RSFC) matrix between all pairs of regions, which in turn allowed us to assess the likely utility of the functional connections for shape completion via a recent brain activity mapping procedure dubbed “ActFlow” (<xref rid="R10" ref-type="bibr">Cole et al., 2016</xref>). The ActFlow method estimates the actual task activation difference (illusory-fragmented) for a given target region by taking the sum of all other task activation differences (in all other regions) weighted by their functional connectivity strength to that target. If the correlation between actual and estimated activation differences is greater than zero across regions for a subject and if this correlation is significantly above zero across subjects (evaluated via a t-test), then the resting-state connections are likely involved in shape completion. The ActFlow approach is justified since task and rest generate highly similar brain-wide functional connectivity (<xref rid="R9" ref-type="bibr">Cole et al., 2014</xref>) and since integrating RSFC into ActFlow has yielded accurate inferences of task- evoked activations in previous studies (<xref rid="R10" ref-type="bibr">Cole et al., 2016</xref>).</p>
      <p id="P10">The results are described in six sections. First, we performed a task activation analysis comparing the task conditions, with careful consideration given to between-task difficulty differences. Second, null V1/V2 effects in the univariate analysis motivated us to perform a post-hoc multivariate pattern analysis (MVPA) to probe for finer-grained task effects. Third, we divided the parcels into 12 different functional networks (<xref rid="R28" ref-type="bibr">Ji et al., 2019</xref>) and quantified each network’s contribution to shape completion by applying MVPA to parcel-wise task-activations. Fourth, we determined the inter-connectedness of task regions by computing the resting-state functional connectomes (RSFC matrices). Fifth, we demonstrated the likely utility of these functional connections for shape completion via ActFlow; that is, we showed that the task activation difference in each parcel could be inferred from the resting-state connections to that parcel along with the task activation differences of the remaining parcels. Finally, again using ActFlow, we determined which network contained the most informative resting-state connections for inferring differential task activity in the secondary visual network (whose relevance was established in Step 3) and in all remaining networks. This last step was done by adding each network individually to determine how ActFlow inferences changed (improved). We conclude by suggesting the existence of a shape completion network coalition, which is seated in the secondary visual network, is coordinated by the dorsal attention net-work, incorporates pieces of three other networks, and interacts with early visual areas at a vertex-wise spatial resolution.</p>
    </sec>
    <sec id="S2">
      <label>2.</label>
      <title>Materials and methods</title>
      <sec id="S3">
        <label>2.1.</label>
        <title>Participants</title>
        <p id="P11">The sample consisted of healthy controls who participated in a larger clinical study on the neural basis of abnormal visual perceptual organization in schizophrenia and bipolar disorder. These results are thus considered a first step in identifying how the brain represents visually completed shapes in health and disease. (Patient data collection is still ongoing and will be reported once sufficient sample sizes are achieved.) The sample comprised 20 psychophysically naïve participants (2 left handed, 8 females) from the Newark, NJ (USA) area with an average age of 37.6 and a racial composition of 35% African American, 10% Asian, 35% Caucasian, 15% mixed, and 5% unknown. A quarter of the participants were of Hispanic ethnicity. To obtain a more representative sample, we preferentially recruited controls without four-year college degrees, so that the average number of years of education was 14.8.</p>
        <p id="P12">The inclusion/exclusion criteria were: (1) age 21–55; (2) no electro-convulsive therapy in the past 8 weeks; (3) no neurological or pervasive developmental disorders; (4) no drug dependence in the last three months (i.e., participants must not have satisfied more than one of the 11 Criterion A symptoms of DSM-5 substance use disorder in the last three months); (5) no positive urine toxicology screen or breathalyzer test on the day of testing; (6) no brain injury due to accident or illness (e.g., stroke or brain tumor); (7) no amblyopia (as assessed by informal observation and self-report); (8) visual acuity of 20/32 or better (with corrective lenses if necessary); (9) the ability to understand English and provide written informed consent; (10) no scanner related contraindications (no claustrophobia, an ability to fit within the scanner bed, and no non-removable ferromagnetic material on or within the body); (11) no DSM-5 diagnosis of past or current psychotic or mood disorders; (12) no current psychotropic- or cognition-enhancing medication; (13) no first-degree relative with schizophrenia, schizoaffective, or bipolar disorder (as indicated by self-report).</p>
      </sec>
      <sec id="S4">
        <label>2.2.</label>
        <title>Assessments</title>
        <p id="P13">Psychiatric diagnosis exclusion was assessed with the Structured Clinical Interview for DSM-5 (SCID) (APA, 2000; First et al., 2002). Intellectual functioning of all subjects was assessed with a brief vocabulary test that correlates highly (<italic>r</italic>=0.80) with WAIS-III full-scale IQ scores (Shipley et al., 2009, p. 65; Canivez and Watkins, 2010). Visual acuity was measured with a logarithmic visual acuity chart under fluorescent overhead lighting (viewing distance = 1 meters, lower limit =20/10), and in-house visual acuity correction was used for individuals without appropriate glasses or contacts. Written informed consent was obtained from all subjects after explanation of the nature and possible consequences of participation. The study followed the tenets of the Declaration of Helsinki and was approved by the Rutgers University Institutional Review Board. All participants received monetary compensation and were naive to the study’s objectives.</p>
      </sec>
      <sec id="S5">
        <label>2.3.</label>
        <title>Experimental design and statistical analysis</title>
        <sec id="S6">
          <label>2.3.1.</label>
          <title>Stimulus and procedure</title>
          <p id="P14">Participants performed a “fat/thin” shape discrimination task in which they indicated whether four pac-men formed a fat or thin shape (“illusory” condition) or whether four downward-facing pac-men were uniformly rotated left or right (“fragmented” condition) (see <xref rid="F1" ref-type="fig">Fig. 1</xref>). The fragmented task is a suitable control in that it involves judging the lateral properties of the stimulus—just like the illusory condition—and in that it uses groupable elements (via common orientation, <xref rid="R3" ref-type="bibr">Beck, 1966</xref>). As described below, the two tasks share most stimulus and procedural details (stimulus timing, pac-man features, spatial distribution, etc.). Accordingly, the two tasks rely on many of the same processes: (1) learning two response alternatives from a limited number of practice exemplars and instructional screens (novel task learning); (2) transferring the learned alternatives to long term memory (consolidation); (3) attending to four discrete spatial regions (divided attention); (4) continuously monitoring the display over specific trial intervals (temporal attention); (5) capturing and extracting spatial information from briefly presented arrays (visual short term memory); (6) discerning fine-grained orientation differences (orientation perception); and (7) repeating the foregoing processes over the task duration (sustained motivation) (<xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>). Perhaps because of all these similarities, the two tasks generate similar performance thresholds (<xref rid="R30" ref-type="bibr">Keane et al., 2014</xref>) and are highly correlated behaviorally (<xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>), which should not be taken for granted being that extremely similar visual tasks are often uncorrelated even with large samples (<xref rid="R22" ref-type="bibr">Grzeczkowski et al., 2017</xref>). In sum, by having employed a closely matched and already tested control condition, we are in a position to identify mechanisms relatively unique to shape completion.</p>
          <p id="P15">Subjects viewed the stimuli in the scanner from a distance of 99 cm by way of a mirror attached to the head coil. There were four white sectored circles (radius = .88 deg, or 60 pixels) centered at the vertices of an invisible square (side = 5.3 deg, or 360 pixels), which itself was centered on a gray screen (RGB: 127; see <xref rid="F3" ref-type="fig">Fig. 3</xref>). Stimuli were initially generated with MATLAB and Psychtoolbox code (<xref rid="R55" ref-type="bibr">Pelli, 1997</xref>) with antialiasing applied for edge artifact removal; images were subsequently presented in the scanner via PsychoPy (version 1.84; (<xref rid="R54" ref-type="bibr">Peirce, 2007</xref>) on a MacBook Pro. Illusory contour formation depended on the geometric property of “relatability” (<xref rid="R34" ref-type="bibr">Kellman and Shipley, 1991</xref>): when the pac-men were properly aligned (relatable), the illusory contours were present (the “illusory” condition); when misaligned (unrelatable), they were absent (“fragmented” condition).</p>
          <p id="P16">Within each of the four runs, there was one block of each task condition, which has the advantage of heightening task-related activation differences. In the illusory block, subjects indicated whether four pac-men formed a fat or thin shape; in the fragmented block, subjects indicated whether four downward-facing pac-men were each rotated left or right (see <xref rid="F1" ref-type="fig">Fig. 1</xref>). Block ordering (illusory/fragmented or vice versa) alternated from one run to the next. Each block had two difficulty levels, corresponding to the magnitude of pac-man rotation (+/− 10 degrees “easy”, or +/− 3 degrees of rotation, “hard”). Within each block, there were 20 task trials and 5 fixation trials. Half of the task trials were easy, and half were hard; half of these two trial types were illusory, and half were fragmented. The ordering of these trial types (including fixation) was counterbalanced. Each trial consisted of a 250 ms pac-man stimulus (task trial) or 250 ms fixation dot (fixation trial), followed by a 2750 ms fixation dot. Subjects needed to issue a response before the end of a task trial; otherwise, a randomly selected response was assigned at the end of that trial and the following trial ensued. Feedback was provided at the end of each run in the form of accuracy averaged cumulatively across all test trials.</p>
          <p id="P17">Subjects received brief practice outside of and within the scanner before the actual experiment. During practice, subjects were reminded orally and in writing to keep focused on a centrally-appearing fixation point for each trial. To ensure that subjects thoroughly understood the task, pictures of the fat/thin stimuli were shown side-by-side and in alternation so that the differences could be clearly envisaged. Subjects issued responses with a two-button response device that was held on their abdomens with their dominant hand; subjects practiced with this same type of device outside of the scanner facility. Feedback after each trial was provided during the practice phase only (“correct”, “incorrect”, or“slow response”).</p>
        </sec>
        <sec id="S7">
          <label>2.3.2.</label>
          <title>fMRI acquisition</title>
          <p id="P18">Data were collected at the Rutgers University Brain Imaging Center (RUBIC) on a Siemens Tim Trio scanner. Whole-brain multiband echoplanar imaging (EPI) acquisitions were collected with a 32-channel head coil with TR = 785 ms, TE = 34.8 ms, flip angle = 55°, bandwidth 1894 Hz/Px, in-plane FoV read = 211 mm, 60 slices, 2.4 mm isotropic voxels, with GRAPPA (PAT = 2) and multiband acceleration factor 6. Whole-brain high-resolution T1-weighted and T2-weighted anatomical scans were also collected with 0.8 mm isotropic voxels. Spin echo field maps were collected in both the anterior-to-posterior and posterior-to-anterior directions in accordance with the Human Connectome Project preprocessing pipeline (version 3.25.1) (<xref rid="R19" ref-type="bibr">Glasser et al., 2013</xref>). After excluding dummy volumes to allow for steady-state magnetization, each experimental functional scan spanned 3 min and 41 s (281 TRs). Scans were collected consecutively with short breaks in between (subjects did not leave the scanner). An additional 10-minute resting-state scan (765 TRs) occurred in a separate session, with the same pulse sequence. Note that collecting multiband (rather than single-band) data allowed better detection of structures along the ventral cortical surface (by minimizing partial voluming) (<xref rid="R43" ref-type="bibr">Merboldt et al., 2000</xref>; <xref rid="R66" ref-type="bibr">Smith et al., 2013</xref>). There is also evidence that—at least with some pulse sequences—multiband increases the effective temporal signal-to-noise ratio (with its higher temporal resolution) and improves the detection of group-level resting-state and task-evoked networks (<xref rid="R5" ref-type="bibr">Bhandari et al., 2020</xref>).</p>
        </sec>
        <sec id="S8">
          <label>2.3.3.</label>
          <title>fMRI preprocessing</title>
          <p id="P19">Preprocessing steps are highly similar to earlier studies (<xref rid="R27" ref-type="bibr">Ito et al., 2017</xref>) but are repeated below. Imaging data were preprocessed using the publicly available Human Connectome Project minimal preprocessing pipeline which included anatomical reconstruction and segmentation, and EPI reconstruction, segmentation, spatial normalization to standard template, intensity normalization, and motion correction (<xref rid="R19" ref-type="bibr">Glasser et al., 2013</xref>). All subsequent preprocessing steps and analyses were conducted on CIFTI 64k grayordinate standard space. This was done for the parcellated time series using the <xref rid="R18" ref-type="bibr">Glasser et al. (2016)</xref> atlas (i.e., one BOLD time series for each of the 360 cortical parcels, where each parcel averaged over vertices). The Glasser surface-based cortical parcellation combined multiple neuroimaging modalities (i.e., myelin mapping, cortical thickness, task fMRI, and RSFC) to improve confidence in cortical area assignment. The parcellation thus provides a principled way to parse the cortex into manageable number of functionally meaningful units and thereby reduce the number of statistical comparisons. Note also that there are 97 newly-defined cortical areas in this parcellation, making it possible to identify entirely new shape completion regions. To conduct a follow-up MVPA analysis within V1 and V2 (see <xref rid="S12" ref-type="sec">Results</xref>), we also per-formed an otherwise identical preprocessing pipeline on the vertex-wise data. In all cases, we performed nuisance regression on the minimally preprocessed task data using 24 motion parameters (6 motion parameter estimates, their derivatives, and the squares of each) and the 4 ventricle and 4 white matter parameters (parameter estimates, the derivates, and the squares of each) (<xref rid="R8" ref-type="bibr">Ciric et al., 2017</xref>). For the task scans, global signal regression, motion scrubbing, spatial smoothing, and temporal filtering were not used. Each run was individually demeaned and detrended (2 additional regressors per run).</p>
          <p id="P20">The resting-state scans were preprocessed in the same way as the parcellated task data (including the absence of global signal regression) except that we removed the first five frames and applied motion scrubbing (<xref rid="R57" ref-type="bibr">Power et al., 2012</xref>). That is, whenever the framewise displacement for a particular frame exceeded 0.3 mm, we removed that frame, one prior frame, and two subsequent frames (<xref rid="R63" ref-type="bibr">Schultz et al., 2018</xref>). Framewise displacement was calculated as the Euclidean distance of the head position in one frame as compared to the one preceding.</p>
          <p id="P21">Functional and anatomical scans were visually inspected for quality. In addition, an MRI quality control package (“MRIQC”) and an accompanying random forest classifier were used to confirm that all T1 anatomical scans were artifact free (<xref rid="R15" ref-type="bibr">Esteban et al., 2017</xref>). (Two other participants, not included in our analyzed sample, had been flagged by MRIQC as having low quality T1 scans.) The mean framewise displacement across scans before motion correction or scrubbing was remarkably similar in the visual completion and rest scans: 0.142 mm for visual completion (averaged across scans) and 0.143 mm for rest. The average number of frames remaining after scrubbing for the rest scan was 696 [range: 548–760].</p>
          <p id="P22">For the task scans, there were 6 task regressors, one for each instructional screen (illusory/fragmented) and one for each of the four trial types (illusory/fragmented,easy/hard). A standard fMRI general linear model (GLM) was fit to task-evoked activity convolved with the SPM canonical hemodynamic response function (using the function spm_hrf.m). Betas for the illusory and fragmented condition were derived from all trials of the relevant condition across all four runs. For the classifier analyses, described below, task activation betas were derived separately for each run, but all other steps were the same as described.</p>
        </sec>
        <sec id="S9">
          <label>2.3.4.</label>
          <title>Task activation and multivariate pattern analyses</title>
          <p id="P23">Analyses were performed with RStudio (Version 1.2.1335) and MAT-LAB R2018b. Cortical visualizations were created with Workbench (version 1.2.3). There were eight parcels of a priori interest in each hemisphere. These ROIs have been given different names in different research studies (shown in parentheses) and are as follows: V1 (17, hOC1, OC, BA17), V2 (18, hOC2, OB, BA18), V4 (V4d, V4v, hV4, hOC4v, hOC4lp), V4t (LO2), LO1 (LO2, hOC4la); LO2 (LO1, hOC4la), LO3 (hOC4la), and V3CD (V3A,V3B, hOC4la) ( <xref rid="R18" ref-type="bibr">Glasser et al., 2016</xref>, see p. 81 of <xref rid="SD1" ref-type="supplementary-material">Supplementary Neuroanatomical Results</xref>). Note that V3CD was included because it corresponds to the anterior third of the middle and inferior lateral occipital gyri (area hOc4la as labeled by <xref rid="R40" ref-type="bibr">Malikovic et al., 2016</xref>). Statistical correction, when applied, was via the False Discovery Rate (FDR) method (<xref rid="R4" ref-type="bibr">Benjamini and Hochberg, 1995</xref>). For the univariate task activation analysis, regions that were and were not of a priori interest were separately FDR-corrected. (Statistical correction is indicated explicitly in the text below via p<sub>corr</sub> values).</p>
          <p id="P24">For the group-level task activation analyses, betas for each subject were derived for each parcel, averaged across difficulty condition, and subtracted (illusory-fragmented). These values were then compared to zero across subjects with a one-sample t-test. As a control analysis, we did the same as just described, except that we averaged across <italic>task</italic> condition and contrasted the easy/hard conditions. As a further demonstration of the robustness of the univariate results, we performed individual subject parcel-wise task activation analyses for the illusory/fragmented contrast (<xref rid="T1" ref-type="table">Table 1</xref>), using the subject’s estimated covariance matrix, task betas, and MATLAB’s linear hypothesis test function (linhyptest).</p>
          <p id="P25">The location and role of each parcel was considered within the con-text of their functional network affiliations. We used the Cole-Anticevic Brain Network partition, which comprised 12 functional networks that were constructed from the above-mentioned parcels and that were defined via a General Louvain community detection algorithm using resting-state data from 337 healthy adults (<xref rid="R28" ref-type="bibr">Ji et al., 2019</xref> see <xref rid="F4" ref-type="fig">Fig. 4 A</xref>). This partition included: well-known sensory networks—primary visual, secondary visual, auditory, somatosensory; previously identified cognitive networks—frontoparietal, dorsal attention, cingulo-opercular, and default mode; a left-lateralized language network; and three entirely novel networks—posterior multimodal, ventral multimodal, and orbito-affective. (For a full list of parcels in the networks central to our analyses, see <xref rid="SD1" ref-type="supplementary-material">Supplementary material</xref>) This partition passed several quality control measures of stability and reliability, was biologically motivated and statistically principled, and was able to demonstrate increased levels of task activations at the network level.</p>
          <p id="P26">Multivariate pattern analyses were performed on the activation betas at two levels of spatial granularity. First, we examined whether 12 different functional networks could individually classify task condition (illusory vs fragmented) or difficulty condition (easy vs hard) using their within-network mean parcel activations as features. Next, on a follow-up post-hoc analysis, we examined, for each parcel, whether vertex-wise activations could classify task condition. MVPA classification accuracy in each case was assessed via leave-two-runs-out cross validation. For example, when classifying task condition for each participant, we examined whether the betas for each of the two left-out runs better correlated to the illusory or fragmented betas averaged across the remaining runs. Note that each run contained an equal number of trials from each of the two conditions, ensuring balanced condition types across test and training. Pearson correlation served as the minimum distance classifier (i.e., 1-r) (<xref rid="R46" ref-type="bibr">Mur et al., 2009</xref>; <xref rid="R67" ref-type="bibr">Spronk et al., 2018</xref>). Results were averaged for each subject across the 6 possible ways to divide the four runs between test and validation. Statistical significance was determined via permutation testing, which generated a null distribution of classification accuracies through the same procedure with 10,000 samples. That is, for each sample, the “illusory” and “fragmented” labels were shuffled for each subject and run, and the classification results were averaged across subjects and across the 6 possible divisions of testing and validation data sets.</p>
        </sec>
        <sec id="S10">
          <label>2.3.5.</label>
          <title>Resting-state functional connectivity derivation</title>
          <p id="P27">We determined the resting-state functional connections for each parcel. Specifically, for each target parcel time series, we decomposed the time series of the remaining (N = 359) parcels into 100 components, regressed the target onto the PCA scores, and back-transformed the PCA betas into a parcel-wise vector. The average amount of variance explained by the components across subjects was 84% [range: 81–88%]. The RSFC computation is equivalent to running a multiple regression for each parcel, with all other parcels serving as regressors. An advantage of using multiple regression is that it removes indirect connections (<xref rid="R10" ref-type="bibr">Cole et al., 2016</xref>). For example, if there exists a true connection from A to B and B to C, a Pearson correlation, but not regression, would incorrectly show connections between A and C. PC regression was preferred over ordinary least squares to prevent over-fitting (using all components would inevitably capture noise in the data). Aside from revealing the functional connectedness of task-modulated regions, the RSFC matrix allowed an assessment of the utility of these connections for estimating task activation differences via ActFlow.</p>
        </sec>
        <sec id="S11">
          <label>2.3.6.</label>
          <title>Activity flow mapping</title>
          <p id="P28"><xref rid="F6" ref-type="fig">Fig. 6</xref> illustrates how we used resting-state data to predict illusory-fragmented task activation differences across cortex (“Activity Flow mapping” or simply “ActFlow”). For each subject, the task activation difference in a held-out parcel (‘j’ in <xref rid="F6" ref-type="fig">Fig. 6 A</xref>) was predicted as the weighted average of the activation difference of all other parcels, with the weights given by the resting-state connections. That is, for each subject, each held out region’s predicted value was given as the dot product of the values in the remaining regions (‘i’ in <xref rid="F6" ref-type="fig">Fig. 6 A</xref>) and the subject’s restFC between j and i (using the FC weight from the appropriately oriented regression, i.e., j as the target and i as the predictor). The accuracy of the activity flow predictions was then assessed by computing the overlap (Pearson correlation) between the predicted and actual task activation difference vectors. Overlap was expressed by comparing actual and predicted activation differences for each subject, and then averaging the resulting Fisher-transformed r values (r<sub>z</sub>) across subjects (subject-level overlap). Statistical significance was determined by comparing the vector of r <sub>z</sub> values to zero via a one-sample t-test. Overlap was expressed by averaging the predicted values across subjects and then comparing that to the averaged actual values, which will yield a single Pearson r value (group-level overlap). If a given RSFC matrix can be used to predict task activation differences, that would show that those same functional connections likely contribute to shape completion. Below, we applied ActFlow once to the full RSFC matrix and once to the matrix involving only the task modulated regions.</p>
          <p id="P29">Since the secondary visual network was central to the shape completion network coalition, we also examined how ActFlow estimates improved in that network, when any of the remaining four networks were individually added (<xref rid="F7" ref-type="fig">Fig. 7</xref>). This change was determined simply by comparing via a paired t-test the prediction accuracies (correlations) before and after adding each network. A significant improvement would indicate which other networks, if any, guide activity flow in the secondary visual network. The success of the ActFlow method also prompted us to also consider whether adding connections from any of the five task modulated networks could improve ActFlow accuracy in the remaining networks. A significant improvement would indicate which other net-work, if any, explains differential activity in the remaining networks.</p>
        </sec>
      </sec>
    </sec>
    <sec id="S12">
      <label>3.</label>
      <title>Results</title>
      <sec id="S13">
        <label>3.1.</label>
        <title>Behavioral task performance</title>
        <p id="P30">Employing a 2 (task condition) by 2 (difficulty) within-subjects ANOVA (type III sum of squares), we found that performance was better in the fragmented than illusory condition (89.6% versus 82.9%, <italic>F</italic>(1,19)= 14.8, <italic>p</italic>&lt; .01) and better in the (“easy”) large-rotation condition than the (“hard”) small-rotation condition (<italic>F</italic>(1,19)= 133, <italic>p</italic>&lt;10<sup>−9</sup>) (See <xref rid="SD1" ref-type="supplementary-material">Supplementary Fig. S1</xref> for graphical depiction of the behavioral results). The accuracy difference between illusory and fragmented conditions did not depend on difficulty level, although there was a trend toward a greater difference on the smaller rotation condition (two-way interaction: (<italic>F</italic>(1,19)= 3.6, <italic>p</italic>=.07). The marginal interaction probably arose from ceiling effects for the fragmented condition since there was no corresponding interaction in the reaction time data (<italic>F</italic>(1,19)= .14, <italic>p</italic>=.7). Reaction time data where in other ways entirely predictable from the accuracy results, with faster performance in the fragmented than the illusory condition (<italic>F</italic>(1,19)= 5.1, <italic>p</italic>=.04), and faster performance in the easy than the hard condition (<italic>F</italic>(1,19)= 21.3, <italic>p</italic>&lt;.001). The no-response trials were infrequent, occurring on only 5.5% of the trials on average. The frequency of no-response trials did not vary with difficulty level or task condition nor was there an interaction between difficulty and task condition (<italic>ps&gt;</italic>.25). Consistent with past results (<xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>), the fragmented and illusory conditions were highly correlated (accuracy—<italic>r</italic>=.74, <italic>p</italic>&lt;.001; RT—<italic>r</italic>=.81, <italic>p</italic>&lt;.0001), confirming that they were reliant upon a common core of mechanisms. The correlations were robust and remained significant when calculated with non-parametric tests or after log-transforming the RT data.</p>
      </sec>
      <sec id="S14">
        <label>3.2.</label>
        <title>Shape completion effects across five large-scale functional networks</title>
        <p id="P31">A general linear model task activation analysis determined the parcels that were differentially active in the illusory versus fragmented condition. Overall, 36 parcels reached significance in five different net-works (<xref rid="T1" ref-type="table">Table 1</xref>; <xref rid="F2" ref-type="fig">Fig. 2</xref>). Of these parcels, 29 (81 percent) were more activated for illusory relative to fragmented trials (<xref rid="F2" ref-type="fig">Fig. 2</xref>). A priori ROIs, when significant, were all more active relative to the control condition; these include bilateral V3CD, V4, L01, and left L02. With the exception of left V4, the ROI effects were robust enough to survive a cortex-wide FDR correction. Notable null results were V2 and V1 which will be discussed further below. Additional positively and significantly activated regions resided in the posterior parietal, dorsolateral prefrontal, and orbitofrontal regions; they belonged primarily to the secondary visual, dorsal attention, and frontoparietal networks. All seven of the regions that were negatively activated in the illusory-fragmented contrast belonged to the default mode network. Note that this finding reflects this network’s established on-task deactivation profile (<xref rid="R1" ref-type="bibr">Anticevic et al., 2012</xref>), i.e. greater deactivation for the illusory relative to the fragmented condition, consistent with greater task engagement in the illusory condition.</p>
        <p id="P32">Because task difficulty was greater in the illusory task, perhaps task difficulty, rather than shape completion, drove the effects just described. We addressed this concern in three ways. First, we performed a contrast comparing activation in the easy versus hard trials, averaged across task conditions. To make the results comparable to before, FDR correction was applied separately to regions that were and were not ROIs. We found 51 parcels that were differentially active, but only eight overlapped with the illusory-fragmented contrast (see <xref rid="F3" ref-type="fig">Fig. 3</xref>). Five of these parcels were less active in both the hard-easy and illusory-fragmented comparisons, and all belonged to the default mode network: bilateral a24, right d23ab, right 31pv, and right PGi. Three parcels were more active in both contrasts (bilateral IFJp, left MIP). None of the 16 ROIs of visual shape completion were related to task difficulty. Thus, on this analysis, while the above-mentioned eight parcels were confounded with task difficulty, the remaining 28 significant parcels in the illusory/fragmented comparison were not confounded.</p>
        <p id="P33">To further assess the extent to which task difficulty might account for the aforementioned shape completion effects, we ran an additional analysis that was restricted to the 10 participants who did the best in the illusory relative to the fragmented condition, so that there was no longer an accuracy difference (<italic>t</italic>(9)=−0.443, <italic>p</italic>=0.669, Mean difference in pro-portion correct=−0.011). In this sample, there was also no reaction time difference between task conditions (<italic>t</italic>(9)=1.63, mean RT difference=−.06 seconds, <italic>p</italic>=.14)). As shown in <xref rid="T1" ref-type="table">Table 1</xref>, with the exception of left V4, the ROIs that were significant in the earlier analysis remained significant in this restricted sample; these include L01 and V3CD in each hemisphere, left LO2, and right V4 (all <italic>p</italic>&lt;.05, uncorrected). Of the eight regions that were significant on both the hard/easy and illusory/fragmented contrast, five remained significant (left MIP, bilateral a24, bilateral IFJp) and are thus are more plausibly independent of task difficulty. The foregoing results were about the same if either 9 or 11 participants were included in this accuracy-matched analysis (See <xref rid="SD1" ref-type="supplementary-material">Supplementary materials</xref>). Other regions that continued to be significant on this accuracy matched analysis are shown in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
        <p id="P34">Finally, we considered whether—across all subjects—there were significant correlations between relative accuracy differences (illusory vs. fragmented) and relative task activation differences. None of the 360 correlations survived FDR correction (all |r|&lt;.48, all p&gt;.03, before multiple comparison correction) suggesting again that the relative performance differences did not play a large role in driving our parcel-wise effects.</p>
        <p id="P35">To examine the robustness of the task activation effects, we additionally report the percentage of subjects showing significant effects (illusory-fragmented) in the group direction on an individual subject analysis (with a linear hypothesis test, see <xref rid="S2" ref-type="sec">Methods</xref>). This was done for regions that were significant on the task activation analysis as well as for other regions that were of a priori interest. As can be seen from <xref rid="T1" ref-type="table">Table 1</xref>, about 80% of subjects showed activation differences in the group di- rection (ranging from 65–95%, depending on the parcel) and about half of subjects (35 – 80%) showed effects that were statistically significant. Intriguingly, the posterior temporal region PH–which was not of <italic>a priori</italic> interest—was <italic>most</italic> associated with shape completion, with 80% of subjects showing a significant effect in the left and right hemispheres, and at least 90% showing group differences in each hemisphere in the group direction. This region’s surprising role in shape completion will be discussed further below.</p>
      </sec>
      <sec id="S15">
        <label>3.3.</label>
        <title>Probing for multivariate traces of shape completion in early visual areas</title>
        <p id="P36">Task activation analyses did not reveal shape completion effects in V1 or V2. Because a region could conceivably encode a completed shape in its vertex-wise pattern rather than in its univariate mean (<xref rid="R24" ref-type="bibr">Haynes, 2015</xref>), we performed MVPA on vertices within these parcels. For completeness, we considered effects within all 360 parcels. The following were significant: L_LO2 (<italic>p</italic>=.02, accuracy=58%), L_V3CD (<italic>p</italic>=.04, accuracy= 58%), R_V4 (<italic>p</italic>=.049, accuracy=56%), R_LO1 (<italic>p</italic>=.03, accuracy=57%), and R_LO3 (<italic>p</italic>=.04, accuracy=56%). These effects were not corrected for multiple comparisons but are credible given the strong prior evidence for their involvement (see <xref rid="S1" ref-type="sec">Introduction</xref>). Outside of the ROIs, the only region that was significant after FDR correction was R_PGp (<italic>p</italic><sub><italic>corr</italic></sub>&lt;.0001, accuracy=66%). Given the hemispherically similar task activations and the bilateral stimulus displays, we performed the same analysis as above, except that vertices were aggregated (with-out averaging) across hemisphere to increase sensitivity. The effects were similar to before with effects for: V4 (<italic>p</italic>=.02, accuracy=58%), LO2 (<italic>p</italic>=.02, accuracy=57%), and V3CD (<italic>p</italic>=.04, accuracy=56%). There was a marginal effect for V1 (<italic>p</italic>=.09, accuracy =55%). For regions that were not of a priori interest, the following reached significance after FDR corretion: PGp (p<sub>corr</sub>=.04, accuracy=60%) in the secondary visual network; MIP and IP0 in the dorsal attention network (p<sub>corr</sub>=.04, accuracy=61%; p<sub>corr</sub>=.04, accuracy= 61%, respectively); and IP1 in the frontoparietal network (p<sub>corr</sub>&lt;.001, accuracy=63%). In sum, neither V1 nor V2 exhibited a robust vertex-wise shape completion effect; however, several ROIs (V4, LO2, V3CD), several other univariate, task-activated regions (e.g., IP1), and a new region, PGp, were consistently significant on this analysis. Possible reasons for null effects are considered in the Discussion.</p>
      </sec>
      <sec id="S16">
        <label>3.4.</label>
        <title>A dominant role for the secondary visual network in shape completion</title>
        <p id="P37">As shown in <xref rid="F4" ref-type="fig">Fig. 4</xref>, most significant parcels resided in the secondary visual network, followed by the dorsal attention, frontoparietal, default mode, and cingulo-opercular networks. To better quantify the network contributions and compare them to one another, we trained MVPA classifiers separately for the 12 functional networks (<xref rid="R28" ref-type="bibr">Ji et al., 2019</xref>), using parcel-wise activations as features (see <xref rid="S2" ref-type="sec">Methods</xref>). After FDR correction (across tests for the 12 networks), the secondary visual network could distinguish the illusory and fragmented conditions at a rate above chance (p<sub>corr</sub>&lt;.001, accuracy=63%), but no other network could do so (all p<sub>corr</sub>&gt;.24, accuracies&lt;57%). Paired t-tests showed that, after FDR correction, the secondary visual network was marginally more predictive than 8 of the remaining 11 networks (all p<sub>corr</sub>≤.10). Note that there was no correlation between network classification accuracy and parcel count (<italic>r</italic>=.05, <italic>p</italic>=.88), suggesting that smaller networks were not unduly handicapped.</p>
      </sec>
      <sec id="S17">
        <label>3.5.</label>
        <title>Modulated task parcels were densely inter-connected during rest</title>
        <p id="P38">To determine how modulated task regions were functionally inter-connected, we derived a whole-cortex RSFC matrix with Pearson correlation (which is more commonly reported) and then with multiple regression (<xref rid="F5" ref-type="fig">Fig. 5A</xref>,<xref rid="F5" ref-type="fig">B</xref>; see <xref rid="S2" ref-type="sec">Methods</xref>). We then homed in on the significant task regions that remained significant when the illusory/fragmented conditions were matched on accuracy/RT. Since the task activations were hemispherically symmetric, contralateral homologues were included so that there was a 42 × 42 RSFC matrix. The betas from the regression-based RSFC matrix were compared to zero for each connection across subjects (one sample t-test) and were FDR-corrected (thresh-olded) across all connections (<xref rid="F5" ref-type="fig">Fig. 5 C</xref>). An assessment of <xref rid="F5" ref-type="fig">Fig. 5 C</xref> shows that parcels had higher within- than between-hemisphere RSFC (210 versus 169 significant connections), a greater proportion of significant cross-hemisphere versus within-hemisphere connections for sensory (visual) than for non-sensory networks (93% versus 33%, excluding connections between parcels and their controlateral homologues), and higher RSFC between parcels and their contralateral homologues than with other contralateral regions. These results are consistent with past work (<xref rid="R58" ref-type="bibr">Power et al., 2011</xref>; <xref rid="R69" ref-type="bibr">Stark et al., 2008</xref>) and demonstrate that the RSFC matrices were yielding sensible results.</p>
        <p id="P39">A major question was whether the significantly modulated task regions were inter-connected during rest. After applying FDR corrections to each matrix separately, we found that the restricted RSFC matrix (42 × 42) contained three times as many significant resting-state connections as the full (360 × 360) matrix, (43% versus 14%). To put this in perspective, two of the twelve resting-state networks—default mode and or-bitoaffective—had a lower proportion of significant <italic>within</italic>-network connections (35% and 25%, respectively). This suggests that the significant task regions, despite falling within five different networks, composed a densely inter-connected network coalition or supra-network. Note that these five networks, as a whole, were not unusually connected to one another: If all regions from all 5 networks were included in the above calculations (to form a 260 × 260 RSFC matrix), the total number of significant resting state connections would still only be 17%. Thus, it is the specific regions within these five networks that appear to be more interconnected during rest.</p>
        <p id="P40">To examine these results in a different way, we examined for each subject the average within-network connection weight and the average out-of-network connection weight across the 42 task parcels (where “network” consisted of just these parcels), and simply compared these two averaged weights across subjects. Shape completion regions cohered more strongly with one another than with other regions (<italic>t</italic>(18)=22.6, <italic>p</italic>&lt;10<sup>−13</sup>,<italic>d</italic>=8.0; within: M=.0088, SD=.0012; between: M=.0019, SD=.00016).</p>
        <p id="P41">The RSFC matrices offers clues as to how the regions were communicating. As can be observed from <xref rid="F5" ref-type="fig">Fig. 5 D</xref>, the secondary visual network most often connected to the dorsal attention network regions, which in turn had the most significant out-of-network connections (168 connections). Moreover, there appear to be a number of routes between frontal cortex and the mid-level vision ROIs. Dorsal lateral prefrontal cortex (p9–46v) connects with MIP, IP0, and IP2 (in posterior parietal cortex), which in turn connect with all of the significant ROI regions. Intriguingly, area 11l (OFC) connected directly with area LO2. Hence there exist clear routes for conceptual or value-laden information to loop back into areas traditionally associated with shape completion, but in most cases these routes must traverse the dorsal attention network and particularly parts of posterior parietal cortex.</p>
      </sec>
      <sec id="S18">
        <label>3.6.</label>
        <title>Resting-state connections are relevant for visual shape completion</title>
        <p id="P42">We have shown that regions that were differentially activated during visual shape completion were also connected during rest. However, despite some indirect evidence from other work (see <xref rid="S1" ref-type="sec">Introduction</xref>), it remains unclear whether these connections in these same subjects played a mechanistic role in shape completion. To address the question, we leveraged a recently-developed predictive modeling approach—activity flow mapping (“ActFlow”)—to assess whether the resting-state connections (derived via multiple regression) were likely instrumental in carrying the flow of activity between regions during task performance (<xref rid="R10" ref-type="bibr">Cole et al., 2016</xref>). In this method, the activation difference (illusory minus fragmented) in a held-out “target” parcel was computed as the linear weighted sum of the activation differences in all other parcels, with the weights being given by the resting-state connections to the target (see <xref rid="F6" ref-type="fig">Fig. 6a</xref>). This can be thought of as a rough simulation of the movement of task-evoked activity between brain regions that likely contributed to each brain region’s task-evoked activity level. This allowed us to assess whether the observed resting-state connections mechanistically supported the perceptual processes associated with shape completion. Prediction accuracy was gauged as the correlation between the actual and predicted activation differences. As can be seen in <xref rid="F6" ref-type="fig">Fig. 6B</xref>, the predictions were highly significant at the whole-cortex level (<italic>r</italic>=.64, <italic>p</italic>&lt;10<sup>−9</sup>). If we were to first average the predicted differences across subjects, then average the actual differences across subjects, and then correlate the two, the resulting group-level accuracy estimate would increase (<italic>r</italic>=.89), probably by increasing the signal-to-noise ratio (<xref rid="R10" ref-type="bibr">Cole et al., 2016</xref>).</p>
        <p id="P43">We next applied a task activation analysis to the ActFlow predicted data (via one-sample t-tests, as before) and compared the results to the original task activation results (shown in <xref rid="F2" ref-type="fig">Fig. 2</xref>). The percentage of parcels that remained significant (sensitivity) with ActFlow was 86%; the percentage of non-significant parcels that remained non-significant (specificity) was 81% (see <xref rid="F6" ref-type="fig">Fig. 6C</xref>). These results again suggest that the observed resting-state connections describe the routes over which task-evoked activity flows during shape completion (controlling for orientation judgement).</p>
        <p id="P44">To assess the relevance of resting-state connections between regions that were modulated during the task, we restricted activity flow mapping only to those regions and their contralateral homologues. To minimize the chance of task difficulty effects, we again used only regions that remained significant when conditions were matched on accuracy/RT so that each held-out parcel’s activation was predicted by 41 other connections/parcels. Despite eliminating 89 percent of the connections for each parcel, the prediction accuracy estimates (r-values) across subjects were still high (illusory-fragmented: <italic>r</italic>=.61, <italic>p</italic>=3.0 <sup>∗</sup> 10<sup>−9</sup>) and did not significantly differ (<italic>p</italic>=.28) from the ActFlow correlations with the full matrix (as assessed with a paired t-test). This suggests that much of shape completion can be understood by only examining the connections and activations of task modulated regions.</p>
      </sec>
      <sec id="S19">
        <label>3.7.</label>
        <title>Dorsal attention regions can model activity flow in the secondary visual network</title>
        <p id="P45">According to the task activation and network-wise MVPA results (<xref rid="T1" ref-type="table">Table 1</xref> and <xref rid="F4" ref-type="fig">Fig. 4</xref>, respectively), shape completion was most undergirded by the secondary visual network. To examine which other net-works might plausibly contribute to the illusory/fragmented activation differences in this network, we determined which ones could improve the ActFlow predictions, using the same significant task regions as before (see <xref rid="F6" ref-type="fig">Fig. 6</xref>). More explicitly, for each subject, we computed a single correlation between the actual and ActFlow parcel difference values across the 12 significant secondary visual network parcels. We then re- computed this correlation, when each of the 12 parcels could <italic>also</italic> be predicted by parcels and connections from one other network. Finally, we Fisher-z transformed the correlations, subtracted the two, and then performed a one-way t-test to see if the correlations increased as a result of the network’s inclusion. The dorsal attention network improved the predictions for the secondary visual network (Δ<italic>r</italic>≈Δr<sub>Z</sub> =.37, p<sub>corr</sub>=.01); no other network generated a significant effect. The improvement from the dorsal attention regions were significant also if we were to use all 360 regions and all possible resting-state connections (rather than restricting to the significantly activated regions (Δ<italic>r</italic>≈Δr<sub>Z</sub> =.11; p<sub>corr</sub>=.04).</p>
      </sec>
      <sec id="S20">
        <label>3.8.</label>
        <title>Dorsal attention and frontoparietal regions can model activity flow across all remaining networks</title>
        <p id="P46">Is there a particular network that plays a dominant role in orchestrating the activity of the other regions? We examined this possibility by using the same approach as just described; that is we calculated, for each subject, the ActFlow accuracy for all regions outside of a held-out network and considered how that accuracy improved—that is, how the Fisher-Z correlations increased (Δr<sub>Z</sub>)—when the held-out network regions were allowed to contribute (<xref rid="R44" ref-type="bibr">Mill et al., 2020</xref>). This was done for each of the five networks, using only the significant task regions (viz., 42 regions were treated as targets for ActFlow in <xref rid="F6" ref-type="fig">Fig 6A</xref>). Consistent with observations from the functional connectivity matrix, the dorsal attention network significantly improved inferences for the significant regions within the remaining four networks (Δ<italic>r</italic>≈Δr<sub>Z</sub> =.10;<italic>t</italic>(18)=3.84, p<sub>corr</sub>=.006). The frontoparietal network issued a somewhat weaker but still detectable effect (Δ<italic>r</italic>≈Δr<sub>Z</sub>=.06;<italic>t</italic>(18)=2.83, p<sub>corr</sub>=.03). Interestingly, the other three networks—including the secondary visual—failed to influence the results on this analysis (all p<sub>corr</sub>&gt;.6). The improvement from the dorsal attention regions and frontoparietal regions would also be significant if we were to use all 360 regions and all possible resting-state connections (rather than restricting to the significantly modulated regions; dorsal attention: Δ<italic>r</italic>≈Δr<sub>Z</sub>=.03; <italic>t</italic>(18)=3.55, p<sub>corr</sub>=.007; frontoparietal: Δ<italic>r</italic>≈Δr<sub>Z</sub>=.05; <italic>t</italic>(18)=4.55, p<sub>corr</sub>=.002).</p>
      </sec>
    </sec>
    <sec id="S21">
      <label>4.</label>
      <title>Discussion</title>
      <p id="P47">Visual shape completion plays a critical role in extracting object shape, size, position, and number from edge elements dispersed across the field of view. The process relies on lateral occipital and early visual areas, but it is unclear what other regions might be utilized, how they are functionally connected, or what networks they reside within. To shed light on the foregoing, we scanned participants during rest and during a task in which they discriminated pac-man quartets that either formed or failed to form visually completed shapes. Six major findings emerged.</p>
      <p id="P48">One is that although only a few dozen parcels were differentially activated, the effects were impressively consistent, with one region—parcel PH—exhibiting similar effects across 90–95% of subjects in each hemisphere. Next, the secondary visual network played a dominant role in shape completion but parcels within the dorsal attention, frontoparietal, and default mode, and cingulo-opercular network were also influential, suggesting that shape completion is a distributed process. Third, task-activated parcels were highly connected during rest, being significantly more connected to one another than to other regions. Fourth, resting-state connections could accurately predict illusory/fragmented task activation differences via ActFlow, which implies that these same connections were employed for shape completion. Fifth, dorsal attention regions could model activity in the secondary visual network, and across all remaining networks, indicating that this network may orchestrate activity across cortex during shape completion. Finally, frontoparietal cortex appears to globally coordinate activity during shape completion as well. Below, we discuss these findings in more detail, provide a sketch of how these regions might interact during shape completion, identify potential limitations, and suggest future directions.</p>
      <sec id="S22">
        <label>4.1.</label>
        <title>The role of visual networks in shape completion</title>
        <p id="P49">The secondary visual network played a central role for shape completion. It contained 31 percent of all significantly activated parcels and the parcel-wise task activation differences in this network—but not others—could classify task condition. <italic>A priori</italic> regions of interest—V4, LO1, LO2, V3CD—were all significant in at least one hemisphere on the task activation analysis; V4, LO2, and V3CD were each significant in at least one hemisphere on the vertex-wise MVPA analysis. Significant visual parcels were categorically more active in the illusory than fragmented condition without regard to accuracy and were spatially contiguous on the lateral surface (see swath of purple in the lateral views of <xref rid="F4" ref-type="fig">Fig. 4A</xref>), suggesting that shape completion could potentially be augmented by transcranially stimulating this network. Such interventions could potentially treat conditions that impair shape completion such as developmental agnosia (deactivated mid-level visual areas), schizophrenia, brain injury (infarct/hemorrhage), or recent recovery from congenital blindness (cataract removal) (<xref rid="R17" ref-type="bibr">Gilaie-Dotan et al., 2009</xref>; <xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>; <xref rid="R53" ref-type="bibr">Ostrovsky et al., 2009</xref>; <xref rid="R75" ref-type="bibr">Vuilleumier et al., 2001</xref>).</p>
        <p id="P50">There was no robust MVPA or task activation result for V1 or V2. A likely reason is that—according to a population receptive field mapping approach (<xref rid="R35" ref-type="bibr">Kok and de Lange, 2014</xref>)—the illusory shape surface region (corresponding to a portion of V1 vertices) is more activated in V1 relative to baseline and the inducer (pac-man) regions are <italic>less</italic> activated. A similar result was reported for V2. Therefore, averaging across these two retinotopic region types will reveal no changes in overall activity nor will MVPA be revelatory when individual voxels are responding to both the inducer and the shape regions simultaneously. This may also explain why, historically, the methods with the highest spatial resolution were those that provided the most convincing evidence for illusory contour formation in V1 and V2 (<xref rid="R21" ref-type="bibr">Grosof et al., 1993</xref>; <xref rid="R35" ref-type="bibr">Kok and de Lange, 2014</xref>; e.g., <xref rid="R38" ref-type="bibr">Lee and Nguyen, 2001</xref>) and why many lower-resolution neuroimaging studies have often failed to find effects at this level (<xref rid="R64" ref-type="bibr">Seghier and Vuilleumier, 2006</xref>). For example, a study using the fat/thin discrimination task with 3 mm voxels found no modulation of early visual areas (<xref rid="R68" ref-type="bibr">Stanley and Rubin, 2003</xref>) whereas a behaviorally similar study using 2 mm voxels and a surface-based analysis revealed effects (<xref rid="R39" ref-type="bibr">Maertens et al., 2008</xref>). Another implication of the population receptive field result is that larger stimuli will make it easier to distinguish up- and down-regulated retinotopic regions. Again, the data speak to this possibility: We used illusory shapes that were 5 degrees on a side, Stanley and Rubin used stimuli 5 degrees on a side, but Maertens et al used squares that were 7.4 deg on a side. Therefore, higher resolution fMRI and larger illusory shapes, may be needed to better bring effects more fully within V1 and V2.</p>
      </sec>
      <sec id="S23">
        <label>4.2.</label>
        <title>Area PH: A potential “classical region ” for shape completion and a link to reading</title>
        <p id="P51">Area PH is a recently re-defined region in the posterior temporal cortex, corresponding to the superior part of PH in the von Economo and Koskinas atlas (<xref rid="R18" ref-type="bibr">Glasser et al., 2016</xref>; <xref rid="R71" ref-type="bibr">Triarhou, 2007</xref>); it is not commonly reported in the neuroimaging literature and was not of a priori interest. Nevertheless, in our study it was the most consistently active parcel across subjects (when considering both hemispheres), the most frequently significant parcel within subject, and the most densely connected task-modulated visual parcel, communicating directly with lateral occipital cortex (V3CD), consistent with past research (<xref rid="R18" ref-type="bibr">Glasser et al., 2016</xref>). In light of these results, PH should be considered a candidate “classical region” for shape completion along with other more recognized areas such as lateral occipital cortex. Strong activation of PH could also explain why the fusiform face area has been occasionally reported in past studies of shape completion (<xref rid="R23" ref-type="bibr">Halgren et al., 2003</xref>; <xref rid="R37" ref-type="bibr">Larsson et al., 1999</xref>) since PH is immediately bordering the fusiform face complex and since signal leakage or improper delineation of PH would inevitably result in false positives. Finally, PH has been considered by some to be the best atlas-based alternative to the functionally-defined visual word form area (VWFA; <xref rid="R76" ref-type="bibr">Weiss et al., 2019</xref>). The VWFA has been shown to have high functional connectivity to the dorsal attention network (<xref rid="R74" ref-type="bibr">Vogel et al., 2012</xref>). Consistent with this finding, we showed that area PH was significantly connected to task-modulated dorsal attention regions in each hemisphere (MIP, LIPd, PFt, AIP, PHT, IP0); <xref rid="F5" ref-type="fig">Fig. 5C</xref>). An interesting possibility is that visual shape completion ability may be compromised in those with dyslexia (<xref rid="R45" ref-type="bibr">Monzalvo et al., 2012</xref>) and may correlate with reading skills in non-clinical populations. A related possibility is that area PH may help explain why people with schizophrenia exhibit both reading (<xref rid="R60" ref-type="bibr">Revheim et al., 2014</xref>) and completion deficits (<xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>), why patients with worse shape completion exhibit worse premorbid scholastic performance (ibid), and why patients with schizophrenia are more susceptible to developmental dyslexia (<xref rid="R77" ref-type="bibr">Whitford et al., 2018</xref>).</p>
      </sec>
      <sec id="S24">
        <label>4.3.</label>
        <title>Frontoparietal feedback to mid-level vision via the dorsal attention network</title>
        <p id="P52">Frontoparietal network regions were differentially active in or- bitofrontal, dorsolateral prefrontal, and posterior parietal cortex, and activations within this network were able to estimate activations in the remaining modulated task regions. Despite receiving little regard in the literature (M. M. <xref rid="R49" ref-type="bibr">Murray and Herrmann, 2013</xref>; <xref rid="R64" ref-type="bibr">Seghier and Vuilleumier, 2006</xref>), frontoparietal involvement is not wildly unexpected. In the aforementioned MEG study, peak orbitofrontal modulation from passively-viewed Kanizsa shapes arose 340 ms post stimulus onset (<xref rid="R23" ref-type="bibr">Halgren et al., 2003</xref>). In eight month- (but not six month-) old infants, gamma band oscillations (40 HZ) from Kanizsa shapes were generated over frontal electrodes between 240–320 ms (<xref rid="R12" ref-type="bibr">Csibra et al., 2000</xref>).</p>
        <p id="P53">Frontoparietal regions may create expectation-based predictions (<xref rid="R2" ref-type="bibr">Bar, 2003</xref>) for amplifying less salient illusory contours and thereby improving task performance. For example, blurry lightness-induced surfaces (so-called “salient regions; <xref rid="R68" ref-type="bibr">Stanley and Rubin, 2003</xref> ) generate a delayed LOC activation relative to standard Kanizsa shapes (<xref rid="R65" ref-type="bibr">Shpaner et al., 2009</xref>), potentially reflecting the brain’s late-arriving best guesses about the precise shape of the incoming stimulus. In a fat/thin discrimination behavioral study, biasing observers to see edge elements as disconnected worsened the discrimination of illusory but not fragmented shapes (<xref rid="R32" ref-type="bibr">Keane et al., 2012</xref>), suggesting again that noticing and using illusory contours for shape discrimination requires appropriately conceptualizing the stimulus. Top-down signals may additionally allow observers to cognitively infer (or “abstract”) missing contours that cannot be formed via illusory contour formation such as when edge elements are extremely sparse, misaligned, or misoriented (<xref rid="R29" ref-type="bibr">Keane, 2018</xref>; <xref rid="R79" ref-type="bibr">Wyatte et al., 2014</xref>). Finally, the frontoparietal network may communicate with mid-level visual structures primarily by way of the dorsal attention network (<xref rid="R6" ref-type="bibr">Cavada and Goldman-Rakic, 1989</xref>). As evidence, all nine modulated frontoparietal parcels in our resting-state analysis were significantly connected to at least one dorsal attention region, most typically in the posterior parietal cortex.</p>
        <p id="P54">Note that high-level feedback of the type described is compatible with a fast, automatic and overall modular illusory contour formation process (<xref rid="R29" ref-type="bibr">Keane, 2018</xref>) that does not require conscious access (<xref rid="R73" ref-type="bibr">Vandenbroucke et al., 2014</xref>; <xref rid="R75" ref-type="bibr">Vuilleumier, Valenza, &amp; Landis, 2001</xref>). Illusory contours begin forming at 70 ms post-stimulus onset in V2 (<xref rid="R38" ref-type="bibr">Lee and Nguyen, 2001</xref>) and 90 ms in LOC (M. <xref rid="R47" ref-type="bibr">Murray et al., 2002</xref>). Prefrontal feedback during object recognition plausibly occurs at 150 ms post-stimulus onset, according to TMS, backward masking, and EEG/MEG studies (<xref rid="R79" ref-type="bibr">Wyatte et al., 2014</xref>). Therefore, prefrontal cortical signals probably arrive too late to influence contour completion in its initial stages. Higher-order cortical feedback may also be ineffectual after its arrival, if it must compete with persistently salient bottom-up signals (<xref rid="R13" ref-type="bibr">Desimone and Duncan, 1995</xref>; <xref rid="R29" ref-type="bibr">Keane, 2018</xref>; <xref rid="R41" ref-type="bibr">McMains and Kastner, 2010</xref>). Parietal neglect patients with damage to inferior parietal cortex can form illusory contours (<xref rid="R75" ref-type="bibr">Vuilleumier, Valenza, &amp; Landis, 2001</xref>) and people with prefrontal cortical lesions can integrate disconnected contour elements (<xref rid="R7" ref-type="bibr">Ciaramelli et al., 2007</xref>), suggesting again that these areas may not be necessary for forming illusory contours. Thus, frontoparietal signals—and their dorsal attention conduits—may primarily be important for performing computations on contours already formed in mid-level vision or for enabling conscious access to such contours. Others have also argued via visual evoked potentials for a dissociable automatic illusory contour formation stage and an effortful shape discrimination stage (M. M. <xref rid="R50" ref-type="bibr">Murray et al., 2006</xref>).</p>
      </sec>
      <sec id="S25">
        <label>4.4.</label>
        <title>Objections, limitations, and opportunities for future research</title>
        <p id="P55">An objection is that the illusory and fragmented conditions required observers to judge different aspects of the stimulus (orientation or shape), and so differences in “task set ” rather than shape completion may explain our results. To address this objection, we first note that <italic>any</italic> adequate control condition will lack shape completion and will require seeing the stimulus as categorically different. Therefore, it is not possible to perfectly control for task set without obliterating the difference of interest. Second, differences in task set—at least in our study—did not make our two conditions incommensurable since the two were highly correlated in accuracy and reaction time (<italic>r</italic>s&gt;.7.s, <italic>p</italic>s&lt;.001). These correlations—which are consistent with an earlier study (<xref rid="R33" ref-type="bibr">Keane et al., 2019</xref>)—are noteworthy because most visual tasks are only weakly correlated despite having high test-retest reliability (<xref rid="R22" ref-type="bibr">Grzeczkowski et al., 2017</xref>). Such correlations, coupled with the a priori considerations of there being shared processes (see <xref rid="S2" ref-type="sec">Methods</xref>), suggest that the left/right task successfully controlled for processes that were not of central interest (visual short term memory, spatial attention, vigilance, etc.).</p>
        <p id="P56">Another objection is that eye movement differences could have confounded our results. This objection is weakened by five considerations: 1) all subjects were repeatedly asked to fixate within and outside of the scanner; 2) pac-men locations were equidistant from fixation, equally informative within a trial, and matched between conditions, reducing the chance of systematic differences between tasks; 3) the illusory and fragmented conditions were correlated in RT and accuracy, even for the accuracy matched sub-sample (n=10; <italic>r</italic>s &gt;.8, <italic>p</italic>s&lt;.01), suggesting again that any possible eye movement differences impacted performance minimally; 4) saccading after stimulus onset would offer little benefit since saccade latency is ~200 ms (<xref rid="R70" ref-type="bibr">Sumner, 2011</xref>) and the stimuli appeared for only 250 ms at unpredictable times during a block; and, 5) there is little evidence that eye movements impact visual shape completion in non-translating displays and some evidence that it has no effect relative to a control “fragmented ” condition (<xref rid="R11" ref-type="bibr">Cox et al., 2013</xref>; see the fixational heat maps in their <xref rid="SD1" ref-type="supplementary-material">Fig. S2</xref>). Thus, while we cannot completely rule out eye movement confounds, they are unlikely to explain our results.</p>
        <p id="P57">Resting-state functional connectivity methodology is far from perfect and thus our results may be questioned on that basis alone. For example, non-neural factors such as head motion, physiological artifacts, and the scanner environment can generate correlated noise across regions; image reconstruction introduces spatial smoothing artifacts; and so on (<xref rid="R59" ref-type="bibr">Reid et al., 2019</xref>). We mitigated some of these shortcomings, for example, by using PC multiple regression (to avoid overfitting and to reduce spurious connections), by censoring high-motion frames (to avoid over-estimating short-distance connections and underestimating far-distance connections; <xref rid="R57" ref-type="bibr">Power et al., 2012</xref>), and by using smaller voxel sizes (to reduce autocorrelation between parcels). The fact that our functional connectivity matrices could generate approximate task activation results via ActFlow and the fact that our group-averaged RSFC matrix was sensible in other respects (e.g., clustering into known functional net-works, having more cross-hemisphere connections in sensory areas, see <xref rid="S17" ref-type="sec">section 3.5</xref> of the Results) suggest that our efforts to extract the functional connectome were reasonably successful.</p>
        <p id="P58">Past psychophysical studies have shown similar illusory and fragmented task performance (<xref rid="R30" ref-type="bibr">Keane et al., 2014</xref>) but in the present study the fragmented task was about 7 percent better. Why? A possible reason is that past studies required a verbal response on each trial whereas ours required a button press. The congruence between the left and right rotations and left and right button press may have conferred a small but consistent benefit perhaps by diminishing the likelihood of misremembering the mapping between keypress and response. We do not view this as problematic, since the effects arose when the congruence benefit was behaviorally eliminated—both in RT and accuracy. Therefore, while large task accuracy differences clearly alter the neural data (as in the easy versus hard contrast), smaller differences appear to have little effect.</p>
        <p id="P59">Limitations are worth noting. Although we used a nominal 2.4 mm voxel size, higher spatial resolution methods would likely provide additional insights such as whether particular parcels project backwards to specific layers—since superficial V1 and V2 layers exhibit more robust firing responses to illusory shape contours than deep layers (<xref rid="R38" ref-type="bibr">Lee and Nguyen, 2001</xref>)—or whether specific parcels are responsible for up- versus down-regulating parts of retinotopic cortex (<xref rid="R35" ref-type="bibr">Kok and de Lange, 2014</xref>). A larger sample size could have allowed us to identify additional regions, connections, and networks of shape completion, or additional associations between task activations and behavioral performance. As has already been noted, the slow hemodynamic response prevents a full description of the temporal dynamics. Additional control conditions (e.g., matching on other features such as the central energy point of the pac-men) could further support the conclusions argued above; so too could eye movement analyses. While it was not a goal to tease apart the various component processes leading up to shape completion, future investigations will need to identify the specific regions, networks, and connections associated with local edge detection, illusory contour formation, lightness induced surface spreading, surface scission, and shape perception.</p>
        <p id="P60">To summarize, the present research identified a restricted set of densely-interconnected regions that were responsive to visually completed shapes. The secondary visual network—especially area PH—played a dominant role in the process, but portions of at least four other networks were also involved, suggesting that shape completion is a distributed process. The dorsal attention network parcels appeared to coordinate activity in the secondary visual network and across cortex during visual shape completion. The frontoparietal network also appears to play a globally coordinating role. A logical next step will be to apply neurostimulation to probe parcel-wise causal interactions or electrophysiology to assess their activity flow dynamics.</p>
      </sec>
    </sec>
    <sec sec-type="supplementary-material" id="SM1">
      <title>Supplementary Material</title>
      <supplementary-material content-type="local-data" id="SD1">
        <label>mmc</label>
        <media xlink:href="NIHMS1722730-supplement-mmc.docx" orientation="portrait" id="d40e1146" position="anchor"/>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack id="S26">
      <title>Acknowledgments</title>
      <p id="P61">We thank Laura Crespo, Lisa Cruz, Dillon Smith, and Megan Serody for help in recruiting participants and collecting and organizing study data. We are also indebted to Michael Harms for assistance in finalizing the pulse sequence, and Takuya Ito and Carrisa Cocuzza for providing sample code. The authors additionally acknowledge the Office of Advanced Research Computing (OARC) at Rutgers University for providing access to the Amarel cluster and associated research computing resources (<ext-link ext-link-type="uri" xlink:href="http://oarc.rutgers.edu/">http://oarc.rutgers.edu</ext-link>).</p>
      <p id="P62">Funding</p>
      <p id="P63">This work was supported by a National Institutes of Health Mentored Career Development Award (<ext-link ext-link-type="uri" xlink:href="http://www.k01mh108783/">K01MH108783</ext-link>) to BPK.</p>
    </ack>
    <fn-group>
      <fn id="FN3">
        <p id="P64">Data/code availability</p>
        <p id="P65">Brain activity flow mapping matlab code is part of the freely-available ActFlow toolbox: <ext-link ext-link-type="uri" xlink:href="https://github.com/ColeLab/ActflowToolbox">https://github.com/ColeLab/ActflowToolbox</ext-link>. HCP minimal preprocessing pipelines are also publicly available: <ext-link ext-link-type="uri" xlink:href="https://github.com/Washington-University/HCPpipelines/releases">https://github.com/Washington-University/HCPpipelines/releases</ext-link>. The Cole Anticevic Brain Network partition can be found here: <ext-link ext-link-type="uri" xlink:href="https://github.com/ColeLab/ColeAnticevicNetPartition">https://github.com/ColeLab/ColeAnticevicNetPartition</ext-link>. Neural data are part of a larger clinical data set and will be released within 12 months on OpenNeuro.org, along with resting-state functional connectivity matrices and unthresholded task activation maps.</p>
      </fn>
      <fn id="FN4">
        <p id="P66"><bold>Dedications</bold> None.</p>
      </fn>
      <fn id="FN5">
        <p id="P67">Declaration of Competing Interest</p>
        <p id="P68">The authors declare no competing conflicts of interest.</p>
      </fn>
      <fn id="FN6">
        <p id="P69">Supplementary materials</p>
        <p id="P70">Supplementary material associated with this article can be found, in the online version, at doi: <ext-link ext-link-type="uri" xlink:href="http://www.10.1016/j.neuroimage.2021.118069">10.1016/j.neuroimage.2021.118069</ext-link>.</p>
      </fn>
      <fn id="FN7">
        <label>1</label>
        <p id="P71">Shape completion effects in IT (<xref rid="R25" ref-type="bibr">Huxlin et al., 2000</xref>; <xref rid="R62" ref-type="bibr">Sáry et al., 2008</xref>) also count as evidence for classical regions since this structure is a plausible LO homologue (<xref rid="R52" ref-type="bibr">Orban et al., 2004</xref>).</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="R1">
        <mixed-citation publication-type="journal"><name><surname>Anticevic</surname><given-names>A</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <name><surname>Murray</surname><given-names>JD</given-names></name>, <name><surname>Corlett</surname><given-names>PR</given-names></name>, <name><surname>Wang</surname><given-names>X-J</given-names></name>, <name><surname>Krystal</surname><given-names>JH</given-names></name>, <year>2012</year>. <article-title>The role of default network deactivation in cognition and disease</article-title>. <source>Trends Cogn. Sci. (Regul Ed)</source><volume>16</volume>, <fpage>584</fpage>–<lpage>592</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.tics.2012.10.008</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R2">
        <mixed-citation publication-type="journal"><name><surname>Bar</surname><given-names>M</given-names></name>, <year>2003</year>. <article-title>A cortical mechanism for triggering top-down facilitation in visual object recognition</article-title>. <source>J. Cogn. Neurosci</source><volume>15</volume>, <fpage>600</fpage>–<lpage>609</lpage>. doi: <pub-id pub-id-type="doi">10.1162/089892903321662976</pub-id><comment>.</comment><pub-id pub-id-type="pmid">12803970</pub-id></mixed-citation>
      </ref>
      <ref id="R3">
        <mixed-citation publication-type="journal"><name><surname>Beck</surname><given-names>J</given-names></name>, <year>1966</year>. <article-title>Effect of orientation and of shape similarity on perceptual grouping</article-title>. <source>Percept. Psychophys</source><volume>1</volume>, <fpage>300</fpage>–<lpage>302</lpage>.</mixed-citation>
      </ref>
      <ref id="R4">
        <mixed-citation publication-type="journal"><name><surname>Benjamini</surname><given-names>Y</given-names></name>, <name><surname>Hochberg</surname><given-names>J</given-names></name>, <year>1995</year>. <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>. <source>J. R. Stat. Soc. Ser. B-Methodol</source><volume>57</volume>, <fpage>289</fpage>–<lpage>300</lpage>.</mixed-citation>
      </ref>
      <ref id="R5">
        <mixed-citation publication-type="journal"><name><surname>Bhandari</surname><given-names>R</given-names></name>, <name><surname>Kirilina</surname><given-names>E</given-names></name>, <name><surname>Caan</surname><given-names>M</given-names></name>, <name><surname>Suttrup</surname><given-names>J</given-names></name>, <name><surname>De Sanctis</surname><given-names>T</given-names></name>, <name><surname>De Angelis</surname><given-names>L</given-names></name>, <name><surname>Keysers</surname><given-names>C</given-names></name>, <name><surname>Gazzola</surname><given-names>V</given-names></name>, <year>2020</year>. <article-title>Does higher sampling rate (multiband + SENSE) improve group statistics - an example from social neuroscience block design at 3T</article-title>. <source>Neuroimage</source><volume>213</volume>, <comment>116731.</comment> doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116731</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R6">
        <mixed-citation publication-type="journal"><name><surname>Cavada</surname><given-names>C</given-names></name>, <name><surname>Goldman-Rakic</surname><given-names>PS</given-names></name>, <year>1989</year>. <article-title>Posterior parietal cortex in rhesus monkey: II. Evidence for segregated corticocortical networks linking sensory and limbic areas with the frontal lobe</article-title>. <source>J. Comp. Neurol</source><volume>287</volume>, <fpage>422</fpage>–<lpage>445</lpage>. doi: <pub-id pub-id-type="doi">10.1002/cne.902870403</pub-id><comment>.</comment><pub-id pub-id-type="pmid">2477406</pub-id></mixed-citation>
      </ref>
      <ref id="R7">
        <mixed-citation publication-type="journal"><name><surname>Ciaramelli</surname><given-names>E</given-names></name>, <name><surname>Leo</surname><given-names>F</given-names></name>, <name><surname>Del Viva</surname><given-names>MM</given-names></name>, <name><surname>Burr</surname><given-names>DC</given-names></name>, <name><surname>Ladavas</surname><given-names>E</given-names></name>, <year>2007</year>. <article-title>The contribution of prefrontal cortex to global perception</article-title>. <source>Exp. Brain Res</source><volume>181</volume>, <fpage>427</fpage>–<lpage>434</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00221-007-0939-7</pub-id><comment>.</comment><pub-id pub-id-type="pmid">17401551</pub-id></mixed-citation>
      </ref>
      <ref id="R8">
        <mixed-citation publication-type="journal"><name><surname>Ciric</surname><given-names>R</given-names></name>, <name><surname>Wolf</surname><given-names>DH</given-names></name>, <name><surname>Power</surname><given-names>JD</given-names></name>, <name><surname>Roalf</surname><given-names>DR</given-names></name>, <name><surname>Baum</surname><given-names>GL</given-names></name>, <name><surname>Ruparel</surname><given-names>K</given-names></name>, <name><surname>Shinohara</surname><given-names>RT</given-names></name>, <name><surname>Elliott</surname><given-names>MA</given-names></name>, <name><surname>Eickhoff</surname><given-names>SB</given-names></name>, <name><surname>Davatzikos</surname><given-names>C</given-names></name>, <name><surname>Gur</surname><given-names>RC</given-names></name>, <name><surname>Gur</surname><given-names>RE</given-names></name>, <name><surname>Bassett</surname><given-names>DS</given-names></name>, <name><surname>Satterthwaite</surname><given-names>TD</given-names></name>, <year>2017</year>. <article-title>Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity</article-title>. <source>Neuroimage</source><volume>154</volume>, <fpage>174</fpage>–<lpage>187</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.03.020</pub-id><comment>.</comment><pub-id pub-id-type="pmid">28302591</pub-id></mixed-citation>
      </ref>
      <ref id="R9">
        <mixed-citation publication-type="journal"><name><surname>Cole</surname><given-names>MW</given-names></name>, <name><surname>Bassett</surname><given-names>DS</given-names></name>, <name><surname>Power</surname><given-names>JD</given-names></name>, <name><surname>Braver</surname><given-names>TS</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <year>2014</year>. <article-title>Intrinsic and task-evoked network architectures of the human brain</article-title>. <source>Neuron</source><volume>83</volume>, <fpage>238</fpage>–<lpage>251</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.014</pub-id><comment>.</comment><pub-id pub-id-type="pmid">24991964</pub-id></mixed-citation>
      </ref>
      <ref id="R10">
        <mixed-citation publication-type="journal"><name><surname>Cole</surname><given-names>MW</given-names></name>, <name><surname>Ito</surname><given-names>T</given-names></name>, <name><surname>Bassett</surname><given-names>DS</given-names></name>, <name><surname>Schultz</surname><given-names>DH</given-names></name>, <year>2016</year>. <article-title>Activity flow over restingstate networks shapes cognitive task activations</article-title>. <source>Nature Neurosci</source><volume>19</volume>, <fpage>1718</fpage>–<lpage>1726</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nn.4406</pub-id><comment>.</comment><pub-id pub-id-type="pmid">27723746</pub-id></mixed-citation>
      </ref>
      <ref id="R11">
        <mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>MA</given-names></name>, <name><surname>Schmid</surname><given-names>MC</given-names></name>, <name><surname>Peters</surname><given-names>AJ</given-names></name>, <name><surname>Saunders</surname><given-names>RC</given-names></name>, <name><surname>Leopold</surname><given-names>DA</given-names></name>, <name><surname>Maier</surname><given-names>A</given-names></name>, <year>2013</year>. <article-title>Receptive field focus of visual area V4 neurons determines responses to illusory surfaces</article-title>. <source>Proc. Natl Acad. Sci. USA</source><volume>110</volume>, <fpage>17095</fpage>–<lpage>17100</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1310806110/-/DCSupplemental</pub-id><comment>.</comment><pub-id pub-id-type="pmid">24085849</pub-id></mixed-citation>
      </ref>
      <ref id="R12">
        <mixed-citation publication-type="journal"><name><surname>Csibra</surname><given-names>G</given-names></name>, <name><surname>Davis</surname><given-names>G</given-names></name>, <name><surname>Spratling</surname><given-names>MW</given-names></name>, <name><surname>Johnson</surname><given-names>MH</given-names></name>, <year>2000</year>. <article-title>Gamma oscillations and object processing in the infant brain</article-title>. <source>Science</source><volume>290</volume>, <fpage>1582</fpage>–<lpage>1585</lpage>.<pub-id pub-id-type="pmid">11090357</pub-id></mixed-citation>
      </ref>
      <ref id="R13">
        <mixed-citation publication-type="journal"><name><surname>Desimone</surname><given-names>R</given-names></name>, <name><surname>Duncan</surname><given-names>J</given-names></name>, <year>1995</year>. <article-title>Neural mechanisms of selective visual attention</article-title>. <source>Annu. Rev. Neurosci</source><volume>18</volume>, <fpage>193</fpage>–<lpage>222</lpage>.<pub-id pub-id-type="pmid">7605061</pub-id></mixed-citation>
      </ref>
      <ref id="R14">
        <mixed-citation publication-type="journal"><name><surname>Doniger</surname><given-names>GM</given-names></name>, <name><surname>Foxe</surname><given-names>JJ</given-names></name>, <name><surname>Murray</surname><given-names>MM</given-names></name>, <name><surname>Higgins</surname><given-names>BA</given-names></name>, <name><surname>Javitt</surname><given-names>DC</given-names></name>, <year>2002</year>. <article-title>Impaired visual object recognition and dorsal/ventral stream interaction in schizophrenia</article-title>. <source>Arch. Gen. Psychiatry</source><volume>59</volume>, <fpage>1011</fpage>–<lpage>1020</lpage>.<pub-id pub-id-type="pmid">12418934</pub-id></mixed-citation>
      </ref>
      <ref id="R15">
        <mixed-citation publication-type="journal"><name><surname>Esteban</surname><given-names>O</given-names></name>, <name><surname>Birman</surname><given-names>D</given-names></name>, <name><surname>Schaer</surname><given-names>M</given-names></name>, <name><surname>Koyejo</surname><given-names>OO</given-names></name>, <name><surname>Poldrack</surname><given-names>RA</given-names></name>, <name><surname>Gorgolewski</surname><given-names>KJ</given-names></name>, <year>2017</year>. <article-title>MRIQC: Advancing the automatic prediction of image quality in MRI from unseen sites</article-title>. <source>PLoS One</source><volume>12</volume>, <comment>e0184661.</comment> doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0184661.s001</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R16">
        <mixed-citation publication-type="journal"><name><surname>Foxe</surname><given-names>JJ</given-names></name>, <name><surname>Murray</surname><given-names>MM</given-names></name>, <name><surname>Javitt</surname><given-names>DC</given-names></name>, <year>2005</year>. <article-title>Filling-in in schizophrenia: a high-density electrical mapping and source-analysis investigation of illusory contour processing</article-title>. <source>Cereb. Cortex</source><volume>15</volume>, <fpage>1914</fpage>–<lpage>1927</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/bhi069</pub-id>.<pub-id pub-id-type="pmid">15772373</pub-id></mixed-citation>
      </ref>
      <ref id="R17">
        <mixed-citation publication-type="journal"><name><surname>Gilaie-Dotan</surname><given-names>S</given-names></name>, <name><surname>Perry</surname><given-names>A</given-names></name>, <name><surname>Bonneh</surname><given-names>Y</given-names></name>, <name><surname>Malach</surname><given-names>R</given-names></name>, <name><surname>Bentin</surname><given-names>S</given-names></name>, <year>2009</year>. <article-title>Seeing with pro-foundly deactivated mid-level visual areas: non-hierarchical functioning in the human visual cortex</article-title>. <source>Cerebral Cortex</source><volume>19</volume>, <fpage>1687</fpage>–<lpage>1703</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/bhn205</pub-id><comment>.</comment><pub-id pub-id-type="pmid">19015369</pub-id></mixed-citation>
      </ref>
      <ref id="R18">
        <mixed-citation publication-type="journal"><name><surname>Glasser</surname><given-names>MF</given-names></name>, <name><surname>Coalson</surname><given-names>TS</given-names></name>, <name><surname>Robinson</surname><given-names>EC</given-names></name>, <name><surname>Hacker</surname><given-names>CD</given-names></name>, <name><surname>Harwell</surname><given-names>J</given-names></name>, <name><surname>Yacoub</surname><given-names>E</given-names></name>, <name><surname>U ğurbil</surname><given-names>K</given-names></name>, <name><surname>Andersson</surname><given-names>J</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <name><surname>Jenkinson</surname><given-names>M</given-names></name>, <name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Van Essen</surname><given-names>DC</given-names></name>, <year>2016</year>. <article-title>A multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source><volume>536</volume>, <fpage>171</fpage>–<lpage>178</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature18933</pub-id><comment>.</comment><pub-id pub-id-type="pmid">27437579</pub-id></mixed-citation>
      </ref>
      <ref id="R19">
        <mixed-citation publication-type="journal"><name><surname>Glasser</surname><given-names>MF</given-names></name>, <name><surname>Sotiropoulos</surname><given-names>SN</given-names></name>, <name><surname>Wilson</surname><given-names>JA</given-names></name>, <name><surname>Coalson</surname><given-names>TS</given-names></name>, <name><surname>Fischl</surname><given-names>B</given-names></name>, <name><surname>Andersson</surname><given-names>JL</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Jbabdi</surname><given-names>S</given-names></name>, <name><surname>Webster</surname><given-names>M</given-names></name>, <name><surname>Polimeni</surname><given-names>JR</given-names></name>, <name><surname>Van Essen</surname><given-names>DC</given-names></name>, <name><surname>Jenkinson</surname><given-names>M</given-names></name>, <name><surname>Consortium</surname><given-names>FTW-MH</given-names></name>, <year>2013</year>. <article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>105</fpage>–<lpage>124</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23668970</pub-id></mixed-citation>
      </ref>
      <ref id="R20">
        <mixed-citation publication-type="journal"><name><surname>Gold</surname><given-names>JM</given-names></name>, <name><surname>Murray</surname><given-names>RF</given-names></name>, <name><surname>Bennett</surname><given-names>PJ</given-names></name>, <name><surname>Sekuler</surname><given-names>AB</given-names></name>, <year>2000</year>. <article-title>Deriving behavioural receptive fields for visually completed contours</article-title>. <source>Curr. Biol</source><volume>10</volume>, <fpage>663</fpage>–<lpage>666</lpage>.<pub-id pub-id-type="pmid">10837252</pub-id></mixed-citation>
      </ref>
      <ref id="R21">
        <mixed-citation publication-type="journal"><name><surname>Grosof</surname><given-names>DH</given-names></name>, <name><surname>Shapley</surname><given-names>RM</given-names></name>, <name><surname>Hawken</surname><given-names>MJ</given-names></name>, <year>1993</year>. <article-title>Macaque V1 neurons can signal “illusory” contours</article-title>. <source>Nature</source><volume>365</volume>, <fpage>550</fpage>–<lpage>552</lpage>. doi: <pub-id pub-id-type="doi">10.1038/365550a0</pub-id><comment>.</comment><pub-id pub-id-type="pmid">8413610</pub-id></mixed-citation>
      </ref>
      <ref id="R22">
        <mixed-citation publication-type="journal"><name><surname>Grzeczkowski</surname><given-names>L</given-names></name>, <name><surname>Clarke</surname><given-names>AM</given-names></name>, <name><surname>Francis</surname><given-names>G</given-names></name>, <name><surname>Mast</surname><given-names>FW</given-names></name>, <name><surname>Herzog</surname><given-names>MH</given-names></name>, <year>2017</year>. <article-title>About individual differences in vision</article-title>. <source>Vision Res</source>. <volume>141</volume>, <fpage>282</fpage>–<lpage>292</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.visres.2016.10.006</pub-id><comment>.</comment><pub-id pub-id-type="pmid">27919676</pub-id></mixed-citation>
      </ref>
      <ref id="R23">
        <mixed-citation publication-type="journal"><name><surname>Halgren</surname><given-names>E</given-names></name>, <name><surname>Mendola</surname><given-names>J</given-names></name>, <name><surname>Chong</surname><given-names>CDR</given-names></name>, <name><surname>Dale</surname><given-names>AM</given-names></name>, <year>2003</year>. <article-title>Cortical activation to illusory shapes as measured with magnetoencephalography</article-title>. <source>Neuroimage</source><volume>18</volume>, <fpage>1001</fpage>–<lpage>1009</lpage>.<pub-id pub-id-type="pmid">12725774</pub-id></mixed-citation>
      </ref>
      <ref id="R24">
        <mixed-citation publication-type="journal"><name><surname>Haynes</surname><given-names>J-D</given-names></name>, <year>2015</year>. <article-title>A primer on pattern-based approaches to fmri: principles, pitfalls, and perspectives</article-title>. <source>Neuron</source><volume>87</volume>, <fpage>257</fpage>–<lpage>270</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.025</pub-id><comment>.</comment><pub-id pub-id-type="pmid">26182413</pub-id></mixed-citation>
      </ref>
      <ref id="R25">
        <mixed-citation publication-type="journal"><name><surname>Huxlin</surname><given-names>KR</given-names></name>, <name><surname>Saunders</surname><given-names>RC</given-names></name>, <name><surname>Marchionini</surname><given-names>D</given-names></name>, <name><surname>Pham</surname><given-names>HA</given-names></name>, <name><surname>Merigan</surname><given-names>WH</given-names></name>, <year>2000</year>. <article-title>Perceptual deficits after lesions of inferotemporal cortex in macaques</article-title>. <source>Cereb. Cortex</source><volume>10</volume>, <fpage>671</fpage>–<lpage>683</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/10.7.671</pub-id><comment>.</comment><pub-id pub-id-type="pmid">10906314</pub-id></mixed-citation>
      </ref>
      <ref id="R26">
        <mixed-citation publication-type="journal"><name><surname>Iacaruso</surname><given-names>MF</given-names></name>, <name><surname>Gasler</surname><given-names>IT</given-names></name>, <name><surname>Hofer</surname><given-names>SB</given-names></name>, <year>2017</year>. <article-title>Synaptic organization of visual space in primary visual cortex</article-title>. <source>Nature</source><volume>547</volume>, <fpage>449</fpage>–<lpage>452</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature23019</pub-id><comment>.</comment><pub-id pub-id-type="pmid">28700575</pub-id></mixed-citation>
      </ref>
      <ref id="R27">
        <mixed-citation publication-type="journal"><name><surname>Ito</surname><given-names>T</given-names></name>, <name><surname>Kulkarni</surname><given-names>KR</given-names></name>, <name><surname>Schultz</surname><given-names>DH</given-names></name>, <name><surname>Mill</surname><given-names>RD</given-names></name>, <name><surname>Chen</surname><given-names>RH</given-names></name>, <name><surname>Solomyak</surname><given-names>LI</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <year>2017</year>. <article-title>Cognitive task information is transferred between brain regions via resting-state network topology</article-title>. <source>Nat. Comms</source><volume>8</volume>, <fpage>1027</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41467-017-01000-w</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R28">
        <mixed-citation publication-type="journal"><name><surname>Ji</surname><given-names>JL</given-names></name>, <name><surname>Spronk</surname><given-names>M</given-names></name>, <name><surname>Kulkarni</surname><given-names>K</given-names></name>, <name><surname>Repovs</surname><given-names>G</given-names></name>, <name><surname>Anticevic</surname><given-names>A</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <year>2019</year>. <article-title>Mapping the human brain’s cortical-subcortical functional network organization</article-title>. <source>Neuroimage</source><volume>185</volume>, <fpage>35</fpage>–<lpage>57</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.006</pub-id><comment>.</comment><pub-id pub-id-type="pmid">30291974</pub-id></mixed-citation>
      </ref>
      <ref id="R29">
        <mixed-citation publication-type="journal"><name><surname>Keane</surname><given-names>BP</given-names></name>, <year>2018</year>. <article-title>Contour interpolation: a case study in modularity of mind</article-title>. <source>Cognition</source><volume>174</volume>, <fpage>1</fpage>–<lpage>18</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cognition.2018.01.008</pub-id><comment>.</comment><pub-id pub-id-type="pmid">29407601</pub-id></mixed-citation>
      </ref>
      <ref id="R30">
        <mixed-citation publication-type="journal"><name><surname>Keane</surname><given-names>BP</given-names></name>, <name><surname>Joseph</surname><given-names>J</given-names></name>, <name><surname>Silverstein</surname><given-names>SM</given-names></name>, <year>2014</year>. <article-title>Late, not early, stages of Kanizsa shape perception are compromised in schizophrenia</article-title>. <source>Neuropsychologia</source><volume>56</volume>, <fpage>302</fpage>–<lpage>311</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.02.001</pub-id>.<pub-id pub-id-type="pmid">24513023</pub-id></mixed-citation>
      </ref>
      <ref id="R31">
        <mixed-citation publication-type="journal"><name><surname>Keane</surname><given-names>BP</given-names></name>, <name><surname>Lu</surname><given-names>H</given-names></name>, <name><surname>Kellman</surname><given-names>PJ</given-names></name>, <year>2007</year>. <article-title>Classification images reveal spatiotemporal con- tour interpolation</article-title>. <source>Vision Res</source>. <volume>47</volume>, <fpage>3460</fpage>–<lpage>3475</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.visres.2007.10.003</pub-id><comment>.</comment><pub-id pub-id-type="pmid">18053850</pub-id></mixed-citation>
      </ref>
      <ref id="R32">
        <mixed-citation publication-type="journal"><name><surname>Keane</surname><given-names>BP</given-names></name>, <name><surname>Lu</surname><given-names>H</given-names></name>, <name><surname>Papathomas</surname><given-names>TV</given-names></name>, <name><surname>Silverstein</surname><given-names>SM</given-names></name>, <name><surname>Kellman</surname><given-names>PJ</given-names></name>, <year>2012</year>. <article-title>Is interpolation cognitively encapsulated? Measuring the effects of belief on Kanizsa shape discrimination and illusory contour formation</article-title>. <source>Cognition</source><volume>123</volume>, <fpage>404</fpage>–<lpage>418</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cognition.2012.02.004</pub-id><comment>.</comment><pub-id pub-id-type="pmid">22440789</pub-id></mixed-citation>
      </ref>
      <ref id="R33">
        <mixed-citation publication-type="journal"><name><surname>Keane</surname><given-names>BP</given-names></name>, <name><surname>Paterno</surname><given-names>D</given-names></name>, <name><surname>Kastner</surname><given-names>S</given-names></name>, <name><surname>Krekelberg</surname><given-names>B</given-names></name>, <name><surname>Silverstein</surname><given-names>SM</given-names></name>, <year>2019</year>. <article-title>In- tact illusory contour formation but equivalently impaired visual shape completion in first- and later-episode schizophrenia</article-title>. <source>J. Abnorm. Psychol</source><volume>128</volume>, <fpage>57</fpage>–<lpage>68</lpage>. doi: <pub-id pub-id-type="doi">10.1037/abn0000384</pub-id>.<pub-id pub-id-type="pmid">30346202</pub-id></mixed-citation>
      </ref>
      <ref id="R34">
        <mixed-citation publication-type="journal"><name><surname>Kellman</surname><given-names>PJ</given-names></name>, <name><surname>Shipley</surname><given-names>T</given-names></name>, <year>1991</year>. <article-title>A theory of visual interpolation in object perception</article-title>. <source>Cogn. Psychol</source><volume>23</volume>, <fpage>141</fpage>.<pub-id pub-id-type="pmid">2055000</pub-id></mixed-citation>
      </ref>
      <ref id="R35">
        <mixed-citation publication-type="journal"><name><surname>Kok</surname><given-names>P</given-names></name>, <name><surname>de Lange</surname><given-names>FP</given-names></name>, <year>2014</year>. <article-title>Shape perception simultaneously up- and downregulates neural activity in the primary visual cortex</article-title>. <source>Curr. Biol</source><volume>24</volume>, <fpage>1531</fpage>–<lpage>1535</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cub.2014.05.042</pub-id>.<pub-id pub-id-type="pmid">24980501</pub-id></mixed-citation>
      </ref>
      <ref id="R36">
        <mixed-citation publication-type="journal"><name><surname>Kruggel</surname><given-names>F</given-names></name>, <name><surname>Herrmann</surname><given-names>CS</given-names></name>, <name><surname>Wiggins</surname><given-names>CJ</given-names></name>, <name><surname>von Cramon</surname><given-names>DY</given-names></name>, <year>2001</year>. <article-title>Hemodynamic and electroencephalographic responses to illusory figures: recording of the evoked potentials during functional MRI</article-title>. <source>Neuroimage</source><volume>14</volume>, <fpage>1327</fpage>–<lpage>1336</lpage>. doi: <pub-id pub-id-type="doi">10.1006/nimg.2001.0948</pub-id><comment>.</comment><pub-id pub-id-type="pmid">11707088</pub-id></mixed-citation>
      </ref>
      <ref id="R37">
        <mixed-citation publication-type="journal"><name><surname>Larsson</surname><given-names>J</given-names></name>, <name><surname>Amunts</surname><given-names>K</given-names></name>, <name><surname>Gulyás</surname><given-names>B</given-names></name>, <name><surname>Malikovic</surname><given-names>A</given-names></name>, <name><surname>Zilles</surname><given-names>K</given-names></name>, <name><surname>Roland</surname><given-names>PE</given-names></name>, <year>1999</year>. <article-title>Neuronal correlates of real and illusory contour perception: functional anatomy with PET</article-title>. <source>Eur. J. Neurosci</source><volume>11</volume>, <fpage>4024</fpage>–<lpage>4036</lpage>. doi: <pub-id pub-id-type="doi">10.1046/j.1460-9568.1999.00805.x</pub-id>.<pub-id pub-id-type="pmid">10583491</pub-id></mixed-citation>
      </ref>
      <ref id="R38">
        <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>T</given-names></name>, <name><surname>Nguyen</surname><given-names>M</given-names></name>, <year>2001</year>. <article-title>Dynamics of subjective contour formation in the early visual cortex</article-title>. <source>Proc. Nat. Acad. Sci</source><volume>98</volume>, <fpage>1907</fpage>–<lpage>1911</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.031579998</pub-id>.<pub-id pub-id-type="pmid">11172049</pub-id></mixed-citation>
      </ref>
      <ref id="R39">
        <mixed-citation publication-type="journal"><name><surname>Maertens</surname><given-names>M</given-names></name>, <name><surname>Pollmann</surname><given-names>S</given-names></name>, <name><surname>Hanke</surname><given-names>M</given-names></name>, <name><surname>Mildner</surname><given-names>T</given-names></name>, <name><surname>Möller</surname><given-names>H</given-names></name>, <year>2008</year>. <article-title>Retinotopic activation in response to subjective contours in primary visual cortex</article-title>. <source>Front. Hum. Neurosci</source><volume>2</volume>, <fpage>2</fpage>. doi: <pub-id pub-id-type="doi">10.3389/neuro.09.002.2008</pub-id><comment>.</comment><pub-id pub-id-type="pmid">18958203</pub-id></mixed-citation>
      </ref>
      <ref id="R40">
        <mixed-citation publication-type="journal"><name><surname>Malikovic</surname><given-names>A</given-names></name>, <name><surname>Amunts</surname><given-names>K</given-names></name>, <name><surname>Schleicher</surname><given-names>A</given-names></name>, <name><surname>Mohlberg</surname><given-names>H</given-names></name>, <name><surname>Kujovic</surname><given-names>M</given-names></name>, <name><surname>Palomero-Gallagher</surname><given-names>N</given-names></name>, <name><surname>Eickhoff</surname><given-names>SB</given-names></name>, <name><surname>Zilles</surname><given-names>K</given-names></name>, <year>2016</year>. <article-title>Cytoarchitecture of the human lateral occipital cortex: mapping of two extrastriate areas hOc4la and hOc4lp</article-title>. <source>Brain Struct. Funct</source><volume>221</volume>, <fpage>1877</fpage>–<lpage>1897</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00429-015-1009-8</pub-id><comment>.</comment><pub-id pub-id-type="pmid">25687261</pub-id></mixed-citation>
      </ref>
      <ref id="R41">
        <mixed-citation publication-type="journal"><name><surname>McMains</surname><given-names>SA</given-names></name>, <name><surname>Kastner</surname><given-names>S</given-names></name>, <year>2010</year>. <article-title>Defining the units of competition: influences of perceptual organization on competitive interactions in human visual cortex</article-title>. <source>J. Cogn. Neurosci</source><volume>22</volume>, <fpage>2417</fpage>–<lpage>2426</lpage>. doi: <pub-id pub-id-type="doi">10.1162/jocn.2009.21391</pub-id>.<pub-id pub-id-type="pmid">19925189</pub-id></mixed-citation>
      </ref>
      <ref id="R42">
        <mixed-citation publication-type="journal"><name><surname>Mendola</surname><given-names>JD</given-names></name>, <name><surname>Dale</surname><given-names>AM</given-names></name>, <name><surname>Fischl</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>AK</given-names></name>, <name><surname>Tootell</surname><given-names>RB</given-names></name> , <year>1999</year>. <article-title>The representation of illusory and real contours in human cortical visual areas revealed by functional magnetic resonance imaging</article-title>. <source>J. Neurosci</source>
<volume>19</volume>, <fpage>8560</fpage>–<lpage>8572</lpage>.<pub-id pub-id-type="pmid">10493756</pub-id></mixed-citation>
      </ref>
      <ref id="R43">
        <mixed-citation publication-type="journal"><name><surname>Merboldt</surname><given-names>K-D</given-names></name>, <name><surname>Finsterbusch</surname><given-names>J</given-names></name>, <name><surname>Frahm</surname><given-names>J</given-names></name>, <year>2000</year>. <article-title>Reducing inhomogeneity artifacts in functional MRI of human brain activation—thin sections vs gradient compensation</article-title>. <source>J. Magnetic Resonance</source><volume>145</volume>, <fpage>184</fpage>–<lpage>191</lpage>. doi: <pub-id pub-id-type="doi">10.1006/jmre.2000.2105</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R44">
        <mixed-citation publication-type="journal"><name><surname>Mill</surname><given-names>RD</given-names></name>, <name><surname>Gordon</surname><given-names>BA</given-names></name>, <name><surname>Balota</surname><given-names>DA</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <year>2020</year>. <article-title>Predicting dysfunctional age-related task activations from resting-state network alterations</article-title>. <source>Neuroimage</source>, <comment>117167</comment> doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117167</pub-id>, –37 .</mixed-citation>
      </ref>
      <ref id="R45">
        <mixed-citation publication-type="journal"><name><surname>Monzalvo</surname><given-names>K</given-names></name>, <name><surname>Fluss</surname><given-names>J</given-names></name>, <name><surname>Billard</surname><given-names>C</given-names></name>, <name><surname>Dehaene</surname><given-names>S</given-names></name>, <name><surname>Dehaene-Lambertz</surname><given-names>G</given-names></name>, <year>2012</year>. <article-title>Cortical networks for vision and language in dyslexic and normal children of variable socioeconomic status</article-title>. <source>Neuroimage</source><volume>61</volume>, <fpage>258</fpage>–<lpage>274</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.02.035</pub-id><comment>.</comment><pub-id pub-id-type="pmid">22387166</pub-id></mixed-citation>
      </ref>
      <ref id="R46">
        <mixed-citation publication-type="journal"><name><surname>Mur</surname><given-names>M</given-names></name>, <name><surname>Bandettini</surname><given-names>PA</given-names></name>, <name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <year>2009</year>. <article-title>Revealing representational content with pattern-information fMRI–an introductory guide</article-title>. <source>Soc. Cogn. Affect. Neurosci</source><volume>4</volume>, <fpage>101</fpage>–<lpage>109</lpage>. doi: <pub-id pub-id-type="doi">10.1093/scan/nsn044</pub-id>.<pub-id pub-id-type="pmid">19151374</pub-id></mixed-citation>
      </ref>
      <ref id="R47">
        <mixed-citation publication-type="journal"><name><surname>Murray</surname><given-names>M</given-names></name>, <name><surname>Wylie</surname><given-names>G</given-names></name>, <name><surname>Higgins</surname><given-names>B</given-names></name>, <name><surname>Javitt</surname><given-names>D</given-names></name>, <name><surname>Schroeder</surname><given-names>C</given-names></name>, <name><surname>Foxe</surname><given-names>J</given-names></name>, <year>2002</year>. <article-title>The spatiotemporal dynamics of illusory contour processing: combined high-density electrical map- ping, source analysis, and functional magnetic resonance imaging</article-title>. <source>J. Neurosci</source><volume>22</volume>, <fpage>5055</fpage>.<pub-id pub-id-type="pmid">12077201</pub-id></mixed-citation>
      </ref>
      <ref id="R48">
        <mixed-citation publication-type="journal"><name><surname>Murray</surname><given-names>MM</given-names></name>, <name><surname>Foxe</surname><given-names>DM</given-names></name>, <name><surname>Javitt</surname><given-names>DC</given-names></name>, <name><surname>Foxe</surname><given-names>JJ</given-names></name>, <year>2004</year>. <article-title>Setting boundaries: brain dynamics of modal and amodal illusory shape completion in humans</article-title>. <source>J. Neurosci</source><volume>24</volume>, <fpage>6898</fpage>–<lpage>6903</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1996-04.2004</pub-id><comment>.</comment><pub-id pub-id-type="pmid">15295024</pub-id></mixed-citation>
      </ref>
      <ref id="R49">
        <mixed-citation publication-type="journal"><name><surname>Murray</surname><given-names>MM</given-names></name>, <name><surname>Herrmann</surname><given-names>CS</given-names></name>, <year>2013</year>. <article-title>Illusory contours: a window onto the neurophysiology of constructing perception</article-title>. <source>Trends Cogn. Sci. (Regul Ed.)</source> doi: <pub-id pub-id-type="doi">10.1016/j.tics.2013.07.004</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R50">
        <mixed-citation publication-type="journal"><name><surname>Murray</surname><given-names>MM</given-names></name>, <name><surname>Imber</surname><given-names>ML</given-names></name>, <name><surname>Javitt</surname><given-names>DC</given-names></name>, <name><surname>Foxe</surname><given-names>JJ</given-names></name>, <year>2006</year>. <article-title>Boundary completion is automatic and dissociable from shape discrimination</article-title>. <source>J. Neurosci</source><volume>26</volume>, <fpage>12043</fpage>–<lpage>12054</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3225-06.2006</pub-id><comment>.</comment><pub-id pub-id-type="pmid">17108178</pub-id></mixed-citation>
      </ref>
      <ref id="R51">
        <mixed-citation publication-type="journal"><name><surname>Nieder</surname><given-names>A</given-names></name>, <year>2002</year>. <article-title>Seeing more than meets the eye: processing of illusory contours in animals</article-title>. <source>J. Comp. Physiol. A Neuroethol. Sens. Neural Behav. Physiol</source><volume>188</volume>, <fpage>249</fpage>–<lpage>260</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00359-002-0306-x</pub-id><comment>.</comment><pub-id pub-id-type="pmid">12012096</pub-id></mixed-citation>
      </ref>
      <ref id="R52">
        <mixed-citation publication-type="journal"><name><surname>Orban</surname><given-names>GA</given-names></name>, <name><surname>Van Essen</surname><given-names>D</given-names></name>, <name><surname>Vanduffel</surname><given-names>W</given-names></name>, <year>2004</year>. <article-title>Comparative mapping of higher visual areas in monkeys and humans</article-title>. <source>Trends Cogn. Sci. (Regul. Ed.)</source><volume>8</volume>, <fpage>315</fpage>–<lpage>324</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.tics.2004.05.009</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R53">
        <mixed-citation publication-type="journal"><name><surname>Ostrovsky</surname><given-names>Y</given-names></name>, <name><surname>Meyers</surname><given-names>E</given-names></name>, <name><surname>Ganesh</surname><given-names>S</given-names></name>, <name><surname>Mathur</surname><given-names>U</given-names></name>, <name><surname>Sinha</surname><given-names>P</given-names></name>, <year>2009</year>. <article-title>Visual parsing after recovery from blindness</article-title>. <source>Psychol. Sci</source><volume>20</volume>, <fpage>1484</fpage>–<lpage>1491</lpage>. doi: <pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02471.x</pub-id><comment>.</comment><pub-id pub-id-type="pmid">19891751</pub-id></mixed-citation>
      </ref>
      <ref id="R54">
        <mixed-citation publication-type="journal"><name><surname>Peirce</surname><given-names>JW</given-names></name>, <year>2007</year>. <article-title>PsychoPy—psychophysics software in Python</article-title>. <source>J. Neurosci. Methods</source><volume>162</volume>, <fpage>8</fpage>–<lpage>13</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.11.017</pub-id><comment>.</comment><pub-id pub-id-type="pmid">17254636</pub-id></mixed-citation>
      </ref>
      <ref id="R55">
        <mixed-citation publication-type="journal"><name><surname>Pelli</surname><given-names>DG</given-names></name>, <year>1997</year>. <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source>Spat. Vis</source><volume>10</volume>, <fpage>437</fpage>–<lpage>442</lpage>.<pub-id pub-id-type="pmid">9176953</pub-id></mixed-citation>
      </ref>
      <ref id="R56">
        <mixed-citation publication-type="journal"><name><surname>Pillow</surname><given-names>J</given-names></name>, <name><surname>Rubin</surname><given-names>N</given-names></name>, <year>2002</year>. <article-title>Perceptual completion across the vertical meridian and the role of early visual cortex</article-title>. <source>Neuron</source><volume>33</volume>, <fpage>805</fpage>–<lpage>813</lpage>.<pub-id pub-id-type="pmid">11879656</pub-id></mixed-citation>
      </ref>
      <ref id="R57">
        <mixed-citation publication-type="journal"><name><surname>Power</surname><given-names>JD</given-names></name>, <name><surname>Barnes</surname><given-names>KA</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <year>2012</year>. <article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title>. <source>Neuroimage</source><volume>59</volume>, <fpage>2142</fpage>–<lpage>2154</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.018</pub-id><comment>.</comment><pub-id pub-id-type="pmid">22019881</pub-id></mixed-citation>
      </ref>
      <ref id="R58">
        <mixed-citation publication-type="journal"><name><surname>Power</surname><given-names>JD</given-names></name>, <name><surname>Cohen</surname><given-names>AL</given-names></name>, <name><surname>Nelson</surname><given-names>SM</given-names></name>, <name><surname>Wig</surname><given-names>GS</given-names></name>, <name><surname>Barnes</surname><given-names>KA</given-names></name>, <name><surname>Church</surname><given-names>JA</given-names></name>, <name><surname>Vo- gel</surname><given-names>AC</given-names></name>, <name><surname>Laumann</surname><given-names>TO</given-names></name>, <name><surname>Miezin</surname><given-names>FM</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <year>2011</year>. <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source><volume>72</volume>, <fpage>665</fpage>–<lpage>678</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.006</pub-id><comment>.</comment><pub-id pub-id-type="pmid">22099467</pub-id></mixed-citation>
      </ref>
      <ref id="R59">
        <mixed-citation publication-type="journal"><name><surname>Reid</surname><given-names>AT</given-names></name>, <name><surname>Headley</surname><given-names>DB</given-names></name>, <name><surname>Mill</surname><given-names>RD</given-names></name>, <name><surname>Sanchez-Romero</surname><given-names>R</given-names></name>, <name><surname>Uddin</surname><given-names>LQ</given-names></name>, <name><surname>Marinazzo</surname><given-names>D</given-names></name>, <name><surname>Lurie</surname><given-names>DJ</given-names></name>, <name><surname>Valdés-Sosa</surname><given-names>PA</given-names></name>, <name><surname>Hanson</surname><given-names>SJ</given-names></name>, <name><surname>Biswal</surname><given-names>BB</given-names></name>, <name><surname>Calhoun</surname><given-names>V</given-names></name>, <name><surname>Poldrack</surname><given-names>RA</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <year>2019</year>. <article-title>Advancing functional connectivity research from association to causation</article-title>. <source>Nature Neurosci</source><volume>22</volume>, <fpage>1751</fpage>–<lpage>1760</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41593-019-0510-4</pub-id><comment>.</comment><pub-id pub-id-type="pmid">31611705</pub-id></mixed-citation>
      </ref>
      <ref id="R60">
        <mixed-citation publication-type="journal"><name><surname>Revheim</surname><given-names>N</given-names></name>, <name><surname>Corcoran</surname><given-names>CM</given-names></name>, <name><surname>Dias</surname><given-names>E</given-names></name>, <name><surname>Hellmann</surname><given-names>E</given-names></name>, <name><surname>Martinez</surname><given-names>A</given-names></name>, <name><surname>Butler</surname><given-names>PD</given-names></name>, <name><surname>Lehrfeld</surname><given-names>JM</given-names></name>, <name><surname>DiCostanzo</surname><given-names>J</given-names></name>, <name><surname>Albert</surname><given-names>J</given-names></name>, <name><surname>Javitt</surname><given-names>DC</given-names></name>, <year>2014</year>. <article-title>Reading deficits in schizophrenia and individuals at high clinical risk: relationship to sensory function, course of illness, and psychosocial outcome</article-title>. <source>Am. J. Psychiatry</source><volume>171</volume>, <fpage>949</fpage>–<lpage>959</lpage>. doi: <pub-id pub-id-type="doi">10.1176/appi.ajp.2014.13091196</pub-id><comment>.</comment><pub-id pub-id-type="pmid">25178752</pub-id></mixed-citation>
      </ref>
      <ref id="R61">
        <mixed-citation publication-type="journal"><name><surname>Ringach</surname><given-names>D</given-names></name>, <name><surname>Shapley</surname><given-names>R</given-names></name>, <year>1996</year>. <article-title>Spatial and temporal properties of illusory contours and amodal boundary completion</article-title>. <source>Vision Res</source><volume>36</volume>, <fpage>3037</fpage>–<lpage>3050</lpage>.<pub-id pub-id-type="pmid">8917767</pub-id></mixed-citation>
      </ref>
      <ref id="R62">
        <mixed-citation publication-type="journal"><name><surname>Sáry</surname><given-names>G</given-names></name>, <name><surname>Köteles</surname><given-names>K</given-names></name>, <name><surname>Kaposvári</surname><given-names>P</given-names></name>, <name><surname>Lenti</surname><given-names>L</given-names></name>, <name><surname>Csifcsák</surname><given-names>G</given-names></name>, <name><surname>Frankó</surname><given-names>E</given-names></name>, <name><surname>Benedek</surname><given-names>G</given-names></name>, <name><surname>Tompa</surname><given-names>T</given-names></name>, <year>2008</year>. <article-title>The representation of Kanizsa illusory contours in the monkey inferior temporal cortex</article-title>. <source>European J. Neurosci</source><volume>28</volume>, <fpage>2137</fpage>–<lpage>2146</lpage>. doi: <pub-id pub-id-type="doi">10.3758/BF03198792</pub-id><comment>.</comment><pub-id pub-id-type="pmid">19046395</pub-id></mixed-citation>
      </ref>
      <ref id="R63">
        <mixed-citation publication-type="journal"><name><surname>Schultz</surname><given-names>DH</given-names></name>, <name><surname>Ito</surname><given-names>T</given-names></name>, <name><surname>Solomyak</surname><given-names>LI</given-names></name>, <name><surname>Chen</surname><given-names>RH</given-names></name>, <name><surname>Mill</surname><given-names>RD</given-names></name>, <name><surname>Anticevic</surname><given-names>A</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <year>2018</year>. <article-title>Global connectivity of the fronto-parietal cognitive control network is related to depression symptoms in the general population</article-title>. <source>Netw. Neurosci</source><volume>3</volume>, <fpage>107</fpage>–<lpage>123</lpage>. doi: <pub-id pub-id-type="doi">10.1162/netn_a_00056</pub-id><comment>.</comment><pub-id pub-id-type="pmid">30793076</pub-id></mixed-citation>
      </ref>
      <ref id="R64">
        <mixed-citation publication-type="journal"><name><surname>Seghier</surname><given-names>ML</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P</given-names></name>, <year>2006</year>. <article-title>Functional neuroimaging findings on the human perception of illusory contours</article-title>. <source>Neurosci. Biobehav. Rev</source><volume>30</volume>, <fpage>595</fpage>–<lpage>612</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neubiorev.2005.11.002</pub-id><comment>.</comment><pub-id pub-id-type="pmid">16457887</pub-id></mixed-citation>
      </ref>
      <ref id="R65">
        <mixed-citation publication-type="journal"><name><surname>Shpaner</surname><given-names>M</given-names></name>, <name><surname>Murray</surname><given-names>MM</given-names></name>, <name><surname>Foxe</surname><given-names>JJ</given-names></name>, <year>2009</year>. <article-title>Early processing in the human lateral occipital complex is highly responsive to illusory contours but not to salient regions</article-title>. <source>European J. Neurosci</source><volume>30</volume>, <fpage>2018</fpage>–<lpage>2028</lpage>. doi: <pub-id pub-id-type="doi">10.1111/j.1460-9568.2009.06981.x</pub-id><comment>.</comment><pub-id pub-id-type="pmid">19895562</pub-id></mixed-citation>
      </ref>
      <ref id="R66">
        <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <name><surname>Andersson</surname><given-names>J</given-names></name>, <name><surname>Auerbach</surname><given-names>EJ</given-names></name>, <name><surname>Bijsterbosch</surname><given-names>J</given-names></name>, <name><surname>Douaud</surname><given-names>G</given-names></name>, <name><surname>Duff</surname><given-names>E</given-names></name>, <name><surname>Feinberg</surname><given-names>DA</given-names></name>, <name><surname>Griffanti</surname><given-names>L</given-names></name>, <name><surname>Harms</surname><given-names>MP</given-names></name>, <name><surname>Kelly</surname><given-names>M</given-names></name>, <name><surname>Laumann</surname><given-names>T</given-names></name>, <name><surname>Miller</surname><given-names>KL</given-names></name>, <name><surname>Moeller</surname><given-names>S</given-names></name>, <name><surname>Petersen</surname><given-names>S</given-names></name>, <name><surname>Power</surname><given-names>J</given-names></name>, <name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Vu</surname><given-names>AT</given-names></name>, <name><surname>Wool- rich</surname><given-names>MW</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Yacoub</surname><given-names>E</given-names></name>, <name><surname>U ğurbil</surname><given-names>K</given-names></name>, <name><surname>Van Essen</surname><given-names>DC</given-names></name>, <name><surname>Glasser</surname><given-names>MF</given-names></name>, <year>2013</year>. <article-title>Resting-state fMRI in the human connectome project</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>144</fpage>–<lpage>168</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.039</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23702415</pub-id></mixed-citation>
      </ref>
      <ref id="R67">
        <mixed-citation publication-type="journal"><name><surname>Spronk</surname><given-names>M</given-names></name>, <name><surname>Kulkarni</surname><given-names>K</given-names></name>, <name><surname>Ji</surname><given-names>JL</given-names></name>, <name><surname>Keane</surname><given-names>BP</given-names></name>, <name><surname>Anticevic</surname><given-names>A</given-names></name>, <name><surname>Cole</surname><given-names>MW</given-names></name>, <year>2018</year>. <article-title>A whole-brain and cross-diagnostic perspective on functional brain network dysfunction</article-title>. <source>BioRxiv</source><fpage>1</fpage>–<lpage>23</lpage>. doi:<pub-id pub-id-type="doi">10.1101/326728</pub-id></mixed-citation>
      </ref>
      <ref id="R68">
        <mixed-citation publication-type="journal"><name><surname>Stanley</surname><given-names>DA</given-names></name>, <name><surname>Rubin</surname><given-names>N</given-names></name>, <year>2003</year>. <article-title>fMRI activation in response to illusory contours and salient regions in the human lateral occipital complex</article-title>. <source>Neuron</source><volume>37</volume>, <fpage>323</fpage>–<lpage>331</lpage>.<pub-id pub-id-type="pmid">12546826</pub-id></mixed-citation>
      </ref>
      <ref id="R69">
        <mixed-citation publication-type="journal"><name><surname>Stark</surname><given-names>DE</given-names></name>, <name><surname>Margulies</surname><given-names>DS</given-names></name>, <name><surname>Shehzad</surname><given-names>ZE</given-names></name>, <name><surname>Reiss</surname><given-names>P</given-names></name>, <name><surname>Kelly</surname><given-names>AMC</given-names></name>, <name><surname>Uddin</surname><given-names>LQ</given-names></name>, <name><surname>Gee</surname><given-names>DG</given-names></name>, <name><surname>Roy</surname><given-names>AK</given-names></name>, <name><surname>Banich</surname><given-names>MT</given-names></name>, <name><surname>Castellanos</surname><given-names>FX</given-names></name>, <name><surname>Milham</surname><given-names>MP</given-names></name>, <year>2008</year>. <article-title>Regional variation in interhemispheric coordination of intrinsic hemodynamic fluctuations</article-title>. <source>J. Neurosci</source><volume>28</volume>, <fpage>13754</fpage>–<lpage>13764</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4544-08.2008</pub-id>.<pub-id pub-id-type="pmid">19091966</pub-id></mixed-citation>
      </ref>
      <ref id="R70">
        <mixed-citation publication-type="book"><name><surname>Sumner</surname><given-names>P</given-names></name>, <year>2011</year>. <part-title>Determinants of saccade latency</part-title>. In: <name><surname>Liversedge</surname><given-names>S</given-names></name>, <name><surname>Gilchrist</surname><given-names>I</given-names></name>, <name><surname>Everling</surname><given-names>S</given-names></name> (Eds.), <source>The Oxford Handbook of Eye Movements</source>
<publisher-name>books.google.com</publisher-name>, <publisher-loc>New York</publisher-loc>, pp. <fpage>411</fpage>–<lpage>424</lpage>.</mixed-citation>
      </ref>
      <ref id="R71">
        <mixed-citation publication-type="journal"><name><surname>Triarhou</surname><given-names>LC</given-names></name>, <year>2007</year>. <article-title>The Economo–Koskinas atlas revisited: cytoarchitectonics and functional context</article-title>. <source>Stereotact. Funct. Neurosurg</source><volume>85</volume>, <fpage>195</fpage>–<lpage>203</lpage>. doi: <pub-id pub-id-type="doi">10.1159/000103258</pub-id>.<pub-id pub-id-type="pmid">17534132</pub-id></mixed-citation>
      </ref>
      <ref id="R72">
        <mixed-citation publication-type="journal"><name><surname>Valenza</surname><given-names>E</given-names></name>, <name><surname>Bulf</surname><given-names>H</given-names></name>, <year>2010</year>. <article-title>Early development of object unity: evidence for perceptual completion in newborns</article-title>. <source>Development. Sci</source><fpage>1</fpage>–<lpage>10</lpage>. doi: <pub-id pub-id-type="doi">10.1111/j.1467-7687.2010.01026.x</pub-id><comment>.</comment><pub-id pub-id-type="pmid">20890392</pub-id></mixed-citation>
      </ref>
      <ref id="R73">
        <mixed-citation publication-type="journal"><name><surname>Vandenbroucke</surname><given-names>ARE</given-names></name>, <name><surname>Fahrenfort</surname><given-names>JJ</given-names></name>, <name><surname>Sligte</surname><given-names>IG</given-names></name>, <name><surname>Lamme</surname><given-names>VAF</given-names></name>, <year>2014</year>. <article-title>Seeing without knowing: neural signatures of perceptual inference in the absence of report</article-title>. <source>J. Cogn. Neurosci</source><volume>26</volume>, <fpage>955</fpage>–<lpage>969</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nn1294</pub-id>.<pub-id pub-id-type="pmid">24283494</pub-id></mixed-citation>
      </ref>
      <ref id="R74">
        <mixed-citation publication-type="journal"><name><surname>Vogel</surname><given-names>AC</given-names></name>, <name><surname>Miezin</surname><given-names>FM</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <year>2012</year>. <article-title>The putative visual word form area is functionally connected to the dorsal attention network</article-title>. <source>Cerebral Cortex</source><volume>22</volume>, <fpage>537</fpage>–<lpage>549</lpage>. doi: <pub-id pub-id-type="doi">10.1093/cercor/bhr100</pub-id><comment>.</comment><pub-id pub-id-type="pmid">21690259</pub-id></mixed-citation>
      </ref>
      <ref id="R75">
        <mixed-citation publication-type="journal"><name><surname>Vuilleumier</surname><given-names>P</given-names></name>, <name><surname>Valenza</surname><given-names>N</given-names></name>, <name><surname>Landis</surname><given-names>T</given-names></name>, <year>2001</year>. <article-title>Explicit and implicit perception of illusory contours in unilateral spatial neglect: behavioural and anatomical correlates of preat-tentive grouping mechanisms</article-title>. <source>Neuropsychologia</source><volume>39</volume>, <fpage>597</fpage>–<lpage>610</lpage>.<pub-id pub-id-type="pmid">11257285</pub-id></mixed-citation>
      </ref>
      <ref id="R76">
        <mixed-citation publication-type="journal"><name><surname>Weiss</surname><given-names>F</given-names></name>, <name><surname>Greenlee</surname><given-names>MW</given-names></name>, <name><surname>Volbert</surname><given-names>G</given-names></name>, <year>2019</year>. <article-title>No atypical white-matter structures in grapheme-or color-sensitive areas in synesthetes</article-title>. <source>BioRxiv</source>. doi:<pub-id pub-id-type="doi">10.1101/618611</pub-id></mixed-citation>
      </ref>
      <ref id="R77">
        <mixed-citation publication-type="journal"><name><surname>Whitford</surname><given-names>V</given-names></name>, <name><surname>O’Driscoll</surname><given-names>GA</given-names></name>, <name><surname>Titone</surname><given-names>D</given-names></name>, <year>2018</year>. <article-title>Reading deficits in schizophrenia and their relationship to developmental dyslexia: a review</article-title>. <source>Schizophr. Res</source><volume>193</volume>, <fpage>11</fpage>–<lpage>22</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.schres.2017.06.049</pub-id><comment>.</comment><pub-id pub-id-type="pmid">28688740</pub-id></mixed-citation>
      </ref>
      <ref id="R78">
        <mixed-citation publication-type="journal"><name><surname>Wokke</surname><given-names>ME</given-names></name>, <name><surname>Vandenbroucke</surname><given-names>ARE</given-names></name>, <name><surname>Scholte</surname><given-names>HS</given-names></name>, <name><surname>Lamme</surname><given-names>VAF</given-names></name>, <year>2013</year>. <article-title>Confuse your illusion: feedback to early visual cortex contributes to perceptual completion</article-title>. <source>Psychol. Sci</source><volume>24</volume>, <fpage>63</fpage>–<lpage>71</lpage>. doi: <pub-id pub-id-type="doi">10.1177/0956797612449175</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23228938</pub-id></mixed-citation>
      </ref>
      <ref id="R79">
        <mixed-citation publication-type="journal"><name><surname>Wyatte</surname><given-names>D</given-names></name>, <name><surname>Jilk</surname><given-names>DJ</given-names></name>, <name><surname>O’Reilly</surname><given-names>RC</given-names></name>, <year>2014</year>. <article-title>Early recurrent feedback facilitates visual object recognition under challenging conditions</article-title>. <source>Front. Psychol</source><volume>5</volume>, <fpage>760</fpage>. doi: <pub-id pub-id-type="doi">10.3389/fp-syg.2014.00674</pub-id>, –10.<pub-id pub-id-type="pmid">25101028</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig id="F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <title>Stimuli, trial sequence, and block arrangement for the visual shape completion experiment.</title>
        <p id="P72">(A) Sectored circles (pac-men) were oriented to generate visually completed shapes (illusory condition) or fragmented configurations that lacked interpolated boundaries (fragmented condition). There were two difficulty conditions corresponding to the amount by which the pac-men were individually rotated to create the response alternatives. (B) After briefly seeing the target, subjects responded. (C) Each half of a run consisted of a fixation screen, a 5 second instructional screen, 25 trials of a single task condition (including 5 fixation trials), and then another fixation screen.</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0001"/>
    </fig>
    <fig id="F2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <p id="P73">FDR-corrected activation difference amplitudes (Z-normalized) for all parcels for the illusory – fragmented contrast. ROIs are shown with black outlines. The anterior and posterior views are shown laterally; the dorsal and ventral views are shown at the top and bottom. Hot colors indicate regions that were more active for the illusory versus fragmented task; cool colors indicate the reverse.</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0002"/>
    </fig>
    <fig id="F3" orientation="portrait" position="float">
      <label>Fig 3.</label>
      <caption>
        <title>Task activation differences for hard - easy trials (collapsed across illusory/fragmented).</title>
        <p id="P74">Opposite to the illusory-fragmented contrast, we found that harder trials generally elicited less activation throughout the brain relative to easier trials and the location of these significant activations overlapped little with the activations shown in <xref rid="F2" ref-type="fig">Fig. 2</xref>. The illusory/fragmented a priori ROIs (black outlines) are shown for comparison purposes only and did not contain significant parcels.</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0003"/>
    </fig>
    <fig id="F4" orientation="portrait" position="float">
      <label>Fig. 4.</label>
      <caption>
        <p id="P75">(A) The Cole-Anticevic Brain Network partition. We considered whether parcel-wise activation patterns in the cortical networks could individually classify task betas as deriving from the illusory or fragmented condition; these included the primary visual, secondary visual, somatomotor, cingulo-opercular, dorsal attention, language, frontoparietal, auditory, default, posterior multimodal, ventral multimodal, and orbito-affective networks. Networks are color coded to match the parcels in panels B and C. (B) The percentage of significantly modulated parcels that belonged to each network for the illusory/fragmented contrast. (C) Classification accuracy for the illusory/fragmented comparison. The red dot-ted line shows chance performance, the box segments denote median scores, the box hinges correspond to the 25th and 75th percentiles, and the box whiskers extend to the largest or smallest value (but no further than 1.5x the interquartile range). Only the secondary visual network could significantly predict illusory/fragmented activations (<sup>∗∗∗</sup>p<sub>corr</sub>&lt;.001). (See <xref rid="SD1" ref-type="supplementary-material">Supplementary materials</xref> for the exact parcels incorporated by this network).</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0004"/>
    </fig>
    <fig id="F5" orientation="portrait" position="float">
      <label>Fig. 5.</label>
      <caption>
        <title>Resting-state functional connectivity (RSFC) matrices.</title>
        <p id="P76">(A) Pearson correlation between the resting-state time series of all parcel pairs (360 × 360 parcels). Parcels are sorted into previously established (color-coded) functional connectivity networks (<xref rid="R28" ref-type="bibr">Ji et al., 2019</xref>) (see also <xref rid="F4" ref-type="fig">Fig. 4 A</xref>). The block-like structure along the diagonal exemplifies the stronger connectivity within relative to between each network. (B) An RSFC matrix computed via multiple regression (see <xref rid="S2" ref-type="sec">Methods</xref>). The blue/red colors indicate the degree to which a given parcel time series was predicted by all remaining parcels. Note that this matrix is much sparser than the correlational matrix since it eliminates many of the indirect connections between parcels (<xref rid="R10" ref-type="bibr">Cole et al., 2016</xref>). (C) Thresholded (FDR-corrected) resting-state connections between significantly modulated task regions (see text), which are ordered first by hemisphere and then by network. Compared to the full matrix in panel B, this pared down matrix had about 1 percent the number of possible connections (matrix elements) and triple the proportion of (FDR-corrected) significant connections. (D) Averaging the connection weights across hemisphere increased the proportion even further (from 43% to 60%), highlighting the broadly symmetric connectivity patterns. Note that one parcel, IFSa, was split between the frontoparietal (left hemisphere) and <sub>10</sub>cingulo-opercular networks (right), and was assigned to the frontoparietal network in this plot since only the frontoparietal parcel was significant in the task activation analysis.</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0005"/>
    </fig>
    <fig id="F6" orientation="portrait" position="float">
      <label>Fig. 6.</label>
      <caption>
        <title>Activity flow mapping for visual shape completion.</title>
        <p id="P77">(A) For each subject, the task activation differences (illusory-fragmented) in a held-out parcel (j) is given by the dot product between the activation differences in the remaining parcels (regions i) and the resting-state connection strengths (betas) between i and j. (B) Unthresholded z-normalized activation differences (illusory – fragmented) as compared to those that were predicted via ActFlow using resting state. (C) When a task activation analysis was applied to the data predicted from ActFlow, statistical significance (or lack thereof) was correctly determined for 82% of the 360 parcels (see also <xref rid="F2" ref-type="fig">Fig. 2</xref>). This suggests that the connection weights derived from resting state were reflective of the actual connections used during shape completion.</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0006"/>
    </fig>
    <fig id="F7" orientation="portrait" position="float">
      <label>Fig. 7.</label>
      <caption>
        <title>Gauging contributions of the dorsal attention network to the secondary visual network (Visual2).</title>
        <p id="P78">(A) For a given subject, task activation differences for each significant Visual2 parcel were estimated (dotted circles) using <italic>actual</italic> task activation differences in the remaining parcels (solid circles) and their resting-state connections (red lines). For illustration purposes, only one hemisphere is shown. (B) ActFlow accuracy was defined as the correlation between actual and estimated task activation differences, across the Visual2 parcels. (C) Task activation differences were again estimated via ActFlow, except that, this time, the connections and activation differences from the significant dorsal attention regions could also contribute. (D) The difference between the original and re-calculated estimates was computed for each subject (after a Fisher Z-transform) and compared to zero across subjects. Only the dorsal attention network could significantly improve ActFlow estimates in the secondary visual network. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p>
      </caption>
      <graphic xlink:href="nihms-1722730-f0007"/>
    </fig>
    <table-wrap id="T1" position="float" orientation="portrait">
      <label>Table 1</label>
      <caption>
        <p id="P79">Results for parcels that that were either of a priori interest or that were significant on the illusory-fragmented task activation analysis (see <xref rid="F2" ref-type="fig">Fig. 2</xref> ). The rows were sorted in descending order, first, by the percentage of subjects showing the effect in the group direction (column 2) and then, by the percentage of subjects showing significant effects on the individual subject analysis (column 3). The prefix of each parcel name (“L_“or“R_”) indicated its hemisphere. The fourth and fifth columns indicate a parcel’s ROI status (yes/no) and functional network. The next three columns indicate whether a parcel was significant after FDR correction, whether it remained significant when task conditions were matched on accuracy/RT, and whether it was significant using the predicted ActFlow data. In the final column, we show the average task activation difference, with more positive values indicating more illusory relative to fragmented activation.</p>
      </caption>
      <table frame="hsides" rules="none">
        <colgroup span="1">
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th align="left" valign="bottom" rowspan="1" colspan="1">Parcel Name</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">% With Difference In Group Direction</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">% With Sig. Difference</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">ROI?</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">Network</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">Sig. with FDR correction?</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">Sig. with accuracy matching?</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">Sig. with Act-Flow?</th>
            <th align="left" valign="bottom" rowspan="1" colspan="1">Mean Beta Difference [95% CI]</th>
          </tr>
          <tr>
            <th colspan="9" align="left" valign="top" rowspan="1">
<hr/>
</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_PH</td>
            <td align="left" valign="top" rowspan="1" colspan="1">95</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">113.8 [77.6,150.1]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_MIP</td>
            <td align="left" valign="top" rowspan="1" colspan="1">95</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">82.2 [43.7,120.6]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_V4</td>
            <td align="left" valign="top" rowspan="1" colspan="1">95</td>
            <td align="left" valign="top" rowspan="1" colspan="1">55</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">46 [21.4, 70.7]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_IFJp</td>
            <td align="left" valign="top" rowspan="1" colspan="1">95</td>
            <td align="left" valign="top" rowspan="1" colspan="1">50</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">88 [50, 126]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_PH</td>
            <td align="left" valign="top" rowspan="1" colspan="1">90</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">95.6 [66.1,125.1]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_6r</td>
            <td align="left" valign="top" rowspan="1" colspan="1">90</td>
            <td align="left" valign="top" rowspan="1" colspan="1">55</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Cingulo-Opercular</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">56.4 [29.3, 83.4]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_a24</td>
            <td align="left" valign="top" rowspan="1" colspan="1">90</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">-47.6 [-69.7,-25.5]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_V3CD</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">70</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">76.2 [45.4, 107]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_IP1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65.7 [23.5,107.9]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_V3CD</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">64.3 [29.3, 99.3]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_IP0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">75 [44.4,105.6]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_PFt</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">55</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">62.2 [28.5, 95.8]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_PGi</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">55</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">-43.2 [-69.6,-16.8]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_LO1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">64 [34.3, 93.7]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_a24</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">−52 [-77.1,-26.9]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_IP0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">64.2 [26.2,102.3]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_LO1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">55.2 [31.1, 79.4]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_TGd</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">−37.8 [-58.4,-17.2]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_IP2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">74.2 [30.3,118.2]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_11l</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">61.4 [32.2, 90.6]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_AIP</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">78.1 [39.4,116.8]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_MIP</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">81.1 [38.8,123.5]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_V3B</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">50</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">54.9 [22.9, 87]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_LIPd</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">50</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">79.3 [36.7, 122]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_V4</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40.3 [11.3, 69.3]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_IFJp</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">85.4 [36.5,134.2]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_d23ab</td>
            <td align="left" valign="top" rowspan="1" colspan="1">80</td>
            <td align="left" valign="top" rowspan="1" colspan="1">35</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">−58.3 [-92.9,-23.6]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_LO2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">75</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">47.6 [6, 89.3]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_p9–46v</td>
            <td align="left" valign="top" rowspan="1" colspan="1">75</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">62 [29.1, 94.8]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_AIP</td>
            <td align="left" valign="top" rowspan="1" colspan="1">75</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">59.4 [23.2, 95.5]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_IFSa</td>
            <td align="left" valign="top" rowspan="1" colspan="1">75</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">49.9 [22.3, 77.4]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_PHT</td>
            <td align="left" valign="top" rowspan="1" colspan="1">75</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Dorsal-attention</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">51.5 [19, 84]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_FST</td>
            <td align="left" valign="top" rowspan="1" colspan="1">75</td>
            <td align="left" valign="top" rowspan="1" colspan="1">35</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45.5 [18.7, 72.3]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_TGd</td>
            <td align="left" valign="top" rowspan="1" colspan="1">70</td>
            <td align="left" valign="top" rowspan="1" colspan="1">45</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">−32.5 [-53.3,-11.8]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_31pv</td>
            <td align="left" valign="top" rowspan="1" colspan="1">70</td>
            <td align="left" valign="top" rowspan="1" colspan="1">40</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Default</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">−58.5 [-95, -22]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_LO2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">70</td>
            <td align="left" valign="top" rowspan="1" colspan="1">35</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">48.6 [21.5, 75.8]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_LO3</td>
            <td align="left" valign="top" rowspan="1" colspan="1">70</td>
            <td align="left" valign="top" rowspan="1" colspan="1">30</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">21.9 [-13.2, 56.9]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_V4t</td>
            <td align="left" valign="top" rowspan="1" colspan="1">70</td>
            <td align="left" valign="top" rowspan="1" colspan="1">25</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">15.4 [-21.5, 52.3]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_IP1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">50</td>
            <td align="left" valign="top" rowspan="1" colspan="1"/>
            <td align="left" valign="top" rowspan="1" colspan="1">Frontoparietal</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">51.7 [20.5, 83]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_LO3</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">35</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">24.2 [-13.3, 61.7]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_V2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">65</td>
            <td align="left" valign="top" rowspan="1" colspan="1">20</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">7.4 [-25.8, 40.5]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_V1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">30</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">9.9 [-22.8, 42.6]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_V2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">25</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">4.3 [-32.2, 40.7]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">R_V1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">60</td>
            <td align="left" valign="top" rowspan="1" colspan="1">20</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">5.5 [-28.9, 39.9]</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">L_V4t</td>
            <td align="left" valign="top" rowspan="1" colspan="1">55</td>
            <td align="left" valign="top" rowspan="1" colspan="1">10</td>
            <td align="left" valign="top" rowspan="1" colspan="1">1</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Visual2</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">0</td>
            <td align="left" valign="top" rowspan="1" colspan="1">−2.2 [- 34.7, 30.4]</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </floats-group>
</article>
