<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Neuroinformatics</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1662-5196</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">35095453</article-id>
      <article-id pub-id-type="pmc">8792610</article-id>
      <article-id pub-id-type="doi">10.3389/fninf.2021.802305</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Multi-Scale Graph Representation Learning for Autism Identification With Functional MRI</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Chu</surname>
            <given-names>Ying</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Guangyu</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>Liang</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Qiao</surname>
            <given-names>Lishan</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Mingxia</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref>
          <xref rid="c002" ref-type="corresp">
<sup>*</sup>
</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><sup>1</sup><institution>School of Mathematics Science, Liaocheng University</institution>, <addr-line>Liaocheng</addr-line>, <country>China</country></aff>
      <aff id="aff2"><sup>2</sup><institution>Department of Information Science and Technology, Taishan University</institution>, <addr-line>Taian</addr-line>, <country>China</country></aff>
      <aff id="aff3"><sup>3</sup><institution>Taian Tumor Prevention and Treatment Hospital</institution>, <addr-line>Taian</addr-line>, <country>China</country></aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: Antonio Fernández-Caballero, University of Castilla-La Mancha, Spain</p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: Mingliang Wang, Nanjing University of Information Science and Technology, China; Meiling Wang, Nanjing University of Aeronautics and Astronautics, China; Liang Sun, Nanjing University of Aeronautics and Astronautics, China</p>
        </fn>
        <corresp id="c001">*Correspondence: Lishan Qiao <email>qiaolishan@lcu.edu.cn</email></corresp>
        <corresp id="c002">Mingxia Liu <email>mxliu1226@gmail.com</email></corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>13</day>
        <month>1</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2021</year>
      </pub-date>
      <volume>15</volume>
      <elocation-id>802305</elocation-id>
      <history>
        <date date-type="received">
          <day>26</day>
          <month>10</month>
          <year>2021</year>
        </date>
        <date date-type="accepted">
          <day>06</day>
          <month>12</month>
          <year>2021</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2022 Chu, Wang, Cao, Qiao and Liu.</copyright-statement>
        <copyright-year>2022</copyright-year>
        <copyright-holder>Chu, Wang, Cao, Qiao and Liu</copyright-holder>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Resting-state functional MRI (rs-fMRI) has been widely used for the early diagnosis of autism spectrum disorder (ASD). With rs-fMRI, the functional connectivity networks (FCNs) are usually constructed for representing each subject, with each element representing the pairwise relationship between brain region-of-interests (ROIs). Previous studies often first extract handcrafted network features (such as node degree and clustering coefficient) from FCNs and then construct a prediction model for ASD diagnosis, which largely requires expert knowledge. Graph convolutional networks (GCNs) have recently been employed to jointly perform FCNs feature extraction and ASD identification in a data-driven manner. However, existing studies tend to focus on the single-scale topology of FCNs by using one single atlas for ROI partition, thus ignoring potential complementary topology information of FCNs at different spatial scales. In this paper, we develop a multi-scale graph representation learning (MGRL) framework for rs-fMRI based ASD diagnosis. The MGRL consists of three major components: (1) multi-scale FCNs construction using multiple brain atlases for ROI partition, (2) FCNs representation learning via multi-scale GCNs, and (3) multi-scale feature fusion and classification for ASD diagnosis. The proposed MGRL is evaluated on 184 subjects from the public Autism Brain Imaging Data Exchange (ABIDE) database with rs-fMRI scans. Experimental results suggest the efficacy of our MGRL in FCN feature extraction and ASD identification, compared with several state-of-the-art methods.</p>
      </abstract>
      <kwd-group>
        <kwd>functional connectivity</kwd>
        <kwd>graph convolutional networks</kwd>
        <kwd>autism</kwd>
        <kwd>resting-state functional MRI</kwd>
        <kwd>classification</kwd>
      </kwd-group>
      <funding-group>
        <award-group>
          <funding-source id="cn001">
            <institution-wrap>
              <institution>National Natural Science Foundation of China</institution>
              <institution-id institution-id-type="doi">10.13039/501100001809</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id award-type="contract" rid="cn001">11931008</award-id>
          <award-id award-type="contract" rid="cn001">61976110</award-id>
          <award-id award-type="contract" rid="cn001">62176112</award-id>
        </award-group>
      </funding-group>
      <counts>
        <fig-count count="9"/>
        <table-count count="4"/>
        <equation-count count="7"/>
        <ref-count count="62"/>
        <page-count count="14"/>
        <word-count count="9318"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro" id="s1">
      <title>1. Introduction</title>
      <p>Autism spectrum disorder (ASD) is a developmental disorder that can cause major social, communication, and behavioral challenges (Simonoff et al., <xref rid="B43" ref-type="bibr">2008</xref>). In 2014, the overall prevalence of autism was estimated at 16.8 per 1, 000 8-year-old children, and the prevalence of ASD reached nearly 3% in some communities (Baio et al., <xref rid="B5" ref-type="bibr">2018</xref>). In recent years, people have been worried about the increased prevalence of ASD in children (Hodges et al., <xref rid="B23" ref-type="bibr">2020</xref>; Ahammed et al., <xref rid="B1" ref-type="bibr">2021</xref>). However, the current diagnosis of autism is highly dependent on traditional behavioral symptoms, which are usually subjective and can easily lead to neglect early symptoms and misdiagnosis (American Psychiatric Association, <xref rid="B2" ref-type="bibr">2013</xref>; Lord et al., <xref rid="B34" ref-type="bibr">2018</xref>). Therefore, seeking an objective biomarker for early diagnosis and timely intervention in the treatment of autism has attracted increasing attention in the field of psychiatry and neuroscience.</p>
      <p>Resting-state functional MRI (rs-fMRI) is a technique to measure a subject's blood-oxygen-level-dependent (BOLD) signals without performing any specific task and has been widely used in neuroimaging analysis (Buckner et al., <xref rid="B8" ref-type="bibr">2013</xref>; Li et al., <xref rid="B33" ref-type="bibr">2020</xref>). With rs-fMRI, the functional connectivity networks (FCNs) are usually constructed for representing each subject, with each element representing the pairwise relationship between brain region-of-interests (ROIs) (Dvornek et al., <xref rid="B19" ref-type="bibr">2017</xref>; Xing et al., <xref rid="B55" ref-type="bibr">2019</xref>). Therefore, FCNs tend to capture the dependencies between BOLD signals of paired region-of-interests (ROIs) of the brain and have been used to identify potential neuroimaging biomarkers for the diagnosis of neurological diseases (El Gazzar et al., <xref rid="B20" ref-type="bibr">2019</xref>; Wang et al., <xref rid="B52" ref-type="bibr">2019a</xref>). It can help us understand brain organization patterns and diagnose neurological diseases such as ASD (Bijsterbosch and Beckmann, <xref rid="B6" ref-type="bibr">2017</xref>; Kazi et al., <xref rid="B26" ref-type="bibr">2019</xref>), Alzheimer's disease and its prodromal stage (i.e., mild cognitive impairment) (Amini et al., <xref rid="B3" ref-type="bibr">2021</xref>), Parkinson's disease (Vivar-Estudillo et al., <xref rid="B48" ref-type="bibr">2021</xref>). However, previous studies often first extract handcrafted network features (such as node degree and clustering coefficient) from FCNs and then conduct prediction models for ASD diagnosis (Wang et al., <xref rid="B53" ref-type="bibr">2019b</xref>), where these two steps are treated separately and highly rely on expert knowledge.</p>
      <p>With the development of deep learning, especially graph neural networks (GNNs) have been developed to identify potential fMRI biomarkers in brain FCNs for disease diagnosis (Li et al., <xref rid="B32" ref-type="bibr">2019</xref>; Wu et al., <xref rid="B54" ref-type="bibr">2020</xref>). In general, each brain network can be viewed as a complex graph structure composed of irregular data (Zhang et al., <xref rid="B60" ref-type="bibr">2018a</xref>), containing not only node features but also topology information among different nodes. Graph convolutional networks (GCNs) provide an end-to-end deep learning framework to automatically learn node features and topology information between nodes. Current studies have shown that the application of GCNs in fMRI analysis helps automatically capture the high-level topological information of brain networks through operations, such as convolution and graph pooling, thus significantly improving the diagnosis performance of brain diseases (Yu et al., <xref rid="B59" ref-type="bibr">2020</xref>). To facilitate functional connectivity (FC) analysis and computational modeling of human brain functions, existing studies generally partition each brain into multiple ROIs (Dvornek et al., <xref rid="B19" ref-type="bibr">2017</xref>; Xing et al., <xref rid="B55" ref-type="bibr">2019</xref>), followed by GCN models for FCNs feature learning and disease diagnosis. However, previous studies usually focus on single-scale topology of FCNs by using one single atlas for brain ROIs partition (Chen et al., <xref rid="B12" ref-type="bibr">2017</xref>; Wang et al., <xref rid="B49" ref-type="bibr">2018</xref>), thus ignoring the potential complementary topology information of FCNs at different spatial scales.</p>
      <p>To this end, we develop a multi-scale graph representation learning (MGRL) framework for rs-fMRI based ASD diagnosis. As shown in <xref rid="F1" ref-type="fig">Figure 1</xref>, we first construct multi-scale graphs (with each graph corresponding to a specific FCN) for each subject, by partitioning the brain into multiple ROIs using two atlases, i.e., Automated Anatomical Labeling (AAL) (Tzourio-Mazoyer et al., <xref rid="B46" ref-type="bibr">2002</xref>) atlas with 116 ROIs and Craddock200 (CC200) (Craddock et al., <xref rid="B14" ref-type="bibr">2012</xref>) atlas with 200 ROIs. Then, we propose to learn multi-scale graph representations via GCNs for each subject, followed by multi-scale features fusion. The fused features are finally fed into three fully-connected layers and a classification layer (via Softmax) for disease diagnosis. The proposed MGRL allows the automated integration of fine-grained topology information of FCNs at different spatial scales. Experiments on 184 subjects with rs-fMRI data from the Autism Brain Imaging Data Exchange (ABIDE) database suggest that the MGRL helps improve the performance of ASD diagnosis, compared with several state-of-the-art methods.</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p>Illustration of the proposed multi-scale graph representation learning (MGRL) framework for autism spectrum disorder (ASD) identification, consisting of three components. <bold>(A)</bold> Multi-scale graph construction. Let's say there are <italic>N</italic> subjects in the classification task. First, think of the brain (region of interests, ROIs) as nodes on a graph. Based on the Automated Anatomical Labeling (AAL) atlas and Craddock200 (CC200) atlas, 2<italic>N</italic> functional connectivity networks (FCNs) are constructed by Pearson's correlation (PC). PC coefficient matrix can represent the paired similarity relation between brain regions, so as to construct weighted edge connection of brain graphs and establish a multi-scale graph of each subject. (<italic>G</italic><sub>116</sub>, <italic>Y</italic>) and (<italic>G</italic><sub>200</sub>, <italic>Y</italic>). Subscripts 116, 200 represent different brain atlases, and <italic>Y</italic>∈{0, 1} represents the label of the subject (with 0 indicating NC and 1 representing ASD). <bold>(B)</bold> MRGL. The graph structure and node content information of different scales from the same subject are used as input of Graph convolutional networks (GCN) to train independent GCN models. Convolution operation and readout operation are used to automatically learn graph representation vectors of different scales. <bold>(C)</bold> Multi-scale feature fusion and classification. Read higher-order graph representation vectors are spliced together to integrate complementary information at the multi-scale graph. The final classification results are obtained through three fully-connected layers and a softmax layer for classification.</p>
        </caption>
        <graphic xlink:href="fninf-15-802305-g0001" position="float"/>
      </fig>
      <p>The rest of this paper is organized as follows. In section Related Work, we review the most relevant studies. In section Materials and Methods, we describe the data set used in this study and the proposed method. We then present experimental settings, competing methods, and results of ASD diagnosis achieved by different methods in section Experiments. In section Discussion, we investigate the influence of several major components of the proposed MGRL method and discuss the limitations of the current work and several possible future research directions. Finally, this paper is concluded in section Conclusion.</p>
    </sec>
    <sec id="s2">
      <title>2. Related Work</title>
      <p>In this section, we first briefly introduce the most relevant studies on features extraction of FCNs based on rs-fMRI and then introduce existing GCN based methods for computer-aided disease diagnosis.</p>
      <sec>
        <title>2.1. Feature Extraction of Functional Connectivity Networks (FCNs)</title>
        <p>Functional MRI has been widely used to establish brain FCNs (Yu et al., <xref rid="B58" ref-type="bibr">2019</xref>; Xue et al., <xref rid="B56" ref-type="bibr">2020</xref>) by focusing on measuring the FC between two network nodes. Identifying distinguishable and explainable features from FCNs is essential for subsequent classification/regression tasks and helps us understand the pathological mechanisms of related brain disorders. Previous studies usually extract node statistics or edge weights from functional brain networks to represent each subject and mine the correlation of temporal and spatial information between brain regions. For example, Chen et al. used Pearson's correlation (PC) coefficient to compute edge weights for FCNs construction (Chen et al., <xref rid="B11" ref-type="bibr">2020</xref>). Hhimilon et al. extracted both global and node-level statistics (such as local clustering coefficients) as FCN attributes (Hamilton, <xref rid="B21" ref-type="bibr">2020</xref>). Jie et al. extracted local clustering coefficients from hyperconnected FCNs to represent each FCN for disease diagnosis (Jie et al., <xref rid="B24" ref-type="bibr">2016</xref>). Recently, Zhang et al. proposed a modularity-based feature selection method to identify discriminative and interpretable features from functional brain networks for the diagnosis of Alzheimer's disease (AD) and related disorders (Zhang et al., <xref rid="B62" ref-type="bibr">2021</xref>).</p>
        <p>Although previous studies have yielded promising results, topological measures involved in these methods require manual design (i.e., manual definition of FCNs features), which is usually subjective and largely relies on expert knowledge. Besides, Mangor et al. found that handcrafted features (e.g.„ median centrality) of individuals with focal epilepsy did not differ significantly between patients and healthy controls and could not be discriminative for disease classification (Pedersen et al., <xref rid="B37" ref-type="bibr">2015</xref>). This implies that the handcrafted FCNs features could be suboptimal for diagnosis, due to the fact that these features are extracted independently from subsequent classification models.</p>
      </sec>
      <sec>
        <title>2.2. GCN for fMRI Analysis</title>
        <p>With the development of deep learning techniques, GCNs have been increasingly employed to model topological information of brain FCNs (Anirudh and Thiagarajan, <xref rid="B4" ref-type="bibr">2019</xref>). Significant progress has been made in early intervention of neurological diseases. Song et al. extracted the mean rs-fMRI time series of a set of 90 ROIs based on the AAL atlas, and then proposed similarity-aware adaptive calibrated GCN to predict significant memory concern and MCI (Song et al., <xref rid="B44" ref-type="bibr">2021</xref>). Wang et al. constructed FCNs based on the Power atlas (Power et al., <xref rid="B38" ref-type="bibr">2011</xref>) and utilized a GCN model to extract the spatial characteristics of linogroups from rs-fMRI data for ASD classification (Wang et al., <xref rid="B51" ref-type="bibr">2021</xref>). Ktena et al. extracted brain time series based on Harvard Oxford (HO) (Craddock et al., <xref rid="B14" ref-type="bibr">2012</xref>) atlas and proposed to use Siamese GCN (SGCN) to analyze the brain FCNs of autism classification (Ktena et al., <xref rid="B29" ref-type="bibr">2018</xref>).</p>
        <p>These deep learning methods show excellent performance in automated FCNs features extraction, and some of them have realized that fine-grained and coarse-grained topological properties of FCNs at different spatial scales may affect the final performance. However, existing GCN-based studies tend to extract single-scale representations of FCNs by using one single atlas for brain ROIs partition. This will ignore the potential complementary topological information conveyed by multi-scale brain atlases, thereby reducing the learning performance of the prediction/diagnostic model. Intuitively, it is interesting to model multi-scale representations of brain FCNs to improve the performance of ASD diagnosis. In this work, we will develop an MGRL framework to capture multi-scale topological features of FCNs for automated ASD identification.</p>
      </sec>
    </sec>
    <sec sec-type="materials and methods" id="s3">
      <title>3. Materials and Methods</title>
      <p>In this section, we will first introduce the data set and image preprocessing steps used in this study. Then, we will introduce the proposed MGRL framework and the implementation details.</p>
      <sec>
        <title>3.1. Subjects and Image Processing</title>
        <p>The ABIDE (Di Martino et al., <xref rid="B17" ref-type="bibr">2014</xref>) includes baseline resting-state fMRI data from patients with ASD and normal controls (NC). In this work, we use rs-fMRI data from the New York University (NYU) site with the largest sample size collected in this database. Specifically, the NYU site includes 184 subjects, 79 of whom were from ASD and 105 NC cases. We report the phenotype information of the studied subjects in <xref rid="T1" ref-type="table">Table 1</xref>. All fMRI data involved are provided by the Preprocessed Connectome Project initiative. The 3.0 Tesla Allegra scanner is used to collect data, and the imaging parameters are set as follows: the number of slices is 33, and TR/TE is 2, 000/15 ms with 180 volumes. Then, the remaining volumes are processed by a well-accepted pipeline with the Data Processing Assistant for Resting-State fMRI toolbox (DPARSF) (Yan et al., <xref rid="B57" ref-type="bibr">2016</xref>). Specifically, the preprocessed pipeline primarily includes the following: (1) head motion correction, (2) nuisance signals regression (ventricle, cerebrospinal fluid (CSF), white matter signals and the high-order effect of head motion described by Friston 24-parameters model), (3) spatial standardization of the Montreal Neurological Institute (MNI) template (Tzourio-Mazoyer et al., <xref rid="B46" ref-type="bibr">2002</xref>), 3 × 3 × 3<italic>mm</italic><sup>3</sup> resolution, and (4) time-high pass filtering (0.01–0.10<italic>Hz</italic>) based on a linear downtrend and fast Fourier transform. Then, each brain is partitioned into 116 and 200 ROIs based on multi-scale atlases, i.e., AAL atlas and CC200 atlas, respectively. Finally, the extracted mean time series from all these ROIs are put into the data matrix <italic>S</italic>∈<italic>R</italic><sup>(175 × <italic>n</italic>)</sup> (<italic>n</italic> = 116 or <italic>n</italic> = 200).</p>
        <table-wrap position="float" id="T1">
          <label>Table 1</label>
          <caption>
            <p>Demographic information of the subjects in New York University (NYU) site and the University of Michigan (UM) site of the Autism Brain Imaging Data Exchange (ABIDE) dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Dataset</bold>
</th>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Category</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Gender (M/F)</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Age</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>FIQ</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">NYU</td>
                <td valign="top" align="left" rowspan="1" colspan="1">ASD (<italic>N</italic> = 79)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">68/11</td>
                <td valign="top" align="center" rowspan="1" colspan="1">14.51 ± 6.23</td>
                <td valign="top" align="center" rowspan="1" colspan="1">107.92 ± 3.15</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1">NC (<italic>N</italic> = 105)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">79/26</td>
                <td valign="top" align="center" rowspan="1" colspan="1">15.80 ± 3.23</td>
                <td valign="top" align="center" rowspan="1" colspan="1">113.15 ± 2.45</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">UM</td>
                <td valign="top" align="left" rowspan="1" colspan="1">ASD (<italic>N</italic> = 68)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">58/10</td>
                <td valign="top" align="center" rowspan="1" colspan="1">13.13 ± 2.41</td>
                <td valign="top" align="center" rowspan="1" colspan="1">105.46 ± 17.28</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1">NC (<italic>N</italic> = 77)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">59/18</td>
                <td valign="top" align="center" rowspan="1" colspan="1">14.79 ± 3.57</td>
                <td valign="top" align="center" rowspan="1" colspan="1">108.12 ± 9.80</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="TN1">
              <p><italic>Values are reported as mean ± SD. M/F, Male/Female; FIQ, Full-scale intelligence quotient; ASD, Autism spectrum disorder; NC, Normal control; ABIDE, Autism brain imaging data exchange</italic>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.2. Proposed Method</title>
        <p>We attempt to solve two challenging problems in fMRI-based FCNs analysis: (1) how to model multi-scale topological information of brain FCNs, and (2) how to integrate these multi-scale FCNs features for ASD diagnosis. To this end, we develop a multi-scale graph representation learning (MGRL) framework to first extract brain FCNs features at multiple scales and then fuse them for automated brain disease identification. The MGRL framework consists of three main components: (1) multi-scale graph construction; (2) multi-scale graph representation learning; and (3) multi-scale feature fusion and classification.</p>
        <sec>
          <title>3.2.1. Multi-Scale Graph Construction</title>
          <p>Let <italic>G</italic> = {<italic>V, E, A</italic>} denotes an undirected graph with <italic>n</italic> nodes/ROIs, where <italic>V</italic> (||<italic>V</italic>|| = <italic>n</italic>) is a set of nodes and <italic>E</italic>∈ℝ<sup><italic>n</italic>×<italic>n</italic></sup> is a set of edges, and <italic>A</italic>∈ℝ<sup><italic>n</italic>×<italic>n</italic></sup> represents an adjacency matrix corresponding to a specific FCN. The adjacency matrix defines the interconnections between nodes/ROIs.</p>
          <p>Craddock et al. found that when the brain is divided into about 200 brain regions, the ROI obtained is appropriately large, which can adapt to individual anatomical variation (Craddock et al., <xref rid="B14" ref-type="bibr">2012</xref>). Wang et al. also proposed that aMCI and NC can be better distinguished when the number of segmented brain regions is appropriate (Wang et al., <xref rid="B50" ref-type="bibr">2013</xref>). In this study, we use AAL atlas and CC200 atlas, which are widely used to locate brain active regions in functional neuroimaging studies, to obtain ROIs time series at different spatial scales. Thus, for each subject, we have two FC matrices established on two different scales. For each FC matrix, each connectivity represents the PC of the mean time series signals between a pair of ROIs. The edge weight <italic>e</italic><sub><italic>ij</italic></sub>∈[−1, 1] between the <italic>i</italic>-th and <italic>j</italic>-th ROIs is defined as follows:</p>
          <disp-formula id="E1">
<label>(1)</label>
<mml:math id="M1" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>Where, <inline-formula><mml:math id="M2" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> represents the time series of BOLD signals extracted from the <italic>i</italic>-th ROI. <italic>t</italic> represents the number of time points in the average time series of each ROI, <inline-formula><mml:math id="M3" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean vector corresponding to <italic>s</italic><sub><italic>i</italic></sub>.</p>
          <p>We describe the features of each node/region in the brain network through the correlation coefficient (i.e., the edge weight <italic>e</italic><sub><italic>ij</italic></sub>). All subjects are divided into 116 ROIs by AAL atlas and 200 ROIs by CC200 atlas. Therefore, the similarity between the <italic>i</italic>-th brain region and other brain regions constitutes the <italic>n</italic>-dimensional feature vector (<italic>e</italic><sub><italic>i</italic>1</sub>, <italic>e</italic><sub><italic>i</italic>2</sub>, ⋯ , <italic>e</italic><sub><italic>in</italic></sub>), <italic>n</italic> = 116 or <italic>n</italic> = 200. Then, for the same subject, we will get two feature matrices <italic>X</italic><sup>(116)</sup>∈<italic>R</italic><sup>116 × 116</sup>, <italic>X</italic><sup>(200)</sup>∈<italic>R</italic><sup>200 × 200</sup>. At the same time, we define <italic>X</italic>∈{<italic>X</italic><sup>(116)</sup>, <italic>X</italic><sup>(200)</sup>}.</p>
          <p>We use the connection strength between the current ROI and other ROIs to measure the edge of the FCNs. The assumption that the edge weight is non-negative conforms to the structural equilibrium theory (Heider, <xref rid="B22" ref-type="bibr">1946</xref>; Cartwright and Harary, <xref rid="B10" ref-type="bibr">1956</xref>). That is, if and only if the edge weights of all edges are positive, the estimated network structure is balanced. In addition, this assumption can simplify subsequent FCNs analysis and convolution operations, and many FC indicators, such as mutual information (Salvador et al., <xref rid="B40" ref-type="bibr">2007</xref>), are also non-negative. Here, we assume that the strength of marginal connections between brain regions, whether the positive correlation of promotion or negative correlation of inhibition, is measured by the value of marginal weight (<italic>e</italic><sub><italic>ij</italic></sub>). Then, the connection strength between the <italic>i</italic>-th brain region and other brain regions will form the <italic>n</italic>-dimensional vector (|<italic>e</italic><sub><italic>i</italic>1</sub>|, |<italic>e</italic><sub><italic>i</italic>2</sub>|, ⋯ , |<italic>e</italic><sub><italic>in</italic></sub>|), <italic>n</italic> = 116 or <italic>n</italic> = 200. Therefore, for the same subject, the adjacency matrices <italic>A</italic><sup>(116)</sup>∈<italic>R</italic><sup>116 × 116</sup> and <italic>A</italic><sup>(200)</sup>∈<italic>R</italic><sup>200 × 200</sup> for two spatial scales will be defined. At the same time, we define <italic>A</italic>∈{<italic>A</italic><sup>(116)</sup>, <italic>A</italic><sup>(200)</sup>}. Finally, two graphs [i.e., <inline-formula><mml:math id="M4" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>116</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>116</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>116</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M5" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>200</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>200</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>200</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>] are constructed for each subject based on two spatial scales.</p>
        </sec>
        <sec>
          <title>3.2.2. Multi-Scale Graph Representation Learning</title>
          <p>Brain FCNs can be regarded as an irregular graph, internal structure and hence, we resort to spectral GCN (Zhang et al., <xref rid="B61" ref-type="bibr">2018b</xref>) to analyze brain FCNs and learn new graph representations for ASD diagnosis in this work. Spectral GCN uses Fourier transform and inverse Fourier transform to realize the aggregation of information between nodes in the spectral space (Bruna et al., <xref rid="B7" ref-type="bibr">2013</xref>; Kawahara et al., <xref rid="B25" ref-type="bibr">2017</xref>).</p>
          <p>The Fourier transform on the graph depends on the eigenvector of the Laplacian matrix. The Laplacian matrix (i.e., L) can be defined as (Bruna et al., <xref rid="B7" ref-type="bibr">2013</xref>):</p>
          <disp-formula id="E2">
<label>(2)</label>
<mml:math id="M6" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo>-</mml:mo><mml:mi>A</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where <italic>D</italic> is a diagonal matrix and its diagonal element <italic>D</italic><sub><italic>ii</italic></sub> represents the degree of the <italic>i</italic>-th node and <italic>D</italic><sub><italic>ii</italic></sub> = Σ<sub><italic>j</italic></sub><italic>A</italic><sub><italic>ij</italic></sub>.</p>
          <p>A more common form of Laplacian matrix is the symmetric normalized Laplacian matrix:</p>
          <disp-formula id="E3">
<label>(3)</label>
<mml:math id="M7" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi>L</mml:mi><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mi>A</mml:mi><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where <italic>I</italic><sub><italic>n</italic></sub> is an identity matrix.</p>
          <p>The <italic>L</italic> can be eigen-decomposed to <italic>UΛU</italic><sup><italic>T</italic></sup>. <inline-formula><mml:math id="M8" overflow="scroll"><mml:mrow><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> represents orthogonal eigenvectors, <inline-formula><mml:math id="M9" overflow="scroll"><mml:mi>Λ</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is a diagonal matrix, and λ<sub><italic>i</italic></sub> represents the eigenvalues of <italic>u</italic><sub><italic>i</italic></sub>. Where, <italic>U</italic> can transform variables into spectral space for convolution operation on the graph.</p>
          <p>The Fourier transform of signal convolution is equivalent to the product of signal Fourier transform (Shuman et al., <xref rid="B42" ref-type="bibr">2013</xref>). Let <italic>x</italic>, <italic>y</italic> represent the signal (variable) of the node domain. The graph convolution can be defined as:</p>
          <disp-formula id="E4">
<label>(4)</label>
<mml:math id="M10" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mo>*</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where * represents the convolution operation.</p>
          <p>Based on the above graph convolution definition (Equation 4), ChebyNet (Defferrard et al., <xref rid="B15" ref-type="bibr">2016</xref>) is proposed for reducing computational complexity. Then, Kipf et al. further deduced the 1-order approximation of the <italic>l</italic>+1 layer network of ChebyNet for artificial convenience (Kipf and Welling, <xref rid="B28" ref-type="bibr">2016</xref>):</p>
          <disp-formula id="E5">
<label>(5)</label>
<mml:math id="M11" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mover accent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where <italic>H</italic> represents the features of nodes on the graph, <italic>W</italic> is the network parameter to be learned, <inline-formula><mml:math id="M12" overflow="scroll"><mml:mover accent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="M13" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and σ(·) is a non-linear activation function.</p>
          <p>In this paper, we construct a GCN model with two-layer convolution for each scale graph, and the activation function of each layer convolution is ReLU. Then, the overall forward propagation formula is:</p>
          <disp-formula id="E6">
<label>(6)</label>
<mml:math id="M14" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where, <italic>f</italic>(<italic>X, A</italic>)∈<italic>R</italic><sup><italic>n</italic>×<italic>d</italic></sup>, <italic>X</italic>∈{<italic>X</italic><sup>(116)</sup>, <italic>X</italic><sup>(200)</sup>}, <italic>A</italic>∈{<italic>A</italic><sup>(116)</sup>, <italic>A</italic><sup>(200)</sup>}, <italic>d</italic> represents the output feature dimension. <italic>W</italic><sup>(0)</sup> is the weight parameter matrix of the 1-th convolution layer, and <italic>W</italic><sup>(1)</sup> is the weight parameter matrix of the 2-th convolution layer.</p>
          <p>We use graph structure and node content information of different scales from the same subject as inputs to independently train GCN models of different scales so as to predict the category labels of the whole graph. The convolution layer is responsible for strict higher-order graph representation. After the convolution layer, the graph classification task usually needs to use the readout layer to read the graph level representation of the whole graph. Inspired by Lee et al., we use both maximum pool and average pool operations to aggregate node features and readout fixed-size graph representation vectors of two scales from the same subject (Lee et al., <xref rid="B30" ref-type="bibr">2019</xref>). The readout layer is defined as:</p>
          <disp-formula id="E7">
<label>(7)</label>
<mml:math id="M15" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder></mml:mstyle><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where <italic>f</italic><sub><italic>i</italic></sub>(<italic>X, A</italic>) is the feature vector of the <italic>i</italic>-th ROI obtained by the convolution operation and || denotes concatenation operation as illustrated in <xref rid="F2" ref-type="fig">Figure 2</xref>.</p>
          <fig position="float" id="F2">
            <label>Figure 2</label>
            <caption>
              <p>Illustration of the readout operation. Each graph convolution layer updates the features of the central node (green) by aggregating the information of connected nodes and non-linear activation of ReLU to obtain the feature matrix [<italic>f</italic>(<italic>X, A</italic>)] of each subject. Then, the graph-level vector representation (<italic>F</italic>) of each subject is summarized by maximum pool and average pool readout operations.</p>
            </caption>
            <graphic xlink:href="fninf-15-802305-g0002" position="float"/>
          </fig>
          <p>As illustrated in <xref rid="F1" ref-type="fig">Figure 1</xref>, finally, we extract the 64-dimensional graph representation vectors of different scale graphs: <inline-formula><mml:math id="M16" overflow="scroll"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>64</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>21</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>64</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em" class="thinspace"/><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>64</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="M17" overflow="scroll"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>64</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>22</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>64</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em" class="thinspace"/><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>64</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula>, where, <italic>F</italic><sub><italic>m</italic>1</sub>, <italic>F</italic><sub><italic>m</italic>2</sub> represent the graph representation vector of different scales of the <italic>m</italic>-th subject and <italic>m</italic> = 1, 2, 3, ⋯ , <italic>N</italic>.</p>
        </sec>
        <sec>
          <title>3.2.3. Multi-Scale Feature Fusion and Classification</title>
          <p>Here, we treat equally (through concatenation) the graph-level representation vector obtained through the above readout operation for subsequent multi-scale feature fusion. Then, the 128-dimensional new graph representation vector for each subject (<inline-formula><mml:math id="M18" overflow="scroll"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>128</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>128</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em" class="thinspace"/><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>128</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mtext>T</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula>) is connected to three fully-connected layers and the feature information on the graph is further learned. The final output is sent to a Softmax layer for classification.</p>
          <p>In the experiment, we will further study the influence of the combination of these two scale features in different proportions. Therefore, our model can automatically learn the topology information of the brain network through the convolution operation and make full use of the complementary information from the multi-scale FCNs of the same subject for classification.</p>
        </sec>
      </sec>
      <sec>
        <title>3.3. Implementation Details</title>
        <p>The proposed MGRL is implemented on Pytorch, with a GPU (NVIDIA GeForce RTX with 8 GB memory). The MGRL framework includes two GCN modules layers, three fully-connected layers, and a Softmax layer for prediction. Each GCN module is composed of two convolutional layers and a readout layer. Moreover, these two GCNs are independent of each other. Both the convolutional layers and the fully-connected layers are activated non-linearly by ReLU. The number of neurons in the two graph convolution layers is set as 32 and 32, respectively. The number of neurons in the three fully-connected layers are set as 128, 32, 16, respectively. The dropout for the fully-connected layers is 0.5. The Adaptive Moment Estimation (Adam) (Kingma and Ba, <xref rid="B27" ref-type="bibr">2014</xref>) optimizer is used to optimize the model. The learning rate is 0.01, the regularization parameter is 0.00001, and the training epoch is 50.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>4. Experiments</title>
      <sec>
        <title>4.1. Experimental Settings</title>
        <p>Considering the small amount of subjects, we randomly select 80% of all the samples as training data, 10% of all samples as validation data, and the remaining 10% as test data. We repeat the random partition process 100 times and record the mean and SD results of each method. For a fair comparison, we use the same data partitioning and model training strategies to evaluate our MGRL and the competing methods.</p>
        <p>In order to evaluate the effectiveness of different methods, five metrics including accuracy, recall, precision, F1-score, and area under ROC curve (AUC) are used to evaluate the performance of the model. TP, TN, FP, and FN are denoted as True Positive, True Negative, False Positive, and False Negative, respectively. The first four metrics are defined as follows: Accuracy = <inline-formula><mml:math id="M19" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>, Precision = <inline-formula><mml:math id="M20" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>, Recall = <inline-formula><mml:math id="M21" overflow="scroll"><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>, and F1-Score = <inline-formula><mml:math id="M22" overflow="scroll"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:math></inline-formula>. For these metrics, a higher value denotes that the corresponding model can achieve better classification performance. Besides, the Receiver Operating Characteristics (ROC) curve is composed of true positive rate (TPR, y-axis) and false positive rate (FPR, x-axis). The area under the ROC curve (AUC) is equal to the probability that the classifier will rank randomly selected positive cases higher than randomly selected negative cases, and the AUC value close to 1 is better.</p>
      </sec>
      <sec>
        <title>4.2. Methods for Comparison</title>
        <p>We compare the proposed MGRL approaches with three conventional networks representation methods and two GCNs based methods: (1) multi-scale feature fusion based on degree centrality (<bold>DCF</bold>), (2) multi-scale feature fusion based on local clustering coefficients (<bold>LCCF</bold>), (3) multi-scale feature fusion based on closeness centrality (<bold>CCF</bold>), (4) GCN with AAL atlas (<bold>GCNA</bold>), and (5) GCN with CC200 atlas (<bold>GCNC</bold>).</p>
        <list list-type="simple">
          <list-item>
            <p>1) <bold>Degree centrality</bold>: This method uses DC to measure the node centrality that represents the FCN of each brain. That is, the greater the degree of the node, the higher the DC of the node, indicating that the node is more important in describing the network. Similar to MGRL, in this method, we first construct two fixed FC matrices (based on AAL and CC200 atlases) for each subject by calculating the PC coefficient between any pair of ROI time series (size: 116 × 116 and 200 × 200). We extract the DC value of each node for each specific FC matrix and then represent each FC network as a 116-dimensional (or 200-dimensional) feature vector based on a specific atlas. The two feature vectors are concatenated into a 316-dimensional feature vector to represent each subject, followed by 3 fully-connected layers for feature abstraction and a softmax layer for classification.</p>
          </list-item>
          <list-item>
            <p>2) <bold>Local clustering coefficients</bold>: This method uses the local clustering coefficient (LCC) of the nodes to measure the degree of aggregation of each node on the FCNs with other nodes. That is, the larger the local clustering of a node, the stronger the correlation between the node and other nodes in the network. First, we use the PC coefficient of the BOLD signals in the same ROI to measure the pairwise correlation of the average time series of two ROIs and construct two FC matrices (based on AAL and CC200 atlases) for each subject (size: 116 × 116 and 200 × 200). We extract the LCC value of each node in each specific FC matrix and then represent each FCN as a 116-dimensional (or 200-dimensional) feature vector based on a specific atlas. Similar to the DCF method, a 316-dimensional feature vector is generated to represent each subject, followed by three fully-connected layers for feature abstraction and a softmax layer for classification.</p>
          </list-item>
          <list-item>
            <p>3) <bold>Closeness centrality</bold>: This method uses closeness centrality (CC), which reflects the distance between an absolute node and other nodes in FC. First, we also use the PC coefficient to construct two FC matrices (size: 116 × 116 and 200 × 200) for each subject. Then, we calculate the shortest path distance from one node to all other nodes based on the calculations on these two FC matrices, respectively, and calculate the closeness centrality of each ROI. For a node/ROI, the closer it is to other nodes/ROIs, the greater its CC, and the greater the influence of this node/ROI on other nodes/ROIs in the network. Finally, the 116-dimensional and 200-dimensional feature vectors are obtained for each subject to represent each FCN, which are further concatenated into a 316-dimensional feature vector to represent each FCN/subject. The feature vector is further input to three fully-connected layers for feature extraction and a softmax layer for ASD diagnosis.</p>
          </list-item>
          <list-item>
            <p>4) <bold>GCN with AAL atlas</bold>: The method uses the AAL atlas for ROI partitioning. Using AAL, the brain is divided into 116 interpretable ROIs and the average time series of the BOLD signals of the ROIs are extracted. We use the PC to calculate the pairwise correlation between brain signals and construct a FC matrix (size: 116 × 116) for each subject. In order to be comparable with the MGRL method, we use similar graph construction, graph convolution, and graph readout operations. The absolute value of the FC matrix is used as the adjacency matrix of the graph. The constructed graph is used as the input of the GCNA model to perform classification. The above models all include two graph convolutional layers, a readout layer and three fully-connected layers.</p>
          </list-item>
          <list-item>
            <p>5) <bold>GCN with CC200 atlas</bold>: The method uses the CC200 atlas for ROI partitioning. Using the CC200 atlas, the brain is divided into 200 ROIs and the average time series of the BOLD signals of the ROIs are extracted. We also use PC to calculate construct an FC (size: 200 × 200) for each subject. Similar to GCNA, the GCNC method inputs each FC network to two graph convolutional layers, a readout layer, and three fully-connected layers for feature extraction and fusion, followed by a softmax layer for classification.</p>
          </list-item>
        </list>
        <p>For three handcrafted FCN feature based methods (i.e., DCF, LCCF and CCF), the ReLU activation and 0.2 dropout are used after each fully-connected layer. The numbers of neurons in the three fully-connected layers are 316, 32, and 16, respectively. For two GCN-based methods (i.e., GCNA and GCNC), the number of neurons in the convolutional layers are set to 32 and 32, the number of neurons in three fully-connected layers are 64, 16, 8, respectively. Also, the classification is performed by the final layer (with two neurons) via Softmax. Note that the proposed MGRL and three handcrafted feature based methods (i.e., DCF, LCCF, and CCF) share the same multi-scale atlases (i.e., AAL and CC200) for ROIs partition, as well as the same multi-scale feature fusion strategy (i.e., multi-scale concatenation followed by three fully-connected layers). Besides, two GCN-based methods (i.e., GCNA and GCNC) use a single atlas and share the same network architecture as MGRL. For a fair comparison, five competing methods use the Adam optimizer and cross-entropy loss for network training. The learning rate is set to 0.01, the regularization parameter is 0.00001, while the training epoch is 50.</p>
      </sec>
      <sec>
        <title>4.3. Classification Results</title>
        <p>The quantitative results of our MGRL and five competing methods in ASD vs. NC classification are reported in <xref rid="T2" ref-type="table">Table 2</xref>, while the ROC curves of these methods are shown in <xref rid="F3" ref-type="fig">Figure 3</xref>. From <xref rid="T2" ref-type="table">Table 2</xref> and <xref rid="F3" ref-type="fig">Figure 3</xref>, one can have the following interesting observations. <italic>First</italic>, the proposed MGRL achieves the overall best results in ASD vs. NC classification in terms of five metrics and ROC curve, compared with five competing methods. <italic>Second</italic>, compared with two single-scale GCN methods (i.e., GCNA and GCNC), the MGRL improved the classification performance by at least 3% in terms of accuracy, F1-score, recall, precision, and AUC. These results suggest that using multi-scale brain atlases helps boost the classification performance, when compared with that using a single atlas. The underlying reason is that FCNs features learned at different spatial scales may contain complementary information that can be collaboratively used to improve the classification results. <italic>Besides</italic>, among four multi-scale methods, the proposed MGRL method generally outperforms the other three methods (i.e., DCF, LCCF, and CCF) in terms of five evaluation metrics. This further demonstrates the advantage of deep learning models in ASD diagnosis by jointly performing FCNs feature learning and classification.</p>
        <table-wrap position="float" id="T2">
          <label>Table 2</label>
          <caption>
            <p>Performance (mean ± SD) of different models in autism spectrum disorder (ASD) vs. normal control (NC) classification based on resting-state functional MRI (rs-fMRI) data in NYU site of the ABIDE dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Model</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Accuracy</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Recall</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Precision</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>F1-score</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>AUC</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">DCF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.624 ± 0.060</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.703 ± 0.197</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.676 ± 0.142</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.652 ± 0.076</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.711 ± 0.071</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">LCCF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.705 ± 0.085</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.676 ± 0.196</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.819 ± 0.171</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.698 ± 0.102</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.812 ± 0.033</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CCF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.672 ± 0.111</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.781 ± 0.153</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.724 ± 0.173</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.719 ± 0.060</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.792 ± 0.039</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">GCNA</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.758 ± 0.075</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.761 ± 0.146</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.789 ± 0.089</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.763 ± 0.087</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.854 ± 0.058</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">GCNC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.753 ± 0.080</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.773 ± 0.171</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.759 ± 0.100</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.757 ± 0.120</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.808 ± 0.074</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">MGRL (Ours)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.795 ± 0.068</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.809 ± 0.146</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.823 ± 0.103</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.802 ± 0.075</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.886 ± 0.062</bold>
</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>The bold values mean to highlight the experiment results</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
        <fig position="float" id="F3">
          <label>Figure 3</label>
          <caption>
            <p>ROC curves achieved by six different methods in ASD vs. normal controls (NC) classification.</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0003" position="float"/>
        </fig>
        <p>To further test the robustness of the MGRL model, we also perform ASD vs. NC classification on the University of Michigan (UM) site from ABIDE. The phenotype information of UM site is in <xref rid="T1" ref-type="table">Table 1</xref>, and the experimental results are in <xref rid="T3" ref-type="table">Table 3</xref>. The results in <xref rid="T3" ref-type="table">Table 3</xref> suggest that our MGRL outperforms five competing methods (GCNA, GCNC, DCF, LCCF, and CCF) on the UM site, in terms of accuracy, F1-score, and recall. The underlying reason is that FCN features learned at different spatial scales may contain complementary information, which can be used together to improve the classification results.</p>
        <table-wrap position="float" id="T3">
          <label>Table 3</label>
          <caption>
            <p>Performance (mean ± SD) of different models in ASD vs. NC classification based on rs-fMRI data in UM site of the ABIDE dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Model</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Accuracy</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Recall</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Precision</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>F1-score</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>AUC</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">DCF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.645 ± 0.089</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.733 ± 0.187</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.691 ± 0.046</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.702 ± 0.103</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.633 ± 0.039</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">LCCF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.620 ± 0.077</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.720 ± 0.200</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.670 ± 0.059</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.681 ± 0.116</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.573 ± 0.045</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CCF</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.634 ± 0.105</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.761 ± 0.190</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.662 ± 0.076</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.702 ± 0.131</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.542 ± 0.049</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">GCNA</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.739 ± 0.098</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.710 ± 0.159</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.927 ± 0.067</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.790 ± 0.102</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.875 ± 0.065</bold>
</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">GCNC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.725 ± 0.082</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.651 ± 0.186</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.751 ± 0.108</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.677 ± 0.121</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.824 ± 0.057</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">MGRL (Ours)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.762 ± 0.078</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.843 ± 0.070</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.794 ± 0.100</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.812 ± 0.054</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.867 ± 0.049</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>The bold values mean to highlight the experiment results</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>4.4. Visualization of Network Features</title>
        <p>To investigate the distributions of FCNs features learned by different methods, we use the t-SNE (Van der Maaten and Hinton, <xref rid="B47" ref-type="bibr">2008</xref>) algorithm to reduce the dimensionality of FCN features of six methods (i.e., DCF, LCCF, CCF, GCNA, GCNC, and MGRL) to two dimensions, with results shown in <xref rid="F4" ref-type="fig">Figure 4</xref>. Note that the FCN features of three GCN-based methods (i.e., GCNA, GCNC, and MGRL) are generated by graph representation learning, while three conventional methods (i.e., DCF, LCCF, and CCF) use the concatenation of two-atlas features (i.e., degree centrality, local clustering coefficient, or closeness centrality features). As can be seen from <xref rid="F4" ref-type="fig">Figure 4</xref>, with three GCN-based methods (i.e., GCNA, GCNC, and our MGRL), samples of different categories tend to be as far as possible, while those of the same category tend to be as close as possible. But this trend is not obvious for three conventional methods (i.e., DCF, LCCF, and CCF). This implies that graph convolution operation used in GCN-based methods help extract more discriminative features for ASD detection, compared with three conventional methods.</p>
        <fig position="float" id="F4">
          <label>Figure 4</label>
          <caption>
            <p>Manifold visualization of ASD and NC training subjects in the New York University (NYU) site, where t-SNE (Van der Maaten and Hinton, <xref rid="B47" ref-type="bibr">2008</xref>) is used to project the multi-scale graph representations of FCNs learned by six different models. Note that the original features of three GCN-based methods (i.e., GCN with AAL atlas, GCNA; GCN with CC200 atlas, GCNC; and multi-scale graph representation learning, MGRL) are generated by graph representation learning, while three conventional methods (i.e., DCF, LCCF, and CCF) use the concatenation of two-atlas features (i.e., degree centrality, local clustering coefficient, or closeness centrality features), respectively.</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0004" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec sec-type="discussion" id="s5">
      <title>5. Discussion</title>
      <sec>
        <title>5.1. Influence of FCN Construction</title>
        <p>In the experiments, we use Pearson's correlation (PC) for FCNs construction. To investigate the influence of different FCN construction strategies, we compare our MGRL with two additional methods: (1) <bold>MGRL_Li</bold> uses the method proposed by Li et al. for FCNs construction Li et al. (<xref rid="B31" ref-type="bibr">2017</xref>), (2) <bold>MGRL_SR</bold> employs the sparse representation (SR) method Qiao et al. (<xref rid="B39" ref-type="bibr">2016</xref>) for FCNs construction. For clarity, we denote our MGRL with PC as <bold>MGRL_PC</bold> here. For fair comparison, these three methods share the same network architecture and parameter settings, and they differ only in FC construction strategies. In <xref rid="F5" ref-type="fig">Figure 5</xref>, we report the results of three methods in ASD vs. NC classification. This figure suggests that three methods achieve comparable results, while MGRL_SR is superior to MGRL_PC and MGRL_Li in terms of accuracy, recall, and F1-score. The underlying reason is that the SR algorithm can generate much sparser and less noisy brain FCNs, compared with the other two methods.</p>
        <fig position="float" id="F5">
          <label>Figure 5</label>
          <caption>
            <p>Results of three methods (with different network construction strategies) based on NYU site for identifying ASD from NC.</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0005" position="float"/>
        </fig>
        <p>At the same time, in <xref rid="F6" ref-type="fig">Figure 6</xref>, we visualize FCNs constructed via three models based on both the AAL (<xref rid="F6" ref-type="fig">Figure 6a</xref>) and CC200 (<xref rid="F6" ref-type="fig">Figure 6b</xref>) atlases. From this figure, we can see that compared with the other two methods, MGRL_SR can generate brain FCNs where functional connections among different ROIs tend to be sparser.</p>
        <fig position="float" id="F6">
          <label>Figure 6</label>
          <caption>
            <p>Visualization of FCNs for the same subject (NYU_50952) constructed by MGRL_PC (1st row), MGRL_Li (2nd row), and MGRL_SR (3rd row) based on the AAL atlas <bold>(a)</bold> and the CC200 atlas <bold>(b)</bold>.</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0006" position="float"/>
        </fig>
        <p>In addition, we select the threshold corresponding to the different sparsity in the set [60, 70, 80, 90, 100%] for multi-scale FCNs of MGRL_PC, where the percentage indicates the proportion of the edges that are retained. Then, we perform ASD vs. NC classification on the NYU site. The experimental results are reported in <xref rid="F7" ref-type="fig">Figure 7</xref>. As shown in <xref rid="F7" ref-type="fig">Figure 7</xref>, the MGRL_PC model with 80% brain FC achieves the best performance in terms of accuracy, recall, F1-score, and AUC. This implies that brain FCN may contain some noisy/redundant connections that may negatively affect the performance of the model.</p>
        <fig position="float" id="F7">
          <label>Figure 7</label>
          <caption>
            <p>Results of MGRL_PC in ASD vs. NC classification when retaining 100%, 90%, 80%, 70% and 60% functional connections of original brain FC networks on the NYU site.</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0007" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>5.2. Influence of Atlas Fusion</title>
        <p>In the proposed MGRL, two brain atlases (i.e., AAL and CC200) are used for ROI partition, and the generated FCN features are equally treated and fused for classification. We now investigate the influence of these two spatial scales when performing multi-scale feature fusion by varying the ratio of AAL to CC200 within the range of <inline-formula><mml:math id="M23" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mspace width="0.3em" class="thinspace"/><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, with experimental results reported in <xref rid="F8" ref-type="fig">Figure 8</xref>.</p>
        <fig position="float" id="F8">
          <label>Figure 8</label>
          <caption>
            <p>The results of the influence of different proportions of AAL and CC200 brain atlas on the classification accuracy of our MGRL model based on the NYU site during feature information fusion. The horizontal axis represents the proportion of AAL atlas and CC200 atlas features in fusion. The ordinate represents model classification accuracy.</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0008" position="float"/>
        </fig>
        <p>It can be seen from <xref rid="F8" ref-type="fig">Figure 8</xref> that the fusion ratio has a significant impact on the classification accuracy of the proposed MGRL in ASD diagnosis. As the ratio increases, the accuracy value gradually rises, and the best accuracy is obtained when the fusion ratio of AAL to CC200 is <inline-formula><mml:math id="M24" overflow="scroll"><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula>. This may be because the AAL atlas is a functional template divided according to the data of brain structure items, which is more consistent with our cognition and more beneficial to ASD diagnosis. In addition, these results also suggest that the fusion of multi-scale FCNs features does improve the learning performance compared to using only a single atlas for ROI partition.</p>
        <p>Besides, we also study the influence of the number of atlases and report the ASD diagnosis results of our MGRL method with two (i.e., AAL and CC200), three (i.e., AAL, CC200, and HO), and four (i.e., AAL, CC200, HO and Dosenbach) atlases in <xref rid="F9" ref-type="fig">Figure 9</xref>. This figure suggests that MGRL with two atlases achieves the best results and adding more atlases does not boost the performance. The possible reason is that high-dimensional node features obtained from multiple atlases may contain redundant or noisy information, thus reducing the classification performance.</p>
        <fig position="float" id="F9">
          <label>Figure 9</label>
          <caption>
            <p>Results of the proposed MGRL method based on NYU site using multi-scale atlases for ROI partition in the task of ASD vs. NC classification. HO, Harvard Oxford atlas with 112 ROIs; DOH, Dosenbach atlas with 160 ROIs (Dosenbach et al., <xref rid="B18" ref-type="bibr">2010</xref>).</p>
          </caption>
          <graphic xlink:href="fninf-15-802305-g0009" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>5.3. Comparison With State-Of-The-Art</title>
        <p>We further compared the results of the MGRL experiment with several state-of-the-art methods for fMRI-based ASD diagnosis based on the ABIDE database. Specifically, Sun et al. proposed an FCNs estimation model (without hyperparameters) to avoid the parameter selection problem and used the traditional support vector machine (SVM) (Cortes and Vapnik, <xref rid="B13" ref-type="bibr">1995</xref>) for classification (Sun et al., <xref rid="B45" ref-type="bibr">2021</xref>). Wang et al. proposed a multi-site domain adaptation framework with low-rank representation and used traditional SVM classifier to identify ASD (Wang et al., <xref rid="B53" ref-type="bibr">2019b</xref>). The AAL atlas with 116 brain regions was used for the above-mentioned two methods. Parisot et al. and Cao et al. employed fMRI data and phenotypic information of ROIs based on the HO atlas and constructed a GCN model to identify ASD from NC (Parisot et al., <xref rid="B36" ref-type="bibr">2018</xref>; Cao et al., <xref rid="B9" ref-type="bibr">2021</xref>). Shrivastava et al. used the Craddock 400 (CC400) (Desikan et al., <xref rid="B16" ref-type="bibr">2006</xref>) atlas for ROI partition and developed a convolutional neural network (CNN) for ASD diagnosis (Shrivastava et al., <xref rid="B41" ref-type="bibr">2020</xref>). Niu et al. proposed to take advantage of complementary information provided by different brain atlases and designed a multi-channel Deep Attention Neural Network (DANN) model for automated ASD diagnosis (Niu et al., <xref rid="B35" ref-type="bibr">2020</xref>). The classification results of our MGRL and these state-of-the-art methods are given in the <xref rid="T4" ref-type="table">Table 4</xref>. Note that the results in this table are not fully comparable, since different studies use different subsets of ABIDE. The rough comparison in <xref rid="T4" ref-type="table">Table 4</xref> demonstrates the superiority of the MGRL method in mining and fusing multi-scale FCNs features for ASD diagnosis.</p>
        <table-wrap position="float" id="T4">
          <label>Table 4</label>
          <caption>
            <p>Performance comparison between the proposed MGRL and several state-of-the-art methods for ASD vs. NC classification with fMRI data from ABIDE.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Method</bold>
</th>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Algorithm</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Accuracy</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Recall</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Precision</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>AUC</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Sample #</bold>
</th>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Brain Atlas</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">MGRL (Ours)</td>
                <td valign="top" align="left" rowspan="1" colspan="1">GCN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.795</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.809</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.823</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>0.886</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">184</td>
                <td valign="top" align="left" rowspan="1" colspan="1">AAL, CC200</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>The results of multi-scale graph representation learning (MGRL) are based on the NYU site. <sup>#</sup>represents the number of samples. The bold values mean to highlight the experiment results</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>5.4. Limitations and Future Work</title>
        <p>To further improve the performance of the proposed method, several technical issues need to be considered. <italic>On the one hand</italic>, to avoid significant inter-site heterogeneity, we mainly used rs-fMRI data from the NYU site. While ABIDE contains data from 21 sites, as a future work, we will evaluate the proposed method on all sites in ABIDE and design smart techniques to reduce inter-site data heterogeneity. <italic>On the other hand</italic>, the direct fusion of multi-scale FCN features may introduce redundant or even noise information, thus degrading the learning performance. Interestingly, incorporating the high-level attention mechanism into the current framework can avoid the negative impact of redundant/noisy information, which is also our next consideration.</p>
      </sec>
    </sec>
    <sec sec-type="conclusions" id="s6">
      <title>6. Conclusion</title>
      <p>In this paper, we develop a multi-scale graph representation learning (MGRL) framework for the automatic diagnosis of ASD based on rs-fMRI. In MGRL, for each subject, we first use multiple brain atlases for ROI partition to construct multi-scale FCNs. Then, we employ multi-scale GCNs for FCNs feature learning, followed by feature fusion and classification. We evaluate the MGRL on 184 subjects from ABIDE database with rs-fMRI scans, with results demonstrating its effectiveness in FCNs feature learning and ASD diagnosis.</p>
    </sec>
    <sec sec-type="data-availability" id="s7">
      <title>Data Availability Statement</title>
      <p>The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s.</p>
    </sec>
    <sec id="s8">
      <title>Ethics Statement</title>
      <p>Ethical review and approval was not required for the study on human participants in accordance with the local legislation and institutional requirements. Written informed consent from the participants' legal guardian/next of kin was not required to participate in this study in accordance with the national legislation and the institutional requirements.</p>
    </sec>
    <sec id="s9">
      <title>Author Contributions</title>
      <p>YC and ML designed the study. YC downloaded and analyzed the data, performed the experiments, and drafted the manuscript. YC, GW, LC, LQ, and ML revised the manuscript. All authors have read and approved the final manuscript.</p>
    </sec>
    <sec sec-type="funding-information" id="s10">
      <title>Funding</title>
      <p>YC, GW, and LQ were partly supported by National Natural Science Foundation of China (Nos. 62176112, 61976110, and 11931008), Natural Science Foundation of Shandong Province (Nos. ZR2018MF020 and ZR2019YQ27), and Taishan Scholar Program of Shandong Province and the Open Project of Liaocheng University Animal Husbandry Discipline (No. 319312101-01).</p>
    </sec>
    <sec sec-type="COI-statement" id="conf1">
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
    <sec sec-type="disclaimer" id="s11">
      <title>Publisher's Note</title>
      <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ahammed</surname><given-names>M. S.</given-names></name><name><surname>Niu</surname><given-names>S.</given-names></name><name><surname>Ahmed</surname><given-names>M. R.</given-names></name><name><surname>Dong</surname><given-names>J.</given-names></name><name><surname>Gao</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name></person-group> (<year>2021</year>). <article-title>Bag-of-features model for asd fMRI classification using SVM,</article-title> in <source>2021 Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)</source>, 52–57. <pub-id pub-id-type="doi">10.1109/ACCTCS52002.2021.00019</pub-id></mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>American Psychiatric Association</collab></person-group> (<year>2013</year>). <source>Diagnostic and Statistical Manual of Mental Disorders</source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychiatric Association</publisher-name>. <pub-id pub-id-type="doi">10.1176/appi.books.9780890425596</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amini</surname><given-names>M.</given-names></name><name><surname>Pedram</surname><given-names>M.</given-names></name><name><surname>Moradi</surname><given-names>A.</given-names></name><name><surname>Ouchani</surname><given-names>M.</given-names></name></person-group> (<year>2021</year>). <article-title>Diagnosis of Alzheimer's disease severity with fMRI images using robust multitask feature extraction method and convolutional neural network (CNN)</article-title>. <source>Comput. Math. Methods Med</source>. <volume>2021</volume>:<fpage>5514839</fpage>. <pub-id pub-id-type="doi">10.1155/2021/5514839</pub-id><pub-id pub-id-type="pmid">34007305</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anirudh</surname><given-names>R.</given-names></name><name><surname>Thiagarajan</surname><given-names>J. J.</given-names></name></person-group> (<year>2019</year>). <article-title>Bootstrapping graph convolutional neural networks for Autism spectrum disorder classification,</article-title> in <source>ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</source> (<publisher-loc>IEEE</publisher-loc>), <fpage>3197</fpage>–<lpage>3201</lpage>. <pub-id pub-id-type="doi">10.1109/ICASSP.2019.8683547</pub-id></mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baio</surname><given-names>J.</given-names></name><name><surname>Wiggins</surname><given-names>L.</given-names></name><name><surname>Christensen</surname><given-names>D. L.</given-names></name><name><surname>Maenner</surname><given-names>M. J.</given-names></name><name><surname>Daniels</surname><given-names>J.</given-names></name><name><surname>Warren</surname><given-names>Z.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Prevalence of autism spectrum disorder among children aged 8 years—autism and developmental disabilities monitoring network, 11 sites, United States, 2014</article-title>. <source>MMWR Surveill. Summ.</source>
<volume>67</volume>:<fpage>1</fpage>.<pub-id pub-id-type="pmid">29701730</pub-id></mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bijsterbosch</surname><given-names>J.</given-names></name><name><surname>Beckmann</surname><given-names>C.</given-names></name></person-group> (<year>2017</year>). <source>An Introduction to Resting State fMRI Functional Connectivity</source>. Oxford University Press.</mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Bruna</surname><given-names>J.</given-names></name><name><surname>Zaremba</surname><given-names>W.</given-names></name><name><surname>Szlam</surname><given-names>A.</given-names></name><name><surname>LeCun</surname><given-names>Y.</given-names></name></person-group> (<year>2013</year>). <source>Spectral networks and locally connected networks on graphs. <italic>arXiv Preprint arXiv:1312.6203</italic></source>. Available online at: <ext-link xlink:href="http://arxiv.org/abs/1312.6203" ext-link-type="uri">http://arxiv.org/abs/1312.6203</ext-link></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>R. L.</given-names></name><name><surname>Krienen</surname><given-names>F. M.</given-names></name><name><surname>Yeo</surname><given-names>B. T.</given-names></name></person-group> (<year>2013</year>). <article-title>Opportunities and limitations of intrinsic functional connectivity MRI</article-title>. <source>Nat. Neurosci</source>. <volume>16</volume>, <fpage>832</fpage>–<lpage>837</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3423</pub-id><pub-id pub-id-type="pmid">23799476</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>M.</given-names></name><name><surname>Qin</surname><given-names>C.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Using deepGCN to identify the autism spectrum disorder from multi-site resting-state data</article-title>. <source>Biomed. Signal Process. Control</source>
<volume>70</volume>:<fpage>103015</fpage>. <pub-id pub-id-type="doi">10.1016/j.bspc.2021.103015</pub-id></mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cartwright</surname><given-names>D.</given-names></name><name><surname>Harary</surname><given-names>F.</given-names></name></person-group> (<year>1956</year>). <article-title>Structural balance: a generalization of Heider's theory</article-title>. <source>Psychol. Rev</source>. <volume>63</volume>:<fpage>277</fpage>. <pub-id pub-id-type="doi">10.1037/h0046049</pub-id><pub-id pub-id-type="pmid">13359597</pub-id></mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Estimating brain functional networks based on adaptively-weighted fMRI signals for MCI identification</article-title>. <source>Front. Aging Neurosci</source>. <volume>12</volume>:<fpage>595322</fpage>. <pub-id pub-id-type="doi">10.3389/fnagi.2020.595322</pub-id><pub-id pub-id-type="pmid">33584242</pub-id></mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>C.</given-names></name><name><surname>Lee</surname><given-names>S.-W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>Extraction of dynamic functional connectivity from brain grey matter and white matter for MCI classification</article-title>. <source>Hum. Brain Mapp</source>. <volume>38</volume>, <fpage>5019</fpage>–<lpage>5034</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23711</pub-id><pub-id pub-id-type="pmid">28665045</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>). <article-title>Support-vector networks</article-title>. <source>Mach. Learn</source>. <volume>20</volume>, <fpage>273</fpage>–<lpage>297</lpage>. <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>James</surname><given-names>G. A.</given-names></name><name><surname>Holtzheimer</surname><given-names>P. E.</given-names><suffix>III.</suffix></name><name><surname>Hu</surname><given-names>X. P.</given-names></name><name><surname>Mayberg</surname><given-names>H. S.</given-names></name></person-group> (<year>2012</year>). <article-title>A whole brain fMRI atlas generated via spatially constrained spectral clustering</article-title>. <source>Hum. Brain Mapp</source>. <volume>33</volume>, <fpage>1914</fpage>–<lpage>1928</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.21333</pub-id><pub-id pub-id-type="pmid">21769991</pub-id></mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Defferrard</surname><given-names>M.</given-names></name><name><surname>Bresson</surname><given-names>X.</given-names></name><name><surname>Vandergheynst</surname><given-names>P.</given-names></name></person-group> (<year>2016</year>). <article-title>Convolutional neural networks on graphs with fast localized spectral filtering</article-title>. <source>Adv. Neural Inform. Process. Syst</source>. <volume>29</volume>, <fpage>3844</fpage>–<lpage>3852</lpage>. Available online at: <ext-link xlink:href="http://arxiv.org/abs/1606.09375v2" ext-link-type="uri">http://arxiv.org/abs/1606.09375v2</ext-link></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname><given-names>R. S.</given-names></name><name><surname>Ségonne</surname><given-names>F.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Quinn</surname><given-names>B. T.</given-names></name><name><surname>Dickerson</surname><given-names>B. C.</given-names></name><name><surname>Blacker</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>Neuroimage</source>
<volume>31</volume>, <fpage>968</fpage>–<lpage>980</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><pub-id pub-id-type="pmid">16530430</pub-id></mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>A.</given-names></name><name><surname>Yan</surname><given-names>C.-G.</given-names></name><name><surname>Li</surname><given-names>Q.</given-names></name><name><surname>Denio</surname><given-names>E.</given-names></name><name><surname>Castellanos</surname><given-names>F. X.</given-names></name><name><surname>Alaerts</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>. <source>Mol. Psychiatry</source>
<volume>19</volume>, <fpage>659</fpage>–<lpage>667</lpage>. <pub-id pub-id-type="doi">10.1038/mp.2013.78</pub-id><pub-id pub-id-type="pmid">23774715</pub-id></mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosenbach</surname><given-names>N. U.</given-names></name><name><surname>Nardos</surname><given-names>B.</given-names></name><name><surname>Cohen</surname><given-names>A. L.</given-names></name><name><surname>Fair</surname><given-names>D. A.</given-names></name><name><surname>Power</surname><given-names>J. D.</given-names></name><name><surname>Church</surname><given-names>J. A.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Prediction of individual brain maturity using fMRI</article-title>. <source>Science</source>
<volume>329</volume>, <fpage>1358</fpage>–<lpage>1361</lpage>. <pub-id pub-id-type="doi">10.1126/science.1194144</pub-id><pub-id pub-id-type="pmid">20829489</pub-id></mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dvornek</surname><given-names>N. C.</given-names></name><name><surname>Ventola</surname><given-names>P.</given-names></name><name><surname>Pelphrey</surname><given-names>K. A.</given-names></name><name><surname>Duncan</surname><given-names>J. S.</given-names></name></person-group> (<year>2017</year>). <article-title>Identifying Autism from resting-state fMRI using long short-term memory networks,</article-title> in <source>International Workshop on Machine Learning in Medical Imaging</source> (<publisher-loc>Springer</publisher-loc>), <fpage>362</fpage>–<lpage>370</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-67389-9_42</pub-id></mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>El Gazzar</surname><given-names>A.</given-names></name><name><surname>Cerliani</surname><given-names>L.</given-names></name><name><surname>van Wingen</surname><given-names>G.</given-names></name><name><surname>Thomas</surname><given-names>R. M.</given-names></name></person-group> (<year>2019</year>). <article-title>Simple 1-D convolutional networks for resting-state fMRI based classification in autism,</article-title> in <source>2019 International Joint Conference on Neural Networks (IJCNN)</source> (<publisher-loc>IEEE</publisher-loc>), <fpage>1</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1109/IJCNN.2019.8852002</pub-id></mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>W. L..</given-names></name></person-group> (<year>2020</year>). <article-title>Graph representation learning</article-title>. <source>Synthesis Lectures Artif. Intell. Mach. Learn</source>. <volume>14</volume>, <fpage>1</fpage>–<lpage>159</lpage>. <pub-id pub-id-type="doi">10.2200/S01045ED1V01Y202009AIM046</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heider</surname><given-names>F..</given-names></name></person-group> (<year>1946</year>). <article-title>Attitudes and cognitive organization</article-title>. <source>J. Psychol</source>. <volume>21</volume>, <fpage>107</fpage>–<lpage>112</lpage>. <pub-id pub-id-type="doi">10.1080/00223980.1946.9917275</pub-id><pub-id pub-id-type="pmid">21010780</pub-id></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hodges</surname><given-names>H.</given-names></name><name><surname>Fealko</surname><given-names>C.</given-names></name><name><surname>Soares</surname><given-names>N.</given-names></name></person-group> (<year>2020</year>). <article-title>Autism spectrum disorder: definition, epidemiology, causes, and clinical evaluation</article-title>. <source>Transl. Pediatr</source>. 9(Suppl 1):S55. <pub-id pub-id-type="doi">10.21037/tp.2019.09.09</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>Hyper-connectivity of functional networks for brain disease diagnosis</article-title>. <source>Med. Image Anal</source>. <volume>32</volume>, <fpage>84</fpage>–<lpage>100</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2016.03.003</pub-id><pub-id pub-id-type="pmid">27060621</pub-id></mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawahara</surname><given-names>J.</given-names></name><name><surname>Brown</surname><given-names>C. J.</given-names></name><name><surname>Miller</surname><given-names>S. P.</given-names></name><name><surname>Booth</surname><given-names>B. G.</given-names></name><name><surname>Chau</surname><given-names>V.</given-names></name><name><surname>Grunau</surname><given-names>R. E.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>BrainNetCNN: Convolutional neural networks for brain networks; towards predicting neurodevelopment</article-title>. <source>Neuroimage</source>
<volume>146</volume>, <fpage>1038</fpage>–<lpage>1049</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.09.046</pub-id><pub-id pub-id-type="pmid">27693612</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kazi</surname><given-names>A.</given-names></name><name><surname>Shekarforoush</surname><given-names>S.</given-names></name><name><surname>Krishna</surname><given-names>S. A.</given-names></name><name><surname>Burwinkel</surname><given-names>H.</given-names></name><name><surname>Vivar</surname><given-names>G.</given-names></name><name><surname>Kortüm</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>InceptionGCN: receptive field aware graph convolutional network for disease prediction,</article-title> in <source>International Conference on Information Processing in Medical Imaging</source> (<publisher-loc>Springer</publisher-loc>), <fpage>73</fpage>–<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-20351-1_6</pub-id></mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D. P.</given-names></name><name><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <source>Adam: a method for stochastic optimization. <italic>arXiv preprint arXiv:1412.6980</italic></source>. Available online at: <ext-link xlink:href="http://arxiv.org/abs/1412.6980" ext-link-type="uri">http://arxiv.org/abs/1412.6980</ext-link></mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Kipf</surname><given-names>T. N.</given-names></name><name><surname>Welling</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>). <source>Semi-supervised classification with graph convolutional networks. <italic>arXiv Preprint arXiv:1609.02907</italic></source>. Available online at: <ext-link xlink:href="http://arxiv.org/abs/1609.02907" ext-link-type="uri">http://arxiv.org/abs/1609.02907</ext-link></mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ktena</surname><given-names>S. I.</given-names></name><name><surname>Parisot</surname><given-names>S.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Rajchl</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Glocker</surname><given-names>B.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Metric learning with spectral graph convolutions on brain connectivity networks</article-title>. <source>Neuroimage</source>
<volume>169</volume>, <fpage>431</fpage>–<lpage>442</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.12.052</pub-id><pub-id pub-id-type="pmid">29278772</pub-id></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>I.</given-names></name><name><surname>Kang</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>Self-attention graph pooling,</article-title> in <source>International Conference on Machine Learning</source> (<publisher-loc>PMLR</publisher-loc>), <fpage>3734</fpage>–<lpage>3743</lpage>.</mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>Remodeling Pearson's correlation for functional brain network estimation and autism spectrum disorder identification</article-title>. <source>Front. Neuroinform</source>. <volume>11</volume>:<fpage>55</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2017.00055</pub-id><pub-id pub-id-type="pmid">28912708</pub-id></mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Dvornek</surname><given-names>N. C.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Zhuang</surname><given-names>J.</given-names></name><name><surname>Ventola</surname><given-names>P.</given-names></name><name><surname>Duncan</surname><given-names>J. S.</given-names></name></person-group> (<year>2019</year>). <article-title>Graph neural network for interpreting task-fMRI biomarkers,</article-title> in <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Springer</publisher-loc>), <fpage>485</fpage>–<lpage>493</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-32254-0_54</pub-id></mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Tang</surname><given-names>Z.</given-names></name><name><surname>Lei</surname><given-names>B.</given-names></name></person-group> (<year>2020</year>). <article-title>Deep spatial-temporal feature fusion from adaptive dynamic functional connectivity for MCI identification</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>39</volume>, <fpage>2818</fpage>–<lpage>2830</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2020.2976825</pub-id><pub-id pub-id-type="pmid">32112678</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lord</surname><given-names>C.</given-names></name><name><surname>Elsabbagh</surname><given-names>M.</given-names></name><name><surname>Baird</surname><given-names>G.</given-names></name><name><surname>Veenstra-Vanderweele</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). <article-title>Autism spectrum disorder</article-title>. <source>Lancet</source>
<volume>392</volume>, <fpage>508</fpage>–<lpage>520</lpage>. <pub-id pub-id-type="doi">10.1016/S0140-6736(18)31129-2</pub-id><pub-id pub-id-type="pmid">30078460</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>K.</given-names></name><name><surname>Guo</surname><given-names>J.</given-names></name><name><surname>Pan</surname><given-names>Y.</given-names></name><name><surname>Gao</surname><given-names>X.</given-names></name><name><surname>Peng</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Multichannel deep attention neural networks for the classification of autism spectrum disorder using neuroimaging and personal characteristic data</article-title>. <source>Complexity</source>
<volume>2020</volume>:<fpage>1357853</fpage>. <pub-id pub-id-type="doi">10.1155/2020/1357853</pub-id></mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parisot</surname><given-names>S.</given-names></name><name><surname>Ktena</surname><given-names>S. I.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Guerrero</surname><given-names>R.</given-names></name><name><surname>Glocker</surname><given-names>B.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Disease prediction using graph convolutional networks: application to Autism spectrum disorder and Alzheimer's disease</article-title>. <source>Med. Image Anal</source>. <volume>48</volume>, <fpage>117</fpage>–<lpage>130</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2018.06.001</pub-id><pub-id pub-id-type="pmid">29890408</pub-id></mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedersen</surname><given-names>M.</given-names></name><name><surname>Omidvarnia</surname><given-names>A. H.</given-names></name><name><surname>Walz</surname><given-names>J. M.</given-names></name><name><surname>Jackson</surname><given-names>G. D.</given-names></name></person-group> (<year>2015</year>). <article-title>Increased segregation of brain networks in focal epilepsy: an fMRI graph theory finding</article-title>. <source>Neuroimage Clin</source>. <volume>8</volume>, <fpage>536</fpage>–<lpage>542</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2015.05.009</pub-id><pub-id pub-id-type="pmid">26110111</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>J. D.</given-names></name><name><surname>Cohen</surname><given-names>A. L.</given-names></name><name><surname>Nelson</surname><given-names>S. M.</given-names></name><name><surname>Wig</surname><given-names>G. S.</given-names></name><name><surname>Barnes</surname><given-names>K. A.</given-names></name><name><surname>Church</surname><given-names>J. A.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source>
<volume>72</volume>, <fpage>665</fpage>–<lpage>678</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.006</pub-id><pub-id pub-id-type="pmid">22099467</pub-id></mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Kim</surname><given-names>M.</given-names></name><name><surname>Teng</surname><given-names>S.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>Estimating functional brain networks by incorporating a modularity prior</article-title>. <source>Neuroimage</source>
<volume>141</volume>, <fpage>399</fpage>–<lpage>407</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.07.058</pub-id><pub-id pub-id-type="pmid">27485752</pub-id></mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salvador</surname><given-names>R.</given-names></name><name><surname>Martinez</surname><given-names>A.</given-names></name><name><surname>Pomarol-Clotet</surname><given-names>E.</given-names></name><name><surname>Sarró</surname><given-names>S.</given-names></name><name><surname>Suckling</surname><given-names>J.</given-names></name><name><surname>Bullmore</surname><given-names>E.</given-names></name></person-group> (<year>2007</year>). <article-title>Frequency based mutual information measures between clusters of brain regions in functional magnetic resonance imaging</article-title>. <source>NeuroImage</source>
<volume>35</volume>, <fpage>83</fpage>–<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.12.001</pub-id><pub-id pub-id-type="pmid">17240167</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shrivastava</surname><given-names>S.</given-names></name><name><surname>Mishra</surname><given-names>U.</given-names></name><name><surname>Singh</surname><given-names>N.</given-names></name><name><surname>Chandra</surname><given-names>A.</given-names></name><name><surname>Verma</surname><given-names>S.</given-names></name></person-group> (<year>2020</year>). <article-title>Control or autism-classification using convolutional neural networks on functional MRI,</article-title> in <source>2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)</source> (<publisher-loc>IEEE</publisher-loc>), <fpage>1</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1109/ICCCNT49239.2020.9225506</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shuman</surname><given-names>D. I.</given-names></name><name><surname>Narang</surname><given-names>S. K.</given-names></name><name><surname>Frossard</surname><given-names>P.</given-names></name><name><surname>Ortega</surname><given-names>A.</given-names></name><name><surname>Vandergheynst</surname><given-names>P.</given-names></name></person-group> (<year>2013</year>). <article-title>The emerging field of signal processing on graphs: extending high-dimensional data analysis to networks and other orregular domains</article-title>. <source>IEEE Signal Process. Mag</source>. <volume>30</volume>, <fpage>83</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1109/MSP.2012.2235192</pub-id><pub-id pub-id-type="pmid">27295638</pub-id></mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonoff</surname><given-names>E.</given-names></name><name><surname>Pickles</surname><given-names>A.</given-names></name><name><surname>Charman</surname><given-names>T.</given-names></name><name><surname>Chandler</surname><given-names>S.</given-names></name><name><surname>Loucas</surname><given-names>T.</given-names></name><name><surname>Baird</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Psychiatric disorders in children with autism spectrum disorders: prevalence, comorbidity, and asociated factors in a population-derived sample</article-title>. <source>J. Am. Acad. Child Adolesc. Psychiatry</source>
<volume>47</volume>, <fpage>921</fpage>–<lpage>929</lpage>. <pub-id pub-id-type="doi">10.1097/CHI.0b013e318179964f</pub-id><pub-id pub-id-type="pmid">18645422</pub-id></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>F.</given-names></name><name><surname>Frangi</surname><given-names>A. F.</given-names></name><name><surname>Cao</surname><given-names>J.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Lei</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Graph convolution network with similarity awareness and adaptive calibration for disease-induced deterioration prediction</article-title>. <source>Med. Image Anal</source>. <volume>69</volume>:<fpage>101947</fpage>. <pub-id pub-id-type="doi">10.1016/j.media.2020.101947</pub-id><pub-id pub-id-type="pmid">33388456</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>L.</given-names></name><name><surname>Xue</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2021</year>). <article-title>Estimating sparse functional connectivity networks via hyperparameter-free learning model</article-title>. <source>Artif. Intell. Med</source>. <volume>111</volume>:<fpage>102004</fpage>. <pub-id pub-id-type="doi">10.1016/j.artmed.2020.102004</pub-id><pub-id pub-id-type="pmid">33461688</pub-id></mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name><name><surname>Landeau</surname><given-names>B.</given-names></name><name><surname>Papathanassiou</surname><given-names>D.</given-names></name><name><surname>Crivello</surname><given-names>F.</given-names></name><name><surname>Etard</surname><given-names>O.</given-names></name><name><surname>Delcroix</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2002</year>). <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>Neuroimage</source>
<volume>15</volume>, <fpage>273</fpage>–<lpage>289</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id><pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Maaten</surname><given-names>L.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res.</source>
<volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>. Available online at: <ext-link xlink:href="http://www.marcottelab.org/users/BCH339N_2018/tSNE.pdf" ext-link-type="uri">http://www.marcottelab.org/users/BCH339N_2018/tSNE.pdf</ext-link></mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vivar-Estudillo</surname><given-names>G.</given-names></name><name><surname>Hajari</surname><given-names>N.</given-names></name><name><surname>Ibarra-Manzano</surname><given-names>M.-A.</given-names></name><name><surname>Cheng</surname><given-names>I.</given-names></name></person-group> (<year>2021</year>). <article-title>Parkinson's disease detection and diagnosis from fMRI: a literature review,</article-title> in <source>International Conference on Human-Computer Interaction</source> (<publisher-loc>Springer</publisher-loc>), <fpage>630</fpage>–<lpage>638</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-78092-0_44</pub-id></mixed-citation>
      </ref>
      <ref id="B49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H. E.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Bénar</surname><given-names>C. G.</given-names></name><name><surname>Woodman</surname><given-names>M. M.</given-names></name><name><surname>Chauvel</surname><given-names>P.</given-names></name><name><surname>Jirsa</surname><given-names>V.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Mulan: evaluation and ensemble statistical inference for functional connectivity</article-title>. <source>Neuroimage</source>
<volume>166</volume>, <fpage>167</fpage>–<lpage>184</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.036</pub-id><pub-id pub-id-type="pmid">29111409</pub-id></mixed-citation>
      </ref>
      <ref id="B50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Zuo</surname><given-names>X.</given-names></name><name><surname>Dai</surname><given-names>Z.</given-names></name><name><surname>Xia</surname><given-names>M.</given-names></name><name><surname>Zhao</surname><given-names>Z.</given-names></name><name><surname>Zhao</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Disrupted functional brain connectome in individuals at risk for Alzheimer's disease</article-title>. <source>Biol. Psychiatry</source>
<volume>73</volume>, <fpage>472</fpage>–<lpage>481</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2012.03.026</pub-id><pub-id pub-id-type="pmid">22537793</pub-id></mixed-citation>
      </ref>
      <ref id="B51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name><name><surname>Hu</surname><given-names>X. P.</given-names></name></person-group> (<year>2021</year>). <article-title>Graph convolutional network for fMRI analysis based on connectivity neighborhood</article-title>. <source>Netw. Neurosci</source>. <volume>5</volume>, <fpage>83</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1162/netn_a_00171</pub-id><pub-id pub-id-type="pmid">33688607</pub-id></mixed-citation>
      </ref>
      <ref id="B52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Lian</surname><given-names>C.</given-names></name><name><surname>Yao</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2019a</year>). <article-title>Spatial-temporal dependency modeling and network hub detection for functional MRI analysis via convolutional-recurrent network</article-title>. <source>IEEE Trans. Biomed. Eng</source>. <volume>67</volume>, <fpage>2241</fpage>–<lpage>2252</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2019.2957921</pub-id><pub-id pub-id-type="pmid">31825859</pub-id></mixed-citation>
      </ref>
      <ref id="B53">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Yap</surname><given-names>P.-T.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2019b</year>). <article-title>Identifying autism spectrum disorder with multi-site fMRI via low-rank domain adaptation</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>39</volume>, <fpage>644</fpage>–<lpage>655</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2019.2933160</pub-id><pub-id pub-id-type="pmid">31395542</pub-id></mixed-citation>
      </ref>
      <ref id="B54">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Pan</surname><given-names>S.</given-names></name><name><surname>Chen</surname><given-names>F.</given-names></name><name><surname>Long</surname><given-names>G.</given-names></name><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Philip</surname><given-names>S. Y.</given-names></name></person-group> (<year>2020</year>). <article-title>A comprehensive survey on graph neural networks</article-title>. <source>IEEE Trans. Neural Netw. Learn. Syst</source>. <volume>32</volume>, <fpage>4</fpage>–<lpage>24</lpage>. <pub-id pub-id-type="doi">10.1109/TNNLS.2020.2978386</pub-id><pub-id pub-id-type="pmid">32217482</pub-id></mixed-citation>
      </ref>
      <ref id="B55">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>Q.</given-names></name><name><surname>Wei</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Zhan</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>X. S.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Dynamic spectral graph convolution networks with assistant task training for early MCI diagnosis,</article-title> in <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Springer</publisher-loc>), <fpage>639</fpage>–<lpage>646</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-32251-9_70</pub-id></mixed-citation>
      </ref>
      <ref id="B56">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xue</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Estimating sparse functional brain networks with spatial constraints for MCI identification</article-title>. <source>PLoS ONE</source>
<volume>15</volume>:<fpage>e0235039</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0235039</pub-id><pub-id pub-id-type="pmid">32707574</pub-id></mixed-citation>
      </ref>
      <ref id="B57">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>C.-G.</given-names></name><name><surname>Wang</surname><given-names>X.-D.</given-names></name><name><surname>Zuo</surname><given-names>X.-N.</given-names></name><name><surname>Zang</surname><given-names>Y.-F.</given-names></name></person-group> (<year>2016</year>). <article-title>DPABI: data processing &amp; analysis for (resting-state) brain imaging</article-title>. <source>Neuroinformatics</source>
<volume>14</volume>, <fpage>339</fpage>–<lpage>351</lpage>. <pub-id pub-id-type="doi">10.1007/s12021-016-9299-4</pub-id><pub-id pub-id-type="pmid">27075850</pub-id></mixed-citation>
      </ref>
      <ref id="B58">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>R.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Chen</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>S.-W.</given-names></name><name><surname>Fei</surname><given-names>X.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2019</year>). <article-title>Weighted graph regularized sparse brain network construction for MCI identification</article-title>. <source>Pattern Recogn</source>. <volume>90</volume>, <fpage>220</fpage>–<lpage>231</lpage>. <pub-id pub-id-type="doi">10.1016/j.patcog.2019.01.015</pub-id><pub-id pub-id-type="pmid">31579345</pub-id></mixed-citation>
      </ref>
      <ref id="B59">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Cao</surname><given-names>J.</given-names></name><name><surname>Yue</surname><given-names>G.</given-names></name><name><surname>Liu</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Multi-scale enhanced graph convolutional network for early mild cognitive impairment detection,</article-title> in <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Springer</publisher-loc>), <fpage>228</fpage>–<lpage>237</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-59728-3_23</pub-id></mixed-citation>
      </ref>
      <ref id="B60">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Du</surname><given-names>J.</given-names></name><name><surname>Tu</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2018a</year>). <article-title>Ordinal pattern: a new descriptor for brain connectivity networks</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>37</volume>, <fpage>1711</fpage>–<lpage>1722</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2018.2798500</pub-id><pub-id pub-id-type="pmid">29969421</pub-id></mixed-citation>
      </ref>
      <ref id="B61">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Cui</surname><given-names>Z.</given-names></name><name><surname>Neumann</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name></person-group> (<year>2018b</year>). <article-title>An end-to-end deep learning architecture for graph classification,</article-title> in <source>Thirty-Second AAAI Conference on Artificial Intelligence</source>.</mixed-citation>
      </ref>
      <ref id="B62">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Jiang</surname><given-names>X.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2021</year>). <article-title>Modularity-guided functional brain network analysis for early-stage dementia identification</article-title>. <source>Front. Neurosci</source>. <volume>15</volume>:<fpage>720909</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2021.720909</pub-id><pub-id pub-id-type="pmid">34421530</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
