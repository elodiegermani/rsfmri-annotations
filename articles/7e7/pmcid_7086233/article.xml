<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">32062083</article-id>
      <article-id pub-id-type="pmc">7086233</article-id>
      <article-id pub-id-type="publisher-id">S1053-8119(20)30091-4</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2020.116604</article-id>
      <article-id pub-id-type="publisher-id">116604</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Optimising network modelling methods for fMRI</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" id="au1">
          <name>
            <surname>Pervaiz</surname>
            <given-names>Usama</given-names>
          </name>
          <email>usama.pervaiz@ndcn.ox.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="cor1" ref-type="corresp">∗</xref>
        </contrib>
        <contrib contrib-type="author" id="au2">
          <name>
            <surname>Vidaurre</surname>
            <given-names>Diego</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">b</xref>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author" id="au3">
          <name>
            <surname>Woolrich</surname>
            <given-names>Mark W.</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author" id="au4">
          <name>
            <surname>Smith</surname>
            <given-names>Stephen M.</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>a</label>Oxford Centre for Functional MRI of the Brain (FMRIB), Wellcome Centre for Integrative Neuroimaging, Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, OX3 9DU, United Kingdom</aff>
      <aff id="aff2"><label>b</label>Oxford Centre for Human Brain Activity (OHBA), Wellcome Centre for Integrative Neuroimaging, Department of Psychiatry, University of Oxford, Oxford, OX3 7JX, United Kingdom</aff>
      <aff id="aff3"><label>c</label>Department of Clinical Medicine, Aarhus University, Denmark</aff>
      <author-notes>
        <corresp id="cor1"><label>∗</label>Corresponding author. <email>usama.pervaiz@ndcn.ox.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>01</day>
        <month>5</month>
        <year>2020</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="ppub">.-->
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>5</month>
        <year>2020</year>
      </pub-date>
      <volume>211</volume>
      <elocation-id>116604</elocation-id>
      <history>
        <date date-type="received">
          <day>5</day>
          <month>11</month>
          <year>2019</year>
        </date>
        <date date-type="rev-recd">
          <day>30</day>
          <month>1</month>
          <year>2020</year>
        </date>
        <date date-type="accepted">
          <day>1</day>
          <month>2</month>
          <year>2020</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2020 The Author(s)</copyright-statement>
        <copyright-year>2020</copyright-year>
        <license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/">
          <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
        </license>
      </permissions>
      <abstract id="abs0010">
        <p>A major goal of neuroimaging studies is to develop predictive models to analyze the relationship between whole brain functional connectivity patterns and behavioural traits. However, there is no single widely-accepted standard pipeline for analyzing functional connectivity. The common procedure for designing functional connectivity based predictive models entails three main steps: parcellating the brain, estimating the interaction between defined parcels, and lastly, using these integrated associations between brain parcels as features fed to a classifier for predicting non-imaging variables e.g., behavioural traits, demographics, emotional measures, etc. There are also additional considerations when using correlation-based measures of functional connectivity, resulting in three supplementary steps: utilising Riemannian geometry tangent space parameterization to preserve the geometry of functional connectivity; penalizing the connectivity estimates with shrinkage approaches to handle challenges related to short time-series (and noisy) data; and removing confounding variables from brain-behaviour data. These six steps are contingent on each-other, and to optimise a general framework one should ideally examine these various methods simultaneously. In this paper, we investigated strengths and short-comings, both independently and jointly, of the following measures: parcellation techniques of four kinds (categorized further depending upon number of parcels), five measures of functional connectivity, the decision of staying in the ambient space of connectivity matrices or in tangent space, the choice of applying shrinkage estimators, six alternative techniques for handling confounds and finally four novel classifiers/predictors. For performance evaluation, we have selected two of the largest datasets, UK Biobank and the Human Connectome Project resting state fMRI data, and have run more than 9000 different pipeline variants on a total of <inline-formula><mml:math id="M1" altimg="si1.svg"><mml:mo>∼</mml:mo></mml:math></inline-formula>14000 individuals to determine the optimum pipeline. For independent performance validation, we have run some best-performing pipeline variants on ABIDE and ACPI datasets (<inline-formula><mml:math id="M2" altimg="si1.svg"><mml:mo>∼</mml:mo></mml:math></inline-formula>1000 subjects) to evaluate the generalisability of proposed network modelling methods.</p>
      </abstract>
      <abstract abstract-type="graphical" id="abs0015">
        <title>Graphical abstract</title>
        <p>
          <fig id="undfig1" position="anchor">
            <alt-text id="alttext0010">Image 1</alt-text>
            <graphic xlink:href="fx1"/>
          </fig>
        </p>
      </abstract>
      <kwd-group id="kwrds0010">
        <title>Keywords</title>
        <kwd>Functional Connectivity</kwd>
        <kwd>Connectome</kwd>
        <kwd>Netmat</kwd>
        <kwd>Riemannian geometry</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Convolutional neural networks</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <label>1</label>
      <title>Introduction</title>
      <p id="p0010">It is valuable to understand large-scale networks of brain activity. Most of the literature is focused on recognizing brain networks that are spatially and temporally linked to a given task (<xref rid="bib29" ref-type="bibr">Fox et al., 2005</xref>). In this paper, we aim to explore brain networks measured from resting state functional magnetic resonance imaging (rfMRI). In contrast to task-based fMRI, during rfMRI the brain is not occupied by a pre-defined task. However, studies have shown that the brain activity at rest is not random (<xref rid="bib52" ref-type="bibr">De Luca et al., 2006</xref>; <xref rid="bib88" ref-type="bibr">Tavor et al., 2016</xref>; <xref rid="bib16" ref-type="bibr">Bzdok et al., 2016</xref>), but is hierarchically organized in time and significantly correlated with behaviour (<xref rid="bib92" ref-type="bibr">Vidaurre et al., 2017</xref>).</p>
      <p id="p0015">The analysis of rfMRI data largely relies on estimates of functional connectivity. Functional connectivity is defined as the statistical association between time-series of anatomically distinct brain regions (<xref rid="bib71" ref-type="bibr">Rogers et al., 2007</xref>), which in fMRI is typically calculated as zero-lag correlation. To simplify, if two brain regions have blood-oxygen-level-dependent (BOLD) signals that are correlated, it means they are functionally connected. Functional connectivity is dynamic as it can be observed to change over time (<xref rid="bib92" ref-type="bibr">Vidaurre et al., 2017</xref>; <xref rid="bib42" ref-type="bibr">Hutchison et al., 2013</xref>; <xref rid="bib3" ref-type="bibr">Allen et al., 2014</xref>). Contrasting with this metric is static connectivity, which is an average of all dynamic connectivity states, and is thereby is less noisy. Static (or average) connectivity is also simpler to estimate and interpret, and is at this point in more common usage. The methodological research conducted in this article is purely based on exploring static functional connectivity.</p>
      <p id="p0020">A number of research studies have shown the utility of functional connectivity in identifying neuropsychiatric disorders such as Alzheimer’s disease (<xref rid="bib32" ref-type="bibr">Greicius et al., 2004</xref>), depression (<xref rid="bib4" ref-type="bibr">Anand et al., 2005</xref>), social anxiety disorder (<xref rid="bib34" ref-type="bibr">Hahn et al., 2011</xref>) autism spectrum disorder (<xref rid="bib59" ref-type="bibr">Nair et al., 2013</xref>), Parkinson’s disease (<xref rid="bib33" ref-type="bibr">Hacker et al., 2012</xref>) and schizophrenia (<xref rid="bib53" ref-type="bibr">Lynall et al., 2010</xref>). Resting state functional connectivity also has been shown to correlate with emotional measures (<xref rid="bib5" ref-type="bibr">Banks et al., 2007</xref>) and behavioral performance (<xref rid="bib36" ref-type="bibr">He et al., 2007</xref>; <xref rid="bib46" ref-type="bibr">Kelly et al., 2008</xref>). Overall, functional connectivity is gaining visibility as a salient tool for assessing functional brain organization and as an important biomarker for neurological disorders.</p>
      <p id="p0025">As the rfMRI scan is composed of thousands of voxels at each time-point per subject, this poses extreme challenges to working with raw voxel-wise time-series data. To avoid working in high dimensional space (and to increase interpretability and effective SNR), the standard processing procedure entails the determination of parcels which are defined over a group of voxels sharing similar timecourses. However, the method by which the brain is segmented into these different regions, or parcels, before estimating functional connectivity is far from standardized (<xref rid="bib25" ref-type="bibr">Eickhoff et al., 2015</xref>). Some of the existing parcellation techniques are based on mapping anatomical or functional atlases onto an individual’s brain (<xref rid="bib75" ref-type="bibr">Shen et al., 2013</xref>; <xref rid="bib24" ref-type="bibr">Desikan et al., 2006</xref>; <xref rid="bib28" ref-type="bibr">Fischl et al., 2004</xref>). Other brain parcellation techniques are more data driven and attempt to derive parcels based upon common features within the data (<xref rid="bib39" ref-type="bibr">Honnorat et al., 2015</xref>; <xref rid="bib64" ref-type="bibr">Parisot et al., 2016a</xref>, <xref rid="bib65" ref-type="bibr">2016b</xref>). After parcellating the brain, the next step is estimating functional connectivity. Functional connectivity is conventionally estimated through taking a full (Pearson) correlation between brain parcels over time (<xref rid="bib9" ref-type="bibr">Bastos and Schoffelen, 2016</xref>). The use of full correlation in deriving these estimates however, has some drawbacks as this method does not distinguish direct vs. indirect pathways by which two brain regions may be connected (<xref rid="bib81" ref-type="bibr">Smith et al., 2011a</xref>). Additionally, the utilization of this method results in numerous other limitations related to low SNR, primarily because of short scanning sessions. This paper provides a detailed account of several functional connectivity estimation techniques that may mitigate these challenges, which consequently can result in enhanced sensitivity in signal detection.</p>
      <p id="p0030">After derivation of brain parcels and functional connectivity estimates, there remains further decisions of how to optimally utilize these in conjunction with other data, such as behavioral metrics. The commonly followed procedure is to directly use elements of correlation-based functional connectivity estimates as features for regression or classification algorithms. This direct usage however has fallen subject to criticism, as correlation-based functional connectivity does not naturally form a Euclidean space (<xref rid="bib90" ref-type="bibr">Varoquaux et al., 2010</xref>; <xref rid="bib7" ref-type="bibr">Barachant et al., 2013a</xref>). In this paper, we evaluate an arguably more principled approach to represent correlation-based functional connectivity using Riemannian geometry (<xref rid="bib90" ref-type="bibr">Varoquaux et al., 2010</xref>; <xref rid="bib7" ref-type="bibr">Barachant et al., 2013a</xref>). This method is founded upon mathematical principles which involve manipulating correlation-based estimates in the tangential space of Riemannian manifold (<xref rid="bib62" ref-type="bibr">Ng et al., 2015a</xref>) where Euclidean geometry can be applied.</p>
      <p id="p0035">Additionally, there is also a concern of noise causing an increase in inter- and intra-subject variance in functional connectivity estimates. One method to alleviate this is to apply conventional regularization techniques in the ambient space when functional connectivity is estimated. The other approach is to apply covariance shrinkage estimators (<xref rid="bib17" ref-type="bibr">Chen et al., 2010</xref>) in the tangential space of Riemannian manifold. In this paper, we have evaluated the effects of covariance shrinkage techniques both in the ambient space and the tangent space (isotropic (<xref rid="bib49" ref-type="bibr">Ledoit and Wolf, 2004</xref>) and non-isotropic covariance shrinkage techniques (<xref rid="bib68" ref-type="bibr">Rahim et al., 2019</xref>)) on the prediction of individual demographic and behavioural phenotypes. Moreover, we have assessed the performance of shrinkage approaches in following framework, (i) no shrinkage in the ambient space or the tangent space, (ii) shrinkage in the ambient space but no shrinkage in the tangent space, (iii) no shrinkage in the ambient space but shrinkage in the tangent space, and (iv) shrinkage approaches both in the ambient space and the tangent space.</p>
      <p id="p0040">To predict individual phenotypes from rfMRI data, the elements of the functional connectivity matrix, where each element represents the strength of connection between two parcels, can be used as input features for a machine learning classifier (or continuous variable predictor). In this paper, we compare the performance of a selection of existing state of the art methods with several proposed deep learning based architectures. We also demonstrate a baseline application for using neural networks in brain functional connectivity modelling.</p>
      <p id="p0045">There is currently no general agreement on a single common pipeline for estimating and using functional connectivity. We aim to help with this situation by answering several major questions:<list list-type="simple" id="olist0010"><list-item id="o0010"><label>1.</label><p id="p0050">How should we parcellate the brain? Should this technique be data driven or based upon hard parcellation? How many parcels should we derive?</p></list-item><list-item id="o0015"><label>2.</label><p id="p0055">How should we estimate correlation-based functional connectivity? Should we remain with full, or partial correlation, or do we have better choices?</p></list-item><list-item id="o0020"><label>3.</label><p id="p0060">Should we preserve the geometry and shape of correlation-based functional connectivity elements within a Riemannian framework, and what would be the optimal way to do this?</p></list-item><list-item id="o0025"><label>4.</label><p id="p0065">Should we utilize covariance shrinkage estimators? Should shrinkage occur in ambient space of covariances or in tangent space?</p></list-item><list-item id="o0030"><label>5.</label><p id="p0070">How should we remove the effect of confounding variables in rfMRI?</p></list-item><list-item id="o0035"><label>6.</label><p id="p0075">Which classifier/predictor provides optimal prediction of age, sex and other non-imaging variables using these functional connectivity estimates? Is a deep learning approach of value?</p></list-item></list></p>
      <p id="p0080">The questions raised above may be treated as six steps to derive a framework for estimation and accurate usage of functional connectivity estimates. This paper will attempt to address the above questions in order to propose a comprehensive pipeline that takes into account several central methodological issues when estimating and using functional connectivity.</p>
      <p id="p0085">For performance evaluation of the different methods, we have chosen two rich datasets which contain both rfMRI and phenotypic data. The first is 13301 subjects from UK Biobank (UKB) (<xref rid="bib56" ref-type="bibr">Miller et al., 2016</xref>) and other is 1003 healthy subjects from the Human Connectome project (HCP) (<xref rid="bib26" ref-type="bibr">Van Essen et al., 2013</xref>). Our assessment criteria are based on the prediction accuracy of age, sex, fluid intelligence and neuroticism score, using correlation-based functional connectivity estimates. To establish the most optimum and reliable pipeline, we have run more than 9000 combinations of different steps of methodology detailed below. This computation has involved thousands of hours of computing on both CPUs and GPUs. The overall methodology is summarized in <xref rid="fig1" ref-type="fig">Fig. 1</xref>.<fig id="fig1"><label>Fig. 1</label><caption><p>Flow chart summarizing the six major steps of the methodology framework for rfMRI analysis.</p></caption><alt-text id="alttext0020">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
    </sec>
    <sec id="sec2">
      <label>2</label>
      <title>Methods</title>
      <sec id="sec2.1">
        <label>2.1</label>
        <title>Finding the best parcellation approach</title>
        <p id="p0090">The standard procedure for parcellation entails the grouping of voxels sharing similar time-courses into parcels. A parcel can be any spatial region of the brain, associated with a single time course (found by averaging the spontaneous fluctuation over all voxels within the parcel). For our analyses, we considered the following spatial properties in parcels, 1) parcels may or may not be allowed to overlap, 2) parcels can have both positive and negative spatial weight, or be binary masks 3) parcels may be composed from multiple disconnected regions.</p>
        <p id="p0095">Following the above criteria, we estimated parcels (spatial maps and associated time-series) across the brain using four different methods. In the literature, parcels can also be referred as nodes, modes, networks or region of interests, but here for simplicity and continuity, we will only refer to them as parcels. We only consider rfMRI-driven parcellations, as there is plenty of existing evidence that these outperform parcellations derived from pre-defined structural atlases (<xref rid="bib72" ref-type="bibr">SalaLlonch et al., 2019</xref>; <xref rid="bib82" ref-type="bibr">Smith et al., 2011b</xref>; <xref rid="bib89" ref-type="bibr">Thirion et al., 2014</xref>).</p>
        <sec id="sec2.1.1">
          <label>2.1.1</label>
          <title>Data-driven parcellation: SHEN functional parcels</title>
          <p id="p0100">The simplest way to identify parcels is to extract time courses from pre-defined, labelled regions, which often come from anatomical atlases. For resting state studies, a preferred method is to use a functional brain atlas based on correlated BOLD signal, rather than anatomical distinctions (<xref rid="bib82" ref-type="bibr">Smith et al., 2011b</xref>). In this study, we applied a functional brain atlas known as the SHEN parcellation (<xref rid="bib75" ref-type="bibr">Shen et al., 2013</xref>) which covers the cortex, subcortex and cerebellum. To derive the SHEN atlas, a spectral clustering method was applied which ensured the functional homogeneity within each parcel (<xref rid="bib75" ref-type="bibr">Shen et al., 2013</xref>). SHEN parcellation is based on rfMRI data of 79 healthy normal volunteers and provides more coherent resting state time-course estimates when compared with anatomical atlases. The total number of parcels in SHEN parcellation is 268. SHEN is a volumetric parcellation, and for both UKB and HCP data, we used the preprocessed released data in standard volumetric space after ICA FIX denoising (<xref rid="bib73" ref-type="bibr">Salimi-Khorshidi et al., 2014</xref>).</p>
        </sec>
        <sec id="sec2.1.2">
          <label>2.1.2</label>
          <title>Data-driven parcellation: YEO functional parcels</title>
          <p id="p0105">We applied another functional brain atlas known as the YEO parcellation (<xref rid="bib74" ref-type="bibr">Schaefer et al., 2017</xref>). The YEO parcellation is based on rfMRI data from 1489 subjects which were registered using surface-based alignment. To derive the YEO atlas, a gradient weighted Markov random field approach was employed which integrates local gradient and global similarity approaches. This ensured the parcels were functionally and connectionally homogeneous, and also agreed with the boundaries of certain cortical areas defined using histology and visuotopic fMRI. The YEO parcellation is available at multiple resolution levels, and we have applied the YEO parcellation where the total number of parcels is 100. The YEO parcellation is available both in volumetric and grayordinate space. For HCP data, we use the minimally-preprocessed released data in grayordinates, and for UKB data, we used the preprocessed released data in standard volumetric space. UKB has not yet been processed with a pipeline like HCP, but future UKB data releases will include versions of the data transformed into grayordinate space. For now, this helps to span the space of approaches commonly taken (some volumetric, some surface-based). YEO parcellation is often known as the “Schaefer” parcellation, from the name of the first author (<xref rid="bib74" ref-type="bibr">Schaefer et al., 2017</xref>).</p>
        </sec>
        <sec id="sec2.1.3">
          <label>2.1.3</label>
          <title>Data driven soft parcellation: spatially independent parcels</title>
          <p id="p0110">We also applied a popular data-driven parcellation scheme called Group Independent Component Analysis, or GroupICA (<xref rid="bib84" ref-type="bibr">Smith et al., 2014a</xref>; <xref rid="bib10" ref-type="bibr">Beckmann and Smith, 2004</xref>) to our data. There are two popular variants of GroupICA, spatial ICA (sICA), which identifies spatially independent components, and temporal ICA (tICA) (<xref rid="bib83" ref-type="bibr">Smith et al., 2012</xref>), which put restrictions on temporal dynamics. The parcels identified by tICA are coerced to have orthogonal time-series which therefore precludes further network analyses of the kind covered in this paper. Therefore, we opted for sICA and applied<xref rid="fn1" ref-type="fn">1</xref> sICA by concatenating the time courses from all subjects. The ICA parcels can be spatially overlapping and non-contiguous. The dimensionality (d) of sICA corresponds to the number of desired parcels. For HCP data, we applied sICA at d ​= ​15, 50 and 200, and for UKB, d ​= ​25 and 100. With UKB data, we disregarded four components from ICA 25, and 45 components from ICA 100 as they were judged to be artefacts.<xref rid="fn2" ref-type="fn">2</xref> This left us with d ​= ​21, and 55 for UKB.<xref rid="fn3" ref-type="fn">3</xref> For HCP data we use the minimally-preprocessed released data, in grayordinates (cortical surface vertices and subcortical voxels), with ICA FIX denoising having been applied (<xref rid="bib73" ref-type="bibr">Salimi-Khorshidi et al., 2014</xref>). For UKB data, we used the preprocessed released data in standard volumetric space after ICA FIX denoising.</p>
        </sec>
        <sec id="sec2.1.4">
          <label>2.1.4</label>
          <title>Data driven parcellation: probabilistic functional parcels</title>
          <p id="p0115">While ICA based approaches provide a choice between spatial or temporal independence, these approaches can be problematic as the brain is probably not perfectly segregated either in space or time, and they typically to do not have any modelling of between-subject variability. We applied another framework used for identifying large-scale probabilistic functional modes (PROFUMO) (<xref rid="bib35" ref-type="bibr">Harrison et al., 2015</xref>; <xref rid="bib41" ref-type="bibr">https://www.biorxiv.org/c, 1101</xref>) to identify parcels which are allowed to be correlated with each other in space and/or time, and which explicitly models between-subject variability in the parcels. In contrast to the above methods, therefore, PROFUMO does not require parcels to be orthogonal or non-overlapping. We applied PROFUMO on the HCP for d ​= ​50, but we are not yet able to apply PROFUMO on the UKB data due to prohibitive computational cost with the larger cohort.</p>
        </sec>
      </sec>
      <sec id="sec2.2">
        <label>2.2</label>
        <title>Finding the best correlation-based functional connectivity estimate method</title>
        <p id="p0120">We extracted a timeseries signal for each subject, <inline-formula><mml:math id="M3" altimg="si2.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <italic>T</italic> corresponds to the number of timepoints and <italic>d</italic> correponds to the number of parcels for each subject. Functional connectivity estimates are also referred to in the literature as parcellated connectomes or netmats, but here we will refer to these estimates as functional connectivity. <xref rid="tbl1" ref-type="table">Table 1</xref> lists symbols for the different correlation-based functional connectivity estimates we evaluated.<table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>The symbols used for various functional connectivity estimates in this paper.</p></caption><alt-text id="alttext0075">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Term</th><th>Symbol</th></tr></thead><tbody><tr><td align="left">Empirical covariance</td><td align="left"><inline-formula><mml:math id="M4" altimg="si3.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Full correlation</td><td align="left"><inline-formula><mml:math id="M5" altimg="si4.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>˘</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Precision matrix</td><td align="left"><inline-formula><mml:math id="M6" altimg="si5.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Tikhonov precision matrix</td><td align="left"><inline-formula><mml:math id="M7" altimg="si6.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Oracle approximate shrinkage precision matrix</td><td align="left"><inline-formula><mml:math id="M8" altimg="si7.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Partial correlation</td><td align="left"><italic>ρ</italic></td></tr><tr><td align="left">Any of above functional connectivity matrix</td><td align="left"><italic>C</italic></td></tr><tr><td align="left">Any of above functional connectivity matrix in tangent space</td><td align="left"><inline-formula><mml:math id="M9" altimg="si8.svg"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr></tbody></table></table-wrap></p>
        <sec id="sec2.2.1">
          <label>2.2.1</label>
          <title>Estimating the functional connectivity</title>
          <p id="p0125">Empirical Covariance: Functional connectivity is calculated by estimating the empirical (sample) covariance matrix of timeseries signal for each subject. The range of elements of the empirical covariance matrix, <inline-formula><mml:math id="M10" altimg="si3.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, lies between <inline-formula><mml:math id="M11" altimg="si9.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M12" altimg="si10.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math></inline-formula> and can be defined as:<disp-formula id="fd1"><label>(1)</label><mml:math id="M13" display="block" altimg="si11.svg" alttext="Equation 1."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>T</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
          <p id="p0130"><bold>Full Correlation:</bold> The full correlation coefficient, or Pearson’s correlation coefficient can be defined in terms of covariance. Mathematically, full correlation <inline-formula><mml:math id="M14" altimg="si4.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>˘</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is a standardized form of covariance. The value of correlation takes place between −1 and +1. Conversely, the value of covariance lies between <inline-formula><mml:math id="M15" altimg="si9.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M16" altimg="si10.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math></inline-formula>.</p>
          <p id="p0135"><bold>Partial Correlation:</bold> Although commonly used, using full correlation to derive connectivity estimates is problematic, as it does not distinguish whether two parcels of brain are directly connected or indirectly connected through another parcel. To mitigate this, we define partial correlation, which is correlation between the time series of two parcels after adjusting for the time series of all other network parcels. Partial correlation is calculated from the inverse of the covariance matrix, also known as the precision matrix. We calculated inverse covariance using cholesky decomposition (<xref rid="bib48" ref-type="bibr">Krishnamoorthy and Menon, 2013</xref>) as illustrated in Equation <xref rid="fd2" ref-type="disp-formula">(2)</xref>. For this derivation, we first factorized <inline-formula><mml:math id="M17" altimg="si3.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> into an upper triangular <italic>U</italic> that satisfies <inline-formula><mml:math id="M18" altimg="si12.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>U</mml:mi><mml:mo>′</mml:mo><mml:mtext>*</mml:mtext><mml:mi>U</mml:mi></mml:mrow></mml:math></inline-formula> and then calculated the precision matrix <inline-formula><mml:math id="M19" altimg="si13.svg"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>Ω</mml:mtext><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mtext>ij</mml:mtext><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mtext>MxM</mml:mtext><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. To convert precision into partial correlation <italic>ρ</italic>, there is a sign flip of the non-diagonal elements and also normalization as shown in Equation <xref rid="fd3" ref-type="disp-formula">(3)</xref> where i and j are nodes.<disp-formula id="fd2"><label>(2)</label><mml:math id="M20" display="block" altimg="si14.svg" alttext="Equation 2."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>˘</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mi>U</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:math></disp-formula><disp-formula id="fd3"><label>(3)</label><mml:math id="M21" display="block" altimg="si15.svg" alttext="Equation 3."><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="goodbreak">−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mtext>ij</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mtext>ii</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mtext>jj</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
          <p id="p0140"><bold>Tikhonov Partial Correlation:</bold> As partial correlation involves the calculation of the inverse of covariance matrix, this method becomes problematic when there are not considerably more timepoints than nodes. Several approaches based on regularization have been proposed in the literature to address this unstable matrix inversion problem. We implemented the Tikhonov regularization (also referred as L<sub>2</sub> ridge regression) (<xref rid="bib31" ref-type="bibr">Golub et al., 1999</xref>) as shown in Equation <xref rid="fd4" ref-type="disp-formula">(4)</xref>. This equation involves the addition of a regularization term <inline-formula><mml:math id="M22" altimg="si16.svg"><mml:mrow><mml:mtext>Γ</mml:mtext><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>α</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:math></inline-formula>, a multiple of the identity matrix. The scalar <italic>α</italic> is optimised here by minimizing the root mean square distance<xref rid="fn4" ref-type="fn">4</xref> between regularized subject precision matrices (<inline-formula><mml:math id="M23" altimg="si6.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>‾</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>) and the group average of the unregularised subject precision matrices (<inline-formula><mml:math id="M24" altimg="si5.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>). We optimised a single <italic>α</italic> for all the subjects.<disp-formula id="fd4"><label>(4)</label><mml:math id="M25" display="block" altimg="si17.svg" alttext="Equation 4."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>‾</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>˘</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>Γ</mml:mtext></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p>
          <p id="p0145"><bold>Sparse Group Gaussian Graphical Modelling (SGGGM) Partial Correlation:</bold> Tikhnov regularization allows for a stable inversion for the covariance matrix; however, it uniformly shrinks off-diagonal elements. Sparse Group Graphical Gaussian Modelling (SGGGM) (<xref rid="bib61" ref-type="bibr">Ng et al., 2013</xref>) learns group-level connectivity in a data-driven way using an L<sub>1</sub> prior and regularization of each subject’s connectivity towards the group mean using an L<sub>2</sub> prior. The advantage of SGGGM is that it supports intra-subject inverse covariance being similar, but not exactly the same as the group inverse covariance estimate in a similar manner to (<xref rid="bib19" ref-type="bibr">Colclough et al., 2018</xref>). The inverse covariance (<inline-formula><mml:math id="M26" altimg="si7.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>) fed into SGGGM, is calculated using the regularization technique known as oracle approximating shrinkage (OAS), as described in the original paper (<xref rid="bib61" ref-type="bibr">Ng et al., 2013</xref>), and is well regularized. SGGGM is posed as a regularized consensus optimization problem which can be solved using an alternating direction method of multipliers (ADMM) (<xref rid="bib14" ref-type="bibr">Boyd et al., 2011</xref>). In Equation <xref rid="fd5" ref-type="disp-formula">(5)</xref>, <inline-formula><mml:math id="M27" altimg="si18.svg"><mml:mrow><mml:mo>∥</mml:mo><mml:mo>∥</mml:mo></mml:mrow></mml:math></inline-formula>. Corresponds to the Frobenius norm penalty, applied to the difference between the subjects’ matrices and the group. <inline-formula><mml:math id="M28" altimg="si19.svg"><mml:mrow><mml:mo>∥</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>G</mml:mi></mml:msup><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is used for enforcing sparsity on the group prior and <inline-formula><mml:math id="M29" altimg="si20.svg"><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the representation of each subject’s own observation. Parameter <inline-formula><mml:math id="M30" altimg="si21.svg"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> controls sparsity and <inline-formula><mml:math id="M31" altimg="si22.svg"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> regulates the group consistency. We optimised these hyper-parameters (<inline-formula><mml:math id="M32" altimg="si21.svg"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M33" altimg="si22.svg"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) by minimizing the root mean square distance between regularized subject precision matrices estimated using SGGGM and the group average of the unregularised subject precision matrices (<inline-formula><mml:math id="M34" altimg="si5.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>).<disp-formula id="fd5"><label>(5)</label><mml:math id="M35" display="block" altimg="si23.svg" alttext="Equation 5."><mml:mrow><mml:munder><mml:munder><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>G</mml:mi></mml:msup><mml:mo linebreak="badbreak">&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup><mml:mo linebreak="badbreak">&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∥</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>G</mml:mi></mml:msup><mml:mo>∥</mml:mo><mml:msub><mml:mspace width="0.5em"/><mml:mn>1</mml:mn></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∥</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>S</mml:mi></mml:msup><mml:mo linebreak="goodbreak">−</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mtext>Ω</mml:mtext><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mi>G</mml:mi></mml:msup><mml:msup><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        </sec>
        <sec id="sec2.2.2">
          <label>2.2.2</label>
          <title>Tangent space parameterization</title>
          <p id="p0150">Covariance matrices<xref rid="fn5" ref-type="fn">5</xref> by construction are symmetric and live in space of positive definitive (PD) matrices. The PD matrix is a symmetric matrix whose eigenvalues are all positive. The standard practice is to directly vectorize (unwrap) these covariance matrices and then feed them into a machine learning predictor/classifier, however there are a few downfalls to this practice. One issue is that PD matrices do not naturally form a Euclidean space, meaning mathematical operations like subtraction do not apply, if geometry is to be preserved (and the PD nature preserved). For example, the difference of two PD matrices does not correspond to the PD covariance matrix of a signal. <inline-formula><mml:math id="M36" altimg="si24.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mi>S</mml:mi><mml:mi>y</mml:mi><mml:msubsup><mml:mi>m</mml:mi><mml:mtext>n</mml:mtext><mml:mo>+</mml:mo></mml:msubsup><mml:mi mathvariant="normal">⇏</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mi>S</mml:mi><mml:mi>y</mml:mi><mml:msubsup><mml:mi>m</mml:mi><mml:mtext>n</mml:mtext><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> (<xref rid="bib90" ref-type="bibr">Varoquaux et al., 2010</xref>). Another problem is that in the space of the positive definitive cone, where covariance matrices exist, elements of covariance are inter-correlated. This goes against the underlying assumption for some predictors/classifiers, which assume features are uncorrelated. Lastly, these vectorized connectivity estimates do not follow a normal distribution, which violates the assumptions of some methods, like Linear Discriminant Analysis (LDA).</p>
          <p id="p0155">If we follow the geometry of PD matrices, we note that the space of PD matrices forms a differentiable manifold M. PD matrices therefore cannot directly be treated as an element of Euclidean space; therefore, to correctly apply mathematical formulations on these matrices, we utilize Riemannian geometry (<xref rid="bib67" ref-type="bibr">Pennec et al., 2006</xref>). For each covariance matrix C in manifold <italic>M</italic>, we can define a scalar product in the associated tangent space (T) as <inline-formula><mml:math id="M37" altimg="si25.svg"><mml:mrow><mml:mi>M</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. This tangent space is homomorphic to the manifold, and therefore we can approximate the Riemannian distance in the manifold by using Euclidean distance in the tangent space. This allows us to apply simple Euclidean mathematical operations in the tangent space without breaking the geometry of connectivity matrices. Moreover, many popular classification/prediction algorithms (for example, Neural Network, LDA and SVM) cannot be directly implemented to act in a Riemannian manifold. As the projected connectivity matrices in the tangent space are treated as Euclidean objects, such classification algorithms can be readily applied in the associated tangent space.</p>
          <p id="p0160">Another important consideration for the tangent space parametrization is that the projection requires a reference point in the manifold (this is the point where the tangent plane touches the manifold) that should be close to the subject’s projected covariance matrix. If we have a different reference point for each subject, each subject’s covariance matrix would be projected to a different tangent plane. To ensure that all projected covariance matrices lie in the same tangent plane, we must find a reference covariance matrix close to all subjects’ covariance estimates. This reference covariance matrix could be an average of the whole set of covariance matrices (<xref rid="bib6" ref-type="bibr">Barachant et al., 2011</xref>) and is referred to here as <inline-formula><mml:math id="M38" altimg="si26.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Following the logarithmic map for projecting any covariance matrix to its tangent plane (<xref rid="bib8" ref-type="bibr">Barachant et al., 2013b</xref>), any covariance matrix <italic>C</italic> can be projected to tangent space as shown in Equation <xref rid="fd6" ref-type="disp-formula">(6)</xref>, where <inline-formula><mml:math id="M39" altimg="si27.svg"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is matrix logarithm. Once the covariance matrices are in tangent space, they are no longer linked by the PD constraint, and hence these uncorrelated features are more useful for classifiers/predictors.<disp-formula id="fd6"><label>(6)</label><mml:math id="M40" display="block" altimg="si28.svg" alttext="Equation 6."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo linebreak="badbreak">→</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>G</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>C</mml:mi><mml:msubsup><mml:mi>C</mml:mi><mml:mi>G</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
          <p id="p0165"><bold>Reference Point in Tangent Space:</bold><inline-formula><mml:math id="M41" altimg="si26.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> symbolizes the group reference estimate which may be estimated in different ways. The choice of reference PD matrix would normally be a group mean estimate as stated in <xref rid="tbl2" ref-type="table">Table 2</xref>. Euclidean mean is the average of all covariance matrices whereas harmonic mean is the reciprocal of the arithmetic mean of the reciprocals. The Euclidean and harmonic means are calculated in the manifold space. Log Euclidean is calculated by first applying matrix logarithm, then computing the mean, and lastly applying the matrix exponential to bring back the mean to the manifold. The Riemannian mean is introduced in (<xref rid="bib57" ref-type="bibr">Moakher, 2005</xref>) and can be computed in three iterative steps: (1) projecting connectivity estimates to the tangent space (initialized by using the arithmetic mean, <inline-formula><mml:math id="M42" altimg="si29.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), (2) calculating the arithmetic mean in the tangent space, <inline-formula><mml:math id="M43" altimg="si30.svg"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo linebreak="badbreak" stretchy="true">→</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, and (3) mapping the arithmetic mean back to the manifold i.e., <inline-formula><mml:math id="M44" altimg="si29.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> ​= <inline-formula><mml:math id="M45" altimg="si31.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo linebreak="badbreak" stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>e</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. These three steps are repeated until convergence (<inline-formula><mml:math id="M46" altimg="si32.svg"><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo linebreak="badbreak" stretchy="true">→</mml:mo></mml:mover><mml:mo stretchy="true">|</mml:mo><mml:msub><mml:mo stretchy="true">|</mml:mo><mml:mi>F</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">&lt;</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:math></inline-formula>) (<xref rid="bib7" ref-type="bibr">Barachant et al., 2013a</xref>). The Kullback mean is the geometric mean between harmonic mean and arithmetic mean. It is not evident in the literature which mean would lead to better representation of the manifold and therefore, we considered all these alternatives for reference point estimation.<table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Reference mean estimation.</p></caption><alt-text id="alttext0080">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Reference Mean</th><th>Equation</th></tr></thead><tbody><tr><td align="left">Euclidean</td><td align="left"><inline-formula><mml:math id="M47" altimg="si33.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Harmonic</td><td align="left"><inline-formula><mml:math id="M48" altimg="si34.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msubsup><mml:mi>C</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Log Euclidean</td><td align="left"><inline-formula><mml:math id="M49" altimg="si35.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Riemannian Mean</td><td align="left"><inline-formula><mml:math id="M50" altimg="si36.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>argmin</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>δ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td align="left">Kullback</td><td align="left"><inline-formula><mml:math id="M51" altimg="si37.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>C</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mi>α</mml:mi></mml:msup><mml:msubsup><mml:mi>C</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula></td></tr></tbody></table><table-wrap-foot><fn><p><inline-formula><mml:math id="M52" altimg="si38.svg"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the functional connectivity matrix for subject i.</p></fn></table-wrap-foot></table-wrap></p>
        </sec>
        <sec id="sec2.2.3">
          <label>2.2.3</label>
          <title>Shrinkage in tangent space</title>
          <p id="p0170">To further reduce estimation variability, we can apply regularization in the tangent space. The Ledoit-Wolf estimator shrinks the covariance towards a target matrix T as <inline-formula><mml:math id="M53" altimg="si39.svg"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo linebreak="badbreak">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>C</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">+</mml:mo><mml:mi>λ</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula>. In (<xref rid="bib49" ref-type="bibr">Ledoit and Wolf, 2004</xref>), the authors proposed shrinkage towards an identity matrix. A better alternative is to shrink towards the group mean covariance matrix. The Ledoit-Wolf shrinkage can also be applied in tangent space as shown in Equation <xref rid="fd7" ref-type="disp-formula">(7)</xref>.<disp-formula id="fd7"><label>(7)</label><mml:math id="M54" display="block" altimg="si40.svg" alttext="Equation 7."><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo linebreak="badbreak">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo linebreak="badbreak">→</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p>
          <p id="p0175">This shrinkage is isotropic and therefore does not take into consideration the distribution of the population. Recently, another method called PoSCE was proposed (<xref rid="bib68" ref-type="bibr">Rahim et al., 2019</xref>) in which the population prior is not based on just the mean, but uses information from the probabilistic distribution of covariances. The prior dispersion is calculated as the mean outer product of the parametrized tangent space connectivity estimates as <inline-formula><mml:math id="M55" altimg="si41.svg"><mml:mrow><mml:msub><mml:mtext>Λ</mml:mtext><mml:mi>o</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M56" altimg="si42.svg"><mml:mrow><mml:mtext>Λ</mml:mtext><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>λ</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:math></inline-formula> is likelihood covariance where <italic>λ</italic> is the shrinkage control parameter. The shrunk covariance matrices in the tangent space can then be calculated as in Equation <xref rid="fd8" ref-type="disp-formula">(8)</xref>.<disp-formula id="fd8"><label>(8)</label><mml:math id="M57" display="block" altimg="si43.svg" alttext="Equation 8."><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo linebreak="badbreak">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>o</mml:mi><mml:mi>S</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mtext>Λ</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mtext>Λ</mml:mtext><mml:mi>o</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mtext>Λ</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo linebreak="badbreak">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></disp-formula></p>
          <p id="p0180">These isotropic and non-isotropic shrinkage techniques could ideally be applied to any projected connectivity estimate (covariance, full correlation, partial correlation, Tikhonov partial correlation or SGGGM partial correlation) in the tangent space. Theoretically, Tikhonov partial correlation and SGGGM connectivity estimates are already well-regularized so they may not require any further shrinkage in the tangent space, but we have tested all possible variants in this study (regularization in the ambient space and then further regularization in the tangent space). Moreover, we have introduced concepts of three spaces as detailed below:<list list-type="simple" id="ulist0010"><list-item id="u0010"><label>•</label><p id="p0185"><bold>Ambient Space</bold>: The estimated functional connectivity estimates (Section <xref rid="sec2.2" ref-type="sec">2.2</xref>) were not projected into the tangent space. The classifier/predictor was directly applied to connectivity estimates in the ambient space.</p></list-item><list-item id="u0015"><label>•</label><p id="p0190"><bold>Tangent Space</bold>: The various functional connectivity estimates (covariance, full correlation, partial correlation, Tikhonov partial correlation or SGGGM partial correlation as defined in Section <xref rid="sec2.2" ref-type="sec">2.2</xref>) were projected to tangent space following Section <xref rid="sec2.2.2" ref-type="sec">2.2.2</xref>, but no shrinkage was applied in the tangent space. The classifier/predictor was applied on the parameterized tangent space connectivity estimates.</p></list-item><list-item id="u0020"><label>•</label><p id="p0195"><bold>Tangent_Shrinkage Space</bold>: The shrunk tangent space in which functional connectivity estimates were projected to tangent space and then shrinkage was applied in the tangent space (Section <xref rid="sec2.2.3" ref-type="sec">2.2.3</xref>). In this case, the classifier/predictor was applied on the parameterized shrunk tangent space connectivity estimates. Most of the analyses carried out in this article are based on using PoSCE tangential space shrinkage, however <xref rid="appsec1" ref-type="sec">Fig. A.19</xref> depicts results comparing PoSCE shrinkage with Lediot-Wolf shrinkage in the tangent space.</p></list-item></list></p>
        </sec>
      </sec>
      <sec id="sec2.3">
        <label>2.3</label>
        <title>Finding the best classifier/predictor</title>
        <p id="p0200">The last step is to fed these covariance matrices to predictor/classifier<xref rid="fn6" ref-type="fn">6</xref> as features to predict non-imaging variables.</p>
        <p id="p0205"><bold>Elastic Net:</bold> The first classifier/predictor we tested is Elastic Net (<xref rid="bib95" ref-type="bibr">Zou and Hastie, 2005</xref>), which is a regularized regression method that combines the penalties of lasso <inline-formula><mml:math id="M58" altimg="si44.svg"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and ridge <inline-formula><mml:math id="M59" altimg="si45.svg"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> methods. <inline-formula><mml:math id="M60" altimg="si46.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> encourages a sparser model (more zeros) but fails to accomplish group variable selection (where strongly correlated features are selected or discarded together) (<xref rid="bib91" ref-type="bibr">Vidaurre et al., 2013</xref>). Alternatively, <inline-formula><mml:math id="M61" altimg="si47.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> encourages the grouping effect and removes the limitation on the number of chosen variables but it does not achieve sparsity. <inline-formula><mml:math id="M62" altimg="si47.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is a reasonable approach to handle the ill-posed problems that result from extremely correlated features. Elastic net aims to overcome the limitations of both <inline-formula><mml:math id="M63" altimg="si46.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M64" altimg="si47.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> penalties. The data matrix X is <italic>s</italic><inline-formula><mml:math id="M65" altimg="si48.svg"><mml:mo>×</mml:mo></mml:math></inline-formula><italic>p</italic>, where <italic>s</italic> is the number of subjects and p is the number of features, and <italic>y</italic> is the response vector, such as age or sex. The functional connectivity matrices are symmetric and only values above the diagonal need to be retained and vectorized, and hence <italic>p</italic> ​= ​<italic>d</italic>(<italic>d</italic>-1)/2, where <italic>d</italic> is number of parcels. We then applied univariate pre-feature selection, and only retained the top 50% features (based on correlation with the target variable). In Equation <xref rid="fd9" ref-type="disp-formula">(9)</xref>, <inline-formula><mml:math id="M66" altimg="si49.svg"><mml:mrow><mml:msub><mml:mo>∥</mml:mo><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> corresponds to the <inline-formula><mml:math id="M67" altimg="si46.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm penalty and the quadratic part (the second term) is the is <inline-formula><mml:math id="M68" altimg="si47.svg"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> norm.<disp-formula id="fd9"><label>(9)</label><mml:math id="M69" display="block" altimg="si50.svg" alttext="Equation 9."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:munder><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mi>β</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>X</mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mi>β</mml:mi><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></disp-formula></p>
        <p id="p0210"><bold>BrainNetCNN:</bold> The second classifier/predictor, BrainNetCNN, is specifically developed to leverage the topological structure of networks (<xref rid="bib45" ref-type="bibr">Kawahara et al., 2017</xref>). It consists of edge-to-edge (E2E), edge-to-node (E2N) and node-to-graph (N2G) convolutional filters, which are all designed to analyze functional connectivity to predict the behavioral information. The main contribution of BrainNetCNN is using a cross shape filter (the dimension of some of the filters are set to be <inline-formula><mml:math id="M70" altimg="si51.svg"><mml:mrow><mml:mi>d</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and others <inline-formula><mml:math id="M71" altimg="si52.svg"><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula>, whereas, the overall size of input connectivity matrix is <inline-formula><mml:math id="M72" altimg="si53.svg"><mml:mrow><mml:mi>d</mml:mi><mml:mo linebreak="badbreak">×</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></inline-formula> instead of the traditional box shape filter. There are primarily three main layers used in this network, E2E, E2N and N2G layers. The E2E layer considers the weights of all the edges which share a node together. Intuitively, the E2E layer resembles a convolutional filter, as for an edge (j,k) in a functional connectivity matrix, it combines the signal with the signal from direct neighbours (edges connected to either node j or node k), but applies a cross shape filter instead of a box shape filter. The output of the E2E layer is fed into the E2N layer. The E2N layer is equivalent to convolving the functional connectivity matrix with a spatial convolutional 1D row filter and a 1D column filter (and adding their results). It gives a unique output value for each node, j, as it takes the average of incoming and outgoing weights of each edge associated to node j. Finally, the N2G graph layer is used, which is similar to the fully connected layer. The N2G layer reduces the spatial dimensionality, and outputs a single scalar for weighted combination of nodes per feature map. The output features from the N2G layer are then fed into a predictor to provide final prediction (non-imaging variables). The architecture of the BrainNetCNN is shown in <xref rid="appsec1" ref-type="sec">Fig. A.13</xref> (sub-figure A).</p>
        <p id="p0215"><bold>Recurrent Convolutional Neural Network:</bold> A Convolutional neural network (CNN) is a feed-forward network inspired by the brain’s visual system; however, in comparing it with the brain, CNN lacks the recurrent connections which are abundant in the brain. Inspired by (<xref rid="bib50" ref-type="bibr">Liang and Hu, 2015</xref>), we have designed a recurrent convolutional neural network (RCNN) by incorporating recurrent connections in each convolutional layer. The activities of RCNN evolve over time (the activity of each unit is modulated by the activities of its neighboring units), which provide the advantage of an increased receptive field, and results in a greater awareness of contextual information. We have implemented a 2D RCNN to extract features from functional connectivity matrices. The most important module of RCNN is the recurrent convolution layer (RCL). The net input <inline-formula><mml:math id="M73" altimg="si54.svg"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> at unit (i,j) on kth feature map is given by<disp-formula id="fd10"><label>(10)</label><mml:math id="M74" display="block" altimg="si55.svg" alttext="Equation 10."><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>k</mml:mi><mml:mi>f</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>k</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p>
        <p id="p0220">In Equation <xref rid="fd10" ref-type="disp-formula">(10)</xref>, <inline-formula><mml:math id="M75" altimg="si56.svg"><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the feed forward input, as in a CNN, while <inline-formula><mml:math id="M76" altimg="si57.svg"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>k</mml:mi><mml:mi>f</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the vectorized feed forward weights. The second term of the equation arises because of the recurrent connections and <inline-formula><mml:math id="M77" altimg="si58.svg"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the recurrent input and <inline-formula><mml:math id="M78" altimg="si59.svg"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>k</mml:mi><mml:mi>r</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is associated with recurrent weights. In other words, <inline-formula><mml:math id="M79" altimg="si56.svg"><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M80" altimg="si58.svg"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are centered at (i, j), and are the vectorized square patches of the feature maps in the present and foregoing layer respectively. The last term of the equation, <inline-formula><mml:math id="M81" altimg="si60.svg"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, is the bias. <inline-formula><mml:math id="M82" altimg="si54.svg"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> will pass through the rectified linear activation function <inline-formula><mml:math id="M83" altimg="si61.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and then local response normalization (LRN) will be applied on it, which imitates lateral inhibition in cortex. In neurobiology, lateral inhibition refers to the capacity of an excited neuron to reduce the activity of its neighbours. Similarly here, feature maps will challenge each other for maximum representation. The architecture of 2D RCNN is shown in <xref rid="appsec1" ref-type="sec">Fig. A.12</xref>. Equation <xref rid="fd10" ref-type="disp-formula">(10)</xref> describes the behaviour of one RCL (recurrent block) in <xref rid="appsec1" ref-type="sec">Fig. A.12</xref>. Unfolding the RCL for t ​= ​0 will result in a purely feed-forward network. In <xref rid="appsec1" ref-type="sec">Fig. A.12</xref>, we have unfolded each RCL for t ​= ​3, leading to a feed-forward network with largest depth of t+1 ​= ​4 and smallest depth of t ​= ​1. Each RCL block has convolution, ReLU, batch normalization and addition layers (collectively named as a residual block). Moreover, each residual block receives input directly from feed-forward and recurrent connections. The recurrent input evolves over iterations but the feed-forward input remains the same for all iterations. The overall 2D RCNN is composed of four RCL blocks, and between each RCL block, only feed forward connections are used. The output from the last RCL is fed into fully connected layers.</p>
        <p id="p0225"><bold>Graph Convolutional Neural Network:</bold> The standard convolution is limited to data on a Euclidean grid; however, the graph convolutional neural network (GraphCNN) extends beyond traditional CNNs to handle data that is supported on a graph. GraphCNN exploits the Laplacian of the graph and is built on spectral filters, graph coarsening, and efficient pooling, which are all based on established tools in graph signal processing (<xref rid="bib78" ref-type="bibr">Shuman et al., 2012</xref>). We followed the approach of (<xref rid="bib23" ref-type="bibr">Defferrard et al., 2016</xref>) and constructed the graph <inline-formula><mml:math id="M84" altimg="si62.svg"><mml:mrow><mml:mi>G</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="M85" altimg="si63.svg"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">|</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="true">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the set of vertices, <italic>E</italic> is the edges and <italic>A</italic> is the adjacency matrix. GraphCNN takes input as a feature matrix <inline-formula><mml:math id="M86" altimg="si64.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <italic>s</italic> is number of nodes and <italic>d</italic> is number of features for each node. In our case, each subject is represented by a node and corresponding features are computed by vectorizing the functional connectivity matrix. The other input to the GraphCNN is an adjacency matrix, <inline-formula><mml:math id="M87" altimg="si65.svg"><mml:mrow><mml:mi>A</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> which is essentially a graph between features. We defined the adjacency matrix based on the similarity estimate between features. For constructing the graph, the Euclidean distance <inline-formula><mml:math id="M88" altimg="si66.svg"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> was used as a distance function, a Gaussian kernel <inline-formula><mml:math id="M89" altimg="si67.svg"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> was applied and a <italic>k</italic> nearest neighbours graph was formulated. The architecture of GraphCNN is shown in <xref rid="appsec1" ref-type="sec">Fig. A13</xref> (sub-figure B).</p>
        <sec id="sec2.3.1">
          <label>2.3.1</label>
          <title>Deconfounding the data</title>
          <p id="p0230">Many participant-related confounds exist in resting state data, which can corrupt associations between the imaging data and non-imaging data. Our main goal was to predict non-imaging variables based only on <italic>pure</italic> functional connectivity, hence we found it was crucial to minimize the impact of confounding variables. The basic confounds we controlled for were age, sex, ethnicity, weight, average head motion, brain size, intercranial volume, variables (x, y, z, table) related to bed position in scanner, imaging centre and confounds modelling slow date-related drift. We also included some non-linear effects, i.e., <inline-formula><mml:math id="M90" altimg="si68.svg"><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M91" altimg="si69.svg"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M92" altimg="si70.svg"><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. We evaluated the effect of various deconfounding schemes on X, a data matrix (i.e, subjects’ functional connectivity), and Y, a response vector (e.g, fluid intelligence). For X there are three possible strategies, (i) no deconfounding (X0), (ii) confound regression from data that is not contained within the cross-validation loop (X1), (iii) fold-wise confound regression (X2), following (<xref rid="bib86" ref-type="bibr">Snoek et al., 2019</xref>). For Y, there are two options, (i) no deconfounding (Y0), or (ii) learning deconfounding regression weights from the training subset, and then applying these weights on the left-out validation subset (Y1). For example, deconfounded <inline-formula><mml:math id="M93" altimg="si71.svg"><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is calculated as <inline-formula><mml:math id="M94" altimg="si72.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mi>C</mml:mi><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> where C are confounds and <italic>β</italic> are regression weights. The <italic>β</italic> can be calculated as <inline-formula><mml:math id="M95" altimg="si73.svg"><mml:mrow><mml:mi>β</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> , where <inline-formula><mml:math id="M96" altimg="si74.svg"><mml:mrow><mml:msup><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is the pseudoinverse of the confounds.</p>
        </sec>
      </sec>
      <sec id="sec2.4">
        <label>2.4</label>
        <title>Training, validation and testing</title>
        <p id="p0235">For the Elastic Net, k fold nested cross-validation was performed (k ​= ​5). The subjects from both HCP and UKB data were divided into k folds. For each folds, a set was selected as the outer test set and the remaining k-1 sets were used as the outer training set. Then, an inner loop is used to tune the hyper-parameters via k-fold validation on the training set. The optimised model (using tuned hyper-parameters) was then evaluated on the test set and this procedure was repeated for all k test folds. In summary, the outer loop is used for model evaluation and the inner loop for the model selection phase. The important hyper-parameter to tune for Elastic Net is the weights on the ridge and lasso penalty. Lastly, we considered the family structure for HCP data and the family members were kept in the same folds. A summary figure explaining the process of nested cross-validation is shown in <xref rid="appsec1" ref-type="sec">Fig. A.34</xref>.</p>
        <p id="p0240">In case of CNNs, there are a number of hyper-parameters to tune, e.g., learning rate, number of hidden units, width of convolutional kernel, etc. For our benchmark study, we have hundreds of different variants of functional connectivity estimates as input, e.g., one possible variant of functional connectivity is estimated by following steps: step-1 (ICA parcellation), step-2 (SGGGM), step-3 (tangent space), step-4 (shrinkage in tangent space), step-5 (X1Y1 as deconfounding). This computationally makes it impossible to tune hyper parameters separately for each input. We randomly selected a few input variants (<inline-formula><mml:math id="M97" altimg="si1.svg"><mml:mo>∼</mml:mo></mml:math></inline-formula> 20) and tune the hyper-parameters for these selected inputs (for all non-imaging variables prediction). This gave us the estimate of hyper-parameter values for which CNNs perform optimally (convergence and relative higher prediction accuracy). We then fixed these hyper-parameters values for all non-imaging variables, prediction for both UKB and HCP datasets for all functional connectivity estimates. In Section <xref rid="sec4" ref-type="sec">4</xref>, we performed external validation of the pipeline, and these hyper-parameters were still fixed on un-seen new datasets. This approach has the disadvantage that it can negatively affect CNN performance but it does avoid over-fitting concerns, and also tests the generalisability of the CNN architecture. The fine-tuning was performed within the training-validation-testing framework. The tuned hyper parameters for CNNs are reported in <xref rid="appsec1" ref-type="sec">Table A.4</xref>.</p>
        <p id="p0245">We took advantage of large N of UKB (and HCP) and did not apply the inner cross-validation framework for CNN evaluation, but used the repeated training-validation-test splits. The subjects were split into training (72%), validation (8%) and testing (20%) sets. The training, validation and testing split was repeated 5 times; therefore, each model was trained five times and all subjects were tested once. The validation set here was used to assess performance of CNN, e.g., early stopping (when error on validation set grows but can select the previous optimum model) and model preparation (deep features selection) etc. It should be noted that any pre-processing of connectivity estimates (e.g., normalization) is performed within the cross-validation/training-validation-testing folds, and all CNN based results reported in this paper are on the testing data.</p>
      </sec>
      <sec id="sec2.5">
        <label>2.5</label>
        <title>Statistical testing</title>
        <p id="p0250"><bold>Paired <italic>t</italic>-test</bold>: A paired <italic>t</italic>-test is performed to determine whether there is statistical evidence that the mean difference between paired observations (e.g., no shrinkage vs shrinkage approaches) on a particular outcome (i.e., fluid intelligence score prediction) is significantly different from zero. We have used symbols to report the test results; ns (not significant) when <inline-formula><mml:math id="M98" altimg="si75.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">&gt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, * when <inline-formula><mml:math id="M99" altimg="si76.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≤</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, ** when <inline-formula><mml:math id="M100" altimg="si77.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≤</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula> and *** when <inline-formula><mml:math id="M101" altimg="si78.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≤</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
        <p id="p0255"><bold>Fisher transformation</bold>: To generate confidence intervals on the prediction correlations (i.e., continuous outputs e.g., age), we computed the Fisher transformation. If the prediction correlation is r, then Fisher transformation F(r) is <inline-formula><mml:math id="M102" altimg="si79.svg"><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. F(r) approximately follows a normal distribution, with mean ​= ​F(p) ​= <inline-formula><mml:math id="M103" altimg="si80.svg"><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and standard error, <inline-formula><mml:math id="M104" altimg="si81.svg"><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, where n is sample size (i.e., number of subjects) and p is the true correlation coefficient. Then z-score is calculated as <inline-formula><mml:math id="M105" altimg="si82.svg"><mml:mrow><mml:mi>z</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:mfrac><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:msqrt><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> . The confidence interval (CI) for p can be calculated as in Equation <xref rid="fd11" ref-type="disp-formula">(11)</xref>. The inverse Fisher transform is then calculated to bring the CI to the r units.<disp-formula id="fd11"><label>(11)</label><mml:math id="M106" display="block" altimg="si83.svg" alttext="Equation 11."><mml:mrow><mml:mn>100</mml:mn><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mtext>%</mml:mtext><mml:mi>C</mml:mi><mml:mi>I</mml:mi><mml:mo>:</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">∈</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">±</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>α</mml:mi><mml:mo linebreak="badbreak">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p id="p0260"><bold>Wilson test</bold>: To draw the confidence intervals on the prediction accuracies (i.e., discrete outputs such as sex), we performed the Wilson test (suitable for the binomial distribution). The Wilson score interval is explained in (<xref rid="bib11" ref-type="bibr">Bender, 2001</xref>; <xref rid="bib93" ref-type="bibr">Wilson score interval and ht, 2019</xref>).</p>
        <p id="p0265"><bold>Repeated k-fold cross validation:</bold> We repeated 100 times the nested 5-fold cross validation on the top performing pipelines. We used the 99% confidence limits on these 100 prediction values to generate the confidence intervals. The rationale is to probe well the sampling variability and to test reproducibility of the top performing pipelines.</p>
      </sec>
      <sec id="sec2.6">
        <label>2.6</label>
        <title>Imaging data</title>
        <p id="p0270">The rfMRI data of 13301 subjects from UKB and 1003 subjects from the HCP were used in this analysis. The pre-processing pipelines for UKB and HCP are described in (<xref rid="bib70" ref-type="bibr">re-processing pipeli, 2019</xref>) and (<xref rid="bib69" ref-type="bibr">re-processing pipeli, 2016</xref>) respectively, although the main steps can be summarized as (1) motion correction, (2) removal of structural artefacts with ICA (Independent Component Analysis and FMRIB’s ICA-based X-noisefier (FIX), and (3) brain parcellation using any of the techniques covered in Section <xref rid="sec2.1" ref-type="sec">2.1</xref>. The length of the scanning session for UKB is 6 ​min, and for HCP is 1 ​h (4 sessions of 15 ​min each). For UKB, we have 490 time-points and for HCP, we used data from all 4 sessions which gave us 4800 time points in total (1200 timepoints in each session).</p>
      </sec>
      <sec id="sec2.7">
        <label>2.7</label>
        <title>Non-imaging data</title>
        <p id="p0275">Here, we have chosen four non-imaging variables: age, sex, fluid intelligence score and neuroticism score (the latter only for UKB), for following reasons:</p>
        <p id="p0280"><bold>Age</bold>: Improving prediction of age from brain data is of interest, to further clinical understanding of how age links to neurodevelopment and degeneration. For instance, comparing the discrepancy between an individual’s chronological age and the age predicted from neuroimaging data can serve as a biomarker for several age-linked brain diseases (<xref rid="bib1" ref-type="bibr">Abbott, 2011</xref>). Age can be accurately predicted from structural MRI data (<xref rid="bib20" ref-type="bibr">Cole et al., 2017</xref>); however, prediction of age from functional connectivity estimates is not as accurate. Nevertheless, this represents a non-imaging variable that can be predicted reasonably strongly (as opposed to fluid intelligence and neuroticism).</p>
        <p id="p0285"><bold>Sex</bold>: Sex classification through functional connectivity is comparatively accurate, and so this variable provides a valuable evaluation parameter to compare benchmark performance of different models.</p>
        <p id="p0290"><bold>Fluid Intelligence</bold>: Fluid intelligence refers to the ability to reason and to solve new problems independently of previously acquired knowledge (<xref rid="bib43" ref-type="bibr">Jaeggi et al., 2008</xref>). It is highly related to professional and educational success and represents overall performance across a broad range of cognitive abilities. A number of recent studies have predicted fluid intelligence from functional connectivity (<xref rid="bib37" ref-type="bibr">He et al., 2018a</xref>), but due to measurement variability, correlations remain rather weak. However, more precise and novel methods for the estimation and use of functional connectivity could lead to better predictions, and provide a more precise understanding of how brain networks relate to cognitive abilities.</p>
        <p id="p0295"><bold>Neuroticism</bold>: Mental health is being assessed in a number of ways within UKB. Participants answer a 12-item neuroticism questionnaire as part of their baseline assessment. We used the algorithm employed in (<xref rid="bib60" ref-type="bibr">Neuroticism Score and https:, 2019</xref>) to calculate the score of neuroticism for each subject.</p>
        <p id="p0300">For the purpose of this paper, we have shown the prediction accuracy (for categorical variables) and prediction correlation (for continuous variables). There could be an argument in favor of variance (or coefficient of determination) over correlation. However, correlation is commonly used and well-understood by the readers and that was our rationale behind selecting correlation (as we want this pipeline paper to be directly comparable to existing literature work). Also, for the reported results in this paper, correlation or coefficient of determination carried exactly the same information.</p>
      </sec>
    </sec>
    <sec id="sec3">
      <label>3</label>
      <title>Results</title>
      <sec id="sec3.1">
        <label>3.1</label>
        <title>Parcellation and functional connectivity estimation</title>
        <p id="p0305"><xref rid="fig2" ref-type="fig">Fig. 2</xref> shows the prediction accuracy/correlation for non-imaging measures from functional connectivity estimates across different parcellation schemes (Section <xref rid="sec2.1" ref-type="sec">2.1</xref>) and functional connectivity estimation methods (Section <xref rid="sec2.2" ref-type="sec">2.2</xref>). The results in <xref rid="fig2" ref-type="fig">Fig. 2</xref> were calculated by directly vectorizing the connectivity estimates without projection into tangent space. Elastic Net was used as a predictor/classifier with nested 5-fold cross-validation. The results illustrated in <xref rid="fig2" ref-type="fig">Fig. 2</xref> are a reduction of the full set of results, chosen to highlight the performance of methods employed in step 1 (brain parcellation) and step 2 (functional connectivity estimation) using the relatively robust Elastic Net as the predictor/classifier. The results shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref> were calculated after removing the effect of confounds from data (deconfounding), and <xref rid="appsec1" ref-type="sec">Fig. A.14</xref> shows prediction estimates without confound removal.<fig id="fig2"><label>Fig. 2</label><caption><p>The impact of various parcellation strategies and functional connectivity estimation methods on prediction power for non-imaging variables <bold>after deconfounding</bold>. <bold>[A,B] (HCP Data), [C,D] (UKB Data):</bold> The violin plots in <bold>A</bold> and <bold>C</bold> show the prediction variability over 5 measures of functional connectivity estimates and in <bold>B</bold> and <bold>D</bold> show the prediction variability the over different parcellation schemes. For HCP, the ICA based parcellation schemes are <inline-formula><mml:math id="M107" altimg="si84.svg"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>_</mml:mo><mml:mn>15</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M108" altimg="si85.svg"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>_</mml:mo><mml:mn>50</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M109" altimg="si86.svg"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>_</mml:mo><mml:mn>200</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula>, and for UKB are <inline-formula><mml:math id="M110" altimg="si87.svg"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>_</mml:mo><mml:mn>21</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M111" altimg="si88.svg"><mml:mrow><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>_</mml:mo><mml:mn>55</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula>, where D ​= ​the number of parcels. For both HCP and UKB, SHEN parcellation was 268D, YEO was 100D, and PROFUMO was 50D (for HCP only). The stars refer to comparison against the next-best method.</p></caption><alt-text id="alttext0025">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p>
      </sec>
      <sec id="sec3.2">
        <label>3.2</label>
        <title>Tangent space projection and shrinkage</title>
        <p id="p0310">A reference point is required when projecting functional connectivity estimates into the tangent space. This reference mean binds each of the connectivity estimates into the same tangential plane. The results in <xref rid="appsec1" ref-type="sec">Fig. A.15</xref> show the prediction correlation for fluid intelligence using different reference means. For each mean, functional connectivity estimates from all parcellation schemes (Section <xref rid="sec2.1" ref-type="sec">2.1</xref>) were estimated by using all functional connectivity estimation methods (Section <xref rid="sec2.2" ref-type="sec">2.2</xref>). The predictor/classifier employed here for fluid intelligence prediction was Elastic Net using nested 5 fold cross validation. For simplicity, only fluid intelligence prediction scores are displayed in <xref rid="appsec1" ref-type="sec">Fig. A15</xref>, as the prediction correlations for other non-imaging variables follows the same trend across various reference mean estimation techniques. The violin plots in <xref rid="appsec1" ref-type="sec">Fig. A.15</xref> show the prediction variability over 4 different parcellation schemes and 5 measures of functional connectivity estimates in the tangent space. The results shown in <xref rid="appsec1" ref-type="sec">Fig. A15</xref> were calculated after deconfounding, and <xref rid="appsec1" ref-type="sec">Fig. A.16</xref> shows prediction estimates without deconfounding.</p>
        <p id="p0315"><xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures A,C,E and G) illustrates how the prediction accuracy was modified by projecting connectivity estimates into the tangent plane. Again, we varied the parcellation schemes and functional connectivity estimation techniques, but fixed Elastic Net as the predictor/classifier. The results illustrated in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures A,C,E and G) are a reduction of the full set of results, chosen to highlight the performance of tangent space parameterization (Section <xref rid="sec2.2.2" ref-type="sec">2.2.2</xref>). <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures B,D,F and H) compares the effect of applying shrinkage in the tangent space (Section <xref rid="sec2.2.3" ref-type="sec">2.2.3</xref>). The shrinkage applied was non-isotropic shrinkage towards the population dispersion (PoSCE). The Results in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures B,D,F and H) are based on functional connectivity estimates that have been projected into the tangent plane (Section <xref rid="sec2.2.2" ref-type="sec">2.2.2</xref>). The violin plots in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures B,D,F and H) show the prediction variability over 4 different parcellation schemes and 5 measures of functional connectivity estimates in the normal tangent space (no shrinkage) versus tangent_shrinkage space (PoSCE), (Section <xref rid="sec2.2.3" ref-type="sec">2.2.3</xref>). Similarly to the previously displayed results, Elastic Net was used as the predictor/classifier for prediction of non-imaging measures. Essentially, <xref rid="fig3" ref-type="fig">Fig. 3</xref> shows side-by-side the effect of tangent space projection (from ambient space to tangent space) and tangent space shrinkage (staying within tangent space). The length of the scanning session in HCP is 60 ​min, <xref rid="fig3" ref-type="fig">Fig. 3</xref> also shows the prediction performance on the original 60 ​min scan, and on cut-down data (first 15 ​min and first 5 ​min of the scan for each subject). Moreover, the results shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref> were calculated after deconfounding, and <xref rid="appsec1" ref-type="sec">Fig. A.17</xref> shows similar prediction estimates without deconfounding (for the full length scanning session only).<fig id="fig3"><label>Fig. 3</label><caption><p>The impact of projecting to tangent space and applying shrinkage in tangent space on prediction power <bold>after deconfounding</bold>. <bold>[A-F] (HCP Data), [G,H] (UKB):</bold> The y-axis depicts the prediction accuracy/correlation for different behavioural measures. “Tangent Space” means that tangent space projection was applied on functional connectivity estimates (originally in the “Ambient Space”). The “Shrinkage” strategy means that non-isotropic PoSCE shrinkage was applied to connectivity estimates in tangent space before feeding to the predictor/classifier. “No Shrinkage” means that projected functional connectivity estimates in tangent space were directly fed to the predictor/classifier, and did not undergo PoSCE shrinkage. The violin plots show the prediction variability over 4 different parcellation schemes and 5 measures of functional connectivity estimates.</p></caption><alt-text id="alttext0030">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
        <p id="p0320">The Bland-Altman plot is shown in <xref rid="appsec1" ref-type="sec">Fig. A.18</xref> to describe agreement between shrinkage versus no shrinkage approaches. <xref rid="fig3" ref-type="fig">Fig. 3</xref> (B and H sub-figures) and <xref rid="appsec1" ref-type="sec">Fig. A.18</xref> are precisely two different ways of visualizing the similar results. <xref rid="appsec1" ref-type="sec">Fig. A.19</xref> compares the performance of isotropic (Ledoit-Wolf) versus non-isotropic (PoSCE) shrinkage in the tangent space and <xref rid="appsec1" ref-type="sec">Fig. A20</xref> compares the performance of isotropic (Ledoit-Wolf) versus no shrinkage strategy (projected functional connectivity estimates in the tangent space were directly fed to the predictor/classifier, and did not undergo any shrinkage). All the results displayed in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, <xref rid="appsec1" ref-type="sec">Figs. A18, A19 and A.20</xref> were calculated after deconfounding. The violin plots in <xref rid="appsec1" ref-type="sec">Fig. A.21</xref> show the effect of varying the dimensionality of parcellation on shrinkage approaches for 5 measures of functional connectivity estimates, e.g., it compared the effect of tangent space shrinkage for higher dimensional ICA vs low dimensional ICA.</p>
      </sec>
      <sec id="sec3.3">
        <label>3.3</label>
        <title>Deconfounding</title>
        <p id="p0325">We compared various deconfounding strategies (Section <xref rid="sec2.3.1" ref-type="sec">2.3.1</xref>), by varying ICA dimensionality (Section <xref rid="sec2.1.3" ref-type="sec">2.1.3</xref>) and using Elastic Net as the predictor/classifier. <xref rid="fig4" ref-type="fig">Fig. 4</xref> shows the prediction correlations of fluid intelligence from functional connectivity estimates for each deconfounding strategy. The violin plots in <xref rid="fig4" ref-type="fig">Fig. 4</xref> shows the prediction variability over each specific sICA dimensionality, 5 measures of functional connectivity estimates and 3 different spaces (ambient space, tangent space and tangent_shrinkage space). Again, the results illustrated in <xref rid="fig4" ref-type="fig">Fig. 4</xref> are a reduction of the full set of results, chosen to highlight the performance of different deconfounding strategies (Section <xref rid="sec2.3" ref-type="sec">2.3</xref>).<fig id="fig4"><label>Fig. 4</label><caption><p>The impact of deconfounding strategies on the prediction power. <bold>[A] (HCP), [B] (UKB)</bold> This figure shows the prediction correlation for fluid intelligence score for various ICA based parcellation techniques across the 6 possible deconfounding strategies that were tested. The violin plots show the prediction variability over each specific sICA dimensionality, 5 measures of functional connectivity estimates and 3 different spaces (ambient space, tangent space and tangent_shrinkage space). X is an input matrix (i.e, subjects’ functional connectivity), and Y, a response vector (e.g., fluid intelligence). The details of different deconfounding strategies are explained in Section <xref rid="sec2.3.1" ref-type="sec">2.3.1</xref>.</p></caption><alt-text id="alttext0035">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
      </sec>
      <sec id="sec3.4">
        <label>3.4</label>
        <title>Predictors/classifiers performance</title>
        <p id="p0330"><xref rid="fig5" ref-type="fig">Fig. 5</xref> compares the performance of different predictors (Section <xref rid="sec2.3" ref-type="sec">2.3</xref>) on the prediction between functional connectivity and non-imaging variables. Inputs included functional connectivity estimates (Section <xref rid="sec2.2" ref-type="sec">2.2</xref>) both in ambient space (without tangent space projection) and tangent space (Section <xref rid="sec2.2.2" ref-type="sec">2.2.2</xref>). Estimates with tangent space parameterization included estimates with and without PoSCE shrinkage (tangent space and tangent_shrinkage space). Therefore, the violin plots in <xref rid="fig5" ref-type="fig">Fig. 5</xref> show the prediction variability over 4 different parcellation schemes, 5 measures of functional connectivity estimates and 3 different spaces (ambient space, tangent space and tangent_shrinkage space). Again, the results illustrated in <xref rid="fig5" ref-type="fig">Fig. 5</xref> are a reduction of the full set of results, chosen to highlight the performance of different classifiers/predictors (Section <xref rid="sec2.3" ref-type="sec">2.3</xref>). The results in <xref rid="fig5" ref-type="fig">Fig. 5</xref> compared the performance of Elastic Net, 2D RCNN and BrainNetCNN (Section <xref rid="sec2.3" ref-type="sec">2.3</xref>). We included GraphCNN initially, but dropped it due to consistently poor performance compared with the other models. <xref rid="appsec1" ref-type="sec">Fig. A31</xref> shows the comparative performance of GraphCNN and Elastic Net. The subset of results chosen for <xref rid="appsec1" ref-type="sec">Fig. A31</xref> were the ones where GraphCNN exhibited the best performance, although still underperforming in comparison to Elastic Net.<fig id="fig5"><label>Fig. 5</label><caption><p>The performance of different classifiers/predictors on prediction power with and without deconfounding. <bold>[A,B,C] (HCP Data), [D,E,F,G] (UKB Data):</bold> The prediction accuracy/correlation for different non-imaging measures is depicted on the y-axis. The violin plots show the prediction variability over 4 different parcellation schemes, 5 measures of functional connectivity estimates and 3 different spaces (ambient space, tangent space and tangent_shrinkage space).</p></caption><alt-text id="alttext0040">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
      </sec>
      <sec id="sec3.5">
        <label>3.5</label>
        <title>Top performing configurations</title>
        <p id="p0335"><xref rid="fig6" ref-type="fig">Fig. 6</xref>, <xref rid="fig7" ref-type="fig">Fig. 7</xref> show the top ten methods in terms of predictive power, with strategies from different steps identified. The results shown in <xref rid="fig6" ref-type="fig">Fig. 6</xref>, <xref rid="fig7" ref-type="fig">Fig. 7</xref> were calculated after deconfounding, and <xref rid="appsec1" ref-type="sec">Figs. A22 and A23</xref> show prediction estimates without deconfounding. The error bars in <xref rid="fig6" ref-type="fig">Fig. 6</xref>, <xref rid="fig7" ref-type="fig">Fig. 7</xref>, <xref rid="appsec1" ref-type="sec">Figs. A22 and A23</xref> were generated using the Fisher transformation (for continuous output) and Wilson test (for discrete output) (Section <xref rid="sec2.5" ref-type="sec">2.5</xref>). The highlighted red blocks show the recommended pipelines (rationale explained in Section <xref rid="sec5" ref-type="sec">5</xref>), and the red dotted lines highlight the point when the error bar of pipeline after the dotted line is out of range from the error bar of the top (first) pipeline.<fig id="fig6"><label>Fig. 6</label><caption><p>The top performing ten configurations for the prediction of each non-imaging variable by dataset <bold>after deconfounding</bold>. <bold>[A,B,C] (HCP Data)</bold> Each data point represents a different configuration strategy that may vary in terms of parcellation strategy, the functional connectivity estimation method, whether tangent space parameterization was employed, whether tangent space regularization was employed, and the predictor that was used. The first word indicates the parcellation strategy, and the second word refers to the functional connectivity estimation method. The third word refers to the geometry in which classifier/predictor is applied, ambient referring to non-tangent space and tangent referring to the projected covariance matrices in tangent space. If non-isotropic shrinkage was applied after projecting covariance matrices to tangent space, the fourth word will be “shrinkage”. The last word indicates the type of classifier/predictor that was used. The highlighted red blocks show the recommended pipelines (rationale explained in Section <xref rid="sec5" ref-type="sec">5</xref>), and red dotted lines highlight the point when the error bar of pipeline after the dotted line is out of range from the error bar of the top (first) pipeline.</p></caption><alt-text id="alttext0045">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig><fig id="fig7"><label>Fig. 7</label><caption><p>The top performing ten configurations for the prediction of each non-imaging variable by dataset <bold>after deconfounding</bold>. <bold>[A,B,C,D] (UKB Data)</bold> Each data point represents a different configuration strategy that may vary in terms of parcellation strategy, the functional connectivity estimation method, whether tangent space parameterization was employed, whether tangent space regularization was employed, and the predictor/classifier that was used. The first word indicates the parcellation strategy, and the second word refers to the functional connectivity estimation method. The third word refers to the geometry in which classifier is applied, ambient referring to non-tangent space and tangent referring to the projected covariance matrices in tangent space. If non-isotropic shrinkage was applied after projecting covariance matrices to tangent space, the fourth word will be “shrinkage”. The last word indicates the type of classifier/predictor that was used. The highlighted red blocks show the recommended pipelines (rationale explained in Section <xref rid="sec5" ref-type="sec">5</xref>), and red dotted lines highlight the point when the error bar of pipeline after the dotted line is out of range from the error bar of the top (first) pipeline.</p></caption><alt-text id="alttext0050">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
      </sec>
      <sec id="sec3.6">
        <label>3.6</label>
        <title>Joint results</title>
        <p id="p0340"><xref rid="fig8" ref-type="fig">Fig. 8</xref>, <xref rid="fig9" ref-type="fig">Fig. 9</xref>, <xref rid="fig10" ref-type="fig">Fig. 10</xref> show the combination of various techniques at different stages of the pipeline for fluid intelligence, sex, and age prediction respectively for both HCP and UKB data after deconfounding. <xref rid="appsec1" ref-type="sec">Figs. A24, A25 and A26</xref> show similar results for fluid intelligence, sex and age prediction respectively but without deconfounding. In each of these figures, a few parameters were fixed across the different pipeline combinations (Euclidean mean as reference mean, non-isotropic shrinkage as shrinkage in tangent space). <xref rid="appsec1" ref-type="sec">Fig. A27</xref> provides results for the prediction of neuroticism score in UKB data, and results are displayed both before and after controlling for confounds.<fig id="fig8"><label>Fig. 8</label><caption><p>This parallel coordinates plot provides a visualization of all possible combinations of options in the pipeline to predict fluid intelligence scores from functional connectivity <bold>after deconfounding</bold>. <bold>[A] (HCP Data), [B] (UKB Data):</bold> The lines are color-coded according to their prediction performance. The vertical ordering is chosen with respect to prediction performance for each sub-block (in ascending order of prediction correlation/accuracy). For example, the lower (from bottom) the position of lines in a block, the higher the prediction accuracy of that variant (and vice-versa). With respect to the vertical ordering of sub-blocks (e.g., ambient or tangent space), that is chosen by hand (but it should not make any difference as the crossing of different lines does not explain any meaningful information here).</p></caption><alt-text id="alttext0055">Fig. 8</alt-text><graphic xlink:href="gr8"/></fig><fig id="fig9"><label>Fig. 9</label><caption><p>This parallel coordinates plot provides a visualization of all possible combinations of options in the pipeline to pipeline to predict sex from functional connectivity <bold>after deconfounding</bold>. <bold>[A] (HCP Data), [B] (UKB Data):</bold> The lines are color-coded according to their prediction performance.</p></caption><alt-text id="alttext0060">Fig. 9</alt-text><graphic xlink:href="gr9"/></fig><fig id="fig10"><label>Fig. 10</label><caption><p>This parallel coordinates plot provides a visualization of all possible combinations of options in the pipeline to pipeline to predict age from functional connectivity <bold>after deconfounding</bold>. <bold>[A] (HCP Data), [B] (UKB Data):</bold> The lines are color-coded according to their prediction performance.</p></caption><alt-text id="alttext0065">Fig. 10</alt-text><graphic xlink:href="gr10"/></fig></p>
      </sec>
      <sec id="sec3.7">
        <label>3.7</label>
        <title>Deconfounding revisited</title>
        <p id="p0345">All the results illustrated in this paper were using X1Y1 or X1Y0 deconfounding strategy (apart from <xref rid="fig4" ref-type="fig">Fig. 4</xref> where all six deconfounding strategies were employed). We have applied the X1Y1 deconfounding for age, fluid intelligence and neuroticism score prediction and X1Y0 for sex prediction (X1Y1 and X1Y0 are detailed in Section <xref rid="sec2.3.1" ref-type="sec">2.3.1</xref> and the reasoning for this is discussed in Section <xref rid="sec5" ref-type="sec">5</xref>). Confounds (particularly head size and motion) are clearly a serious problem if not dealt with for fluid intelligence score prediction. Head size is positively correlated with fluid intelligence and head motion is negatively correlated (detailed further in <xref rid="appsec1" ref-type="sec">Table A5</xref>). For neuroticism score prediction, the confounds which have the most effect on prediction power are age, table position, imaging-centre and date-drift related confounds. This could be because of non-linear interactions between imaging-centre/date-drift related confounds, age, table-position and neuroticism. For age, the crucial confound is head-motion (positively correlated with age), although other than head-motion, we did not find prediction was significantly affected by any confounds. For sex prediction, the crucial confounds are age, height, weight, head motion and head size. For fluid intelligence, neuroticism and age prediction, the deconfounded results are calculated after regressing out all the potential confounding variables. However, in case of sex prediction, for the deconfounded results, we regressed out all the confounds from data except head-size and body density related confounds. The rationale is that sex is a major casual factor for head-size, and head-size causes some confounding effects in the imaging. Regressing out head-size reduces the overall sex prediction accuracy but allows one to focus on the non-headsize sex effects in the imaging. However, one important goal of this work is to optimise functional connectivity estimation methods (i.e., allow maximum predictors/classifiers to converge to make performance of different models comparable). Therefore, we didn’t include head-size and body density related variables as confounds when predicting sex. Most of the results without removing the effect of confounds (i.e., higher prediction accuracy/correlation as compared to deconfounded results in the main text) are shown in the Inline supplementary material.</p>
      </sec>
    </sec>
    <sec id="sec4">
      <label>4</label>
      <title>Results evaluation</title>
      <sec id="sec4.1">
        <label>4.1</label>
        <title>Evaluation on independent datasets</title>
        <p id="p0350">We evaluated the proposed network modelling methods on Autism Brain Imaging Data Exchange (ABIDE) (<xref rid="bib54" ref-type="bibr">Di Martino et al., 2014</xref>) and Addiction Connectome Preprocessed Initiative (ACPI) datasets.<xref rid="fn7" ref-type="fn">7</xref></p>
        <p id="p0355"><bold>ABIDE</bold>: We used the pre-processed resting-state fMRI data from the Preprocessed Connectome Project pipeline (C-PAC) (<xref rid="bib21" ref-type="bibr">Craddock et al., 2013</xref>), without global signal regression and without band-pass filtering. The processed resting-state fMRI data is available for 871 subjects (autism and control). We applied most of the pipeline combinations on ABIDE including all parcellation strategies (except PROFUMO), functional connectivity estimation techniques, tangent space parameterization and shrinkage techniques (non-isotropic shrinkage), and predictors/classifiers (except GraphCNN). We pre-selected our recommended pipelines based on the generally top performing techniques as shown in <xref rid="fig6" ref-type="fig">Fig. 6</xref>, <xref rid="fig7" ref-type="fig">Fig. 7</xref>, <xref rid="appsec1" ref-type="sec">Figs. A22 and A23</xref> (rationale further explained in Section <xref rid="sec5" ref-type="sec">5</xref>); parcellation (ICA), functional connectivity estimation (Tikhonov or SGGGM), tangent space parameterization (yes) and tangent space shrinkage (optional). Regarding recommended predictor/classifier, Elastic Net tends to be more stable but CNN-based architectures can out-perform Elastic Net sometimes, therefore; we tested all the predictors/classifiers. The confounds were not provided for the ABIDE data-set so results reported are based without deconfounding (X0Y0). ABIDE data is comparatively more noisy as compared to HCP and UKB data; the number of time points varies between 115 and 295. We employed predictors to predict age of participants (min ​= ​6.47, max ​= ​64).</p>
        <p id="p0360"><bold>ACPI</bold>: We used the pre-processed resting-state fMRI data from Multimodal treatment study of Attention Deficit Hyperactivity Disorder. The data was processed using the Preprocessed Connectome Project pipeline (C-PAC); with images registered using Advanced Normalization Tools (ANTS), without any scrubbing, and without global signal regression. We applied most of pipeline combinations on ACPI data including all parcellation strategies (except PROFUMO), functional connectivity estimation techniques, tangent space parameterization and shrinkage techniques, and predictors/classifiers (except GraphCNN). The confounds were not provided for ACPI data-set so results reported here are without deconfounding (X0Y0). The number of time points in ACPI dataset for each participant is 179 and the total number of subjects is 126. We employed predictors/classifier to predict whether a subject smokes or not (binary classification).</p>
        <p id="p0365">The results for predicting age on ABIDE and smoking status on ACPI for the chosen subset of pipelines is shown in <xref rid="tbl3" ref-type="table">Table 3</xref>. The top 3 best performing pipelines for both ABIDE and ACPI are highlighted in red. <xref rid="appsec1" ref-type="sec">Figs. A28 and A29</xref> show the full set of results for age and smoking status prediction for both ABIDE and ACPI data respectively.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Predicting age for ABIDE participants and smoking status for ACPI participants. The top 3 best performing pipelines for both ABIDE and ACPI is highlighted in red. The missing lines indicate that predictors/classifier did not converge.</p></caption><alt-text id="alttext0085">Table 3</alt-text><graphic xlink:href="fx2"/></table-wrap></p>
      </sec>
      <sec id="sec4.2">
        <label>4.2</label>
        <title>Comparison with other commonly used methodologies</title>
        <p id="p0370"><bold>Connectome-based predictive modelling</bold>: There is another pipeline in the literature known as Connectome-based predictive modelling (CPM) (<xref rid="bib76" ref-type="bibr">Shen et al., 2017</xref>) that is mainly comprised of three steps: (i) parcellating the brain using the SHEN functional atlas, (ii) estimating connectivity using full correlation, (iii) correlating each edge in the connectivity matrix with behavioral measures, selecting only the most correlated N edges, averaging across these N edges to give a single predictor value for each subject, and then fitting a linear model (e.g., robust regression, polynomial curve fitting) to predict non-imaging variables.</p>
        <p id="p0375"><bold>Random forests</bold>: Random forests algorithm are an ensemble learning method and work as a large collection of decorrelated random trees (<xref rid="bib51" ref-type="bibr">Liaw and Wiener, 2002</xref>). We have compared the prediction performance of Elastic Net and Random Forest for sex prediction, and results are shown in <xref rid="appsec1" ref-type="sec">Fig. A.33</xref>.</p>
        <p id="p0380"><bold>Dictionary Learning</bold>: Massive online dictionary learning (MODL) was used to extract the time-series data (<xref rid="bib55" ref-type="bibr">Mensch et al., 2017</xref>) on ABIDE data-set only. These time-series were originally used in (<xref rid="bib55" ref-type="bibr">Mensch et al., 2017</xref>). We have compared the prediction performance of ICA and Dictionary Learning for a subset of tests, and results are shown in <xref rid="appsec1" ref-type="sec">Fig. A.32</xref>.</p>
        <p id="p0385"><bold>Higher Dimensional YEO Parcellation</bold>: The YEO parcellation is available at multiple resolution levels. For most analysis in this work, we have used d ​= ​100 parcels, but we have compared a subset of methodologies for YEO parcellation with d ​= ​200 and d ​= ​400 parcels. The results are shown in <xref rid="fig11" ref-type="fig">Fig. 11</xref> (sub-figure D).<fig id="fig11"><label>Figure 11</label><caption><p>The relative impact of different steps of pipeline on the non-imaging variables prediction performance for participants in UKB, HCP, ABIDE, and ACPI datasets. Each sub-figure highlights the recommended options which are selected based on quantitative and qualitative analysis. The recommended optimal methodologies from each step of the pipeline are, (1) sICA for parcellation, (2) Tikhonov or SGGGM for functional connectivity estimation, (3) projecting the connectivity estimates to tangent space, (4) optional shrinkage in tangent space, (5) deconfounding the data (both the target and predictor variables) and (6) Elastic Net or 2D RCNN as a predictor/classifier.</p></caption><alt-text id="alttext0070">Figure 11</alt-text><graphic xlink:href="gr11"/></fig></p>
      </sec>
    </sec>
    <sec id="sec5">
      <label>5</label>
      <title>Discussion</title>
      <p id="p0390">A number of research groups are increasingly focussing on rfMRI connectivity, and developing a plethora of methods (<xref rid="bib2" ref-type="bibr">Abraham et al., 2017</xref>; <xref rid="bib27" ref-type="bibr">Finn et al., 2015</xref>). These methods range from neural-level simulations to abstract graph theoretic summaries of a connectivity matrix (<xref rid="bib44" ref-type="bibr">Jonas and Kording, 2017</xref>; <xref rid="bib79" ref-type="bibr">Smith, 2012</xref>). Between these two extremes, we also have several popular network modelling methods (applied to real fMRI data) that can mainly be categorized into the study of functional vs effective connectivity (an over-simplistic division) (<xref rid="bib79" ref-type="bibr">Smith, 2012</xref>; <xref rid="bib15" ref-type="bibr">Buckner et al., 2013</xref>; <xref rid="bib30" ref-type="bibr">Friston, 2011</xref>). In the latter, one is generally attempting to estimate both strengths and the dominant direction of information flow (causality); this aims to be more meaningful than functional connectivity, but is hard to estimate robustly on resting data, and such methods can only cope with fewer parcels. Then, we have functional connectivity (presented in this paper), which comes with the benefits of being simpler, well conditioned and being able to handle more nodes. Functional connectivity has also faced some criticism, as even with partial correlation, one can try to estimate the direct connections, but not the directionalities. Ideally, we would like to work at the more sophisticated bio-physically interpretable level, but considering the current limitations, functional connectivity is a pragmatic choice, particularly for resting-fMRI observational studies (because there are no external interventions such as in task-fMRI). In this paper, we aimed to identify an optimal pipeline to estimate and analyze functional connectivity, entailing few major steps, and in the following section, we will discuss the overall recommendations (and rationale behind these).</p>
      <p id="p0395">We started this work with the hypothesis that different tasks (non-imaging variables to predict) and different datasets may tell different stories, and for that reason, we carefully chose a few different tasks (age, sex, fluid intelligence, neuroticism and smoking status) and four different datasets. We wanted to evaluate trends across different tasks and across different datasets independently. Once we had considered these independent results, we aimed to identify “one best/recommended” pipeline. The remainder of this section evolves systematically, starting from HCP and UKB datasets, and then testing on ABIDE and ACPI datasets, and lastly deducing recommendations which are reliable in all scenarios (consolidated results across all tasks and datasets). Lastly, we illustrate that the recommendations which are based on individual scenarios, and recommendations based on consolidated results are very similar.</p>
      <p id="p0400"><bold>The best parcellation strategy</bold>: The data-driven parcellation techniques we explored for identification of brain parcels included sICA, PROFUMO, SHEN and YEO. PROFUMO yielded less predictive power than sICA identified parcels, as shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. This is consistent with results in (<xref rid="bib12" ref-type="bibr">Bijsterbosch et al., 2018</xref>), where PROFUMO network matrices tend to be quite empty, in part because of the fairly strong temporal independence between probabilistic functional modes. Using sICA, we investigated if the number of parcels (ICA dimensionality) affected the predictive power (illustrated in <xref rid="fig4" ref-type="fig">Fig. 4</xref> and briefly discussed). Our results showed that increasing dimensionality leads to an increase in predictive power. However, higher predictive power using sICA could actually be attributable to cross-subject variations in the spatial configuration of functional brain regions that are represented as changes in functional connectivity (<xref rid="bib12" ref-type="bibr">Bijsterbosch et al., 2018</xref>). Therefore, although PROFUMO yielded lower predictive power, it still may provide a <italic>purer</italic> estimate, as it should not contain as much potential confounding anatomical information. sICA also outperformed SHEN and YEO parcellations in terms of predictive power as illustrated in <xref rid="fig2" ref-type="fig">Fig. 2</xref> (sub-figures A and C). SHEN and YEO parcellations can be affected if the reality is that of overlapping functional organisation, due to incorrect assumption of hard parcels leading to mixing of extracted time-series (<xref rid="bib13" ref-type="bibr">Bijsterbosch et al., 2019</xref>); however, further detailed work is require to understand and address this issue. To conclude, in terms of quantitative assessment, sICA outperformed other parcellations.</p>
      <p id="p0405"><bold>The best functional connectivity estimation method</bold>: When functional connectivity estimates are left in ambient space, without projection into tangent space, our results revealed estimation using regularized partial correlation estimation yields higher predictive power than does using full correlation/covariance and unregularised partial correlation as illustrated by the mean of the violin plots in sub-figures B and D in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. For example, for age prediction task in UKB, average correlation using covariance, full correlation, unregularised partial correlation, Tikhonov and SGGGM is 0.52, 0.52, 0.45, 0.56, and 0.55 respectively. Using partial correlation results in the removal/weakening of a considerable number of marginal and negative connections. The marginal connections were most likely due to global effects or indirect connections. Hence, partial correlation also enhanced the sparsity in the functional connectivity matrix. Partial correlation involves the inversion of covariance matrix, and to stably invert the covariance matrix, regularization should be normally applied to the covariance matrices (<xref rid="bib89" ref-type="bibr">Thirion et al., 2014</xref>). We employed Tikhonov regularization, as it is an efficient and stable method for estimation of a regularized partial correlation matrix. We found this method resulted in increased predictive power as compared to simple partial correlation (particularly for UKB, as duration of scanning session is shorter than with HCP) as illustrated in <xref rid="fig2" ref-type="fig">Fig. 2</xref> (sub-figure D). However, we found a more sophisticated, recent regularization method, SGGGM, also provided reasonable predictive power (on par with Tikhonov). Through incorporation of group information when deriving intra-subject connectivity estimates, this method enables more accurately data-adaptive regularization. This method produced the robust predictions, although optimised tuning of the parameters of SGGGM (such as sparsity level and group consistency) is essential, as the performance of SGGGM is very sensitive to these parameters. Therefore, to find optimal values for these parameters, a comprehensive grid search strategy must be applied (and, for validity, this needs to be done within cross-validation). To conclude, both in terms of qualitative and quantitative assessment, Tikhonov and SGGGM outperformed other connectivity estimation techniques.</p>
      <p id="p0410"><bold>Is tangent space parameterization important:</bold> To test how tangent space parameterization affects predictive power, we projected different functional connectivity estimates into tangent space. As functional connectivity matrices being projected in to tangent space should always be positive definitive, estimates containing values outside of the positive definitive manifold ideally require adjustment. Functional connectivity estimates through covariance or SGGGM are always positive definitive, therefore did not require additional processing. However, partial correlation and Tikhonov connectivity matrices are not always positive definitive. To adjust for these values, we calculated the eigen-decomposition of the matrix. Any eigenvalues close to zero were adjusted to a fixed, small non-zero value. Our results demonstrated that the performance of most functional connectivity estimation techniques were reasonably improved by projecting them into tangent space, as illustrated in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (subfigures A,C,E and G). These convincing results suggest the importance for future studies to consider the application of Riemannian geometry principles (e.g., tangent space parametrization) to functional connectivity estimates. When applied to different functional connectivity estimation methods, we found tangent space parametrization increased the predictive ability of almost all estimation techniques. Our results however failed to delineate a single connectivity estimate that was best improved by this parameterization. Projection of these estimates into tangent space required a reference mean, and so we also compared the performance of different reference means. Specifically, we compared the performance of Euclidean, harmonic, log determinant, log Euclidean and Riemannian means as reference means for tangent space parameterization. In terms of prediction accuracy/correlation, our results demonstrate the Euclidean mean tends to have the most stability (less standard deviation), as shown in <xref rid="appsec1" ref-type="sec">Figs. A15 and A16</xref> (although the differences were not large between any of the reference mean methods). Therefore, we implemented tangent space parameterization using the Euclidean mean as a reference mean for proceeding analyses. The main advantage of tangent space parameterization is that it moved the functional connectivity estimates into a space where the following computations (e.g., prediction) could be done in a Euclidean framework with a corresponding boost in efficiency. To conclude, both in terms of qualitative and quantitative assessment, tangent space parameterization improves the predictive power.</p>
      <p id="p0415"><bold>Regularization in tangent space:</bold> The functional connectivity estimates often have high estimation variability. After projecting functional connectivity estimates to tangent space, we evaluated three possible regularization strategies, (i) No shrinkage, (ii) applying the non-isotropic Population Shrinkage Covariance Estimator (PoSCE) shrinkage, (iii) applying isotropic Ledoit-Wolf shrinkage. We found that applying the PoSCE shrinkage technique as compared to no shrinkage slightly improved the performance in terms of prediction accuracy for UKB data as illustrated from top pipelines in <xref rid="fig7" ref-type="fig">Fig. 7</xref> and <xref rid="appsec1" ref-type="sec">Fig. A23</xref>, but this improvement is not significant, as illustrated in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figure H). Moreover, It did not yield meaningful improvements for HCP data, but deteriorated the performance as shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figure B,D and F). We also tested the effect of tangent space projection and shrinkage on cut-down HCP data (from 60 ​min to 15 and 5 ​min), and found out that it is the tangent space projection which significantly improved the performance as illustrated in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures C and E), but there is no significant performance change using tangent space shrinkage as illustrated in <xref rid="fig3" ref-type="fig">Fig. 3</xref> (sub-figures D and F). We also tested the effect on PoSCE shrinkage by varying the number of parcels, and did not find any significant improvement as illustrated in <xref rid="appsec1" ref-type="sec">Fig. A21</xref>. However, our analyses also revealed that optimization of the shrinkage parameter in PoSCE was not straightforward. For PoSCE, we chose the shrinkage parameter which resulted in the strongest prediction for the non-imaging variables (within an appropriate cross-validation framework). We then compared non-isotropic PoSCE shrinkage to Ledoit-Wolf isotropic shrinkage, and found that PoSCE did not yield a meaningful advantage compared with Ledoit-Wolf shrinkage (as illustrated in <xref rid="appsec1" ref-type="sec">Fig. A19</xref>). Lastly, we compared the isotropic Ledoit-Wolf shrinkage method with the no shrinkage approach, and found that applying simple Ledoit-Wolf shrinkage improved performance for HCP data, but did not significantly improve performance for UKB data (as illustrated in <xref rid="appsec1" ref-type="sec">Fig. A20</xref>). These results imply that simple isotropic shrinkage is more suitable for less noisy data (e.g., HCP data), and aggressive PoSCE can slightly improve performance for data with comparatively high inter- and intra-subject variance (e.g., UKB data, as duration of scanning session is shorter than with HCP). To conclude, we are recommending shrinkage in tangent space as an optional step which could be applied if data is noisy.</p>
      <p id="p0420"><bold>Deconfounding:</bold> Many imaging studies fail to control for confounds in their analyses, which is problematic in providing replicable and interpretable results that are not attributable to extraneous variables. It is correct that in some cases the “confounds” may be useful to keep in the data - that is one reason why we show most results with and without confounds. However, some confounds (e.g., head motion) are generally considered to be an important factor to remove. On the other hand, age is a good example of being a factor that the experimenter may or may not want to remove - although in the context of alzheimer’s disease prediction, presumably one would include it as an additional predictor, as opposed to simply ignoring it (or deconfounding it), in order to both obtain optimal prediction and most interpretable prediction parameters. For an example, in UKB fluid intelligence prediction, one could carry out the intermediate option of deconfounding for all confounds except for head motion or age, which would give intermediate prediction correlations (in between the two extremes already presented). We have shown some of these intermediate-scenario results in <xref rid="appsec1" ref-type="sec">Table A5</xref>.</p>
      <p id="p0425">In our analyses, we found the optimal deconfounding strategy was X1Y1 (and X1Y0 in some cases). The reason we recommend X1Y1 over X2Y1 is because X2Y1 combination consists of performing fold-wise confound regression on the X (the functional connectivity estimates), and fold-wise deconfounding the target variable Y. However, the deconfounding strategy X1Y1 (deconfounding X once, outside of cross-validation) is more aggressive than X2Y1 (X2Y1 is less aggressive as it used cross-validation to limit the parts of the confounds actually used). For some non-imaging target variables prediction (e.g., sex) there is no chance that confound variables would feed into them (e.g., sex could not be corrupted because of head motion or age). In such cases, it is recommended to deconfound only the imaging variables, X (i.e., functional connectivity estimates) and not to deconfound the target variable, Y (i.e., sex); therefore, X1Y0 (or X2Y0) deconfounding strategy should be used for such target variables. The pretext of supporting X1Y0 over X2YO is the same (X1Y0 is more aggressive as compared to X2Y0). Our analysis have revealed that X0Y1 (deconfounding only Y), also theoretically yields plausible results; however, for some cases (e.g., sex prediction), it is not applicable. Based on our analysis, we have the following recommendations, (i) deconfound both X and Y when there is a chance that confounds can corrupt both the imaging data and non-imaging data, such as fluid intelligence score or any given mental health variable, and (ii) where the confound might have been caused by the variables being correlated, it can be dangerous to adjust for it (i.e. apply deconfounding using it), particularly if the two variables being investigated are not correlated before deconfounding (otherwise, this could cause Berkson’s paradox (<xref rid="bib66" ref-type="bibr">Pearl, 2009</xref>; <xref rid="bib94" ref-type="bibr">Zhang, 2008</xref>).<xref rid="fn8" ref-type="fn">8</xref></p>
      <p id="p0430"><bold>The best classifier/predictor:</bold>
<xref rid="fig5" ref-type="fig">Fig. 5</xref> illustrates the performance of different classifiers/predictors in combination with different parcellation and estimation techniques. Elastic Net is a simple regularized regression technique, whereas the other models tested are based on convolutional neural networks. The prediction of age, fluid intelligence and neuroticism is a continuous prediction task, whereas sex prediction is a binary classification problem. 2D RCNN consistently demonstrated the best performance for sex prediction (e.g., UKB data). 2D RCNN and Elastic Net were comparable for the prediction of fluid intelligence score (e.g., HCP data). For the prediction of neuroticism, our results demonstrated that ElasticNet provided the highest predictive power. Across the prediction of all variables, BrainNetCNN underperformed in comparison to other classifiers/predictors, although it is possible that further optimization of parameters could lead to higher accuracy. GraphCNN consistently underperformed in comparison with the other models (results presented in <xref rid="appsec1" ref-type="sec">Fig. A31</xref>). It should be considered that we tested these deep learning architectures (2D RCNN, BrainNetCNN, and GraphCNN) for hundreds of different functional connectivity estimates, which impose practical limitations on our ability to tune hyper-parameters for each possible configuration. This indirectly suggests that only the most stable architecture will show consistent results across different connectivity estimates. Moreover, this suggests the most robust, off-the-shelf types of neural networks must minimize sensitivity to hyper-parameter tuning, to maximize generalisability and minimize over-fitting. Overall, we have demonstrated that a carefully designed 2D Recurrent Convolutional Network or BrainNetCNN (top performing for fluid intelligence prediction in HCP data) can compete with (and in some cases outperform) a simpler regression model. These results contrast with (<xref rid="bib38" ref-type="bibr">He et al., 2018b</xref>), where kernel based regression (non-parametric classical machine learning algorithm (<xref rid="bib58" ref-type="bibr">Murphy, 2012</xref>)) demonstrated better performance than deep neural networks.</p>
      <p id="p0435"><bold>Overall Results (HCP and UKB)</bold>: In the previous sections, we recommended optimal methodologies from each step of the pipeline. Our recommendation from each step is, (1) sICA for parcellation, (2) Tikhonov or SGGGM for functional connectivity estimation, (3) projecting the connectivity estimates to tangent space, (4) optional shrinkage in tangent space, (5) deconfounding the data (X1Y1 or X1Y0) and (6) Elastic Net or 2D RCNN as a predictor/classifier. It is also important to investigate these methods simultaneously (to identify potential interactions between different pipeline decisions). <xref rid="fig6" ref-type="fig">Fig. 6</xref>, <xref rid="fig7" ref-type="fig">Fig. 7</xref>, <xref rid="appsec1" ref-type="sec">Figs. A22 and A23</xref> illustrate the top performing pipelines out of hundreds of combinations. The top performing methods which repeatedly stand out are in-fact the joint combination of these methodologies; i.e., “ICA SGGGM Tangent Elastic Net” or “ICA Tikhonov Tangent_shrinkage 2DRCNN”, etc. It is to be noted that our recommendations are not solely based on quantitative results but also on the qualitative assessment of each step as explained through-out the Discussions (e.g., one has more parcels than time points, Tikhonov or SGGGM may be able to give stable results). The error bars drawn (using Fisher Transformation/Wilson test) in <xref rid="fig6" ref-type="fig">Fig. 6</xref>, <xref rid="fig7" ref-type="fig">Fig. 7</xref>, <xref rid="appsec1" ref-type="sec">Figs. A22 and A23</xref> show that for sex and age prediction, these recommended pipelines are significantly different from the other non-recommended pipelines. To make sure that all non-imaging variables prediction are reproducible and significant, we ran repeated cross-validation on the top performing pipelines. With a 99% confidence interval, the fluid intelligence scores prediction correlation is <inline-formula><mml:math id="M112" altimg="si89.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">~</mml:mo><mml:mn>0.35</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">±</mml:mo><mml:mn>0.006</mml:mn></mml:mrow></mml:math></inline-formula>, for age it is <inline-formula><mml:math id="M113" altimg="si90.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">~</mml:mo><mml:mn>0.58</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">±</mml:mo><mml:mn>0.005</mml:mn></mml:mrow></mml:math></inline-formula> and for sex it is <inline-formula><mml:math id="M114" altimg="si91.svg"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">~</mml:mo><mml:mn>0.92</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">±</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></inline-formula>. This highlights that the identified optimum pipelines are significantly different and reproducible.</p>
      <p id="p0440"><bold>Results External Evaluation (ABIDE and ACPI):</bold> To test the generalisability of our recommendations, we ran our methodological techniques on ABIDE and ACPI datasets. We first compared our recommended pipelines with randomly chosen non-recommended pipelines, and results are presented in <xref rid="tbl3" ref-type="table">Table 3</xref>. It is to be noted that these datasets have fewer subjects and are comparatively more noisy as compared to HCP and UKB. As shown in <xref rid="tbl3" ref-type="table">Table 3</xref>, recommended pipelines outperformed the other pipelines significantly (particularly for participants’ age prediction task on ABIDE). This supports that the recommended steps are generalizable. Moreover, <xref rid="appsec1" ref-type="sec">Figs. A.28 and A29</xref> show the full set of results for age and smoking status prediction for ABIDE and ACPI data respectively. These results support our recommendations in general, although the performance of CNNs (both 2D RCNN and BrainNetCNN) exceeded our expectations. The results reported on CNNs are without hyper-tuning (same fixed parameters as used in HCP/UKB). This could possibly be explained by CNNs being more powerful on noisier data (relatively speaking), may be similar in effect to data augmentation (<xref rid="bib47" ref-type="bibr">Kim et al., 2019</xref>). We have also tested our methodological choices with some other commonly used techniques. We compared the performance of the CPM predictive model with Elastic Net and found that Elastic Net performs better (as shown in <xref rid="appsec1" ref-type="sec">Fig. A30</xref>). We also compared Elastic Net with Random Forests on a subset of results, and found that Elastic Net performs better (as shown in <xref rid="appsec1" ref-type="sec">Fig. A.33</xref>).</p>
      <p id="p0445"><bold>Combined Results across all tasks and datasets</bold>: In this paper, we followed a step-wise approach and have presented our results systematically, starting from HCP and UKB datasets, and then testing on ABIDE and ACPI datasets. Lastly, we condensed the results across all four datasets (UKB, HCP, ABIDE and ACPI) and all tasks (non-imaging variables prediction), and have shown the consolidated results in <xref rid="fig11" ref-type="fig">Fig. 11</xref>. The relative prediction scores shown in <xref rid="fig11" ref-type="fig">Fig. 11</xref> are defined as the prediction score of each pipeline relative to the average across all pipelines. The recommendations which we have found on individual datasets are similar to our conclusions deduced from consolidated results: (1) the mean of relative prediction scores using sICA is 0.07, compared to YEO (0.04), SHEN (0.03) and PROFUMO (−0.03), (2) the mean of relative prediction scores using Tikhonov and SGGGM is 0.02, compared to covariance and Full correlation (0.0), and partial correlation (−0.02), (3) the mean of relative prediction scores using tangent space is 0.05, compared to ambient space (−0.02) and tangent_sharinkage space (−0.04), (4) the mean of relative prediction scores after deconfounding is −0.05, which is negative, but we believe the results without applying deconfounding are inflated due to the shared confounds, and lastly (5) the mean of prediction score using Elastic Net and 2D RCNN is 0.11 and 0.04 respectively, compared to BrainNetCNN (0.0), and GraphCNN (−0.16). To conclude, there is an approximately “optimal” pipeline (or set of recommendations) which performed reasonably well across all tasks whether analysed individually or in a consolidated fashion.</p>
      <p id="p0450"><bold>Dimensionality of Parcellation Revisited:</bold> Finally, it is important to consider the impact of the number of parcels across various parcellation methods, although it is hard to fully disentangle different choices of dimensionality from different parcellation methods. We have nevertheless attempted to draw recommendations by comparing YEO parcellation with varying the number of parcels (d ​= ​100, 200, 400) with sICA (d ​= ​15, 50, 200) as shown in <xref rid="fig11" ref-type="fig">Fig. 11</xref> (sub-figure D). We found that higher dimensional sICA (d ​= ​200) outperforms lower dimensional sICA (d ​= ​50), which is also illustrated in <xref rid="fig4" ref-type="fig">Fig. 4</xref>, and briefly discussed above the “best parcellation strategy” section. Moreover, lower dimensional sICA (d ​= ​50) outperforms both lower and higher dimensional YEO parcellation (d ​= ​100 or 400). Lastly, we found that prediction performance is not always improved by increasing the dimensionality of parcellation method, as better results were obtained by lower dimensional YEO (d ​= ​100) compared to higher dimensional YEO (d ​= ​200 or 400). This was also the main rationale behind showing lower dimensional YEO (d ​= ​100) results throughout the main text. It is also important to comment on the dimensionality of sICA for UKB data, as in theory higher ICA dimensionality might have been useful for UKB data, but we can not explore high dimensionality with ICA as the number of non-artefact (neuronal signal) components barely grows at all (more than the existing 55). As discussed above, we believe this is because of the limitations of volumetric analysis, possibly combined with the 6-min limited duration of the acquisition in UKB (as we do not face such limitations in case of HCP).</p>
      <p id="p0455"><bold>Comparison with Literature:</bold> Somewhat similar evaluations of various methods (in this problem domain) have previously been carried out in (<xref rid="bib63" ref-type="bibr">Ng et al., 2015b</xref>; <xref rid="bib22" ref-type="bibr">Dadi et al., 2019</xref>). In (<xref rid="bib63" ref-type="bibr">Ng et al., 2015b</xref>), authors proposed that matrix whitening transform and parallel transport could be utilized to project covariance matrices into a common tangent space and evaluated this method on twenty four healthy subjects. These former results build a foundation for estimation of functional connectivity using manifold operations, as higher prediction accuracy was achieved using tangent space parameterization.</p>
      <p id="p0460">(<xref rid="bib22" ref-type="bibr">Dadi et al., 2019</xref>) evaluated different modelling choices and recommended a three stage pipeline: (i) ICA or MODL for brain parcellation, (ii) tangent space embedding for functional connectivity estimation and (iii) use of non-sparse models like SVM for non-imaging variables prediction. For brain parcellation (<xref rid="bib22" ref-type="bibr">Dadi et al., 2019</xref>), applied a number of parcellation techniques that differed from our pipeline, however also found that sICA yielded the best performance (alongside with MODL). In terms of step-1 (brain parcellation), we compared sICA with MODL, and found that the performance of these is similar (although sICA outperforms for age prediction, as shown in <xref rid="appsec1" ref-type="sec">Fig. A.32</xref>). We have not included MODL in main analysis as it is already thoroughly evaluated in (<xref rid="bib22" ref-type="bibr">Dadi et al., 2019</xref>) (and it remains a valuable tool for brain parcellation).</p>
      <p id="p0465">Lastly, we have applied deep learning architecture such as CNNs to analyze functional connectivity whereas (<xref rid="bib22" ref-type="bibr">Dadi et al., 2019</xref>) utilized traditional machine learning algorithms. Similarly to the last step of our pipeline (<xref rid="bib38" ref-type="bibr">He et al., 2018b</xref>), compared the performance of three CNNs to kernel regression. The three CNNs tested included a generic fully-connected feedforward network, BrainNetCNN and Graph CNN. This study reported that CNNs did not outperform kernel regression across a wide range of behavioral and demographic measures. However, our results found that our proposed 2D RCNN (architecture illustrated in <xref rid="appsec1" ref-type="sec">Fig. A12</xref>), which has not been previously evaluated against these methods, outperforms the regularized regression and existing CNNs for some tasks (e.g., <xref rid="appsec1" ref-type="sec">Fig. A25</xref>).</p>
    </sec>
    <sec id="sec6">
      <label>6</label>
      <title>Conclusion</title>
      <p id="p0470">Our results have demonstrated that within data driven parcellation, ICA provides the most predictive power for non-imaging variables. For estimating functional connectivity, we have shown that regularized partial correlation like SGGGM or Tikhonov outperforms unregularised partial correlation or full correlation. To correctly apply mathematical formulations on functional connectivity estimates, it is recommended to take into account that these measures should ideally be worked with within the Riemannian manifold. To do so, Riemannian space is approximated with an associated tangent space and then functional connectivity estimates are mapped to the tangent space. We have reported in this paper that this tangent space parameterization results in a significant increase in predictive power of functional connectivity estimates, as previously shown in (<xref rid="bib63" ref-type="bibr">Ng et al., 2015b</xref>; <xref rid="bib22" ref-type="bibr">Dadi et al., 2019</xref>). Our results have also demonstrated that additional shrinkage is not necessarily required on well regularized connectivity estimates in tangent space; however, could be applied for noiser data. Lastly, we evaluated various classifiers for prediction of non-imaging variables from connectivity estimates and concluded that a carefully designed deep learning based architecture (2D RCNN) can be a valuable tool for analyzing functional connectivity. However, Elastic Net probably performs better at present overall.</p>
    </sec>
    <sec id="sec8">
      <title>CRediT authorship contribution statement</title>
      <p id="p0480"><bold>Usama Pervaiz:</bold> Data curation, Conceptualization, Methodology, Writing - original draft, Validation, Visualization. <bold>Diego Vidaurre:</bold> Methodology, Writing - review &amp; editing, Validation, Supervision. <bold>Mark W. Woolrich:</bold> Conceptualization, Writing - review &amp; editing, Validation, Supervision. <bold>Stephen M. Smith:</bold> Data curation, Conceptualization, Methodology, Writing - review &amp; editing, Validation, Supervision.</p>
    </sec>
    <sec sec-type="COI-statement">
      <title>Declaration of competing interest</title>
      <p id="p0520">None.</p>
    </sec>
  </body>
  <back>
    <ref-list id="cebib0010">
      <title>References</title>
      <ref id="bib1">
        <element-citation publication-type="journal" id="sref1">
          <person-group person-group-type="author">
            <name>
              <surname>Abbott</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>A problem for our age</article-title>
          <source>Nature</source>
          <volume>475</volume>
          <issue>7355</issue>
          <year>2011 Jul 14</year>
          <fpage>S2</fpage>
          <pub-id pub-id-type="pmid">21760579</pub-id>
        </element-citation>
      </ref>
      <ref id="bib2">
        <element-citation publication-type="journal" id="sref2">
          <person-group person-group-type="author">
            <name>
              <surname>Abraham</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Di Martino</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Craddock</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Samaras</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Deriving reproducible biomarkers from multi-site resting-state data: an Autism-based example</article-title>
          <source>Neuroimage</source>
          <volume>147</volume>
          <year>2017 Feb 15</year>
          <fpage>736</fpage>
          <lpage>745</lpage>
          <pub-id pub-id-type="pmid">27865923</pub-id>
        </element-citation>
      </ref>
      <ref id="bib3">
        <element-citation publication-type="journal" id="sref3">
          <person-group person-group-type="author">
            <name>
              <surname>Allen</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Damaraju</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Plis</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Erhardt</surname>
              <given-names>E.B.</given-names>
            </name>
            <name>
              <surname>Eichele</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>V.D.</given-names>
            </name>
          </person-group>
          <article-title>Tracking whole-brain connectivity dynamics in the resting state</article-title>
          <source>Cerebr. Cortex</source>
          <volume>24</volume>
          <issue>3</issue>
          <year>2014 Mar 1</year>
          <fpage>663</fpage>
          <lpage>676</lpage>
        </element-citation>
      </ref>
      <ref id="bib4">
        <element-citation publication-type="journal" id="sref4">
          <person-group person-group-type="author">
            <name>
              <surname>Anand</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Bukhari</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Mathews</surname>
              <given-names>V.P.</given-names>
            </name>
            <name>
              <surname>Kalnin</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lowe</surname>
              <given-names>M.J.</given-names>
            </name>
          </person-group>
          <article-title>Activity and connectivity of brain mood regulating circuit in depression: a functional magnetic resonance study</article-title>
          <source>Biol. Psychiatr.</source>
          <volume>57</volume>
          <issue>10</issue>
          <year>2005 May 15</year>
          <fpage>1079</fpage>
          <lpage>1088</lpage>
        </element-citation>
      </ref>
      <ref id="bib5">
        <element-citation publication-type="journal" id="sref5">
          <person-group person-group-type="author">
            <name>
              <surname>Banks</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Eddy</surname>
              <given-names>K.T.</given-names>
            </name>
            <name>
              <surname>Angstadt</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Nathan</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Phan</surname>
              <given-names>K.L.</given-names>
            </name>
          </person-group>
          <article-title>Amygdala–frontal connectivity during emotion regulation</article-title>
          <source>Soc. Cognit. Affect Neurosci.</source>
          <volume>2</volume>
          <issue>4</issue>
          <year>2007 Dec 1</year>
          <fpage>303</fpage>
          <lpage>312</lpage>
          <pub-id pub-id-type="pmid">18985136</pub-id>
        </element-citation>
      </ref>
      <ref id="bib6">
        <element-citation publication-type="journal" id="sref6">
          <person-group person-group-type="author">
            <name>
              <surname>Barachant</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bonnet</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Congedo</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jutten</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Multiclass brain–computer interface classification by Riemannian geometry</article-title>
          <source>IEEE (Inst. Electr. Electron. Eng.) Trans. Biomed. Eng.</source>
          <volume>59</volume>
          <issue>4</issue>
          <year>2011 Oct 14</year>
          <fpage>920</fpage>
          <lpage>928</lpage>
        </element-citation>
      </ref>
      <ref id="bib7">
        <element-citation publication-type="journal" id="sref7">
          <person-group person-group-type="author">
            <name>
              <surname>Barachant</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bonnet</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Congedo</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jutten</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Classification of covariance matrices using a Riemannian-based kernel for BCI applications</article-title>
          <source>Neurocomputing</source>
          <volume>112</volume>
          <year>2013 Jul 18</year>
          <fpage>172</fpage>
          <lpage>178</lpage>
        </element-citation>
      </ref>
      <ref id="bib8">
        <element-citation publication-type="journal" id="sref8">
          <person-group person-group-type="author">
            <name>
              <surname>Barachant</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bonnet</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Congedo</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jutten</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Classification of covariance matrices using a Riemannian-based kernel for BCI applications</article-title>
          <source>Neurocomputing</source>
          <volume>112</volume>
          <year>2013 Jul 18</year>
          <fpage>172</fpage>
          <lpage>178./</lpage>
        </element-citation>
      </ref>
      <ref id="bib9">
        <element-citation publication-type="journal" id="sref9">
          <person-group person-group-type="author">
            <name>
              <surname>Bastos</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Schoffelen</surname>
              <given-names>J.M.</given-names>
            </name>
          </person-group>
          <article-title>A tutorial review of functional connectivity analysis methods and their interpretational pitfalls</article-title>
          <source>Front. Syst. Neurosci.</source>
          <volume>9</volume>
          <year>2016 Jan 8</year>
          <fpage>175</fpage>
          <pub-id pub-id-type="pmid">26778976</pub-id>
        </element-citation>
      </ref>
      <ref id="bib10">
        <element-citation publication-type="journal" id="sref10">
          <person-group person-group-type="author">
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Probabilistic independent component analysis for functional magnetic resonance imaging</article-title>
          <source>IEEE Trans. Med. Imag.</source>
          <volume>23</volume>
          <issue>2</issue>
          <year>2004 Feb</year>
          <fpage>137</fpage>
          <lpage>152</lpage>
        </element-citation>
      </ref>
      <ref id="bib11">
        <element-citation publication-type="journal" id="sref11">
          <person-group person-group-type="author">
            <name>
              <surname>Bender</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Calculating confidence intervals for the number needed to treat</article-title>
          <source>Contr. Clin. Trials</source>
          <volume>22</volume>
          <issue>2</issue>
          <year>2001 Feb 1</year>
          <fpage>102</fpage>
          <lpage>110</lpage>
        </element-citation>
      </ref>
      <ref id="bib12">
        <element-citation publication-type="journal" id="sref12">
          <person-group person-group-type="author">
            <name>
              <surname>Bijsterbosch</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Glasser</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>E.C.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>The relationship between spatial configuration and functional connectivity of brain regions</article-title>
          <source>eLife</source>
          <volume>7</volume>
          <year>2018 Feb 16</year>
          <object-id pub-id-type="publisher-id">e32992</object-id>
        </element-citation>
      </ref>
      <ref id="bib13">
        <element-citation publication-type="journal" id="sref13">
          <person-group person-group-type="author">
            <name>
              <surname>Bijsterbosch</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>S.J.</given-names>
            </name>
          </person-group>
          <article-title>The relationship between spatial configuration and functional connectivity of brain regions revisited</article-title>
          <source>eLife</source>
          <volume>8</volume>
          <year>2019 May 8</year>
          <object-id pub-id-type="publisher-id">e44890</object-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <element-citation publication-type="journal" id="sref14">
          <person-group person-group-type="author">
            <name>
              <surname>Boyd</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Parikh</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Chu</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Peleato</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Eckstein</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Distributed optimization and statistical learning via the alternating direction method of multipliers</article-title>
          <source>Found. Trends Mach. Learn.</source>
          <volume>3</volume>
          <issue>1</issue>
          <year>2011 Jul 26</year>
          <fpage>1</fpage>
          <lpage>22</lpage>
        </element-citation>
      </ref>
      <ref id="bib15">
        <element-citation publication-type="journal" id="sref15">
          <person-group person-group-type="author">
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>Krienen</surname>
              <given-names>F.M.</given-names>
            </name>
            <name>
              <surname>Yeo</surname>
              <given-names>B.T.</given-names>
            </name>
          </person-group>
          <article-title>Opportunities and limitations of intrinsic functional connectivity MRI</article-title>
          <source>Nat. Neurosci.</source>
          <volume>16</volume>
          <issue>7</issue>
          <year>2013 Jul</year>
          <fpage>832</fpage>
          <pub-id pub-id-type="pmid">23799476</pub-id>
        </element-citation>
      </ref>
      <ref id="bib16">
        <element-citation publication-type="journal" id="sref16">
          <person-group person-group-type="author">
            <name>
              <surname>Bzdok</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Grisel</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Eickenberg</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Poupon</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Formal models of the network co-occurrence underlying mental operations</article-title>
          <source>PLoS Comput. Biol.</source>
          <volume>12</volume>
          <issue>6</issue>
          <year>2016 Jun 16</year>
          <object-id pub-id-type="publisher-id">e1004994</object-id>
        </element-citation>
      </ref>
      <ref id="bib17">
        <element-citation publication-type="journal" id="sref17">
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wiesel</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Eldar</surname>
              <given-names>Y.C.</given-names>
            </name>
            <name>
              <surname>Hero</surname>
              <given-names>A.O.</given-names>
            </name>
          </person-group>
          <article-title>Shrinkage algorithms for MMSE covariance estimation</article-title>
          <source>IEEE Trans. Signal Process.</source>
          <volume>58</volume>
          <issue>10</issue>
          <year>2010 Oct</year>
          <fpage>5016</fpage>
          <lpage>5029</lpage>
        </element-citation>
      </ref>
      <ref id="bib19">
        <element-citation publication-type="journal" id="sref19">
          <person-group person-group-type="author">
            <name>
              <surname>Colclough</surname>
              <given-names>G.L.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Harrison</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Rojas Lpez</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Valdes-Sosa</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Multi-subject hierarchical inverse covariance modelling improves estimation of functional brain networks</article-title>
          <source>Neuroimage</source>
          <volume>178</volume>
          <year>2018 Sep</year>
          <fpage>370</fpage>
          <lpage>384</lpage>
          <pub-id pub-id-type="pmid">29746906</pub-id>
        </element-citation>
      </ref>
      <ref id="bib20">
        <element-citation publication-type="journal" id="sref20">
          <person-group person-group-type="author">
            <name>
              <surname>Cole</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Poudel</surname>
              <given-names>R.P.</given-names>
            </name>
            <name>
              <surname>Tsagkrasoulis</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Caan</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Steves</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Spector</surname>
              <given-names>T.D.</given-names>
            </name>
            <name>
              <surname>Montana</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker</article-title>
          <source>Neuroimage</source>
          <volume>163</volume>
          <year>2017 Dec 1</year>
          <fpage>115</fpage>
          <lpage>124</lpage>
          <pub-id pub-id-type="pmid">28765056</pub-id>
        </element-citation>
      </ref>
      <ref id="bib21">
        <element-citation publication-type="journal" id="sref21">
          <person-group person-group-type="author">
            <name>
              <surname>Craddock</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Sikka</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Cheung</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Khanuja</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Ghosh</surname>
              <given-names>S.S.</given-names>
            </name>
            <name>
              <surname>Yan</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Lurie</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Vogelstein</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Burns</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Colcombe</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Towards automated analysis of connectomes: the configurable pipeline for the analysis of connectomes (c-pac)</article-title>
          <source>Front. Neuroinf.</source>
          <year>2013 Jul</year>
          <fpage>42</fpage>
        </element-citation>
      </ref>
      <ref id="bib22">
        <element-citation publication-type="journal" id="sref22">
          <person-group person-group-type="author">
            <name>
              <surname>Dadi</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Rahim</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Abraham</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Chyzhyk</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Alzheimer’s Disease Neuroimaging Initiative</surname>
            </name>
          </person-group>
          <article-title>Benchmarking functional connectome-based predictive models for resting-state fMRI</article-title>
          <source>Neuroimage</source>
          <volume>192</volume>
          <year>2019 May 15</year>
          <fpage>115</fpage>
          <lpage>134</lpage>
          <pub-id pub-id-type="pmid">30836146</pub-id>
        </element-citation>
      </ref>
      <ref id="bib23">
        <element-citation publication-type="journal" id="sref23">
          <person-group person-group-type="author">
            <name>
              <surname>Defferrard</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bresson</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Vandergheynst</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Convolutional neural networks on graphs with fast localized spectral filtering</article-title>
          <source>Adv. Neural. Inf. Process. Syst.</source>
          <year>2016</year>
          <fpage>3844</fpage>
          <lpage>3852</lpage>
        </element-citation>
      </ref>
      <ref id="bib24">
        <element-citation publication-type="journal" id="sref24">
          <person-group person-group-type="author">
            <name>
              <surname>Desikan</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Ségonne</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Fischl</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Quinn</surname>
              <given-names>B.T.</given-names>
            </name>
            <name>
              <surname>Dickerson</surname>
              <given-names>B.C.</given-names>
            </name>
            <name>
              <surname>Blacker</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
            <name>
              <surname>Dale</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Maguire</surname>
              <given-names>R.P.</given-names>
            </name>
            <name>
              <surname>Hyman</surname>
              <given-names>B.T.</given-names>
            </name>
            <name>
              <surname>Albert</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>
          <source>Neuroimage</source>
          <volume>31</volume>
          <issue>3</issue>
          <year>2006 Jul 1</year>
          <fpage>968</fpage>
          <lpage>980</lpage>
          <pub-id pub-id-type="pmid">16530430</pub-id>
        </element-citation>
      </ref>
      <ref id="bib25">
        <element-citation publication-type="journal" id="sref25">
          <person-group person-group-type="author">
            <name>
              <surname>Eickhoff</surname>
              <given-names>S.B.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Bzdok</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Connectivity based parcellation: critique and implications</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>36</volume>
          <issue>12</issue>
          <year>2015 Dec</year>
          <fpage>4771</fpage>
          <lpage>4792</lpage>
          <pub-id pub-id-type="pmid">26409749</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <element-citation publication-type="journal" id="sref26">
          <person-group person-group-type="author">
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Barch</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Yacoub</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ugurbil</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>HCP Consortium</surname>
              <given-names>Wu-Minn</given-names>
            </name>
          </person-group>
          <article-title>The Wu-Minn human connectome project: an overview</article-title>
          <source>Neuroimage</source>
          <volume>80</volume>
          <year>2013 Oct 15</year>
          <fpage>62</fpage>
          <lpage>79</lpage>
          <pub-id pub-id-type="pmid">23684880</pub-id>
        </element-citation>
      </ref>
      <ref id="bib27">
        <element-citation publication-type="journal" id="sref27">
          <person-group person-group-type="author">
            <name>
              <surname>Finn</surname>
              <given-names>E.S.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Scheinost</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Rosenberg</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Chun</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Papademetris</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Constable</surname>
              <given-names>R.T.</given-names>
            </name>
          </person-group>
          <article-title>Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity</article-title>
          <source>Nat. Neurosci.</source>
          <volume>18</volume>
          <issue>11</issue>
          <year>2015 Nov</year>
          <fpage>1664</fpage>
          <pub-id pub-id-type="pmid">26457551</pub-id>
        </element-citation>
      </ref>
      <ref id="bib28">
        <element-citation publication-type="journal" id="sref28">
          <person-group person-group-type="author">
            <name>
              <surname>Fischl</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Van Der Kouwe</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Destrieux</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Halgren</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ségonne</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Salat</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Busa</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Seidman</surname>
              <given-names>L.J.</given-names>
            </name>
            <name>
              <surname>Goldstein</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Kennedy</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Caviness</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Automatically parcellating the human cerebral cortex</article-title>
          <source>Cerebr. Cortex</source>
          <volume>14</volume>
          <issue>1</issue>
          <year>2004 Jan 1</year>
          <fpage>11</fpage>
          <lpage>22</lpage>
        </element-citation>
      </ref>
      <ref id="bib29">
        <element-citation publication-type="journal" id="sref29">
          <person-group person-group-type="author">
            <name>
              <surname>Fox</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Snyder</surname>
              <given-names>A.Z.</given-names>
            </name>
            <name>
              <surname>Vincent</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Corbetta</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Raichle</surname>
              <given-names>M.E.</given-names>
            </name>
          </person-group>
          <article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks</article-title>
          <source>Proc. Natl. Acad. Sci. Unit. States Am.</source>
          <volume>102</volume>
          <issue>27</issue>
          <year>2005 Jul 5</year>
          <fpage>9673</fpage>
          <lpage>9678</lpage>
        </element-citation>
      </ref>
      <ref id="bib30">
        <element-citation publication-type="journal" id="sref30">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.J.</given-names>
            </name>
          </person-group>
          <article-title>Functional and effective connectivity: a review</article-title>
          <source>Brain Connect.</source>
          <volume>1</volume>
          <issue>1</issue>
          <year>2011</year>
          <fpage>13</fpage>
          <lpage>36</lpage>
          <pub-id pub-id-type="pmid">22432952</pub-id>
        </element-citation>
      </ref>
      <ref id="bib31">
        <element-citation publication-type="journal" id="sref31">
          <person-group person-group-type="author">
            <name>
              <surname>Golub</surname>
              <given-names>G.H.</given-names>
            </name>
            <name>
              <surname>Hansen</surname>
              <given-names>P.C.</given-names>
            </name>
            <name>
              <surname>O’Leary</surname>
              <given-names>D.P.</given-names>
            </name>
          </person-group>
          <article-title>Tikhonov regularization and total least squares</article-title>
          <source>SIAM J. Matrix Anal. Appl.</source>
          <volume>21</volume>
          <issue>1</issue>
          <year>1999</year>
          <fpage>185</fpage>
          <lpage>194</lpage>
        </element-citation>
      </ref>
      <ref id="bib32">
        <element-citation publication-type="journal" id="sref32">
          <person-group person-group-type="author">
            <name>
              <surname>Greicius</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Srivastava</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Reiss</surname>
              <given-names>A.L.</given-names>
            </name>
            <name>
              <surname>Menon</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Default-mode network activity distinguishes Alzheimer’s disease from healthy aging: evidence from functional MRI</article-title>
          <source>Proc. Natl. Acad. Sci. Unit. States Am.</source>
          <volume>101</volume>
          <issue>13</issue>
          <year>2004 Mar 30</year>
          <fpage>4637</fpage>
          <lpage>4642</lpage>
        </element-citation>
      </ref>
      <ref id="bib33">
        <element-citation publication-type="journal" id="sref33">
          <person-group person-group-type="author">
            <name>
              <surname>Hacker</surname>
              <given-names>C.D.</given-names>
            </name>
            <name>
              <surname>Perlmutter</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Criswell</surname>
              <given-names>S.R.</given-names>
            </name>
            <name>
              <surname>Ances</surname>
              <given-names>B.M.</given-names>
            </name>
            <name>
              <surname>Snyder</surname>
              <given-names>A.Z.</given-names>
            </name>
          </person-group>
          <article-title>Resting state functional connectivity of the striatum in Parkinson’s disease</article-title>
          <source>Brain</source>
          <volume>135</volume>
          <issue>12</issue>
          <year>2012 Nov 28</year>
          <fpage>3699</fpage>
          <lpage>3711</lpage>
          <pub-id pub-id-type="pmid">23195207</pub-id>
        </element-citation>
      </ref>
      <ref id="bib34">
        <element-citation publication-type="journal" id="sref34">
          <person-group person-group-type="author">
            <name>
              <surname>Hahn</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Stein</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Windischberger</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Weissenbacher</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Spindelegger</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Moser</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Kasper</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Lanzenberger</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Reduced resting-state functional connectivity between amygdala and orbitofrontal cortex in social anxiety disorder</article-title>
          <source>Neuroimage</source>
          <volume>56</volume>
          <issue>3</issue>
          <year>2011 Jun 1</year>
          <fpage>881</fpage>
          <lpage>889</lpage>
          <pub-id pub-id-type="pmid">21356318</pub-id>
        </element-citation>
      </ref>
      <ref id="bib35">
        <element-citation publication-type="journal" id="sref35">
          <person-group person-group-type="author">
            <name>
              <surname>Harrison</surname>
              <given-names>S.J.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>E.C.</given-names>
            </name>
            <name>
              <surname>Glasser</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Jenkinson</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Large-scale probabilistic functional modes from resting state fMRI</article-title>
          <source>Neuroimage</source>
          <volume>109</volume>
          <year>2015 Apr 1</year>
          <fpage>217</fpage>
          <lpage>231</lpage>
          <pub-id pub-id-type="pmid">25598050</pub-id>
        </element-citation>
      </ref>
      <ref id="bib36">
        <element-citation publication-type="journal" id="sref36">
          <person-group person-group-type="author">
            <name>
              <surname>He</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Snyder</surname>
              <given-names>A.Z.</given-names>
            </name>
            <name>
              <surname>Vincent</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Epstein</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Shulman</surname>
              <given-names>G.L.</given-names>
            </name>
            <name>
              <surname>Corbetta</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Breakdown of functional connectivity in frontoparietal networks underlies behavioral deficits in spatial neglect</article-title>
          <source>Neuron</source>
          <volume>53</volume>
          <issue>6</issue>
          <year>2007 Mar 15</year>
          <fpage>905</fpage>
          <lpage>918</lpage>
          <pub-id pub-id-type="pmid">17359924</pub-id>
        </element-citation>
      </ref>
      <ref id="bib37">
        <element-citation publication-type="journal" id="sref37">
          <person-group person-group-type="author">
            <name>
              <surname>He</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Kong</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nguyen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sabuncu</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Eickhoff</surname>
              <given-names>S.B.</given-names>
            </name>
            <name>
              <surname>Bzdok</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Feng</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yeo</surname>
              <given-names>B.T.</given-names>
            </name>
          </person-group>
          <article-title>Do deep neural networks outperform kernel regression for functional connectivity prediction of behavior?</article-title>
          <source>BioRxiv</source>
          <year>2018 Jan 1</year>
          <fpage>473603</fpage>
        </element-citation>
      </ref>
      <ref id="bib38">
        <element-citation publication-type="journal" id="sref38">
          <person-group person-group-type="author">
            <name>
              <surname>He</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Kong</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nguyen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sabuncu</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Eickhoff</surname>
              <given-names>S.B.</given-names>
            </name>
            <name>
              <surname>Bzdok</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Feng</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yeo</surname>
              <given-names>B.T.</given-names>
            </name>
          </person-group>
          <article-title>Do deep neural networks outperform kernel regression for functional connectivity prediction of behavior?</article-title>
          <source>BioRxiv</source>
          <year>2018 Jan 1</year>
          <fpage>473603</fpage>
        </element-citation>
      </ref>
      <ref id="bib39">
        <element-citation publication-type="journal" id="sref39">
          <person-group person-group-type="author">
            <name>
              <surname>Honnorat</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Eavani</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Satterthwaite</surname>
              <given-names>T.D.</given-names>
            </name>
            <name>
              <surname>Gur</surname>
              <given-names>R.E.</given-names>
            </name>
            <name>
              <surname>Gur</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Davatzikos</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>GraSP: geodesic graph-based segmentation with shape priors for the functional parcellation of the cortex</article-title>
          <source>Neuroimage</source>
          <volume>106</volume>
          <year>2015 Feb 1</year>
          <fpage>207</fpage>
          <lpage>221</lpage>
          <pub-id pub-id-type="pmid">25462796</pub-id>
        </element-citation>
      </ref>
      <ref id="bib41">
        <element-citation publication-type="other" id="sref41">
          <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/544817v1" id="intref0020">https://www.biorxiv.org/content/10.1101/544817v1</ext-link>
        </element-citation>
      </ref>
      <ref id="bib42">
        <element-citation publication-type="journal" id="sref42">
          <person-group person-group-type="author">
            <name>
              <surname>Hutchison</surname>
              <given-names>R.M.</given-names>
            </name>
            <name>
              <surname>Womelsdorf</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Allen</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Bandettini</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>V.D.</given-names>
            </name>
            <name>
              <surname>Corbetta</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Della Penna</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Duyn</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Glover</surname>
              <given-names>G.H.</given-names>
            </name>
            <name>
              <surname>Gonzalez-Castillo</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Handwerker</surname>
              <given-names>D.A.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic functional connectivity: promise, issues, and interpretations</article-title>
          <source>Neuroimage</source>
          <volume>80</volume>
          <year>2013 Oct 15</year>
          <fpage>360</fpage>
          <lpage>378</lpage>
          <pub-id pub-id-type="pmid">23707587</pub-id>
        </element-citation>
      </ref>
      <ref id="bib43">
        <element-citation publication-type="journal" id="sref43">
          <person-group person-group-type="author">
            <name>
              <surname>Jaeggi</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Buschkuehl</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Jonides</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Perrig</surname>
              <given-names>W.J.</given-names>
            </name>
          </person-group>
          <article-title>Improving fluid intelligence with training on working memory</article-title>
          <source>Proc. Natl. Acad. Sci. Unit. States Am.</source>
          <volume>105</volume>
          <issue>19</issue>
          <year>2008 May 13</year>
          <fpage>6829</fpage>
          <lpage>6833</lpage>
        </element-citation>
      </ref>
      <ref id="bib44">
        <element-citation publication-type="journal" id="sref44">
          <person-group person-group-type="author">
            <name>
              <surname>Jonas</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Kording</surname>
              <given-names>K.P.</given-names>
            </name>
          </person-group>
          <article-title>Could a neuroscientist understand a microprocessor?</article-title>
          <source>PLoS Comput. Biol.</source>
          <volume>13</volume>
          <issue>1</issue>
          <year>2017 Jan</year>
        </element-citation>
      </ref>
      <ref id="bib45">
        <element-citation publication-type="journal" id="sref45">
          <person-group person-group-type="author">
            <name>
              <surname>Kawahara</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>C.J.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>S.P.</given-names>
            </name>
            <name>
              <surname>Booth</surname>
              <given-names>B.G.</given-names>
            </name>
            <name>
              <surname>Chau</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Grunau</surname>
              <given-names>R.E.</given-names>
            </name>
            <name>
              <surname>Zwicker</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Hamarneh</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>BrainNetCNN: convolutional neural networks for brain networks; towards predicting neurodevelopment</article-title>
          <source>Neuroimage</source>
          <volume>146</volume>
          <year>2017 Feb 1</year>
          <fpage>1038</fpage>
          <lpage>1049</lpage>
          <pub-id pub-id-type="pmid">27693612</pub-id>
        </element-citation>
      </ref>
      <ref id="bib46">
        <element-citation publication-type="journal" id="sref46">
          <person-group person-group-type="author">
            <name>
              <surname>Kelly</surname>
              <given-names>A.C.</given-names>
            </name>
            <name>
              <surname>Uddin</surname>
              <given-names>L.Q.</given-names>
            </name>
            <name>
              <surname>Biswal</surname>
              <given-names>B.B.</given-names>
            </name>
            <name>
              <surname>Castellanos</surname>
              <given-names>F.X.</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>M.P.</given-names>
            </name>
          </person-group>
          <article-title>Competition between functional brain networks mediates behavioral variability</article-title>
          <source>Neuroimage</source>
          <volume>39</volume>
          <issue>1</issue>
          <year>2008 Jan 1</year>
          <fpage>527</fpage>
          <lpage>537</lpage>
          <pub-id pub-id-type="pmid">17919929</pub-id>
        </element-citation>
      </ref>
      <ref id="bib47">
        <element-citation publication-type="journal" id="sref47">
          <person-group person-group-type="author">
            <name>
              <surname>Kim</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Picek</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Heuser</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Bhasin</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Hanjalic</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Make some noise. Unleashing the power of convolutional neural networks for profiled side-channel analysis</article-title>
          <source>IACR Transactions on Cryptogr. Hardw. Embedded Syst.</source>
          <year>2019 May 9</year>
          <fpage>148</fpage>
          <lpage>179</lpage>
        </element-citation>
      </ref>
      <ref id="bib48">
        <element-citation publication-type="book" id="sref48">
          <person-group person-group-type="author">
            <name>
              <surname>Krishnamoorthy</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Menon</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Matrix inversion using Cholesky decomposition</chapter-title>
          <source>In2013 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)</source>
          <year>2013 Sep 26</year>
          <fpage>70</fpage>
          <lpage>72</lpage>
          <comment>(IEEE)</comment>
        </element-citation>
      </ref>
      <ref id="bib49">
        <element-citation publication-type="journal" id="sref49">
          <person-group person-group-type="author">
            <name>
              <surname>Ledoit</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Wolf</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A well-conditioned estimator for large-dimensional covariance matrices</article-title>
          <source>J. Multivariate Anal.</source>
          <volume>88</volume>
          <issue>2</issue>
          <year>2004 Feb 1</year>
          <fpage>365</fpage>
          <lpage>411</lpage>
        </element-citation>
      </ref>
      <ref id="bib50">
        <element-citation publication-type="book" id="sref50">
          <person-group person-group-type="author">
            <name>
              <surname>Liang</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>X.</given-names>
            </name>
          </person-group>
          <chapter-title>Recurrent convolutional neural network for object recognition</chapter-title>
          <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>
          <year>2015</year>
          <fpage>3367</fpage>
          <lpage>3375</lpage>
        </element-citation>
      </ref>
      <ref id="bib51">
        <element-citation publication-type="journal" id="sref51">
          <person-group person-group-type="author">
            <name>
              <surname>Liaw</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Wiener</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Classification and regression by randomForest</article-title>
          <source>R. News</source>
          <volume>2</volume>
          <issue>3</issue>
          <year>2002 Dec 3</year>
          <fpage>18</fpage>
          <lpage>22</lpage>
        </element-citation>
      </ref>
      <ref id="bib52">
        <element-citation publication-type="journal" id="sref52">
          <person-group person-group-type="author">
            <name>
              <surname>De Luca</surname>
              <given-names>M.B.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>De Stefano</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Matthews</surname>
              <given-names>P.M.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>fMRI resting state networks define distinct modes of long-distance interactions in the human brain</article-title>
          <source>Neuroimage</source>
          <volume>29</volume>
          <issue>4</issue>
          <year>2006 Feb 15</year>
          <fpage>1359</fpage>
          <lpage>1367</lpage>
          <pub-id pub-id-type="pmid">16260155</pub-id>
        </element-citation>
      </ref>
      <ref id="bib53">
        <element-citation publication-type="journal" id="sref53">
          <person-group person-group-type="author">
            <name>
              <surname>Lynall</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Bassett</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Kerwin</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>McKenna</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Kitzbichler</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Muller</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Functional connectivity and brain networks in schizophrenia</article-title>
          <source>J. Neurosci.</source>
          <volume>30</volume>
          <issue>28</issue>
          <year>2010 Jul 14</year>
          <fpage>9477</fpage>
          <lpage>9487</lpage>
          <pub-id pub-id-type="pmid">20631176</pub-id>
        </element-citation>
      </ref>
      <ref id="bib54">
        <element-citation publication-type="journal" id="sref54">
          <person-group person-group-type="author">
            <name>
              <surname>Di Martino</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Yan</surname>
              <given-names>C.G.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Denio</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Castellanos</surname>
              <given-names>F.X.</given-names>
            </name>
            <name>
              <surname>Alaerts</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Anderson</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Assaf</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Bookheimer</surname>
              <given-names>S.Y.</given-names>
            </name>
            <name>
              <surname>Dapretto</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Deen</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>
          <source>Mol. Psychiatr.</source>
          <volume>19</volume>
          <issue>6</issue>
          <year>2014 Jun</year>
          <fpage>659</fpage>
        </element-citation>
      </ref>
      <ref id="bib55">
        <element-citation publication-type="journal" id="sref55">
          <person-group person-group-type="author">
            <name>
              <surname>Mensch</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Mairal</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Stochastic subsampling for factorizing huge matrices</article-title>
          <source>IEEE Trans. Signal Process.</source>
          <volume>66</volume>
          <issue>1</issue>
          <year>2017 Sep 14</year>
          <fpage>113</fpage>
          <lpage>128</lpage>
        </element-citation>
      </ref>
      <ref id="bib56">
        <element-citation publication-type="journal" id="sref56">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Alfaro-Almagro</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Bangerter</surname>
              <given-names>N.K.</given-names>
            </name>
            <name>
              <surname>Thomas</surname>
              <given-names>D.L.</given-names>
            </name>
            <name>
              <surname>Yacoub</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Bartsch</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Jbabdi</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Sotiropoulos</surname>
              <given-names>S.N.</given-names>
            </name>
            <name>
              <surname>Andersson</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Griffanti</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Multimodal population brain imaging in the UK Biobank prospective epidemiological study</article-title>
          <source>Nat. Neurosci.</source>
          <volume>19</volume>
          <issue>11</issue>
          <year>2016 Nov</year>
          <fpage>1523</fpage>
          <pub-id pub-id-type="pmid">27643430</pub-id>
        </element-citation>
      </ref>
      <ref id="bib57">
        <element-citation publication-type="journal" id="sref57">
          <person-group person-group-type="author">
            <name>
              <surname>Moakher</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A differential geometric approach to the geometric mean of symmetric positive-definite matrices</article-title>
          <source>SIAM J. Matrix Anal. Appl.</source>
          <volume>26</volume>
          <issue>3</issue>
          <year>2005</year>
          <fpage>735</fpage>
          <lpage>747</lpage>
        </element-citation>
      </ref>
      <ref id="bib58">
        <element-citation publication-type="book" id="sref58">
          <person-group person-group-type="author">
            <name>
              <surname>Murphy</surname>
              <given-names>K.P.</given-names>
            </name>
          </person-group>
          <chapter-title>Machine Learning: a Probabilistic Perspective</chapter-title>
          <year>2012 Sep 7</year>
          <publisher-name>MIT press</publisher-name>
        </element-citation>
      </ref>
      <ref id="bib59">
        <element-citation publication-type="journal" id="sref59">
          <person-group person-group-type="author">
            <name>
              <surname>Nair</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Treiber</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Shukla</surname>
              <given-names>D.K.</given-names>
            </name>
            <name>
              <surname>Shih</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Müller</surname>
              <given-names>R.A.</given-names>
            </name>
          </person-group>
          <article-title>Impaired thalamocortical connectivity in autism spectrum disorder: a study of functional and anatomical connectivity</article-title>
          <source>Brain</source>
          <volume>136</volume>
          <issue>6</issue>
          <year>2013 Jun 1</year>
          <fpage>1942</fpage>
          <lpage>1955</lpage>
          <pub-id pub-id-type="pmid">23739917</pub-id>
        </element-citation>
      </ref>
      <ref id="bib60">
        <element-citation publication-type="other" id="sref60">
          <article-title>Neuroticism score</article-title>
          <comment>Last accessed</comment>
          <ext-link ext-link-type="uri" xlink:href="https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/MentalStatesDerivation.pdf" id="intref0025">https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/MentalStatesDerivation.pdf</ext-link>
        </element-citation>
      </ref>
      <ref id="bib61">
        <element-citation publication-type="book" id="sref61">
          <person-group person-group-type="author">
            <name>
              <surname>Ng</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <chapter-title>A novel sparse group Gaussian graphical model for functional connectivity estimation</chapter-title>
          <source>International Conference on Information Processing in Medical Imaging</source>
          <year>2013 Jun 28</year>
          <publisher-name>Springer</publisher-name>
          <publisher-loc>Berlin, Heidelberg</publisher-loc>
          <fpage>256</fpage>
          <lpage>267</lpage>
        </element-citation>
      </ref>
      <ref id="bib62">
        <element-citation publication-type="journal" id="sref62">
          <person-group person-group-type="author">
            <name>
              <surname>Ng</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Greicius</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Transport on Riemannian manifold for connectivity-based brain decoding</article-title>
          <source>IEEE Trans. Med. Imag.</source>
          <volume>35</volume>
          <issue>1</issue>
          <year>2015 Aug 3</year>
          <fpage>208</fpage>
          <lpage>216</lpage>
        </element-citation>
      </ref>
      <ref id="bib63">
        <element-citation publication-type="journal" id="sref63">
          <person-group person-group-type="author">
            <name>
              <surname>Ng</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
            <name>
              <surname>Greicius</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Transport on Riemannian manifold for connectivity-based brain decoding</article-title>
          <source>IEEE Trans. Med. Imag.</source>
          <volume>35</volume>
          <issue>1</issue>
          <year>2015 Aug 3</year>
          <fpage>208</fpage>
          <lpage>216</lpage>
        </element-citation>
      </ref>
      <ref id="bib64">
        <element-citation publication-type="book" id="sref64">
          <person-group person-group-type="author">
            <name>
              <surname>Parisot</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Glocker</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Schirmer</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Rueckert</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>GraMPa: graph-based multi-modal parcellation of the cortex using fusion moves</chapter-title>
          <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source>
          <year>2016 Oct 17</year>
          <publisher-name>Springer</publisher-name>
          <publisher-loc>Cham</publisher-loc>
          <fpage>148</fpage>
          <lpage>156</lpage>
        </element-citation>
      </ref>
      <ref id="bib65">
        <element-citation publication-type="journal" id="sref65">
          <person-group person-group-type="author">
            <name>
              <surname>Parisot</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Arslan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Passerat-Palmbach</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wells</surname>
              <given-names>W.M.</given-names>
              <suffix>III</suffix>
            </name>
            <name>
              <surname>Rueckert</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Group-wise parcellation of the cortex through multi-scale spectral clustering</article-title>
          <source>Neuroimage</source>
          <volume>136</volume>
          <year>2016 Aug 1</year>
          <fpage>68</fpage>
          <lpage>83</lpage>
          <pub-id pub-id-type="pmid">27192437</pub-id>
        </element-citation>
      </ref>
      <ref id="bib66">
        <element-citation publication-type="journal" id="sref66">
          <person-group person-group-type="author">
            <name>
              <surname>Pearl</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Causal inference in statistics: an overview</article-title>
          <source>Stat. Surv.</source>
          <volume>3</volume>
          <year>2009</year>
          <fpage>96</fpage>
          <lpage>146</lpage>
        </element-citation>
      </ref>
      <ref id="bib67">
        <element-citation publication-type="journal" id="sref67">
          <person-group person-group-type="author">
            <name>
              <surname>Pennec</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Fillard</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Ayache</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>A Riemannian framework for tensor computing</article-title>
          <source>Int. J. Comput. Vis.</source>
          <volume>66</volume>
          <issue>1</issue>
          <year>2006 Jan 1</year>
          <fpage>41</fpage>
          <lpage>66</lpage>
        </element-citation>
      </ref>
      <ref id="bib68">
        <element-citation publication-type="journal" id="sref68">
          <person-group person-group-type="author">
            <name>
              <surname>Rahim</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Population shrinkage of covariance (PoSCE) for better individual brain functional-connectivity estimation</article-title>
          <source>Med. Image Anal.</source>
          <volume>54</volume>
          <year>2019 May</year>
          <fpage>138</fpage>
          <lpage>148</lpage>
          <pub-id pub-id-type="pmid">30903965</pub-id>
        </element-citation>
      </ref>
      <ref id="bib69">
        <element-citation publication-type="other" id="sref69">
          <article-title>HCP Pre-processing pipeline</article-title>
          <comment>Last accessed</comment>
          <ext-link ext-link-type="uri" xlink:href="https://db.humanconnectome.org/megatrawl/HCP820_MegaTrawl_April2016.pdf" id="intref0030">https://db.humanconnectome.org/megatrawl/HCP820_MegaTrawl_April2016.pdf</ext-link>
        </element-citation>
      </ref>
      <ref id="bib70">
        <element-citation publication-type="other" id="sref70">
          <article-title>UKB Pre-processing pipeline</article-title>
          <comment>Last accessed</comment>
          <ext-link ext-link-type="uri" xlink:href="http://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf" id="intref0035">http://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf</ext-link>
        </element-citation>
      </ref>
      <ref id="bib71">
        <element-citation publication-type="journal" id="sref71">
          <person-group person-group-type="author">
            <name>
              <surname>Rogers</surname>
              <given-names>B.P.</given-names>
            </name>
            <name>
              <surname>Morgan</surname>
              <given-names>V.L.</given-names>
            </name>
            <name>
              <surname>Newton</surname>
              <given-names>A.T.</given-names>
            </name>
            <name>
              <surname>Gore</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>Assessing functional connectivity in the human brain by fMRI</article-title>
          <source>Magn. Reson. Imag.</source>
          <volume>25</volume>
          <issue>10</issue>
          <year>2007 Dec 1</year>
          <fpage>1347</fpage>
          <lpage>1357</lpage>
        </element-citation>
      </ref>
      <ref id="bib72">
        <element-citation publication-type="journal" id="sref72">
          <person-group person-group-type="author">
            <name>
              <surname>SalaLlonch</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Duff</surname>
              <given-names>E.P.</given-names>
            </name>
          </person-group>
          <article-title>Spatial parcellations, spectral filtering, and connectivity measures in fMRI: optimizing for discrimination</article-title>
          <source>Hum. Brain Mapp.</source>
          <volume>40</volume>
          <issue>2</issue>
          <year>2019 Feb 1</year>
          <fpage>407</fpage>
          <lpage>419</lpage>
          <pub-id pub-id-type="pmid">30259597</pub-id>
        </element-citation>
      </ref>
      <ref id="bib73">
        <element-citation publication-type="journal" id="sref73">
          <person-group person-group-type="author">
            <name>
              <surname>Salimi-Khorshidi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Douaud</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Glasser</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Griffanti</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Automatic denoising of functional MRI data: combining independent component analysis and hierarchical fusion of classifiers</article-title>
          <source>Neuroimage</source>
          <volume>90</volume>
          <year>2014 Apr 15</year>
          <fpage>449</fpage>
          <lpage>468</lpage>
          <pub-id pub-id-type="pmid">24389422</pub-id>
        </element-citation>
      </ref>
      <ref id="bib74">
        <element-citation publication-type="journal" id="sref74">
          <person-group person-group-type="author">
            <name>
              <surname>Schaefer</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kong</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Gordon</surname>
              <given-names>E.M.</given-names>
            </name>
            <name>
              <surname>Laumann</surname>
              <given-names>T.O.</given-names>
            </name>
            <name>
              <surname>Zuo</surname>
              <given-names>X.N.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.J.</given-names>
            </name>
            <name>
              <surname>Eickhoff</surname>
              <given-names>S.B.</given-names>
            </name>
            <name>
              <surname>Yeo</surname>
              <given-names>B.T.</given-names>
            </name>
          </person-group>
          <article-title>Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title>
          <source>Cerebr. Cortex</source>
          <volume>28</volume>
          <issue>9</issue>
          <year>2017 Jul 18</year>
          <fpage>3095</fpage>
          <lpage>3114</lpage>
        </element-citation>
      </ref>
      <ref id="bib75">
        <element-citation publication-type="journal" id="sref75">
          <person-group person-group-type="author">
            <name>
              <surname>Shen</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Tokoglu</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Papademetris</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Constable</surname>
              <given-names>R.T.</given-names>
            </name>
          </person-group>
          <article-title>Groupwise whole-brain parcellation from resting-state fMRI data for network node identification</article-title>
          <source>Neuroimage</source>
          <volume>82</volume>
          <year>2013 Nov 15</year>
          <fpage>403</fpage>
          <lpage>415</lpage>
          <pub-id pub-id-type="pmid">23747961</pub-id>
        </element-citation>
      </ref>
      <ref id="bib76">
        <element-citation publication-type="journal" id="sref76">
          <person-group person-group-type="author">
            <name>
              <surname>Shen</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Finn</surname>
              <given-names>E.S.</given-names>
            </name>
            <name>
              <surname>Scheinost</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Rosenberg</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Chun</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Papademetris</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Constable</surname>
              <given-names>R.T.</given-names>
            </name>
          </person-group>
          <article-title>Using connectome-based predictive modeling to predict individual behavior from brain connectivity</article-title>
          <source>Nat. Protoc.</source>
          <volume>12</volume>
          <issue>3</issue>
          <year>2017 Mar</year>
          <fpage>506</fpage>
          <pub-id pub-id-type="pmid">28182017</pub-id>
        </element-citation>
      </ref>
      <ref id="bib78">
        <element-citation publication-type="book" id="sref78">
          <person-group person-group-type="author">
            <name>
              <surname>Shuman</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Narang</surname>
              <given-names>S.K.</given-names>
            </name>
            <name>
              <surname>Frossard</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Ortega</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Vandergheynst</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <chapter-title>The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains</chapter-title>
          <year>2012 Oct 31</year>
          <comment>arXiv preprint arXiv:1211.0053</comment>
        </element-citation>
      </ref>
      <ref id="bib79">
        <element-citation publication-type="journal" id="sref79">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>The future of FMRI connectivity</article-title>
          <source>Neuroimage</source>
          <volume>62</volume>
          <issue>2</issue>
          <year>2012 Aug 15</year>
          <fpage>1257</fpage>
          <lpage>1266</lpage>
          <pub-id pub-id-type="pmid">22248579</pub-id>
        </element-citation>
      </ref>
      <ref id="bib81">
        <element-citation publication-type="journal" id="sref81">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Salimi-Khorshidi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Webster</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Ramsey</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
          </person-group>
          <article-title>Network modelling methods for FMRI</article-title>
          <source>Neuroimage</source>
          <volume>54</volume>
          <issue>2</issue>
          <year>2011 Jan 15</year>
          <fpage>875</fpage>
          <lpage>891</lpage>
          <pub-id pub-id-type="pmid">20817103</pub-id>
        </element-citation>
      </ref>
      <ref id="bib82">
        <element-citation publication-type="journal" id="sref82">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Salimi-Khorshidi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Webster</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Ramsey</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
          </person-group>
          <article-title>Network modelling methods for FMRI</article-title>
          <source>Neuroimage</source>
          <volume>54</volume>
          <issue>2</issue>
          <year>2011 Jan 15</year>
          <fpage>875</fpage>
          <lpage>891</lpage>
          <pub-id pub-id-type="pmid">20817103</pub-id>
        </element-citation>
      </ref>
      <ref id="bib83">
        <element-citation publication-type="journal" id="sref83">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Moeller</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Auerbach</surname>
              <given-names>E.J.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Jenkinson</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Andersson</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Glasser</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Temporally-independent functional modes of spontaneous brain activity</article-title>
          <source>Proc. Natl. Acad. Sci. Unit. States Am.</source>
          <volume>109</volume>
          <issue>8</issue>
          <year>2012 Feb 21</year>
          <fpage>3131</fpage>
          <lpage>3136</lpage>
        </element-citation>
      </ref>
      <ref id="bib84">
        <element-citation publication-type="journal" id="sref84">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Hyvärinen</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
          </person-group>
          <article-title>Group-PCA for very large fMRI datasets</article-title>
          <source>Neuroimage</source>
          <volume>101</volume>
          <year>2014 Nov 1</year>
          <fpage>738</fpage>
          <lpage>749</lpage>
          <pub-id pub-id-type="pmid">25094018</pub-id>
        </element-citation>
      </ref>
      <ref id="bib85">
        <element-citation publication-type="journal" id="sref85">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Hyvärinen</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
          </person-group>
          <article-title>Group-PCA for very large fMRI datasets</article-title>
          <source>Neuroimage</source>
          <volume>101</volume>
          <year>2014 Nov 1</year>
          <fpage>738</fpage>
          <lpage>749</lpage>
          <pub-id pub-id-type="pmid">25094018</pub-id>
        </element-citation>
      </ref>
      <ref id="bib86">
        <element-citation publication-type="journal" id="sref86">
          <person-group person-group-type="author">
            <name>
              <surname>Snoek</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Miletić</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Scholte</surname>
              <given-names>H.S.</given-names>
            </name>
          </person-group>
          <article-title>How to control for confounds in decoding analyses of neuroimaging data</article-title>
          <source>Neuroimage</source>
          <volume>184</volume>
          <year>2019 Jan 1</year>
          <fpage>741</fpage>
          <lpage>760</lpage>
          <pub-id pub-id-type="pmid">30268846</pub-id>
        </element-citation>
      </ref>
      <ref id="bib88">
        <element-citation publication-type="journal" id="sref88">
          <person-group person-group-type="author">
            <name>
              <surname>Tavor</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Jones</surname>
              <given-names>O.P.</given-names>
            </name>
            <name>
              <surname>Mars</surname>
              <given-names>R.B.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Jbabdi</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Task-free MRI predicts individual differences in brain activity during task performance</article-title>
          <source>Science</source>
          <volume>352</volume>
          <issue>6282</issue>
          <year>2016 Apr 8</year>
          <fpage>216</fpage>
          <lpage>220</lpage>
          <pub-id pub-id-type="pmid">27124457</pub-id>
        </element-citation>
      </ref>
      <ref id="bib89">
        <element-citation publication-type="journal" id="sref89">
          <person-group person-group-type="author">
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Dohmatob</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.B.</given-names>
            </name>
          </person-group>
          <article-title>Which fMRI clustering gives good brain parcellations?</article-title>
          <source>Front. Neurosci.</source>
          <volume>8</volume>
          <year>2014 Jul 1</year>
          <fpage>167</fpage>
          <pub-id pub-id-type="pmid">25071425</pub-id>
        </element-citation>
      </ref>
      <ref id="bib90">
        <mixed-citation publication-type="other" id="sref90">Varoquaux G, Baronnet F, Kleinschmidt A, Fillard P, Thirion B. Detection of brain functional-connectivity difference in post-stroke patients using group-level covariance modeling. In International Conference on Medical Image Computing and Computer-Assisted Intervention 2010 Sep 20 (pp. 200-208). Springer, Berlin, Heidelberg.</mixed-citation>
      </ref>
      <ref id="bib91">
        <element-citation publication-type="journal" id="sref91">
          <person-group person-group-type="author">
            <name>
              <surname>Vidaurre</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Bielza</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Larrañaga</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>A survey of L1 regression</article-title>
          <source>Int. Stat. Rev.</source>
          <volume>81</volume>
          <issue>3</issue>
          <year>2013 Dec</year>
          <fpage>361</fpage>
          <lpage>387</lpage>
        </element-citation>
      </ref>
      <ref id="bib92">
        <element-citation publication-type="journal" id="sref92">
          <person-group person-group-type="author">
            <name>
              <surname>Vidaurre</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
          </person-group>
          <article-title>Brain network dynamics are hierarchically organized in time</article-title>
          <source>Proc. Natl. Acad. Sci. Unit. States Am.</source>
          <volume>114</volume>
          <issue>48</issue>
          <year>2017 Nov 28</year>
          <fpage>12827</fpage>
          <lpage>12832</lpage>
        </element-citation>
      </ref>
      <ref id="bib93">
        <element-citation publication-type="other" id="sref93">
          <article-title>Wilson score interval</article-title>
          <comment>accessed</comment>
          <ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval.%20Last" id="intref0040">https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval. Last</ext-link>
        </element-citation>
      </ref>
      <ref id="bib94">
        <element-citation publication-type="journal" id="sref94">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias</article-title>
          <source>Artif. Intell.</source>
          <volume>172</volume>
          <issue>16–17</issue>
          <year>2008 Nov 1</year>
          <fpage>1873</fpage>
          <lpage>1896</lpage>
        </element-citation>
      </ref>
      <ref id="bib95">
        <element-citation publication-type="journal" id="sref95">
          <person-group person-group-type="author">
            <name>
              <surname>Zou</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Hastie</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Regularization and variable selection via the elastic net</article-title>
          <source>J. Roy. Stat. Soc. B</source>
          <volume>67</volume>
          <issue>2</issue>
          <year>2005 Apr 1</year>
          <fpage>301</fpage>
          <lpage>320</lpage>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="appsec1" sec-type="supplementary-material">
      <label>Appendix A</label>
      <title>Supplementary data</title>
      <p id="p0505">The following is the Supplementary data to this article:<supplementary-material content-type="local-data" id="mmc1"><caption><title>Multimedia component 1</title></caption><media xlink:href="mmc1.pdf"><alt-text>Multimedia component 1</alt-text></media></supplementary-material></p>
    </sec>
    <ack id="ack0010">
      <title>Acknowledgements</title>
      <p>Computation used the Oxford Biomedical Research Computing (BMRC) facility, a joint development between the Wellcome Centre for Human Genetics and the Big Data Institute supported by <funding-source id="gs20">Health Data Research UK</funding-source> and the <funding-source id="gs6">NIHR Oxford Biomedical Research Centre</funding-source>.</p>
      <p>We are extremely grateful to all UK Biobank (Data Access Application 8107), Human Connectome Project, ACPI, and ABIDE study participants, who generously donated their time to make this resource possible. UK Biobank (including the imaging enhancement) has been generously supported by the <funding-source id="gs26">UK Medical Research Council</funding-source> and the <funding-source id="gs10">Wellcome Trust</funding-source>. Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 <funding-source id="gs21">NIH Institutes and Centers</funding-source> that support the NIH Blueprint for Neuroscience Research; and by the <funding-source id="gs12">McDonnell Center for Systems Neuroscience</funding-source> at Washington University. The ACPI is primarily supported by a grant supplement (R01 MH094639) provided to PI Milham by the <funding-source id="gs14">National Institute on Drug Abuse (NIDA)</funding-source>. Additional support to ACPI is provided by the Child Mind Institute and the Nathan Kline Institute. For ABIDE, the primary support for the work by Adriana Di Martino was provided by the (<funding-source id="gs16">NIMH</funding-source> K23MH087770) and the <funding-source id="gs17">Leon Levy Foundation</funding-source> and primary support for the work by Michael P. Milham and the INDI team was provided by gifts from Joseph P. Healy and the Stavros Niarchos Foundation to the Child Mind Institute, as well as by an NIMH award to MPM (<funding-source id="gs22">NIMH</funding-source> R03MH096321).</p>
      <p>We additionally thanks Gael Varoquaux, Giles Colclough, Mehdi Rahim, Thomas E. Nichols, and Todd Constable for helpful discussions.</p>
      <p>Lastly, U.P is funded by an <funding-source id="gs23">MRC</funding-source> Mental Health Data Pathfinder award (PI Clare Mackay) MC_PC_17215. S.M.S and M.W.W receive support from the <funding-source id="gs25">Wellcome Trust</funding-source> (203139/Z/16/Z). M.W.W research is additionally supported by the <funding-source id="gs1">NIHR Oxford Health Biomedical Research Centre</funding-source> and by the <funding-source id="gs2">Wellcome Trust</funding-source> (106183/Z/14/Z). D.V is supported by the <funding-source id="gs3">Novonordisk Hallas-Møller Emerging Investigator Award</funding-source> (0054895).</p>
    </ack>
    <fn-group>
      <fn id="fn1">
        <label>1</label>
        <p id="ntpara0010">To apply sICA, we first generated the group-PCA (Principal Component Analysis) output using MIGP (MELODIC’s Incremental group-PCA) (<xref rid="bib85" ref-type="bibr">Smith et al., 2014b</xref>) using data from all subjects. This comprises the top few thousands (1000–5000) weighted spatial eigenvectors from a group-averaged PCA, which is a very close approximation to the original data (fully concatenating all subjects’ time-series). Lastly, group sICA is run on the output of group-PCA.</p>
      </fn>
      <fn id="fn2">
        <label>2</label>
        <p id="ntpara0015">Regarding the selection of artefactual components; this was part of the central processing done previously on behalf of UKB (<xref rid="bib56" ref-type="bibr">Miller et al., 2016</xref>). The decisions were made on the basis of spatial layout of components, and average temporal power spectrum.</p>
      </fn>
      <fn id="fn3">
        <label>3</label>
        <p id="ntpara0020">For UKB, the ICA dimensionality cannot go up further (e.g., d ​= ​200), because for larger dimensionalities, the additional components appear as artefactual; the number of non-artefact components barely grows at all (more than the existing 55). We believe this is because of the limitations of volumetric analysis possibly combined with the 6-min limited duration of the acquisition.</p>
      </fn>
      <fn id="fn4">
        <label>4</label>
        <p id="ntpara0025">We have N subjects, and for each subject, we have d parcels. In the case of optimization of the regularising parameters, we first calculated the difference between the regularized subject precision matrices (<inline-formula><mml:math id="M115" altimg="si92.svg"><mml:mrow><mml:mi>d</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>d</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>) and the group average of the unregularised subject precision matrices (<inline-formula><mml:math id="M116" altimg="si93.svg"><mml:mrow><mml:mi>d</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula>). Then, we calculated the sum of the resulting matrices (after squaring matrix elements), and obtained a <inline-formula><mml:math id="M117" altimg="si93.svg"><mml:mrow><mml:mi>d</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> resulting matrix. Then, we summed up the elements in the upper triangular of the resulting matrix, and lastly computed the square root.</p>
      </fn>
      <fn id="fn5">
        <label>5</label>
        <p id="ntpara0030">In a broad sense, we have used the word covariance for different variants of the functional connectivity estimates. This should not be confused with empirical covariance, <inline-formula><mml:math id="M118" altimg="si3.svg"><mml:mrow><mml:mover accent="true"><mml:mtext>Σ</mml:mtext><mml:mo>ˇ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>.</p>
      </fn>
      <fn id="fn6">
        <label>6</label>
        <p id="ntpara0035">Predictor is used sometimes as synonymous for input variable, and <italic>classifier</italic> is mostly used for categorical variables prediction. We have used <italic>predictor/classifier</italic> combination in an effort to make sure that the audience is not confused, and this implies prediction of both categorical and continuous non-imaging variables.</p>
      </fn>
      <fn id="fn7">
        <label>7</label>
        <p id="ntpara0040"><ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/ACPI/html/index.html" id="intref0010">http://fcon_1000.projects.nitrc.org/indi/ACPI/html/index.html</ext-link>.</p>
      </fn>
      <fn id="fn8">
        <label>8</label>
        <p id="ntpara0045">The description of Berkson’s paradox is: “If there exist a causal structure <inline-formula><mml:math id="M119" altimg="si94.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">→</mml:mo><mml:mi>C</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">←</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:math></inline-formula>, where X and Y are not directly connected. If we try to account for (condition on) C in a partial correlation analysis (i.e., testing for conditional independence), by regressing C out of X and Y, we induce a negative correlation between X and Y” (<xref rid="bib79" ref-type="bibr">Smith, 2012</xref>). In the context of the discussion above, if there is no chance of confounds (C), being fed into a target variable (Y), but still by conditioning on C, we might create a spurious association between functional connectivity (X) and Y.</p>
      </fn>
      <fn id="appsec2" fn-type="supplementary-material">
        <label>Appendix A</label>
        <p id="p0510">Supplementary data to this article can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2020.116604" id="intref0015">https://doi.org/10.1016/j.neuroimage.2020.116604</ext-link>.</p>
      </fn>
    </fn-group>
  </back>
</article>
