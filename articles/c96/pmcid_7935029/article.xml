<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Netw Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Netw Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">netn</journal-id>
      <journal-title-group>
        <journal-title>Network Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="epub">2472-1751</issn>
      <publisher>
        <publisher-name>MIT Press</publisher-name>
        <publisher-loc>One Rogers Street, Cambridge, MA 02142-1209USAjournals-info@mit.edu</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">33688607</article-id>
      <article-id pub-id-type="pmc">7935029</article-id>
      <article-id pub-id-type="publisher-id">netn_a_00171</article-id>
      <article-id pub-id-type="doi">10.1162/netn_a_00171</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Methods</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Graph convolutional network for fMRI analysis based on connectivity neighborhood</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Lebo</given-names>
          </name>
          <aff id="aff1">Department of Electrical and Computer Engineering, University of California, Riverside, Riverside, CA, USA</aff>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Kaiming</given-names>
          </name>
          <aff id="aff2">Department of Bioengineering, University of California, Riverside, Riverside, CA, USA</aff>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>Xiaoping P.</given-names>
          </name>
          <xref ref-type="corresp" rid="cor1">*</xref>
          <aff id="aff3">Department of Electrical and Computer Engineering, University of California, Riverside, Riverside, CA, USA</aff>
          <aff id="aff4">Department of Bioengineering, University of California, Riverside, Riverside, CA, USA</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-Statement">
          <p>Competing Interests: The authors have declared that no competing interests exist.</p>
        </fn>
        <corresp id="cor1">* Corresponding Author: <email xlink:href="mailto:xhu@engr.ucr.edu">xhu@engr.ucr.edu</email></corresp>
        <fn>
          <p>Handling Editor: Andrew Zalesky</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>01</day>
        <month>2</month>
        <year>2021</year>
        <string-date>2021</string-date>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2021</year>
      </pub-date>
      <volume>5</volume>
      <issue>1</issue>
      <fpage>83</fpage>
      <lpage>95</lpage>
      <history>
        <date date-type="received">
          <day>14</day>
          <month>5</month>
          <year>2020</year>
        </date>
        <date date-type="accepted">
          <day>24</day>
          <month>9</month>
          <year>2020</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>¬© 2020 Massachusetts Institute of Technology</copyright-statement>
        <copyright-year>2020</copyright-year>
        <copyright-holder>Massachusetts Institute of Technology</copyright-holder>
        <license license-type="open-access">
          <license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. For a full description of the license, please visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/legalcode">https://creativecommons.org/licenses/by/4.0/legalcode</ext-link>.</license-p>
        </license>
      </permissions>
      <self-uri content-type="pdf" xlink:href="netn-05-83.pdf"/>
      <abstract>
        <p>There have been successful applications of deep learning to functional magnetic resonance imaging (fMRI), where fMRI data were mostly considered to be structured grids, and spatial features from Euclidean neighbors were usually extracted by the convolutional neural networks (CNNs) in the computer vision field. Recently, CNN has been extended to graph data and demonstrated superior performance. Here, we define graphs based on functional connectivity and present a connectivity-based graph convolutional network (cGCN) architecture for fMRI analysis. Such an approach allows us to extract spatial features from connectomic neighborhoods rather than from Euclidean ones, consistent with the functional organization of the brain. To evaluate the performance of cGCN, we applied it to two scenarios with resting-state fMRI data. One is individual identification of healthy participants and the other is classification of autistic patients from normal controls. Our results indicate that cGCN can effectively capture functional connectivity features in fMRI analysis for relevant applications.</p>
      </abstract>
      <kwd-group kwd-group-type="text">
        <title>Keywords</title>
        <kwd>Functional connectivity</kwd>
        <x xml:space="preserve">, </x>
        <kwd>Deep learning</kwd>
        <x xml:space="preserve">, </x>
        <kwd>Graph convolutional network</kwd>
        <x xml:space="preserve">, </x>
        <kwd>Connectivity-based neighborhood</kwd>
      </kwd-group>
      <counts>
        <fig-count count="6"/>
        <equation-count count="1"/>
        <ref-count count="55"/>
        <page-count count="13"/>
      </counts>
      <custom-meta-group>
        <custom-meta>
          <meta-name>citation</meta-name>
          <meta-value>Wang, L., Li, K., &amp; Hu, X. P. (2021). Graph convolution network for fMRI analysis based on connectivity neighborhood. <italic>Network Neuroscience</italic>, <italic>5</italic>(1), 83‚Äì95. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/netn_a_00171">https://doi.org/10.1162/netn_a_00171</ext-link></meta-value>
        </custom-meta>
      </custom-meta-group>
    </article-meta>
  </front>
  <body>
    <sec>
      <title>INTRODUCTION</title>
      <p>In recent years, there has been increasing interest in studying the brain via resting-state functional magnetic resonance imaging (<xref rid="def1" ref-type="def">rs-fMRI</xref>). Without any task or external stimulus, rs-fMRI can capture the spontaneous brain activity that reflects the functional organization of the brain. Based on rs-fMRI data, <xref rid="def2" ref-type="def">functional connectivity</xref> (FC) has been calculated using correlations between spatially distant regions within/across functional networks (Rogers, Morgan, Newton, &amp; Gore, <xref rid="bib38" ref-type="bibr">2007</xref>; van den Heuvel &amp; Pol, <xref rid="bib44" ref-type="bibr">2010</xref>). FC is believed to reflect the functional organization of the brain and has been used as a fingerprint to identify individuals (Finn et al., <xref rid="bib15" ref-type="bibr">2015</xref>). Alterations in FC have been associated with psychiatric disorders (Bullmore &amp; Sporns, <xref rid="bib5" ref-type="bibr">2009</xref>; Greicius, Supekar, Menon, &amp; Dougherty, <xref rid="bib20" ref-type="bibr">2009</xref>; van den Heuvel &amp; Pol, <xref rid="bib44" ref-type="bibr">2010</xref>), demonstrating FC‚Äôs potential as biomarkers in clinical neuroscience. Various methods have been introduced to analyze the spatial FC pattern with fMRI data, including correlation-based approaches (Rogers et al., <xref rid="bib38" ref-type="bibr">2007</xref>; van den Heuvel &amp; Pol, <xref rid="bib44" ref-type="bibr">2010</xref>), graph-based methods (Keown et al., <xref rid="bib24" ref-type="bibr">2017</xref>; Lee, Smyser, &amp; Shimony, <xref rid="bib27" ref-type="bibr">2013</xref>; Wang, Zuo, &amp; He, <xref rid="bib48" ref-type="bibr">2010</xref>), and matrix factorization techniques (Andersen, Gash, &amp; Avison, <xref rid="bib2" ref-type="bibr">1999</xref>; van de Ven, Formisano, Prvulovic, Roeder, &amp; Linden, <xref rid="bib45" ref-type="bibr">2004</xref>). The temporal pattern of FC has also been analyzed with several methods, including sliding-window analysis (Sakoƒülu et al., <xref rid="bib40" ref-type="bibr">2010</xref>), time-frequency analysis (Chang &amp; Glover, <xref rid="bib6" ref-type="bibr">2010</xref>), and the Gaussian hidden Markov model (Chen, Langley, Chen, &amp; Hu, <xref rid="bib8" ref-type="bibr">2016</xref>). With the increasing availability of large fMRI datasets (Craddock et al., <xref rid="bib10" ref-type="bibr">2013</xref>; Miller et al., <xref rid="bib30" ref-type="bibr">2016</xref>; Van Essen et al., <xref rid="bib46" ref-type="bibr">2013</xref>), deep learning‚Äìbased methods are becoming more widely used in fMRI analysis.</p>
      <sec>
        <title>Deep Learning on fMRI Data</title>
        <p>Deep learning architectures, especially <xref rid="def3" ref-type="def">convolutional neural networks</xref> (CNN), have achieved remarkable performance in many applications, including image classification (He, Zhang, Ren, &amp; Sun, <xref rid="bib21" ref-type="bibr">2016</xref>), image segmentation (Ronneberger, Fischer, &amp; Brox, <xref rid="bib39" ref-type="bibr">2015</xref>), and machine translation (Vaswani et al., <xref rid="bib47" ref-type="bibr">2017</xref>). These applications mostly utilized automatic feature extraction via an end-to-end training paradigm on structured data (e.g., images and text). Similar strategies were extended to neuroimaging data, and promising results were obtained in several applications, including Alzheimer patient classification (Sarraf &amp; Tofighi, <xref rid="bib42" ref-type="bibr">2016</xref>), subcortical brain structure segmentation (Dolz, Desrosiers, &amp; Ayed, <xref rid="bib13" ref-type="bibr">2018</xref>), and segmentation of longitudinal structural MRI (Gao et al., <xref rid="bib17" ref-type="bibr">2018</xref>). However, there are several limitations to model fMRI data on the perspective of image grids: (a) It is computationally intensive to deal with voxelwise fMRI data via CNN models; (b) Brain activity occurs mostly in cortical and subcortical structures, making convolutions on white matter unnecessary; (c) The fMRI time course from a single voxel is usually very noisy; and (d) spatial features may be confined to a small neighborhood in the Euclidean space, especially in shallow CNN models. Therefore, it is of great necessity to build deep learning models that are more appropriate for the organization of the brain and that can efficiently extract connectomic features beyond a single voxel and its Euclidean neighborhood.</p>
      </sec>
      <sec>
        <title>Deep Learning on FC Matrix</title>
        <p>To reduce the spatial complexity and noise in individual voxel data, many studies have turned to approaches based on <xref rid="def4" ref-type="def">regions of interest</xref> (ROIs). By calculating the correlation coefficients between pairs of ROIs based on the whole scan, the ROI-derived FC matrix reveals the temporal correlation pattern of ROIs. Because of the grid structure of the 2D matrix, the FC matrix shows great compatibility with traditional deep learning models. Therefore, the FC matrix has been directly adopted as inputs of deep learning approaches in several studies. For instance, Suk, Wee, Lee, and Shen (<xref rid="bib43" ref-type="bibr">2016</xref>) introduced a deep learning architecture to investigate functional dynamics for mild cognitive impairment. Heinsfeld, Franco, Craddock, Buchweitz, and Meneguzzi (<xref rid="bib22" ref-type="bibr">2018</xref>) identified <xref rid="def5" ref-type="def">autism spectrum disorder</xref> (ASD) based on autoencoders with the FC matrix as input data. However, the FC matrix describes the linear temporal relationship between ROIs but does not account for the rich temporal dynamic information in the time courses. Our prior work with <xref rid="def6" ref-type="def">recurrent neural network</xref> (RNN) demonstrated that the spatiotemporal information can be beneficial for individual identifications (Chen &amp; Hu, <xref rid="bib7" ref-type="bibr">2018</xref>; L. Wang, Li, Chen, &amp; Hu, <xref rid="bib50" ref-type="bibr">2019</xref>). The initial work applied a fully connected model to extract spatial features from ROI data and used RNN for temporal evolutions (Chen &amp; Hu, <xref rid="bib7" ref-type="bibr">2018</xref>). In a follow-up study, spatial features among connectomic ROIs were extracted by convolutional layers (L. Wang et al., <xref rid="bib50" ref-type="bibr">2019</xref>). It showed that the identification accuracy increased with a larger number of input frames. The superior performance of the latter study suggests that proper convolution between ROIs for spatial features provides extra boosts for identification accuracy. However, it may be suboptimal to apply convolutions based on the predefined neighborhood that is defined by the functional atlas.</p>
      </sec>
      <sec>
        <title>Graph Convolutional Networks</title>
        <p>Motivated by breakthroughs of deep learning on grid data, efforts have been made to extend CNN to graphs, a natural way to represent many forms of data including fMRI data. Two categories of <xref rid="def7" ref-type="def">graph convolutional networks</xref> (GCNs)‚Äîspectral GCNs and spatial GCNs‚Äîhave been proposed. For spectral GCNs, graphs can be decomposed into spectral bases associated with graph-level information according to spectral graph theory (Bruna, Zaremba, Szlam, &amp; LeCun, <xref rid="bib4" ref-type="bibr">2013</xref>). In contrast, spatial GCNs imitate the Euclidean convolution on grid data to aggregate spatial features between neighboring nodes. Although spectral GCNs have achieved great success on both structural and functional MRI applications (Gopinath, Desrosiers, &amp; Lombaert, <xref rid="bib19" ref-type="bibr">2019</xref>; Hong et al., <xref rid="bib23" ref-type="bibr">2019</xref>; Ktena et al., <xref rid="bib26" ref-type="bibr">2018</xref>; Parisot et al., <xref rid="bib34" ref-type="bibr">2017</xref>), spatial models are preferred over the spectral ones because of their efficiency, generalization, and flexibility (Monti et al., <xref rid="bib31" ref-type="bibr">2017</xref>; Wu et al., <xref rid="bib52" ref-type="bibr">2019</xref>; Zhang, Cui, &amp; Zhu, <xref rid="bib54" ref-type="bibr">2018</xref>), and they have gained increasing interest in the community (Azevedo, Passamonti, Li√≤, &amp; Toschi, <xref rid="bib3" ref-type="bibr">2020</xref>; Gadgil et al., <xref rid="bib16" ref-type="bibr">2020</xref>).</p>
        <p>In this paper, we present a <xref rid="def8" ref-type="def">connectivity-based graph convolutional network</xref> (cGCN),a spatial GCN architecture, for fMRI analysis. The graph representation was defined with the <xref rid="def9" ref-type="def"><italic>k</italic>-nearest neighbor</xref> (k-NN) graph based on FC matrix. Convolutions were performed on graphs rather than on an image/ROI grid, which allows us to efficiently extract connectomic features of the underlying brain activity. The present model (L. Wang, <xref rid="bib49" ref-type="bibr">2020</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/Lebo-Wang/cGCN_fMRI">https://github.com/Lebo-Wang/cGCN_fMRI</ext-link>) has been applied in two scenarios, and the results indicate that cGCN is effective for fMRI analysis compared with traditional deep learning architectures.</p>
      </sec>
    </sec>
    <sec>
      <title>MATERIALS AND METHODS</title>
      <sec>
        <title>cGCN Overview</title>
        <p>The overview of our cGCN architecture is shown in <xref ref-type="fig" rid="F1">Figure 1</xref>. ROIs were considered to be graph nodes with the <xref rid="def10" ref-type="def">blood oxygen level‚Äìdependent</xref> (BOLD) signals of each frame as their attributes. Convolutions were performed within neighbors defined by the <italic>k</italic>-NN graph based on the groupwise FC matrix. Specifically, we first obtained the individual FC matrices on training data and averaged them for the group FC matrix. Based on that, a <italic>k</italic>-NN graph was generated by retaining only the top <italic>k</italic> edges in terms of their connectivity strength (i.e., average correlation coefficient) for each node. The FC-based <italic>k</italic>-NN graph was used to guide the convolutional operations with functional connectivity‚Äìbased neighborhoods. For simplicity, the same graph was shared by all subjects and at all time frames. Although each node had a few neighbors, the convolution field of each layer was extended by stacking multiple convolutional layers in the architecture. Between convolutional layers, skip connections were added from the prior convolutional layers to the last one, providing multilevel feature fusion for classification and accelerating the model training by alleviating the vanishing gradient problem. Outputs from the convolutional layers were followed by an RNN (or a temporal average pooling) layer to generate temporal evolutions by combining spatial representations from all frames. A Softmax layer was used at the end for the final classification.</p>
        <fig id="F1" orientation="portrait" position="float">
          <label><bold>Figure 1.</bold>‚ÄÉ</label>
          <caption>
            <p>Overview of cGCN. On the left, the graph definition for cGCN was based on the group FC from all training data, which can be further simplified as a <italic>k</italic>-nearest neighbors (<italic>k</italic>-NN) graph with binarized edges. In the middle, the cGCN architecture consisted of 5 convolutional layers. The convolutional neighborhood was defined by the shared <italic>k</italic>-NN graph across convolutional layers, time frames, and subjects. The recurrent neural network (RNN) layer (or the temporal average pooling layer) obtained latent representations from all frames. The final classification was achieved by the Softmax layer. On the right, an intuitive illustration of the spatial graph convolution showed the information aggregation between neighboring nodes.</p>
          </caption>
          <graphic xlink:href="netn-05-83-g001"/>
        </fig>
      </sec>
      <sec>
        <title>Graph Construction</title>
        <p>We represented each frame of fMRI data with a graph. A shared graph structure that reflects the intrinsic functional connectivity was derived from the group FC matrix (Petersen &amp; Sporns, <xref rid="bib35" ref-type="bibr">2015</xref>), <italic>based on training data only</italic>. The ROIs were considered to be nodes of the graph, and the FC connections were considered edges of the graph. To reduce the total number of edges in the graph, a <italic>k</italic>-NN graph was obtained by keeping only the top <italic>k</italic> connectivity neighbors for each node in terms of the connectivity strength; <italic>k</italic> is the hyperparameter related to the topological structure of graphs, which controls the sparsity of the graph. To evaluate the effect of <italic>k</italic>, different values of <italic>k</italic> (3, 5, 10, and 20) were assessed in our experiments.</p>
      </sec>
      <sec>
        <title>The Edge Function of cGCN</title>
        <p>The <italic>k</italic>-NN graph ùí¢ = (ùí±, ùìî) comprises nodes ùí± = {1, ‚Ä¶, <italic>N</italic>} and edges ùìî ‚äÜ ùí± √ó ùí±. Edge (<italic>i</italic>, <italic>j</italic>) represents the directed edge from <italic>ROI</italic><sub><italic>i</italic></sub> to <italic>ROI</italic><sub><italic>j</italic></sub>. To explicitly model the spatial pattern between ROIs, we chose EdgeConv, an asymmetric edge function (Y. Wang et al., <xref rid="bib51" ref-type="bibr">2018</xref>), as the convolutional operation for our cGCN convolutional layers:<disp-formula><mml:math id="m1"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>‚Ä≤</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àà</mml:mo><mml:mo>ùìî</mml:mo></mml:mrow></mml:munder></mml:mstyle><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo>Œò</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>‚à•</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>‚àí</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>x</italic><sub><italic>i</italic></sub> was the BOLD signal of the central node i and <italic>x</italic><sub><italic>j</italic></sub> was that of a connected neighbor node <italic>j</italic>. In addition to original features from the central node, the node value difference <italic>x</italic><sub><italic>j</italic></sub> ‚àí <italic>x</italic><sub><italic>i</italic></sub> was also appended as the complementary feature. <italic>h</italic><sub>Œò</sub> represents trainable weights Œò with a nonlinear activation function <italic>h</italic>, which was implemented by the multilayer perceptron (MLP) with the rectified linear unit (ReLU). The feature-wise convolution output, <inline-formula><mml:math id="m2"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>‚Ä≤</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>, was the maximal activation from its top <italic>k</italic> neighbors. In this way, spatial features between connectivity-based neighbors were modeled, including the node activity and the coactivation pattern.</p>
      </sec>
      <sec>
        <title>Experiments and Settings</title>
        <p>Two supervised classification experiments were carried out to evaluate the performance of our proposed architecture. In the first experiment, we used the ‚Äú100 unrelated subjects‚Äù dataset (54 females, age: 22‚Äì36) released by the Human Connectome Project (HCP) and aimed to identify them based on their rs-fMRI data. Each subject had four rs-fMRI sessions (each with 1,200 volumes) scanned on two days (Van Essen et al., <xref rid="bib46" ref-type="bibr">2013</xref>). The fMRI data were preprocessed by the HCP minimal preprocessing pipeline (Glasser et al., <xref rid="bib18" ref-type="bibr">2013</xref>) and denoised by ICA-FIX (Salimi-Khorshidi et al., <xref rid="bib41" ref-type="bibr">2014</xref>) to remove spatial artifacts and motion-related fluctuations. Surface-based registration was performed with the MSM-ALL method (Robinson et al., <xref rid="bib37" ref-type="bibr">2014</xref>). We utilized 236 ROIs based on the Power atlas (Power et al., <xref rid="bib36" ref-type="bibr">2011</xref>). The two sessions from Day 1 were employed as the training dataset, and the two sessions from Day 2 were used as the validation dataset and test dataset, respectively. The best model was chosen according to the best validation accuracy and final identification accuracy was assessed on the test dataset. For the training and validation datasets, fMRI time courses were cut into 100-frame clips. The final identification performance was measured with different numbers of frames (from 1,200 frames to a single frame) on the test dataset. To evaluate the contribution of the connectivity-based neighborhood for convolutions, we also ascertained the performance of the same cGCN architecture with random graphs (random GCNs).</p>
        <p>In the second experiment, we used cGCN to classify ASD patients from healthy controls on the ABIDE (Autism Brain Imaging Data Exchange) dataset (Di Martino et al., <xref rid="bib12" ref-type="bibr">2014</xref>). There are 1,057 subjects (525 ASD subjects and 532 neurotypical controls) from 17 imaging sites. All fMRI data were preprocessed by the Connectome Computation System pipeline (Zuo et al., <xref rid="bib55" ref-type="bibr">2013</xref>), with bandpass filtering (0.01‚Äì0.1 Hz) and without global signal regression. The Craddock 200 atlas (Craddock, James, Holtzheimer, Hu, &amp; Mayberg, <xref rid="bib11" ref-type="bibr">2012</xref>) was utilized to extract ROI signals. We adopted both leave-one-site-out and tenfold cross-validations. For the leave-one-site-out cross-validation, data from each site were independently tested with the model trained on data from other sites, which evaluated the model on heterogeneous datasets considering the site-specific variation. The tenfold cross-validation mixed all data together and split them into different folds by keeping the proportions of sites and diagnostic groups across folds. The site-specific heterogeneity was overlooked by the random partition of subsamples.</p>
        <p>We carried out the two experiments in Keras (Chollet, <xref rid="bib9" ref-type="bibr">2015</xref>) using TensorFlow as the back end (Abadi et al., <xref rid="bib1" ref-type="bibr">2016</xref>). Adam optimizer was applied to update model weights with adaptive learning rates (Kingma &amp; Ba, <xref rid="bib25" ref-type="bibr">2014</xref>). Stepwise learning rate decay was also used if the validation accuracy stopped increasing, with the smallest learning rate of 1e-6. The model was evaluated on the validation dataset after each training epoch, and the model parameters were saved only if better validation accuracy was achieved. During training, the L2 regularization was used to avoid overfitting. The final performance was reported with the highest accuracy among different L2 values (0.1, 0.01, 0.001, and 0.0001).</p>
      </sec>
      <sec>
        <title>Visualization</title>
        <p>The occlusion method (Zeiler &amp; Fergus, <xref rid="bib53" ref-type="bibr">2014</xref>) was utilized to visualize the important ROIs for classification in both experiments. With trained model parameters, each ROI of input data was zeroed out one at a time, and the performance degradation under the same model configuration was considered as the contribution of the ROI to the classification task. The occlusion pattern was mapped onto the cortical surface for visualization. We projected ROI data to the cortical surface and obtained the surface renditions. For the individual identification task, the occlusion pattern was generated and averaged on the test dataset. For ASD classification, we utilized the pretrained models from the leave-one-site-out cross-validation and averaged the pattern of performance degradation on each leave-out dataset to get the visualization pattern.</p>
      </sec>
    </sec>
    <sec>
      <title>RESULTS</title>
      <sec>
        <title>Performance Related to the Number of Neighbors</title>
        <p>The hyperparameter <italic>k</italic> determines the number of edges in graphs. The classification performance was evaluated for a range of <italic>k</italic> values (3, 5, 10, and 20). In <xref ref-type="fig" rid="F2">Figure 2</xref>, we show the performance of individual identification. The cGCN with <italic>k</italic> of 5 achieved the highest identification accuracy on average. Increasing the <italic>k</italic> value beyond 5 (<italic>k</italic> = 10 or 20) led to diminished performance. The performance of random GCNs was significantly lower than cGCN models, especially for small <italic>k</italic> values (<italic>k</italic> = 3 or 5).</p>
        <fig id="F2" orientation="portrait" position="float">
          <label><bold>Figure 2.</bold>‚ÄÉ</label>
          <caption>
            <p>Performance on individual identification regarding the number of neighbors and the number of input frames. The highest mean classification accuracy was achieved with <italic>k</italic> = 5. With 20 frames or fewer as input data, cGCN achieved significantly higher classification accuracy compared with random GCNs and the convolutional RNN (ConvRNN) model in our prior study (L. Wang et al., <xref rid="bib50" ref-type="bibr">2019</xref>). Particularly with 5 frames, cGCNs obtained the identifying accuracy of over 49% with <italic>k</italic> = 5, which was much higher than random GCNs and ConvRNN. It demonstrated that spatiotemporal features from each frame of fMRI data was successfully extracted by cGCNs for the individual identification task.</p>
          </caption>
          <graphic xlink:href="netn-05-83-g002"/>
        </fig>
        <p>For ASD classification, the performance with leave-one-site-out and tenfold cross-validation are depicted in <xref ref-type="fig" rid="F3">Figure 3</xref>. With the leave-one-site-out cross-validation, the highest mean accuracy was 71.6% when <italic>k</italic> = 5, and the lowest mean accuracy was 70.1% when <italic>k</italic> = 20. For the tenfold cross-validation, the highest mean accuracy was 70.7% when <italic>k</italic> = 3, and the lowest mean accuracy was 68.0% for cGCN with <italic>k</italic> = 20. On both cross-validations, cGCN with large <italic>k</italic> values (<italic>k</italic> = 10 or 20) had relatively lower classification accuracy.</p>
        <fig id="F3" orientation="portrait" position="float">
          <label><bold>Figure 3.</bold>‚ÄÉ</label>
          <caption>
            <p>Performance on ABIDE datasets with the leave-one-site-out cross-validation and the tenfold cross-validation. The best average accuracy with the leave-one-site-out cross-validation on ABIDE dataset was 71.6% (min: 57.1%, max: 81.5%) when <italic>k</italic> = 5. As a comparison, the DNN model achieved mean accuracy of 65.4% (min: 63%, max: 68%; Heinsfeld et al., <xref rid="bib22" ref-type="bibr">2018</xref>). Except for some imaging sites (CALTECH, MAX_MUN, OHSU, and TRINITY), cGCNs obtained distinct performance improvement compared with the DNN model. The best average accuracy with the tenfold cross-validation was 70.7% (min: 66.7%, max: 79.0%) when <italic>k</italic> = 3, which outperformed the DNN model of 70% (min: 66%, max: 71%).</p>
          </caption>
          <graphic xlink:href="netn-05-83-g003"/>
        </fig>
      </sec>
      <sec>
        <title>Performance Related to the Number of Input Frames</title>
        <p>For the individual identification application, we evaluated cGCNs and random GCNs with different numbers of frames as inputs. With cGCN models, the improved performance of individual identification was shown with increasing numbers of fMRI frames. As shown in <xref ref-type="fig" rid="F2">Figure 2</xref>, cGCN achieved better performance with a larger number of input frames, and the performance gradually saturated at approximately 100 frames. Random GCNs exhibited a similar pattern for large <italic>k</italic> values (<italic>k</italic> = 10 or 20), but with accuracy much lower than that of cGCNs. However, the performance of convolutional RNN (ConvRNN) dropped dramatically with reducing frames, close to the random guess (1%) with fewer than 5 frames. In contrast, cGCN still obtained an identifying accuracy of &gt; 49% with 5 frames when <italic>k</italic> = 5.</p>
        <p>Similarly, for the ASD classification task shown in <xref ref-type="fig" rid="F4">Figure 4</xref>, better classification accuracy can be achieved with a larger number of input frames for different imaging sites in the leave-one-site-out cross-validation. As a contrast, the number of input frames did not significantly affect the classification accuracy of the deep neural network (DNN) model, in which FC matrices were used as inputs without considering the temporal dimension (Heinsfeld et al., <xref rid="bib22" ref-type="bibr">2018</xref>).</p>
        <fig id="F4" orientation="portrait" position="float">
          <label><bold>Figure 4.</bold>‚ÄÉ</label>
          <caption>
            <p>The relationship between the classification accuracy and the number of frames as inputs for the ASD classification task with the leave-one-site-out cross-validation. The average classification accuracy increased linearly with the number of input frames, while the number of input frames did not affect the classification accuracy for the deep neural network model with FC matrices as inputs (Heinsfeld et al., <xref rid="bib22" ref-type="bibr">2018</xref>).</p>
          </caption>
          <graphic xlink:href="netn-05-83-g004"/>
        </fig>
      </sec>
      <sec>
        <title>Comparison</title>
        <p>For the individual identification task, cGCN achieved an accuracy of 98.8% with <italic>k</italic> = 10 when the number of input frames was fixed to 100. It outperformed several prior architectures, including the RNN model of 94.4% (Chen &amp; Hu, <xref rid="bib7" ref-type="bibr">2018</xref>), the ConvRNN model of 98.5% (L. Wang et al., <xref rid="bib50" ref-type="bibr">2019</xref>), and the traditional correlation method of around 70% (Finn et al., <xref rid="bib15" ref-type="bibr">2015</xref>). In particular, cGCNs showed overwhelming superiority over the traditional CNN model with fewer than 20 frames. As shown in <xref ref-type="fig" rid="F2">Figure 2</xref>, the previous ConvRNN model with only 5 frames of input data led to an accuracy close to the random guess (1%).</p>
        <p>For the ASD classification task with the leave-one-site-out cross-validation, the best mean classification accuracy was 71.6% (min: 57.1%, max: 81.5%) when <italic>k</italic> = 5 as shown in <xref ref-type="fig" rid="F3">Figure 3</xref>. Except for some imaging sites (CALTECH, MAX_MUN, OHSU, and TRINITY), our cGCNs obtained significant performance improvement compared with the DNN model, whose mean accuracy was 65.4% (min: 63%, max: 68%; Heinsfeld et al., <xref rid="bib22" ref-type="bibr">2018</xref>). With the tenfold cross-validation, our best average performance was 70.7% (min: 66.7%, max: 79.0%) when <italic>k</italic> = 3, which is better than the RNN model of 68.5% (Dvornek, Ventola, Pelphrey, &amp; Duncan, <xref rid="bib14" ref-type="bibr">2017</xref>) and the DNN model of 70% (min: 66%, max: 71%; Heinsfeld et al., <xref rid="bib22" ref-type="bibr">2018</xref>).</p>
      </sec>
      <sec>
        <title>Visualization</title>
        <p>We applied the occlusion method to identify informative regions for two classification tasks and visualized them in <xref ref-type="fig" rid="F5">Figures 5</xref> and <xref ref-type="fig" rid="F6">6</xref>. For the individual identification task, the smallest accuracy degradation was 0.6% when <italic>k</italic> = 20 and the largest accuracy drop was 2.9% when <italic>k</italic> = 3. Significant performance degradation was observed when some ROIs were individually occluded, while some regions did not suffer from any performance degradation. The salient regions for cGCN models with different <italic>k</italic> values were similar. The significant resting-state networks were default mode network (DMN), frontoparietal network (FPN), as well as visual network (VN).</p>
        <fig id="F5" orientation="portrait" position="float">
          <label><bold>Figure 5.</bold>‚ÄÉ</label>
          <caption>
            <p>Visualization of the performance degradation through the single-ROI occlusion for the individual identification. The red region reflected large performance degradation if corresponding ROIs were occluded. The performance degradation reflects the relative contribution of each ROI. When <italic>k</italic> = 20, the smallest performance drop was only 0.6%, while the largest performance drop of 2.9% was obtained with <italic>k</italic> = 3. Default mode network, frontoparietal network, and visual network contributed more to the individual identification.</p>
          </caption>
          <graphic xlink:href="netn-05-83-g005"/>
        </fig>
        <fig id="F6" orientation="portrait" position="float">
          <label><bold>Figure 6.</bold>‚ÄÉ</label>
          <caption>
            <p>Visualization of the performance degradation through the single-ROI occlusion for the ASD classification. We averaged performance drop on all models used in the leave-one-site-out cross-validation. The maximum performance drop was 7.5% when <italic>k</italic> = 3, and the smallest performance drop was 6.0% when <italic>k</italic> = 20. The color of the region reflected the performance degradation if corresponding ROI was occluded. The salient regions related to the ASD classification included frontoparietal network, default mode network, and ventral attention network.</p>
          </caption>
          <graphic xlink:href="netn-05-83-g006"/>
        </fig>
        <p>The visualization of cGCN for the ASD classification task is shown in <xref ref-type="fig" rid="F6">Figure 6</xref>. The largest performance drop was 7.5% when <italic>k</italic> = 3, and the smallest performance drop was 6.0% when <italic>k</italic> = 20. The salient regions for cGCN models with different <italic>k</italic> values were similar. The salient networks identified by cGCN included FPN, DMN, and ventral attention network.</p>
      </sec>
    </sec>
    <sec>
      <title>DISCUSSION</title>
      <p>We presented cGCN architecture for fMRI analysis and applied cGCN on two classification tasks with rs-fMRI data, that is, the individual identification and classification of ASD, respectively. The superior performance compared with prior studies demonstrated that cGCN can effectively capture spatial features of fMRI data within connectomic neighbors.</p>
      <p>A major contribution of the present work is that rather than performing convolution on structured image grids, ROI-based fMRI data are considered graphs based on FC, and cGCN is carried out between connectomic neighbors on the graph. Previous studies utilized fully connected layers for the spatial feature extraction and ignored the brain‚Äôs functional organization. In addition, it is difficult to train fully connected models with good generalization because of overfitting. Our prior paper demonstrated that it was feasible to capture spatial patterns on a small batch of ROIs from the same FC network by convolutions (L. Wang et al., <xref rid="bib50" ref-type="bibr">2019</xref>), although ROIs were artificially arranged in a predefined order according to the atlas. In the present work, the convolutional neighborhood was defined by the group-level FC matrix. Each ROI was involved in the convolution with its top connectivity-based neighbors, and high-level features were extracted by stacking convolutional layers hierarchically. The superior performance of cGCN over random GCN and previously used methods demonstrated that connectivity-based neighborhood for convolutions was a significant advantage for the cGCN architecture.</p>
      <p>We adopted the <italic>k</italic>-NN graph rather than hard thresholding FC to reduce the size of the neighborhood and effects of noise in connectivity (Liu, Nalci, &amp; Falahpour, <xref rid="bib28" ref-type="bibr">2017</xref>; Murphy &amp; Fox, <xref rid="bib32" ref-type="bibr">2017</xref>). The advantages of <italic>k</italic>-NN graphs lie in the following aspects. First, <italic>k</italic>-NN graphs naturally have good local homogeneity with the same number of edges originating from each node, appropriate for convolutions. Second, hierarchical feature extraction can be easily achieved with stacking layers under the guidance of the <italic>k</italic>-NN graph.</p>
      <p>Like the convolutional kernel size in the traditional CNN models, <italic>k</italic> explicitly determines the convolutional region on graphs, as well as the computational complexity for the cGCN model. We tested the performance of our cGCN architecture with different <italic>k</italic> values. The best performance of the individual identification was achieved when <italic>k</italic> = 5, while the highest classification accuracy on ASD with two types of cross-validations was achieved when <italic>k</italic> = 3 or 5. For both tasks, increasing <italic>k</italic> did not significantly improve the classification accuracy. One possible reason is that convolution on too many neighbors might fail to generate local features with good generalization. The same situation also happened in the modeling of 3D objects (Y. Wang et al., <xref rid="bib51" ref-type="bibr">2018</xref>). Therefore, we suggest a <italic>k</italic> value of 5 or less for good performance, although the exact optimal value may be application dependent.</p>
      <p>Unlike <italic>k</italic>, increasing the number of input frames significantly improved the performance for both tasks. This effect was especially obvious with a few input frames in the beginning and gradually leveled off with over 100 frames for individual identification. This result indicates that cGCN can efficiently extract spatial patterns between functionally ‚Äúadjacent‚Äù nodes from each frame of fMRI data in spite of substantial intersubject and intersession variabilities that arise because of hardware variations, and physiological variations (McGonigle et al., <xref rid="bib29" ref-type="bibr">2000</xref>). Thus, it is beneficial to keep the temporal axis of the fMRI data and apply framewise feature extraction based on fMRI time course rather than the FC matrix.</p>
      <p>There are some appealing properties by using the asymmetric edge function for convolutions according to Y. Wang et al. (<xref rid="bib51" ref-type="bibr">2018</xref>). First, the spatial features of both global information <italic>x</italic><sub><italic>i</italic></sub> and local interactions <italic>x</italic><sub><italic>j</italic></sub> ‚àí <italic>x</italic><sub><italic>i</italic></sub> are captured by the asymmetric edge function. Second, the long-distance characterization of spatial features between multi-hop neighborhoods can be captured by the stacked convolutional structures, based on the topological structure of the graph.</p>
      <p>Furthermore, the single-ROI occlusion experiments revealed the salient regions related to individual identification and classification of ASD tasks, which are in agreement with those seen in previous studies (Finn et al., <xref rid="bib15" ref-type="bibr">2015</xref>; Heinsfeld et al., <xref rid="bib22" ref-type="bibr">2018</xref>; Nielsen et al., <xref rid="bib33" ref-type="bibr">2013</xref>; L. Wang et al., <xref rid="bib50" ref-type="bibr">2019</xref>). For the individual identification task, the performance drop was much smaller than that of the ConvRNN model (L. Wang et al., <xref rid="bib50" ref-type="bibr">2019</xref>), suggesting that the graph-based representation of fMRI data builds robust relationships between ROIs, and missing values of any ROI might be compensated for by its functional neighbors based on the topological structure of graphs.</p>
      <p>Some limitations should be noted for future work. First, the graph topology is invariant from layer to layer, frame to frame, and subject to subject. Considering the significant variability in FC, future work shall adopt dynamic update across convolutional layers, time frames, and subjects. Second, the graph in the present work reflects the brain‚Äôs organization only from the functional perspective. Other image modalities, such as diffusion MRI, could be utilized to build graphs that reflect the brain‚Äôs structural connectivity. Third, intuitive visualization of temporal features captured by cGCN is difficult. This warrants further investigation in future studies.</p>
    </sec>
    <sec>
      <title>CONCLUSION</title>
      <p>In this paper, we describe a connectome-defined neighborhood for graph convolution to extract connectomic features from rs-fMRI data for classification. Our model allows for spatial feature extraction within connectomic neighborhoods rather than Euclidian ones. Significant improvement on individual identification and ASD classification tasks suggests that the cGCN model is effective in capturing connectomic features from fMRI data and is promising for fMRI analysis.</p>
    </sec>
    <sec>
      <title>AUTHOR CONTRIBUTIONS</title>
      <p>Lebo Wang: Conceptualization; Methodology; Software; Validation; Visualization; Writing - Original Draft. Kaiming Li: Formal analysis; Methodology; Writing - Original Draft; Writing - Review &amp; Editing. Xiaoping Hu: Conceptualization; Formal analysis; Methodology; Project administration; Resources; Writing - Original Draft; Writing - Review &amp; Editing.</p>
    </sec>
  </body>
  <back>
    <glossary>
      <title>TECHNICAL TERMS</title>
      <def-list>
        <def-item id="def1">
          <term>rs-fMRI:</term>
          <def>
            <p>Resting-state functional magnetic resonance imaging.</p>
          </def>
        </def-item>
        <def-item id="def2">
          <term>FC:</term>
          <def>
            <p>Functional connectivity.</p>
          </def>
        </def-item>
        <def-item id="def3">
          <term>CNN:</term>
          <def>
            <p>Convolutional neural network.</p>
          </def>
        </def-item>
        <def-item id="def4">
          <term>ROI:</term>
          <def>
            <p>Region of interest.</p>
          </def>
        </def-item>
        <def-item id="def5">
          <term>ASD:</term>
          <def>
            <p>Autism spectrum disorder.</p>
          </def>
        </def-item>
        <def-item id="def6">
          <term>RNN:</term>
          <def>
            <p>Recurrent neural network.</p>
          </def>
        </def-item>
        <def-item id="def7">
          <term>GCN:</term>
          <def>
            <p>Graph convolutional network.</p>
          </def>
        </def-item>
        <def-item id="def8">
          <term>cGCN:</term>
          <def>
            <p>Connectivity-based graph convolutional network.</p>
          </def>
        </def-item>
        <def-item id="def9">
          <term><italic>k</italic>-NN:</term>
          <def>
            <p>k-nearest neighbors.</p>
          </def>
        </def-item>
        <def-item id="def10">
          <term>BOLD:</term>
          <def>
            <p>Blood oxygen level‚Äìdependent.</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    <ref-list>
      <title>REFERENCES</title>
      <ref id="bib1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abadi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Barham</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dean</surname>, <given-names>J.</given-names></string-name>, ‚Ä¶ <string-name><surname>Isard</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Tensorflow: A system for large-scale machine learning</article-title>. <source>Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI, 2016)</source>, <fpage>265</fpage>‚Äì<lpage>283</lpage>.</mixed-citation>
      </ref>
      <ref id="bib2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Andersen</surname>, <given-names>A. H.</given-names></string-name>, <string-name><surname>Gash</surname>, <given-names>D. M.</given-names></string-name>, &amp; <string-name><surname>Avison</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Principal component analysis of the dynamic response measured by fMRI: A generalized linear systems framework</article-title>. <source>Magnetic Resonance Imaging</source>, <volume>17</volume>(<issue>6</issue>), <fpage>795</fpage>‚Äì<lpage>815</lpage>. <pub-id pub-id-type="doi">10.1016/S0730-725X(99)00028-4</pub-id><pub-id pub-id-type="pmid">10402587</pub-id></mixed-citation>
      </ref>
      <ref id="bib3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Azevedo</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Passamonti</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Li√≤</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Toschi</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Towards a predictive spatio-temporal representation of brain data</article-title>. <source>arXiv: 2003.03290</source>.</mixed-citation>
      </ref>
      <ref id="bib4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bruna</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zaremba</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Szlam</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Spectral networks and locally connected networks on graphs</article-title>. <source>arXiv:1312.6203</source>.</mixed-citation>
      </ref>
      <ref id="bib5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Complex brain networks: Graph theoretical analysis of structural and functional systems</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>(<issue>3</issue>), <fpage>186</fpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2575">https://doi.org/10.1038/nrn2575</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/19190637">19190637</ext-link></comment><pub-id pub-id-type="pmid">19190637</pub-id></mixed-citation>
      </ref>
      <ref id="bib6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chang</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Glover</surname>, <given-names>G. H.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Time‚Äìfrequency dynamics of resting-state brain connectivity measured with fMRI</article-title>. <source>NeuroImage</source>, <volume>50</volume>(<issue>1</issue>), <fpage>81</fpage>‚Äì<lpage>98</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.12.011">https://doi.org/10.1016/j.neuroimage.2009.12.011</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/20006716">20006716</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2827259">PMC2827259</ext-link></comment><pub-id pub-id-type="pmid">20006716</pub-id></mixed-citation>
      </ref>
      <ref id="bib7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Hu</surname>, <given-names>X. P.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Individual identification using functional brain fingerprint detected by recurrent neural network</article-title>. <source>Brain Connectivity</source>, <volume>8</volume>(<issue>4</issue>), <fpage>197</fpage>‚Äì<lpage>204</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1089/brain.2017.0561">https://doi.org/10.1089/brain.2017.0561</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/29634323">29634323</ext-link></comment><pub-id pub-id-type="pmid">29634323</pub-id></mixed-citation>
      </ref>
      <ref id="bib8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Langley</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Hu</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Spatiotemporal modeling of brain dynamics using resting-state functional magnetic resonance imaging with Gaussian hidden Markov model</article-title>. <source>Brain Connectivity</source>, <volume>6</volume>(<issue>4</issue>), <fpage>326</fpage>‚Äì<lpage>334</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1089/brain.2015.0398">https://doi.org/10.1089/brain.2015.0398</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/27008543">27008543</ext-link></comment><pub-id pub-id-type="pmid">27008543</pub-id></mixed-citation>
      </ref>
      <ref id="bib9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chollet</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Keras, GitHub</article-title>, <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link></mixed-citation>
      </ref>
      <ref id="bib10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Craddock</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Benhajali</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Chu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chouinard</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Evans</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jakab</surname>, <given-names>A.</given-names></string-name>, ‚Ä¶ <string-name><surname>Milham</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2013</year>). <article-title>The Neuro Bureau Preprocessing Initiative: Open sharing of preprocessed neuroimaging data and derivatives</article-title>. <source>Frontiers in Neuroinformatics</source>, <comment>Conference Abstract: Neuroinformatics 2013</comment>. <pub-id pub-id-type="doi">10.3389/conf.fninf.2013.09.00041</pub-id></mixed-citation>
      </ref>
      <ref id="bib11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Craddock</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>James</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Holtzheimer</surname>
<suffix>III</suffix>, <given-names>P. E.</given-names>, </string-name><string-name><surname>Hu</surname>, <given-names>X. P.</given-names></string-name>, &amp; <string-name><surname>Mayberg</surname>, <given-names>H. S.</given-names></string-name></person-group> (<year>2012</year>). <article-title>A whole brain fMRI atlas generated via spatially constrained spectral clustering</article-title>. <source>Human Brain Mapping</source>, <volume>33</volume>(<issue>8</issue>), <fpage>1914</fpage>‚Äì<lpage>1928</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.21333">https://doi.org/10.1002/hbm.21333</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/21769991">21769991</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3838923">PMC3838923</ext-link></comment><pub-id pub-id-type="pmid">21769991</pub-id></mixed-citation>
      </ref>
      <ref id="bib12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.-G.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Denio</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, ‚Ä¶ <string-name><surname>Milham</surname>, <given-names>M. P.</given-names></string-name></person-group> (<year>2014</year>). <article-title>The autism brain imaging data exchange: Towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>. <source>Molecular Psychiatry</source>, <volume>19</volume>(<issue>6</issue>), <fpage>659</fpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/mp.2013.78">https://doi.org/10.1038/mp.2013.78</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/23774715">23774715</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4162310">PMC4162310</ext-link></comment><pub-id pub-id-type="pmid">23774715</pub-id></mixed-citation>
      </ref>
      <ref id="bib13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dolz</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Desrosiers</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Ayed</surname>, <given-names>I. B.</given-names></string-name></person-group> (<year>2018</year>). <article-title>3D fully convolutional networks for subcortical segmentation in MRI: A large-scale study</article-title>. <source>NeuroImage</source>, <volume>170</volume>, <fpage>456</fpage>‚Äì<lpage>470</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.04.039">https://doi.org/10.1016/j.neuroimage.2017.04.039</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/28450139">28450139</ext-link></comment><pub-id pub-id-type="pmid">28450139</pub-id></mixed-citation>
      </ref>
      <ref id="bib14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dvornek</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Ventola</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pelphrey</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Duncan</surname>, <given-names>J. S.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Identifying autism from resting-state fMRI using long short-term memory networks</article-title>. <source>Machine Learning in Medical Imaging</source>, <volume>10541</volume>, <fpage>362</fpage>‚Äì<lpage>370</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-319-67389-9_42">https://doi.org/10.1007/978-3-319-67389-9_42</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/29104967">29104967</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5669262">PMC5669262</ext-link></comment><pub-id pub-id-type="pmid">29104967</pub-id></mixed-citation>
      </ref>
      <ref id="bib15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Finn</surname>, <given-names>E. S.</given-names></string-name>, <string-name><surname>Shen</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Scheinost</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Rosenberg</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chun</surname>, <given-names>M. M.</given-names></string-name>, ‚Ä¶ <string-name><surname>Constable</surname>, <given-names>R. T.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Functional connectome fingerprinting: Identifying individuals using patterns of brain connectivity</article-title>. <source>Nature Neuroscience</source>, <volume>18</volume>(<issue>11</issue>), <fpage>1664</fpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4135">https://doi.org/10.1038/nn.4135</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/26457551">26457551</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5008686">PMC5008686</ext-link></comment><pub-id pub-id-type="pmid">26457551</pub-id></mixed-citation>
      </ref>
      <ref id="bib16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gadgil</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Adeli</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Pfefferbaum</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sullivan</surname>, <given-names>E. V.</given-names></string-name>, &amp; <string-name><surname>Pohl</surname>, <given-names>K. M.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Spatio-temporal graph convolution for functional MRI analysis</article-title>. <source>arXiv:2003.10613</source>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-030-59728-3_52">https://doi.org/10.1007/978-3-030-59728-3_52</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/33257918">33257918</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7700758">PMC7700758</ext-link></comment></mixed-citation>
      </ref>
      <ref id="bib17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Min</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Fletcher</surname>, <given-names>P. T.</given-names></string-name>, &amp; <string-name><surname>Gerig</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Fully convolutional structured LSTM networks for joint 4D medical image segmentation</article-title>. <source>2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</source>, <fpage>1104</fpage>‚Äì<lpage>1108</lpage>. <pub-id pub-id-type="doi">10.1109/ISBI.2018.8363764</pub-id></mixed-citation>
      </ref>
      <ref id="bib18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Sotiropoulos</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Coalson</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Andersson</surname>, <given-names>J. L.</given-names></string-name>, ‚Ä¶ <string-name><surname>Polimeni</surname>, <given-names>J. R.</given-names></string-name></person-group> (<year>2013</year>). <article-title>The minimal preprocessing pipelines for the Human Connectome Project</article-title>. <source>NeuroImage</source>, <volume>80</volume>, <fpage>105</fpage>‚Äì<lpage>124</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.04.127">https://doi.org/10.1016/j.neuroimage.2013.04.127</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/23668970">23668970</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3720813">PMC3720813</ext-link></comment><pub-id pub-id-type="pmid">23668970</pub-id></mixed-citation>
      </ref>
      <ref id="bib19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gopinath</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Desrosiers</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Lombaert</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Graph convolutions on spectral embeddings for cortical surface parcellation</article-title>. <source>Medical Image Analysis</source>, <volume>54</volume>, <fpage>297</fpage>‚Äì<lpage>305</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.media.2019.03.012">https://doi.org/10.1016/j.media.2019.03.012</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/30974398">30974398</ext-link></comment><pub-id pub-id-type="pmid">30974398</pub-id></mixed-citation>
      </ref>
      <ref id="bib20">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greicius</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Supekar</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Menon</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Dougherty</surname>, <given-names>R. F.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Resting-state functional connectivity reflects structural connectivity in the default mode network</article-title>. <source>Cerebral Cortex</source>, <volume>19</volume>(<issue>1</issue>), <fpage>72</fpage>‚Äì<lpage>78</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhn059">https://doi.org/10.1093/cercor/bhn059</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/18403396">18403396</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605172">PMC2605172</ext-link></comment><pub-id pub-id-type="pmid">18403396</pub-id></mixed-citation>
      </ref>
      <ref id="bib21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Ren</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Sun</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Deep residual learning for image recognition</article-title>. <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>, <fpage>770</fpage>‚Äì<lpage>778</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id></mixed-citation>
      </ref>
      <ref id="bib22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heinsfeld</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Franco</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Craddock</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Buchweitz</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Meneguzzi</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Identification of autism spectrum disorder using deep learning and the ABIDE dataset</article-title>. <source>NeuroImage: Clinical</source>, <volume>17</volume>, <fpage>16</fpage>‚Äì<lpage>23</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.nicl.2017.08.017">https://doi.org/10.1016/j.nicl.2017.08.017</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/29034163">29034163</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5635344">PMC5635344</ext-link></comment><pub-id pub-id-type="pmid">29034163</pub-id></mixed-citation>
      </ref>
      <ref id="bib23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Yap</surname>, <given-names>P.-T.</given-names></string-name>, &amp; <string-name><surname>Shen</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Longitudinal prediction of infant diffusion MRI data via graph convolutional adversarial networks</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>38</volume>(<issue>12</issue>), <fpage>2717</fpage>‚Äì<lpage>2725</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TMI.2019.2911203">https://doi.org/10.1109/TMI.2019.2911203</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/30990424">30990424</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6935161">PMC6935161</ext-link></comment><pub-id pub-id-type="pmid">30990424</pub-id></mixed-citation>
      </ref>
      <ref id="bib24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keown</surname>, <given-names>C. L.</given-names></string-name>, <string-name><surname>Datko</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>C. P.</given-names></string-name>, <string-name><surname>Maximo</surname>, <given-names>J. O.</given-names></string-name>, <string-name><surname>Jahedi</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>M√ºller</surname>, <given-names>R.-A.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Network organization is globally atypical in autism: A graph theory study of intrinsic functional connectivity</article-title>. <source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source>, <volume>2</volume>(<issue>1</issue>), <fpage>66</fpage>‚Äì<lpage>75</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.bpsc.2016.07.008">https://doi.org/10.1016/j.bpsc.2016.07.008</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/28944305">28944305</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5607014">PMC5607014</ext-link></comment><pub-id pub-id-type="pmid">28944305</pub-id></mixed-citation>
      </ref>
      <ref id="bib25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name>, &amp; <string-name><surname>Ba</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv:1412.6980</source>.</mixed-citation>
      </ref>
      <ref id="bib26">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ktena</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Parisot</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ferrante</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Rajchl</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Glocker</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Metric learning with spectral graph convolutions on brain connectivity networks</article-title>. <source>NeuroImage</source>, <volume>169</volume>, <fpage>431</fpage>‚Äì<lpage>442</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.12.052">https://doi.org/10.1016/j.neuroimage.2017.12.052</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/29278772">29278772</ext-link></comment><pub-id pub-id-type="pmid">29278772</pub-id></mixed-citation>
      </ref>
      <ref id="bib27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>M. H.</given-names></string-name>, <string-name><surname>Smyser</surname>, <given-names>C. D.</given-names></string-name>, &amp; <string-name><surname>Shimony</surname>, <given-names>J. S.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Resting-state fMRI: A review of methods and clinical applications</article-title>. <source>American Journal of Neuroradiology</source>, <volume>34</volume>(<issue>10</issue>), <fpage>1866</fpage>‚Äì<lpage>1872</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3174/ajnr.A3263">https://doi.org/10.3174/ajnr.A3263</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/22936095">22936095</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4035703">PMC4035703</ext-link></comment><pub-id pub-id-type="pmid">22936095</pub-id></mixed-citation>
      </ref>
      <ref id="bib28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Nalci</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Falahpour</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2017</year>). <article-title>The global signal in fMRI: Nuisance or Information?</article-title>
<source>NeuroImage</source>, <volume>150</volume>, <fpage>213</fpage>‚Äì<lpage>229</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.02.036">https://doi.org/10.1016/j.neuroimage.2017.02.036</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/28213118">28213118</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5406229">PMC5406229</ext-link></comment><pub-id pub-id-type="pmid">28213118</pub-id></mixed-citation>
      </ref>
      <ref id="bib29">
        <mixed-citation publication-type="journal">
<person-group person-group-type="author"><string-name><surname>McGonigle</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Howseman</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Athwal</surname>, <given-names>B. S.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Frackowiak</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Holmes</surname>, <given-names>A. P.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Variability in fMRI: An examination of intersession differences</article-title>. <source>NeuroImage</source>, <volume>11</volume>(<issue>6</issue>), <fpage>708</fpage>‚Äì<lpage>734</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.2000.0562">https://doi.org/10.1006/nimg.2000.0562</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/10860798">10860798</ext-link></comment><pub-id pub-id-type="pmid">10860798</pub-id></mixed-citation>
      </ref>
      <ref id="bib30">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Alfaro-Almagro</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Bangerter</surname>, <given-names>N. K.</given-names></string-name>, <string-name><surname>Thomas</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>J.</given-names></string-name>, ‚Ä¶ <string-name><surname>Andersson</surname>, <given-names>J. L. R.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Multimodal population brain imaging in the UK Biobank prospective epidemiological study</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>(<issue>11</issue>), <fpage>1523</fpage>‚Äì<lpage>1536</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4393">https://doi.org/10.1038/nn.4393</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/27643430">27643430</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5086094">PMC5086094</ext-link></comment><pub-id pub-id-type="pmid">27643430</pub-id></mixed-citation>
      </ref>
      <ref id="bib31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Monti</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Boscaini</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Masci</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rodola</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Svoboda</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Bronstein</surname>, <given-names>M. M.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Geometric deep learning on graphs and manifolds using mixture model CNNs</article-title>. <source>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</source>, <fpage>5425</fpage>‚Äì<lpage>5434</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR.2017.576</pub-id></mixed-citation>
      </ref>
      <ref id="bib32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Fox</surname>, <given-names>M. D.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Towards a consensus regarding global signal regression for resting state functional connectivity MRI</article-title>. <source>NeuroImage</source>, <volume>154</volume>, <fpage>169</fpage>‚Äì<lpage>173</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2016.11.052">https://doi.org/10.1016/j.neuroimage.2016.11.052</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/27888059">27888059</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5489207">PMC5489207</ext-link></comment><pub-id pub-id-type="pmid">27888059</pub-id></mixed-citation>
      </ref>
      <ref id="bib33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nielsen</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Zielinski</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Fletcher</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Alexander</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Lange</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bigler</surname>, <given-names>E. D.</given-names></string-name>, ‚Ä¶ <string-name><surname>Anderson</surname>, <given-names>J. S.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Multisite functional connectivity MRI classification of autism: ABIDE results</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>7</volume>, <fpage>599</fpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2013.00599">https://doi.org/10.3389/fnhum.2013.00599</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/24093016">24093016</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3782703">PMC3782703</ext-link></comment><pub-id pub-id-type="pmid">24093016</pub-id></mixed-citation>
      </ref>
      <ref id="bib34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Parisot</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ktena</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Ferrante</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Moreno</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Glocker</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Rueckert</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Spectral graph convolutions for population-based disease prediction</article-title>. <source>Medical Image Computing and Computer-Assisted Interventions</source>. <pub-id pub-id-type="doi">10.1007/978-3-319-66179-7_21</pub-id></mixed-citation>
      </ref>
      <ref id="bib35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Petersen</surname>, <given-names>S. E.</given-names></string-name>, &amp; <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Brain networks and cognitive architectures</article-title>. <source>Neuron</source>, <volume>88</volume>(<issue>1</issue>), <fpage>207</fpage>‚Äì<lpage>219</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.09.027">https://doi.org/10.1016/j.neuron.2015.09.027</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/26447582">26447582</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4598639">PMC4598639</ext-link></comment><pub-id pub-id-type="pmid">26447582</pub-id></mixed-citation>
      </ref>
      <ref id="bib36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Wig</surname>, <given-names>G. S.</given-names></string-name>, <string-name><surname>Barnes</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Church</surname>, <given-names>J. A.</given-names></string-name>, ‚Ä¶ <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source>, <volume>72</volume>(<issue>4</issue>), <fpage>665</fpage>‚Äì<lpage>678</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.09.006">https://doi.org/10.1016/j.neuron.2011.09.006</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/22099467">22099467</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3222858">PMC3222858</ext-link></comment><pub-id pub-id-type="pmid">22099467</pub-id></mixed-citation>
      </ref>
      <ref id="bib37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robinson</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Jbabdi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Andersson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Harms</surname>, <given-names>M. P.</given-names></string-name>, ‚Ä¶ <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2014</year>). <article-title>MSM: A new flexible framework for Multimodal Surface Matching</article-title>. <source>NeuroImage</source>, <volume>100</volume>, <fpage>414</fpage>‚Äì<lpage>426</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2014.05.069">https://doi.org/10.1016/j.neuroimage.2014.05.069</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/24939340">24939340</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4190319">PMC4190319</ext-link></comment><pub-id pub-id-type="pmid">24939340</pub-id></mixed-citation>
      </ref>
      <ref id="bib38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rogers</surname>, <given-names>B. P.</given-names></string-name>, <string-name><surname>Morgan</surname>, <given-names>V. L.</given-names></string-name>, <string-name><surname>Newton</surname>, <given-names>A. T.</given-names></string-name>, &amp; <string-name><surname>Gore</surname>, <given-names>J. C.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Assessing functional connectivity in the human brain by fMRI</article-title>. <source>Magnetic Resonance Imaging</source>, <volume>25</volume>(<issue>10</issue>), <fpage>1347</fpage>‚Äì<lpage>1357</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.mri.2007.03.007">https://doi.org/10.1016/j.mri.2007.03.007</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/17499467">17499467</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2169499">PMC2169499</ext-link></comment><pub-id pub-id-type="pmid">17499467</pub-id></mixed-citation>
      </ref>
      <ref id="bib39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Fischer</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Brox</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2015</year>). <article-title>U-net: Convolutional networks for biomedical image segmentation</article-title>. <pub-id pub-id-type="doi">10.1007/978-3-319-24574-4_28</pub-id></mixed-citation>
      </ref>
      <ref id="bib40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sakoƒülu</surname>, <given-names>√ú.</given-names></string-name>, <string-name><surname>Pearlson</surname>, <given-names>G. D.</given-names></string-name>, <string-name><surname>Kiehl</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y. M.</given-names></string-name>, <string-name><surname>Michael</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name></person-group> (<year>2010</year>). <article-title>A method for evaluating dynamic functional network connectivity and task-modulation: Application to schizophrenia</article-title>. <source>Magnetic Resonance Materials in Physics, Biology and Medicine</source>, <volume>23</volume>(<issue>5‚Äì6</issue>), <fpage>351</fpage>‚Äì<lpage>366</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10334-010-0197-8">https://doi.org/10.1007/s10334-010-0197-8</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/20162320">20162320</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2891285">PMC2891285</ext-link></comment></mixed-citation>
      </ref>
      <ref id="bib41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salimi-Khorshidi</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Douaud</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Griffanti</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Automatic denoising of functional MRI data: Combining independent component analysis and hierarchical fusion of classifiers</article-title>. <source>NeuroImage</source>, <volume>90</volume>, <fpage>449</fpage>‚Äì<lpage>468</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.11.046">https://doi.org/10.1016/j.neuroimage.2013.11.046</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/24389422">24389422</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4019210">PMC4019210</ext-link></comment><pub-id pub-id-type="pmid">24389422</pub-id></mixed-citation>
      </ref>
      <ref id="bib42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sarraf</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Tofighi</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2016</year>). <article-title>DeepAD: Alzheimer‚Äô s disease classification via deep convolutional neural networks using MRI and fMRI</article-title>. <source>bioRxiv:070441</source>. <pub-id pub-id-type="doi">10.1101/070441</pub-id></mixed-citation>
      </ref>
      <ref id="bib43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suk</surname>, <given-names>H.-I.</given-names></string-name>, <string-name><surname>Wee</surname>, <given-names>C.-Y.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>S.-W.</given-names></string-name>, &amp; <string-name><surname>Shen</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2016</year>). <article-title>State-space model with deep learning for functional dynamics estimation in resting-state fMRI</article-title>. <source>NeuroImage</source>, <volume>129</volume>, <fpage>292</fpage>‚Äì<lpage>307</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2016.01.005">https://doi.org/10.1016/j.neuroimage.2016.01.005</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/26774612">26774612</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5437848">PMC5437848</ext-link></comment><pub-id pub-id-type="pmid">26774612</pub-id></mixed-citation>
      </ref>
      <ref id="bib44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Heuvel</surname>, <given-names>M. P.</given-names></string-name>, &amp; <string-name><surname>Pol</surname>, <given-names>H. E. H.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Exploring the brain network: A review on resting-state fMRI functional connectivity</article-title>. <source>European Neuropsychopharmacology</source>, <volume>20</volume>(<issue>8</issue>), <fpage>519</fpage>‚Äì<lpage>534</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.euroneuro.2010.03.008">https://doi.org/10.1016/j.euroneuro.2010.03.008</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/20471808">20471808</ext-link></comment><pub-id pub-id-type="pmid">20471808</pub-id></mixed-citation>
      </ref>
      <ref id="bib45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van de Ven</surname>, <given-names>V. G.</given-names></string-name>, <string-name><surname>Formisano</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Prvulovic</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Roeder</surname>, <given-names>C. H.</given-names></string-name>, &amp; <string-name><surname>Linden</surname>, <given-names>D. E. J.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Functional connectivity as revealed by spatial independent component analysis of fMRI measurements during rest</article-title>. <source>Human Brain Mapping</source>, <volume>22</volume>(<issue>3</issue>), <fpage>165</fpage>‚Äì<lpage>178</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.20022">https://doi.org/10.1002/hbm.20022</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/15195284">15195284</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6872001">PMC6872001</ext-link></comment><pub-id pub-id-type="pmid">15195284</pub-id></mixed-citation>
      </ref>
      <ref id="bib46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Barch</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name></person-group>, &amp; <collab collab-type="author">WU-Minn HCP Consortium</collab>. (<year>2013</year>). <article-title>The WU-Minn Human Connectome Project: An overview</article-title>. <source>NeuroImage</source>, <volume>80</volume>, <fpage>62</fpage>‚Äì<lpage>79</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.05.041">https://doi.org/10.1016/j.neuroimage.2013.05.041</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/23684880">23684880</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3724347">PMC3724347</ext-link></comment><pub-id pub-id-type="pmid">23684880</pub-id></mixed-citation>
      </ref>
      <ref id="bib47">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Vaswani</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Shazeer</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Parmar</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Uszkoreit</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gomez</surname>, <given-names>A. N.</given-names></string-name>, ‚Ä¶ <string-name><surname>Polosukhin</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Attention is all you need</article-title>. <source>Advances in Neural Information Processing Systems</source>.</mixed-citation>
      </ref>
      <ref id="bib48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zuo</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>He</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Graph-based network analysis of resting-state functional MRI</article-title>. <source>Frontiers in Systems Neuroscience</source>, <volume>4</volume>, <fpage>16</fpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnsys.2010.00016">https://doi.org/10.3389/fnsys.2010.00016</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/20589099">20589099</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2893007">PMC2893007</ext-link></comment><pub-id pub-id-type="pmid">20589099</pub-id></mixed-citation>
      </ref>
      <ref id="bib49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2020</year>). <article-title>cGCN fMRI, GitHub</article-title>, <ext-link ext-link-type="uri" xlink:href="https://github.com/Lebo-Wang/cGCN_fMRI">https://github.com/Lebo-Wang/cGCN_fMRI</ext-link></mixed-citation>
      </ref>
      <ref id="bib50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Hu</surname>, <given-names>X. P.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Application of convolutional recurrent neural network for individual recognition based on resting state fMRI data</article-title>. <source>Frontiers in Neuroscience</source>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2019.00434">https://doi.org/10.3389/fnins.2019.00434</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/31118882">31118882</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6504790">PMC6504790</ext-link></comment></mixed-citation>
      </ref>
      <ref id="bib51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Sarma</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Bronstein</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Solomon</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Dynamic graph CNN for learning on point clouds</article-title>. <source>arXiv:1801.07829</source>. <pub-id pub-id-type="doi">10.1145/3326362</pub-id></mixed-citation>
      </ref>
      <ref id="bib52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Pan</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Long</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>P. S.</given-names></string-name></person-group> (<year>2019</year>). <article-title>A comprehensive survey on graph neural networks</article-title>. <source>arXiv:1901.00596</source>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TNNLS.2020.2978386">https://doi.org/10.1109/TNNLS.2020.2978386</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/32217482">32217482</ext-link></comment></mixed-citation>
      </ref>
      <ref id="bib53">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeiler</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Fergus</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Visualizing and understanding convolutional networks</article-title>. <source>European Conference on Computer Vision</source>, <fpage>818</fpage>‚Äì<lpage>833</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-10590-1_53</pub-id></mixed-citation>
      </ref>
      <ref id="bib54">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Cui</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Zhu</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Deep learning on graphs: A survey</article-title>. <source>arXiv:1812.04202</source>.</mixed-citation>
      </ref>
      <ref id="bib55">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zuo</surname>, <given-names>X.-N.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Jiang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Cao</surname>, <given-names>X.-Y.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>Y.</given-names></string-name>, ‚Ä¶ <string-name><surname>Milham</surname>, <given-names>M. P.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Toward reliable characterization of functional homogeneity in the human brain: Preprocessing, scan duration, imaging resolution and computational space</article-title>. <source>NeuroImage</source>, <volume>65</volume>, <fpage>374</fpage>‚Äì<lpage>386</lpage>. <comment><bold>DOI:</bold><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.10.017">https://doi.org/10.1016/j.neuroimage.2012.10.017</ext-link>, <bold>PMID:</bold><ext-link ext-link-type="uri" xlink:href="https://europepmc.org/article/MED/23085497">23085497</ext-link>, <bold>PMCID:</bold><ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3609711">PMC3609711</ext-link></comment><pub-id pub-id-type="pmid">23085497</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
