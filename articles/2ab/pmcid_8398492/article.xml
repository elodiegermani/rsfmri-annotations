<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id>
      <journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id>
      <journal-id journal-id-type="publisher-id">sensors</journal-id>
      <journal-title-group>
        <journal-title>Sensors (Basel, Switzerland)</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1424-8220</issn>
      <publisher>
        <publisher-name>MDPI</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">34450699</article-id>
      <article-id pub-id-type="pmc">8398492</article-id>
      <article-id pub-id-type="doi">10.3390/s21165256</article-id>
      <article-id pub-id-type="publisher-id">sensors-21-05256</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Identification of Autism Subtypes Based on Wavelet Coherence of BOLD FMRI Signals Using Convolutional Neural Network</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Al-Hiyali</surname>
            <given-names>Mohammed Isam</given-names>
          </name>
          <xref ref-type="aff" rid="af1-sensors-21-05256">1</xref>
          <xref ref-type="author-notes" rid="fn1-sensors-21-05256">†</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Yahya</surname>
            <given-names>Norashikin</given-names>
          </name>
          <xref ref-type="aff" rid="af1-sensors-21-05256">1</xref>
          <xref rid="c1-sensors-21-05256" ref-type="corresp">*</xref>
          <xref ref-type="author-notes" rid="fn1-sensors-21-05256">†</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-7777-1119</contrib-id>
          <name>
            <surname>Faye</surname>
            <given-names>Ibrahima</given-names>
          </name>
          <xref ref-type="aff" rid="af1-sensors-21-05256">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2483-0028</contrib-id>
          <name>
            <surname>Hussein</surname>
            <given-names>Ahmed Faeq</given-names>
          </name>
          <xref ref-type="aff" rid="af2-sensors-21-05256">2</xref>
        </contrib>
      </contrib-group>
      <contrib-group>
        <contrib contrib-type="editor">
          <name>
            <surname>Prasad</surname>
            <given-names>Mukesh</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
        <contrib contrib-type="editor">
          <name>
            <surname>Cao</surname>
            <given-names>Jian</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
        <contrib contrib-type="editor">
          <name>
            <surname>Bhatt</surname>
            <given-names>Chintan</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
        <contrib contrib-type="editor">
          <name>
            <surname>Bhuyan</surname>
            <given-names>Monowar H.</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
        <contrib contrib-type="editor">
          <name>
            <surname>Ghoraani</surname>
            <given-names>Behnaz</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
      </contrib-group>
      <aff id="af1-sensors-21-05256"><label>1</label>Centre for Intelligent Signal and Imaging Research (CISIR), Department of Electrical and Electronic Engineering, Universiti Teknologi PETRONAS, Seri Iskandar 32610, Perak, Malaysia; <email>mohdisam_19001725@utp.edu.my</email> (M.I.A.-H.); <email>ibrahima_faye@utp.edu.my</email> (I.F.)</aff>
      <aff id="af2-sensors-21-05256"><label>2</label>Biomedical Engineering Department, Faculty of Engineering, Al-Nahrain University, Baghdad 10072, Iraq; <email>ahmed.f.h.1976@gmail.com</email></aff>
      <author-notes>
        <corresp id="c1-sensors-21-05256"><label>*</label>Correspondence: <email>norashikin_yahya@utp.edu.my</email>; Tel.: +605-3687861</corresp>
        <fn id="fn1-sensors-21-05256">
          <label>†</label>
          <p>These authors contributed equally to this work.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>04</day>
        <month>8</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="collection">
        <month>8</month>
        <year>2021</year>
      </pub-date>
      <volume>21</volume>
      <issue>16</issue>
      <elocation-id>5256</elocation-id>
      <history>
        <date date-type="received">
          <day>13</day>
          <month>6</month>
          <year>2021</year>
        </date>
        <date date-type="accepted">
          <day>20</day>
          <month>7</month>
          <year>2021</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2021 by the authors.</copyright-statement>
        <copyright-year>2021</copyright-year>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
        </license>
      </permissions>
      <abstract>
        <p>The functional connectivity (FC) patterns of resting-state functional magnetic resonance imaging (rs-fMRI) play an essential role in the development of autism spectrum disorders (ASD) classification models. There are available methods in literature that have used FC patterns as inputs for binary classification models, but the results barely reach an accuracy of 80%. Additionally, the generalizability across multiple sites of the models has not been investigated. Due to the lack of ASD subtypes identification model, the multi-class classification is proposed in the present study. This study aims to develop automated identification of autism spectrum disorder (ASD) subtypes using convolutional neural networks (CNN) using dynamic FC as its inputs. The rs-fMRI dataset used in this study consists of 144 individuals from 8 independent sites, labeled based on three ASD subtypes, namely autistic disorder (ASD), Asperger’s disorder (APD), and pervasive developmental disorder not otherwise specified (PDD-NOS). The blood-oxygen-level-dependent (BOLD) signals from 116 brain nodes of automated anatomical labeling (AAL) atlas are used, where the top-ranked node is determined based on one-way analysis of variance (ANOVA) of the power spectral density (PSD) values. Based on the statistical analysis of the PSD values of 3-level ASD and normal control (NC), putamen_R is obtained as the top-ranked node and used for the wavelet coherence computation. With good resolution in time and frequency domain, scalograms of wavelet coherence between the top-ranked node and the rest of the nodes are used as dynamic FC feature input to the convolutional neural networks (CNN). The dynamic FC patterns of wavelet coherence scalogram represent phase synchronization between the pairs of BOLD signals. Classification algorithms are developed using CNN and the wavelet coherence scalograms for binary and multi-class identification were trained and tested using cross-validation and leave-one-out techniques. Results of binary classification (ASD vs. NC) and multi-class classification (ASD vs. APD vs. PDD-NOS vs. NC) yielded, respectively, 89.8% accuracy and 82.1% macro-average accuracy, respectively. Findings from this study have illustrated the good potential of wavelet coherence technique in representing dynamic FC between brain nodes and open possibilities for its application in computer aided diagnosis of other neuropsychiatric disorders, such as depression or schizophrenia.</p>
      </abstract>
      <kwd-group>
        <kwd>autism spectrum disorder</kwd>
        <kwd>multi-class classification</kwd>
        <kwd>resting state fMRI</kwd>
        <kwd>BOLD signal</kwd>
        <kwd>scalogram</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro" id="sec1-sensors-21-05256">
      <title>1. Introduction</title>
      <p>Autism spectrum disorder (ASD) is a psychiatric disorder caused by impairment in brain functions [<xref rid="B1-sensors-21-05256" ref-type="bibr">1</xref>]. ASD patients suffer from weakness in verbal and non-verbal communication and difficulty in social activities, which may influence their life quality and interpersonal skills. A report by the World Health Organization has indicated that, in 2019 alone, 1 in 160 children has ASD [<xref rid="B2-sensors-21-05256" ref-type="bibr">2</xref>]. One of the challenges in clinical diagnosis of ASD is the lack of objective interpretation mechanisms of ASD  [<xref rid="B3-sensors-21-05256" ref-type="bibr">3</xref>]. Current practise of clinical diagnosis of ASD is based on behavioral assessment, but with high heterogeneous nature of ASD and varying clinical symptoms [<xref rid="B4-sensors-21-05256" ref-type="bibr">4</xref>] may render the diagnosis to be inaccurate. Based on the Diagnostic and Statistical Manual of Mental Disorders (DSM-4), ASD is categorized into three subtypes based on symptom variations; autistic disorder (ASD), Asperger’s disorder (APD), and pervasive developmental disorder not otherwise specified (PDD-NOS) [<xref rid="B5-sensors-21-05256" ref-type="bibr">5</xref>]. However, accurate behavioral assessment requires a trained psychiatrist and is susceptible to human error either during the assessment or interpreting the results. This issue may hinder the treating progress of the ASD patients. Indeed, an objective early ASD detection and suitable therapeutic plans choice are essential in improving the condition and quality of life of the ASD patients. In the past two decades, neuroscience studies have been making progress in characterizing biomarkers for interpreting neural mechanisms of ASD using functional brain imaging modalities [<xref rid="B6-sensors-21-05256" ref-type="bibr">6</xref>]. In a similar trend, there is also a rapid increase in application of artificial intelligence (AI) models in the medical diagnosis field, especially in psychiatric disorders [<xref rid="B7-sensors-21-05256" ref-type="bibr">7</xref>]. The use of AI has improved the diagnosis results and decreased the decision time associated with the traditional diagnosis method. In ASD cases, several studies are devoted to using resting-state functional magnetic resonance imaging (rs-fMRI) data with different types of AI classifiers [<xref rid="B8-sensors-21-05256" ref-type="bibr">8</xref>]. Generally, the functional magnetic resonance imaging (fMRI) is a non-invasive modality and has emerged as a powerful tool for depicting brain functionality of the cortex to deep brain regions. The fMRI provide the estimation of neuronal activity based on blood-oxygen-level-dependent (BOLD) [<xref rid="B9-sensors-21-05256" ref-type="bibr">9</xref>], as indirect signals that reflect the fluctuation in brain blood flow and blood oxygenation levels coupled to underlying neuronal activity [<xref rid="B10-sensors-21-05256" ref-type="bibr">10</xref>]. In a resting state experiment, the functional brain networks are detected without any specific tasks [<xref rid="B11-sensors-21-05256" ref-type="bibr">11</xref>]. Using the BOLD signals analysis at resting state helps neuroscientists to understand the fundamental mechanism of brain functioning of ASD patients [<xref rid="B7-sensors-21-05256" ref-type="bibr">7</xref>]. One common measure of brain functionality is by using functional connectivity (FC) of BOLD signals between brain regions which gives indication of the statistical correlation between different regions [<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>]. In general, there are two main models applied in BOLD signals analysis, static (SFC) and dynamic (DFC) functional connectivity [<xref rid="B13-sensors-21-05256" ref-type="bibr">13</xref>], both can be used for detection of psychiatric disorders [<xref rid="B14-sensors-21-05256" ref-type="bibr">14</xref>]. The SFC and DFC differ in their method of calculating the correlation coefficients. The SFC represents the interaction between pairs of brain nodes as a single correlation coefficient calculated from the BOLD signals of the entire scan but no temporal variations are considered in the calculation. In contrast, the DFC is calculated using wavelet transform, hence capturing both time and frequency details of the BOLD signals. It indicated the coherence strength between pairs of brain regions, represented in the form of two-dimensional matrix called scalogram.</p>
      <sec>
        <title>Classification of ASD Using Functional Connectivity (FC)—Related Works</title>
        <p>Many researches on brain FC are focussing on identifying the neurological biomarkers for ASD patients [<xref rid="B15-sensors-21-05256" ref-type="bibr">15</xref>]. Application of SFC [<xref rid="B10-sensors-21-05256" ref-type="bibr">10</xref>,<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>,<xref rid="B16-sensors-21-05256" ref-type="bibr">16</xref>,<xref rid="B17-sensors-21-05256" ref-type="bibr">17</xref>,<xref rid="B18-sensors-21-05256" ref-type="bibr">18</xref>], and DFC [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>] for detection of ASD in rs-fMRI has been investigated in the past papers. This section summarized the related works on ASD classification algorithms based on SFC and DFC as inputs to machine learning (ML) [<xref rid="B16-sensors-21-05256" ref-type="bibr">16</xref>,<xref rid="B17-sensors-21-05256" ref-type="bibr">17</xref>,<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>] or deep learning architecture [<xref rid="B10-sensors-21-05256" ref-type="bibr">10</xref>,<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>]. Recent advancement in deep learning has enables the transfer learning technique which is known to effectively improve the identification accuracy of diagnostic algorithms [<xref rid="B20-sensors-21-05256" ref-type="bibr">20</xref>,<xref rid="B21-sensors-21-05256" ref-type="bibr">21</xref>]. The number of SFC features generated from correlation coefficients of the BOLD signals usually amount to the order of thousands but the classification accuracy based on these features still need to be improved. This is because only some regions of the brain carry the informative features that discriminate ASD vs. normal control (NC). In [<xref rid="B16-sensors-21-05256" ref-type="bibr">16</xref>] Chen et al. used Pearson correlation of pairwise BOLD signals in low-frequency bands as input to support vector machine (SVM), achieving 79% accuracy in ASD vs. NC prediction. In another work by Abraham et al. [<xref rid="B17-sensors-21-05256" ref-type="bibr">17</xref>], covariance matrices of pairwise BOLD signals are used as the input features to an SVM classifier giving 67% accuracy. Recently, Chaitra et al. [<xref rid="B18-sensors-21-05256" ref-type="bibr">18</xref>] achieved 70.1% accuracy for ASD prediction using combination of Pearson correlation with complex brain network measurements as input features to the recursive-cluster-elimination-SVM (RCE-SVM) algorithm.</p>
        <p>Apart from using conventional ML techniques, deep learning (DL) algorithms are also used in the development of binary classification algorithms of ASD v. NC using SFC features. The recent one by Heinsfeld, et al. [<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>], used two stacked denoising autoencoders to transfer 19,900 features of FC extracted based on the Pearson correlation into the deep neural network (DNN), giving 70% classification accuracy. The other one is by Zeinab, et al. [<xref rid="B10-sensors-21-05256" ref-type="bibr">10</xref>], where Pearson correlation coefficients are input to the CNN as images and binary classification accuracy of 70.2%. An approach using DFC between pairwise BOLD signals by employing wavelet coherence transforms (WCT) was proposed by Bernas et al. [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>]. The WCT coefficients are used as the input vector to SVM achieving 80% accuracy for ASD vs. NC prediction. Apart from FC, the time-frequency components of BOLD signals are represented into 2D images in our previous study [<xref rid="B21-sensors-21-05256" ref-type="bibr">21</xref>] and used as input to the CNN models for feature extraction, and k-nearest neighbors (KNN) as a best classifier algorithm with 85.9% accuracy.</p>
        <p>The ML-based techniques using either SFC or DFC are not able to capture the topological information within the brain regions and the relationships between the neural activity features and the clinical symptoms [<xref rid="B22-sensors-21-05256" ref-type="bibr">22</xref>]. This is proven to be more difficult especially on the highly heterogeneous symptoms, such as ASD subtypes. However, the results of the studies mentioned above have had a minimal clinical impact. The reason for that is the vast majority of these studies have typically reported differences between ASD patients and normal controls, with best accuracy of 80%. At the same time, in clinical decisions, the ASD subtypes should not be ignored. Thus, the multi-class classification algorithm is critical in assisting ASD health practitioners in correct diagnosis of ASD subtypes. It is to be noted that the SFC features may not carry sufficient information for multi-class classification [<xref rid="B23-sensors-21-05256" ref-type="bibr">23</xref>]. Hence, a better choice would be using the DFC which represents correlation as a function of time-frequency between BOLD signals. There is evidence that DFC patterns may play a crucial role in identifying subtypes of psychiatric disorders, such as ASD. Indeed, the DFC patterns have been rarely investigated as input features for ASD classification models. In [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>] wavelet coherence transforms (WCT) and SVM are used for binary classification of ASD. With accuracy of 80%, this leaves much room for improvement.</p>
        <p>In this work, we developed an ASD classification algorithm based on wavelet coherence of BOLD signals and CNN. In specific, the calculation of the wavelet coherence are calculated between the top-ranked brain node to the rest of the nodes of automated anatomical labeling (AAL) atlas. Method of statistical significance analysis is employed on the power spectral density (PSD) of the BOLD signals from 116 brain nodes to determine the most significant node in multi-class (3-level ASD and NC) settings. A total of 115 wavelet coherence scalograms generated for each subject, represent the time-frequency resolution of the signal which may provide valuable information in identification of ASD subtypes. Results generated from this work are using dataset from the autism brain imaging data exchange (ABIDE) [<xref rid="B24-sensors-21-05256" ref-type="bibr">24</xref>] which is an online data source for rs-fMRI data of ASD patients and normal control (NC) groups collected from several neuroscience laboratories worldwide. The rest of this study is organized as follows. <xref ref-type="sec" rid="sec2-sensors-21-05256">Section 2</xref> describes the materials and proposed methods, including the data preparation, BOLD-dynamic features extraction and classification models. The results and comparison with benchmark studies are explained in <xref ref-type="sec" rid="sec3-sensors-21-05256">Section 3</xref> providing conclusions and future works in this area in <xref ref-type="sec" rid="sec4-sensors-21-05256">Section 4</xref>. The objective of this study is to develop an automated ASD subtypes classification using DFC patterns of rs-fMRI data. DFC features extracted using pairwise WCT, inherently leveraging the rich information of the WCT both in time and frequency domains.</p>
      </sec>
    </sec>
    <sec id="sec2-sensors-21-05256">
      <title>2. Materials and Methods</title>
      <p>Overall methodology in the development of automated ASD subtypes classification using DFC patterns of rs-fMRI data is illustrated in <xref ref-type="fig" rid="sensors-21-05256-f001">Figure 1</xref>. Here, we consider 2 classification techniques, binary and multi-class classifications.</p>
      <sec id="sec2dot1-sensors-21-05256">
        <title>2.1. Data Preparation</title>
        <p>In this study, resting-state fMRI data are collected from multiple sites of ABIDE dataset [<xref rid="B24-sensors-21-05256" ref-type="bibr">24</xref>]. The ABIDE data contain longitudinal relaxation time (T1) structural MRI brain images, fMRI images, and phenotypic information of the patients. Although ABIDE has more than 1000 subjects, with 446 ASD and 590 NC, coming from various contributors, not all ASD data are labeled based on the subtypes of DSM-4. Specifically, the available data based on DSM-4 are 323 ASD, 87 APD, and 36 PDD-NOS subjects. To avoid the issue of an imbalanced dataset which might affect the performance of the classifier, the number of subjects for each group is set at 36, the smallest sample size of ASD class. Details on the dataset, its scanning parameter and the number of subjects are listed in <xref rid="sensors-21-05256-t001" ref-type="table">Table 1</xref>. All datasets were acquired using 3 Tesla (3T) MRI scanners.</p>
        <p>The use of multi-site data introduces larger data variance during the training of the classifier due to differences in scanning parameters or type of scanner. The multi-site data may pose a challenge in generalizing the trained ASD classifiers [<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>] and this issue will be experimented here using leave-one-site out validation method.</p>
        <p>The selected data were pre-processed by using the DPARSF Matlab toolbox followed by BOLD signals extraction [<xref rid="B25-sensors-21-05256" ref-type="bibr">25</xref>] from 116 regions of the automated anatomical labeling (AAL) atlas. The AAL atlas divides the brain region into 116 nodes, as shown in <xref rid="sensors-21-05256-t0A1" ref-type="table">Table A1</xref> under the <xref ref-type="app" rid="app1-sensors-21-05256">Appendix A</xref>. Since there is variation in recording time, the number for sample points of the BOLD signals varies from one site to the other. Therefore, in order to work with the same length of data, the signal is truncated to the shortest sample point, which is 145 time points.</p>
      </sec>
      <sec id="sec2dot2-sensors-21-05256">
        <title>2.2. Statistical Analysis Using Power Spectral Density (PSD)</title>
        <p>The dimension of the BOLD time series for each subject is 145-points × 116-region. If the WCT between all brain nodes are to be used in this investigation, the number of scalogram images for each subject alone will be <inline-formula><mml:math id="mm1"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>115</mml:mn><mml:mo>×</mml:mo><mml:mn>116</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mn>6670</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> which is a large number of images. Furthermore, some of these images may not have a meaningful contribution in the classification of ASD subtypes, thus, would be detrimental to the classification performance. Therefore, a group-level statistical test is performed to select the most significant brain node based on the PSD of the BOLD signals. Power spectral density of the BOLD time-series signals is estimated using Welch method [<xref rid="B26-sensors-21-05256" ref-type="bibr">26</xref>].</p>
        <p>Detail of the steps for finding the top-ranked node using the mean value of PSD is given in Algorithm 1. The PSD values of each 116 brain regions determined using Welch are normalized to zero mean and standard deviation of 1. Normalization is deemed necessary here since the dataset is obtained from different sites, thus ensuring the reliability of the statistical analysis. Next, the average of the normalized PSD values are used as the input for one-way analysis of variance (ANOVA) test.
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1"><bold>Algorithm 1:</bold> Method of finding the top-ranked node in discriminating 3-level ASD subtypes and NC using mean value of PSD.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"><list list-type="simple"><list-item><label>1.</label><p>Input data = matrix (<inline-formula><mml:math id="mm2"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p><p><italic>m</italic> = 36 (number of subjects), <italic>n</italic> = 4 (number of group)</p></list-item><list-item><label>2.</label><p>BOLD signals = <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula></p><p><italic>t</italic> = time points, <inline-formula><mml:math id="mm4"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = node number (<italic>j</italic> = 1, 2, …, 116)</p></list-item><list-item><label>3.</label><p>PSD = estimate PSD for each BOLD signal</p></list-item><list-item><label>4.</label><p><inline-formula><mml:math id="mm5"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> = normalize and determine the average of the PSD values</p></list-item><list-item><label>5.</label><p><inline-formula><mml:math id="mm6"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> = cluster the outcome of (4) into matrix (<inline-formula><mml:math id="mm7"><mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>)</p></list-item><list-item><label>6.</label><p><italic>p</italic>-value = run ANOVA test for each cluster (<inline-formula><mml:math id="mm8"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>)</p><p>While j ≤ 116 repeat step 6</p><p>If <italic>p</italic>-value ≤ 0.05</p><p>save <italic>p</italic>-value at T</p><p>else T = empty</p></list-item><list-item><label>7.</label><p>F = Find top-ranked node based on T-index</p></list-item></list></td></tr></tbody></array></p>
      </sec>
      <sec id="sec2dot3-sensors-21-05256">
        <title>2.3. Wavelet Coherence of BOLD Time-Series Signals</title>
        <p>Wavelet coherence of two signals is a measure of linear interaction or correlation between the signals. Since the wavelet transform provides both time and frequency domain representation of signals, WCT measures the mean resultant vector length of the cross-spectral density between two signals. In another word, the WCT will provide the phase synchronization between the pairwise BOLD signals [<xref rid="B13-sensors-21-05256" ref-type="bibr">13</xref>,<xref rid="B27-sensors-21-05256" ref-type="bibr">27</xref>].</p>
        <p>Firstly, the time-frequency components for each BOLD signal were extracted by using a continuous wavelet transform (CWT). The CWT coefficient is defined as the convolution of the BOLD time series <inline-formula><mml:math id="mm9"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with the scaled and translated version of the mother wavelet <inline-formula><mml:math id="mm10"><mml:mrow><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> [<xref rid="B28-sensors-21-05256" ref-type="bibr">28</xref>], as shown in Equation (<xref ref-type="disp-formula" rid="FD1-sensors-21-05256">1</xref>).
<disp-formula id="FD1-sensors-21-05256"><label>(1)</label><mml:math id="mm11"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>W</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:mi>a</mml:mi></mml:msqrt></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mo>∞</mml:mo></mml:mrow><mml:mo>∞</mml:mo></mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>ψ</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mfenced separators="" open="(" close=")"><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:mfrac></mml:mfenced><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic>a</italic> denotes wavelet scale, <italic>b</italic> denotes positions and * denotes the complex conjugate [<xref rid="B29-sensors-21-05256" ref-type="bibr">29</xref>]. The complex Morlet wavelet was selected as the mother wavelet. Morlet has the best ratio (1.03) between frequency band and wavelet scale, which helps interpreting results in the frequency domain [<xref rid="B28-sensors-21-05256" ref-type="bibr">28</xref>]. CWT is becoming a popular method in biosignal analysis due to its ability to uncover meaningful information of non-stationary signals such as electroencephalogram (EEG) [<xref rid="B30-sensors-21-05256" ref-type="bibr">30</xref>] and BOLD fMRI signals [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>,<xref rid="B21-sensors-21-05256" ref-type="bibr">21</xref>]. In fact, WCT based on CWT, characterizes coherence measures between two signals at multiple time scales, essentially makes no assumption about the stationarity of the input signals. Accordingly, CWT has achieved reasonable trade-off between time and frequency components [<xref rid="B31-sensors-21-05256" ref-type="bibr">31</xref>,<xref rid="B32-sensors-21-05256" ref-type="bibr">32</xref>].</p>
        <p>In the subsequent step, the common power between the pairwise of BOLD signals <italic>x</italic>, <italic>y</italic> is measured at various scales <italic>a</italic> and time shift <italic>b</italic> by Equation (<xref ref-type="disp-formula" rid="FD2-sensors-21-05256">2</xref>):<disp-formula id="FD2-sensors-21-05256"><label>(2)</label><mml:math id="mm12"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm13"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm14"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denote the CWT of <italic>x</italic> and <italic>y</italic> at scales <italic>a</italic> and positions <italic>b</italic>, the superscript * is the complex conjugate, and <italic>S</italic> is a smoothing operator in time and scale.</p>
        <p>Then, the WCT between <italic>x</italic> and <italic>y</italic> is calculated by Equation (<xref ref-type="disp-formula" rid="FD3-sensors-21-05256">3</xref>):<disp-formula id="FD3-sensors-21-05256"><label>(3)</label><mml:math id="mm15"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mi>C</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∣</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mo>∣</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mo>∣</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mo>∣</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>The WCT coefficients were represented as 2-D images involving the phase synchronization features of pairwise BOLD signals called scalogram images and will be used as the input of CNN for classification.</p>
        <p>The scalogram image is a form of DFC between 2 BOLD signals, represented as phase synchronization patterns. In our proposed study, all coherent synchronicity features are represented as 224 × 224-pixel images and used as the input for CNN in binary and multi-class ASD classification models.</p>
        <p>These images are the WCT between the most significant node, as determined using ANOVA test with the rest of 115 brain regions. This pairwise calculation of WCT between the top-ranked node and 115 brain regions is illustrated in <xref ref-type="fig" rid="sensors-21-05256-f002">Figure 2</xref>, which will produce a total of 115 scalograms per subject.</p>
      </sec>
      <sec id="sec2dot4-sensors-21-05256">
        <title>2.4. Convolutional Neural Network (CNN)</title>
        <p>CNN is one of the essential deep neural networks related to applying local convolution filters for extracting regional information. CNNs are designed to process multiple data types, particularly two-dimensional variables, and are specifically influenced by the working principle of the brain’s visual cortex. There is a hierarchy of two basic cell types in the visual cortex: plain cells and complex cells. Simple cells respond to primitive patterns in visual stimulation sub-regions, and complex cells synthesize information from simple cells to recognize more complicated types. Since the visual cortex is such an efficient and normal visual processing device, CNNs are used to mimic three main ideas: local connectivity, position invariance, and local transformation invariance. Groups of local weighted sums, called feature maps, are obtained at the end convolution layer by computing convolutions between local patches and weight vectors called filters for extracting the strongly clustered sub-regions of features. In addition, because similar patterns may occur irrespective of the data position, filters are repeatedly implemented throughout the whole dataset, which often increases the accuracy of the trained network by minimizing the amount of parameters to be trained [<xref rid="B33-sensors-21-05256" ref-type="bibr">33</xref>]. In this work, We proposed a 3-layer CNN model for identifying ASD subtypes based on scalogram classification, using the CNN structure as shown in <xref ref-type="fig" rid="sensors-21-05256-f003">Figure 3</xref>.</p>
      </sec>
      <sec id="sec2dot5-sensors-21-05256">
        <title>2.5. Performance Evaluation Metric</title>
        <p>In order to analyze the performance of the proposed models, the following metrics (<xref ref-type="disp-formula" rid="FD4-sensors-21-05256">4</xref>) to (<xref ref-type="disp-formula" rid="FD8-sensors-21-05256">8</xref>) were chosen. True positive (TP) is the number of ASD patients, and true negative (TN) is the number of NC individuals correctly identified. Conversely, false positive (FP) is the number of ASD patients, and false negative (FN) is the number of NC individuals incorrectly identified.
<disp-formula id="FD4-sensors-21-05256"><label>(4)</label><mml:math id="mm16"><mml:mrow><mml:mrow><mml:mi>Precision</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD5-sensors-21-05256"><label>(5)</label><mml:math id="mm17"><mml:mrow><mml:mrow><mml:mi>Sensitivity</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD6-sensors-21-05256"><label>(6)</label><mml:math id="mm18"><mml:mrow><mml:mrow><mml:mi>Specificity</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD7-sensors-21-05256"><label>(7)</label><mml:math id="mm19"><mml:mrow><mml:mrow><mml:mi>Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD8-sensors-21-05256"><label>(8)</label><mml:math id="mm20"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mo>−</mml:mo><mml:mi>score</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p>The sensitivity measures the effectiveness of proposed models to identify ASD patients correctly, and the specificity measures the effectiveness of models to identify NC individuals. Accuracy is the percentage of total effectiveness of a model. To evaluate our proposed models practically like in clinical set up, we calculate precision and F-score, respectively. The precision refers to the percentage of compatibility between the actual ASD patient class and patient class identified by the model. F-score is calculated from the precision and sensitivity of the model. The highest possible value of an F-score is indicating a perfect model performance.</p>
        <p>Moreover, to analyze the general classification performance of multi-class models, we have chosen the macro-average evaluation, which makes an averaging calculation by class, not the subjects. The macro-average reduces the multi-class identifications down to multiple sets of binary classification, calculates the corresponding metric for each of the binary cases, and then averages the results [<xref rid="B34-sensors-21-05256" ref-type="bibr">34</xref>].</p>
      </sec>
    </sec>
    <sec sec-type="results" id="sec3-sensors-21-05256">
      <title>3. Results and Discussion</title>
      <p>In this section, the performance of ASD classification algorithms using wavelet coherence of rs-fMRI signals and CNN are evaluated. Two frameworks are experimented, binary classification (ASD and NC) and multi-class classification (ASD, APD, PDD-NOS, and NC). Prior to the classification, the most significant brain nodes need to be determined to ensure meaningful wavelet coherence features are input to the CNN.</p>
      <sec id="sec3dot1-sensors-21-05256">
        <title>3.1. Selection of Top-Ranked Brain Node for Classification of ASD Subtypes via Statistical Analysis</title>
        <p>As the first step in a statistical significance test, the mean PSD values of BOLD signals from 116 brain regions are determined as the input to group-level statistical significance tests. Results of the <italic>p</italic>-value are tabulated in <xref rid="sensors-21-05256-t0A1" ref-type="table">Table A1</xref>, under <xref ref-type="app" rid="app1-sensors-21-05256">Appendix A</xref>. From the <italic>p</italic>-value, it can be revealed that putamen_R node is the most significant node in discriminating the 3 ASD classes and NC. The location of putamen_R node, the 2nd (caudate nucleus_L) and 3rd ranked nodes (superior temporal gyrus_L), are shown in <xref ref-type="fig" rid="sensors-21-05256-f004">Figure 4</xref>. Further analysis on the PSD values of putamen_R node is shown as a boxplot in <xref ref-type="fig" rid="sensors-21-05256-f005">Figure 5</xref>. From the boxplot, it is clear that the PSD value is the highest for ASD among the 4 groups, while the lowest is for NC. These results indicate that there is significant variation of PSD based on putamen_R activity.</p>
        <p>In other words, it is indicative that the top-ranked node activity plays an essential role in ASD subtypes classification. The results in this section corroborate the findings in neuroscience studies which reveal that the putamen and caudate are part of the basal ganglia group primarily responsible for motor learning, executive functions, behaviors, and emotions. Several neuroscience studies [<xref rid="B1-sensors-21-05256" ref-type="bibr">1</xref>,<xref rid="B35-sensors-21-05256" ref-type="bibr">35</xref>,<xref rid="B36-sensors-21-05256" ref-type="bibr">36</xref>] demonstrated that the volume in the brain region of putamen node increase in the patients with ASD, followed by the volume differences in the brain region of putamen node among ASD subtypes might reflect the variations of the symptoms of ASD.</p>
      </sec>
      <sec id="sec3dot2-sensors-21-05256">
        <title>3.2. Binary Classification Using Wavelet Coherence of Top Three Significant Nodes</title>
        <p>In the first experiment, we evaluated the significance of wavelet coherence features extracted from top-three nodes; putamen_R, caudate nucleus_L, superior temporal gyrus_L, and their combinations. Evaluation is conducted for discriminating ASD from NC using the proposed 3-layer CNN with the following training parameters: batch size = 32, epochs = 20, learning rate = 0.0005, adaptive moment estimation (ADAM) optimizer and ratio of training:validation:testing = 0.7:0.15:0.15.</p>
        <p>The results for this experiment are presented in <xref rid="sensors-21-05256-t002" ref-type="table">Table 2</xref> where for single-node cases, the best accuracy is 89.2% by the top-ranked node putamen_R which is consistent with the result from ANOVA test, as presented in <xref ref-type="sec" rid="sec3dot1-sensors-21-05256">Section 3.1</xref>. As expected, the accuracy values for the 2nd and 3rd ranked nodes are both lower than the 1st node.</p>
        <p>In the case of combined nodes, although more images are available for training and testing the CNN, the results show that it cannot exceed the performance of the 1st-node. Notably, 1st + 2nd nodes yielded the highest accuracy higher than 2nd and 3rd nodes alone but still lower than the 1st node alone. Subsequent combinations of 1st + 3rd nodes and 1st + 2nd + 3rd nodes still produce lower accuracy than the 1st node. Additionally, despite larger training images for combined nodes, the additional images do not carry meaningful features for discriminating ASD from normal NC</p>
      </sec>
      <sec id="sec3dot3-sensors-21-05256">
        <title>3.3. Binary Classification Using Wavelet Coherence of Putamen_R Node</title>
        <p>In this section, the Putamen_R node will be used for classification of ASD from NC. Except for the cross-validation (CV) framework, the CNN training parameters are the same as in the previous section. The training of the CNN is tested using 3 optimizers, root mean square propagation (RMSPROP), stochastic gradient descent with momentum (SGDM), and adaptive moment estimation (ADAM), and the results for different values of folds are presented in <xref rid="sensors-21-05256-t003" ref-type="table">Table 3</xref>. From the values of accuracy, sensitivity, specificity, precision, and F-score, it is evident that ADAM optimizer results in the best result for k-fold CV, thus, the subsequent experiments are conducted using ADAM optimizer. Evaluation of the proposed algorithm is further tested using k-fold cross validation and the result is tabulated in <xref rid="sensors-21-05256-t004" ref-type="table">Table 4</xref>. As expected, the performance improved as the number of fold increases. However, it is notable that only marginal improvement is achieved as the fold number is increased from 10 to 15 and 20.</p>
        <p>Since the rs-fMRI data were aggregated across ABIDE’s multi-site, validation technique based on leave one-site-out is used to investigate how well the CNN model generalized over different datasets. The results of this experiment are presented in <xref rid="sensors-21-05256-t005" ref-type="table">Table 5</xref>. With average accuracy of <inline-formula><mml:math id="mm21"><mml:mrow><mml:mrow><mml:mn>86.8</mml:mn><mml:mo>±</mml:mo><mml:mn>0.7</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> the proposed binary classification model is considered as robust against the effects of different types of MRI scanners and scanning parameters, as listed in <xref rid="sensors-21-05256-t001" ref-type="table">Table 1</xref>.</p>
        <p>Further performance comparison for binary classification of ASD vs. NC with other related work is presented in <xref rid="sensors-21-05256-t006" ref-type="table">Table 6</xref>. Methods based on static FC of Pearson correlation [<xref rid="B10-sensors-21-05256" ref-type="bibr">10</xref>,<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>,<xref rid="B17-sensors-21-05256" ref-type="bibr">17</xref>] and of covariance matrix [<xref rid="B16-sensors-21-05256" ref-type="bibr">16</xref>] can only yield the highest accuracy of 79.2%, inferior to the dynamic FC. Our proposed method that inputs WCT of putamen_R and 115 brain regions to CNN has shown to result in a good accuracy of 89.8%, that is 9.8% higher than the dynamic FC based method proposed by Bernas et al. [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>]. Although Bernas et al. [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>] used the same WCT, the calculation of the WCT is between 7 brain networks and only in-phase components are input to the SVM classifier.</p>
      </sec>
      <sec id="sec3dot4-sensors-21-05256">
        <title>3.4. Multi-Class Classification</title>
        <p>In the last experiment, the proposed model is trained for multi-class classification of 3-level ASD and NC taking scalogram images for four groups as its input. To evaluate the performance of the proposed CNN model, the scalogram data is divided into 0.7 as training dataset, 0.15 as validation dataset and 0.15 as testing datasets. The rest of the training parameters are the same as in <xref ref-type="sec" rid="sec3dot2-sensors-21-05256">Section 3.2</xref>. The proposed CNN is trained using ADAM, SGDM, and RMSPROP optimizer and the results for each optimizer are presented in <xref rid="sensors-21-05256-t007" ref-type="table">Table 7</xref>. The best performance is achieved by the proposed CNN with ADAM optimizer giving macro-average accuracy 82.1%. Detailed performance of each class is presented in the confusion matrix, as shown in <xref ref-type="fig" rid="sensors-21-05256-f006">Figure 6</xref>. It is worth highlighting that to date, the ASD subtypes classification has not been done in literature so in this first attempt, with macro-average accuracy 82.1%, there are still opportunities for further enhancements to the classification algorithm.</p>
      </sec>
    </sec>
    <sec sec-type="conclusions" id="sec4-sensors-21-05256">
      <title>4. Conclusions and Future Works</title>
      <p>In this study, we proposed scalogram-based classification models using the CNN to identify ASD subtypes. The scalogram is generated based on wavelet coherence of pairwise rs-fMRI BOLD signals of top-rank node and the rest of 115 brain nodes. The multi-class datasets of ASD subtypes comprising 144 subjects are downloaded from the multi-site of ABIDE website. Using statistical significance analysis of mean PSD values, putamen_R node is identified as the most significant node. The WCT scalograms of putamen_R and the rest of 115 nodes are then used as the input for training and testing the 3-layer CNN model. In general, the WCT of pairwise BOLD signals is a 2D feature representation that measures the phase synchronization between putamen_R to other brain nodes. Clearly, the extracted feature is proven to be a discriminative BOLD signals descriptor for ASD subtypes and may be a potential biomarker for diagnosis of ASD. The accuracy of 89.8% for binary and 82.1% for multi-class classification, are obtained based on BOLD signals combined from all subjects in respective class, which may not give true measure of its performance for subject-based diagnosis. Therefore, training and testing the CNN on subject-based needs to be investigated for assessment of its diagnostic ability as in clinical practices. In addition, further investigation to improve its performance may consider utilizing different brain atlases, such as Craddock (CC200, CC400) that extract more information from the BOLD signals. Besides, the scalogram images can also be trained and tested on other CNN architecture, such as residual or inception blocks for better classification of ASD subtypes. Lastly, the phase synchronization between one significant brain node to the rest may also be applied for classification of other neuropsychiatric disorders such as ADHD, bipolar disorders, and schizophrenia. The present study approach of using WCT as DFC of rs-fMRI BOLD signals opens a possibility for further research on new biomarkers of psychiatric disorders.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>We would like to thank Irraivan Elamvazuthi for providing some funding and valuable suggestions to the paper.</p>
    </ack>
    <fn-group>
      <fn>
        <p><bold>Publisher’s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
      </fn>
    </fn-group>
    <notes>
      <title>Author Contributions</title>
      <p>M.I.A.-H. conducted the research and investigation process, finalized the methodology, proposed algorithm &amp; result analysis, and completed the manuscript writing. N.Y. formulated the research goal, provided supervision, validation of results &amp; methodology, revision of manuscript, management of funding for the project. I.F. provided some valuable suggestions and supervision. A.F.H. involved in writing, reviewing and editing the final manuscript. All authors have read and agreed to the published version of the manuscript.</p>
    </notes>
    <notes>
      <title>Funding</title>
      <p>TThis research is supported by three research grants: (1) The Ministry of Education Malaysia under Higher Institutional Centre of Excellence (HICoE) Scheme awarded to Centre for Intelligent Signal and Imaging Research (CISIR), and two of the Yayasan Universiti Teknologi PETRONAS under Grant number (2) YUTP-FRG 015LC0-031 and (3) YUTP-FRG 015LC0-243.</p>
    </notes>
    <notes>
      <title>Institutional Review Board Statement</title>
      <p>Not applicable.</p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      <p>Not applicable.</p>
    </notes>
    <notes notes-type="data-availability">
      <title>Data Availability Statement</title>
      <p>Not applicable.</p>
    </notes>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>Authors declare that they have no conflict of interest to report regarding the present study.</p>
    </notes>
    <app-group>
      <app id="app1-sensors-21-05256">
        <title>Appendix A</title>
        <table-wrap id="sensors-21-05256-t0A1" orientation="portrait" position="anchor">
          <object-id pub-id-type="pii">sensors-21-05256-t0A1_Table A1</object-id>
          <label>Table A1</label>
          <caption>
            <p><italic>p</italic>-Value for all brain nodes based on ANOVA test.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">No.</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Region Label</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1"><italic>p</italic>-Value</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">No.</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Region Label</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1"><italic>p</italic>-Value</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">No.</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Region Label</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1"><italic>p</italic>-Value</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">No.</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Region Label</th>
                <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1"><italic>p</italic>-Value</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">1</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Precentral_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.191</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">31</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cingulum_Ant_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.485</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">61</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Parietal_Inf_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.971</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">91</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_Crus1_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.570</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">2</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Precentral_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.115</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">32</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cingulum_Ant_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.911</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">62</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Parietal_Inf_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.862</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">92</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_Crus1_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.862</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">3</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Sup_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.061</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">33</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cingulum_Mid_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.653</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">63</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">SupraMarginal_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.912</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">93</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_Crus2_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.352</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">4</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Sup_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.138</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">34</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cingulum_Mid_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.820</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">64</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">SupraMarginal_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.162</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">94</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_Crus2_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.662</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">5</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Sup_Orb_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.052</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">35</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cingulum_Post_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.998</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">65</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Angular_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.452</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">95</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_3_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.010</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">6</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Sup_Orb_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.294</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">36</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cingulum_Post_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.146</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">66</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Angular_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.414</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">96</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_3_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.539</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">7</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Mid_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.365</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">37</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Hippocampus_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.847</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">67</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Precuneus_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.890</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">97</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_4_5_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.653</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">8</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Mid_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.333</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">38</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Hippocampus_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.389</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">68</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Precuneus_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.396</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">98</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_4_5_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.412</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">9</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Mid_Orb_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.733</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">39</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">ParaHippocampal_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.052</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">69</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Paracentral_Lobule_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.771</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">99</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_6_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.425</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">10</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Mid_Orb_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.779</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">40</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">ParaHippocampal_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.455</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">70</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Paracentral_Lobule_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.910</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">100</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_6_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.868</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">11</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Inf_Oper_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.800</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">41</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Amygdala_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.176</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">71</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Caudate_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.012</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">101</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_7b_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.044</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">12</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Inf_Oper_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.470</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">42</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Amygdala_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.386</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">72</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Caudate_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.279</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">102</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_7b_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.423</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">13</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Inf_Tri_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.300</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">43</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Calcarine_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.490</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">73</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Putamen_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.143</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">103</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_8_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.951</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">14</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Inf_Tri_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.417</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">44</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Calcarine_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.714</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">74</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Putamen_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.008</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">104</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_8_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.900</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">15</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Inf_Orb_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.283</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">45</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cuneus_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.732</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">75</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Pallidum_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.646</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">105</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_9_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.836</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">16</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Inf_Orb_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.973</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">46</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cuneus_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.750</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">76</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Pallidum_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.561</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">106</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_9_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.096</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">17</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Rolandic_Oper_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.075</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">47</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Lingual_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.685</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">77</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Thalamus_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.990</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">107</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_10_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.903</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">18</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Rolandic_Oper_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.131</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">48</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Lingual_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.256</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">78</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Thalamus_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.594</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">108</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Cerebelum_10_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.836</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">19</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Supp_Motor_Area_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.698</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">49</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Occipital_Sup_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.615</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">79</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Heschl_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.095</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">109</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_1_2</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.649</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">20</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Supp_Motor_Area_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.473</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">50</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Occipital_Sup_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.608</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">80</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Heschl_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.160</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">110</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_3</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.329</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">21</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Olfactory_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.982</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">51</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Occipital_Mid_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.514</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">81</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Sup_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.045</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">111</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_4_5</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.762</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">22</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Olfactory_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.913</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">52</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Occipital_Mid_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.090</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">82</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Sup_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.830</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">112</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_6</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.772</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">23</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Sup_Medial_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.340</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">53</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Occipital_Inf_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.487</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">83</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Pole_Sup_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.070</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">113</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_7</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.738</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">24</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Sup_Medial_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.183</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">54</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Occipital_Inf_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.282</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">84</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Pole_Sup_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.917</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">114</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_8</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.867</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">25</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Med_Orb_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.928</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">55</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Fusiform_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.749</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">85</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Mid_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.900</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">115</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_9</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.592</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">26</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Frontal_Med_Orb_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.769</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">56</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Fusiform_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.938</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">86</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Mid_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.113</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">116</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Vermis_10</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.272</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">27</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Rectus_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.096</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">57</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Postcentral_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.878</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">87</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Pole_Mid_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.364</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">28</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Rectus_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.871</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">58</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Postcentral_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.108</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">88</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Pole_Mid_R</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.860</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
              </tr>
              <tr>
                <td align="left" valign="middle" rowspan="1" colspan="1">29</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Insula_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.075</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">59</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Parietal_Sup_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.984</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">89</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">Temporal_Inf_L</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">0.566</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" rowspan="1" colspan="1">
</td>
              </tr>
              <tr>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">30</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Insula_R</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.744</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">60</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Parietal_Sup_R</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.144</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Temporal_Inf_R</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.343</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td>
                <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </app>
    </app-group>
    <ref-list>
      <title>References</title>
      <ref id="B1-sensors-21-05256">
        <label>1.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pagnozzi</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Conti</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Calderoni</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Fripp</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Rose</surname>
              <given-names>S.E.</given-names>
            </name>
          </person-group>
          <article-title>A systematic review of structural MRI biomarkers in autism spectrum disorder: A machine learning perspective</article-title>
          <source>Int. J. Dev. Neurosci.</source>
          <year>2018</year>
          <volume>71</volume>
          <fpage>68</fpage>
          <lpage>82</lpage>
          <pub-id pub-id-type="doi">10.1016/j.ijdevneu.2018.08.010</pub-id>
          <pub-id pub-id-type="pmid">30172895</pub-id>
        </element-citation>
      </ref>
      <ref id="B2-sensors-21-05256">
        <label>2.</label>
        <element-citation publication-type="web">
          <article-title>Autism Spectrum Disorders</article-title>
          <comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/news-room/fact-sheets/detail/autism-spectrum-disorders">https://www.who.int/news-room/fact-sheets/detail/autism-spectrum-disorders</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-02-07">(accessed on 7 February 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B3-sensors-21-05256">
        <label>3.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hansen</surname>
              <given-names>S.N.</given-names>
            </name>
            <name>
              <surname>Schendel</surname>
              <given-names>D.E.</given-names>
            </name>
            <name>
              <surname>Parner</surname>
              <given-names>E.T.</given-names>
            </name>
          </person-group>
          <article-title>Explaining the increase in the prevalence of autism spectrum disorders: The proportion attributable to changes in reporting practices</article-title>
          <source>JAMA Pediatr.</source>
          <year>2015</year>
          <volume>169</volume>
          <fpage>56</fpage>
          <lpage>62</lpage>
          <pub-id pub-id-type="doi">10.1001/jamapediatrics.2014.1893</pub-id>
          <pub-id pub-id-type="pmid">25365033</pub-id>
        </element-citation>
      </ref>
      <ref id="B4-sensors-21-05256">
        <label>4.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Witwer</surname>
              <given-names>A.N.</given-names>
            </name>
            <name>
              <surname>Lecavalier</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Examining the validity of autism spectrum disorder subtypes</article-title>
          <source>J. Autism Dev. Disord.</source>
          <year>2008</year>
          <volume>38</volume>
          <fpage>1611</fpage>
          <lpage>1624</lpage>
          <pub-id pub-id-type="doi">10.1007/s10803-008-0541-2</pub-id>
          <pub-id pub-id-type="pmid">18327636</pub-id>
        </element-citation>
      </ref>
      <ref id="B5-sensors-21-05256">
        <label>5.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mazurek</surname>
              <given-names>M.O.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Symecko</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Butter</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Bing</surname>
              <given-names>N.M.</given-names>
            </name>
            <name>
              <surname>Hundley</surname>
              <given-names>R.J.</given-names>
            </name>
            <name>
              <surname>Poulsen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kanne</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Macklin</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Handen</surname>
              <given-names>B.L.</given-names>
            </name>
          </person-group>
          <article-title>A prospective study of the concordance of DSM-IV and DSM-5 diagnostic criteria for autism spectrum disorder</article-title>
          <source>J. Autism Dev. Disord.</source>
          <year>2017</year>
          <volume>47</volume>
          <fpage>2783</fpage>
          <lpage>2794</lpage>
          <pub-id pub-id-type="doi">10.1007/s10803-017-3200-7</pub-id>
          <pub-id pub-id-type="pmid">28620892</pub-id>
        </element-citation>
      </ref>
      <ref id="B6-sensors-21-05256">
        <label>6.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Conti</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Mitra</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Calderoni</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Pannek</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Pagnozzi</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Rose</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mazzotti</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Scelfo</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Tosetti</surname>
              <given-names>M.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Network over-connectivity differentiates autism spectrum disorder from other developmental disorders in toddlers: A diffusion MRI study</article-title>
          <source>Hum. Brain Mapp.</source>
          <year>2017</year>
          <volume>38</volume>
          <fpage>2333</fpage>
          <lpage>2344</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.23520</pub-id>
          <pub-id pub-id-type="pmid">28094463</pub-id>
        </element-citation>
      </ref>
      <ref id="B7-sensors-21-05256">
        <label>7.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Thabtah</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Machine learning in autistic spectrum disorder behavioral research: A review and ways forward</article-title>
          <source>Inform. Health Soc. Care</source>
          <year>2019</year>
          <volume>44</volume>
          <fpage>278</fpage>
          <lpage>297</lpage>
          <pub-id pub-id-type="doi">10.1080/17538157.2017.1399132</pub-id>
          <pub-id pub-id-type="pmid">29436887</pub-id>
        </element-citation>
      </ref>
      <ref id="B8-sensors-21-05256">
        <label>8.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yin</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>F.X.</given-names>
            </name>
          </person-group>
          <article-title>Deep learning for brain disorder diagnosis based on fMRI images</article-title>
          <source>Neurocomputing</source>
          <year>2020</year>
          <pub-id pub-id-type="doi">10.1016/j.neucom.2020.05.113</pub-id>
        </element-citation>
      </ref>
      <ref id="B9-sensors-21-05256">
        <label>9.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kassraian-Fard</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Matthis</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Balsters</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Maathuis</surname>
              <given-names>M.H.</given-names>
            </name>
            <name>
              <surname>Wenderoth</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Promises, pitfalls, and basic guidelines for applying machine learning classifiers to psychiatric imaging data, with autism as an example</article-title>
          <source>Front. Psychiatry</source>
          <year>2016</year>
          <volume>7</volume>
          <fpage>177</fpage>
          <pub-id pub-id-type="doi">10.3389/fpsyt.2016.00177</pub-id>
          <pub-id pub-id-type="pmid">27990125</pub-id>
        </element-citation>
      </ref>
      <ref id="B10-sensors-21-05256">
        <label>10.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sherkatghanad</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Akhondzadeh</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Salari</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Zomorodi-Moghadam</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Abdar</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Acharya</surname>
              <given-names>U.R.</given-names>
            </name>
            <name>
              <surname>Khosrowabadi</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Salari</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Automated detection of autism spectrum disorder using a convolutional neural network</article-title>
          <source>Front. Neurosci.</source>
          <year>2020</year>
          <volume>13</volume>
          <fpage>1325</fpage>
          <pub-id pub-id-type="doi">10.3389/fnins.2019.01325</pub-id>
          <pub-id pub-id-type="pmid">32009868</pub-id>
        </element-citation>
      </ref>
      <ref id="B11-sensors-21-05256">
        <label>11.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Iidaka</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Resting state functional magnetic resonance imaging and neural network classified autism and control</article-title>
          <source>Cortex</source>
          <year>2015</year>
          <volume>63</volume>
          <fpage>55</fpage>
          <lpage>67</lpage>
          <pub-id pub-id-type="doi">10.1016/j.cortex.2014.08.011</pub-id>
          <pub-id pub-id-type="pmid">25243989</pub-id>
        </element-citation>
      </ref>
      <ref id="B12-sensors-21-05256">
        <label>12.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Heinsfeld</surname>
              <given-names>A.S.</given-names>
            </name>
            <name>
              <surname>Franco</surname>
              <given-names>A.R.</given-names>
            </name>
            <name>
              <surname>Craddock</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Buchweitz</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Meneguzzi</surname>
              <given-names>F.</given-names>
            </name>
          </person-group>
          <article-title>Identification of autism spectrum disorder using deep learning and the ABIDE dataset</article-title>
          <source>NeuroImage Clin.</source>
          <year>2018</year>
          <volume>17</volume>
          <fpage>16</fpage>
          <lpage>23</lpage>
          <pub-id pub-id-type="doi">10.1016/j.nicl.2017.08.017</pub-id>
          <pub-id pub-id-type="pmid">29034163</pub-id>
        </element-citation>
      </ref>
      <ref id="B13-sensors-21-05256">
        <label>13.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hutchison</surname>
              <given-names>R.M.</given-names>
            </name>
            <name>
              <surname>Womelsdorf</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Allen</surname>
              <given-names>E.A.</given-names>
            </name>
            <name>
              <surname>Bandettini</surname>
              <given-names>P.A.</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>V.D.</given-names>
            </name>
            <name>
              <surname>Corbetta</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Della Penna</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Duyn</surname>
              <given-names>J.H.</given-names>
            </name>
            <name>
              <surname>Glover</surname>
              <given-names>G.H.</given-names>
            </name>
            <name>
              <surname>Gonzalez-Castillo</surname>
              <given-names>J.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Dynamic functional connectivity: Promise, issues, and interpretations</article-title>
          <source>Neuroimage</source>
          <year>2013</year>
          <volume>80</volume>
          <fpage>360</fpage>
          <lpage>378</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.079</pub-id>
          <pub-id pub-id-type="pmid">23707587</pub-id>
        </element-citation>
      </ref>
      <ref id="B14-sensors-21-05256">
        <label>14.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Menon</surname>
              <given-names>S.S.</given-names>
            </name>
            <name>
              <surname>Krishnamurthy</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>A comparison of static and dynamic functional connectivities for identifying subjects and biological sex using intrinsic individual brain connectivity</article-title>
          <source>Sci. Rep.</source>
          <year>2019</year>
          <volume>9</volume>
          <fpage>1</fpage>
          <lpage>11</lpage>
          <pub-id pub-id-type="doi">10.1038/s41598-019-42090-4</pub-id>
          <pub-id pub-id-type="pmid">30626917</pub-id>
        </element-citation>
      </ref>
      <ref id="B15-sensors-21-05256">
        <label>15.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yahata</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Kasai</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Kawato</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Computational neuroscience approach to biomarkers and treatments for mental disorders</article-title>
          <source>Psychiatry Clin. Neurosci.</source>
          <year>2017</year>
          <volume>71</volume>
          <fpage>215</fpage>
          <lpage>237</lpage>
          <pub-id pub-id-type="doi">10.1111/pcn.12502</pub-id>
          <pub-id pub-id-type="pmid">28032396</pub-id>
        </element-citation>
      </ref>
      <ref id="B16-sensors-21-05256">
        <label>16.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chen</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Duan</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Uddin</surname>
              <given-names>L.Q.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Multivariate classification of autism spectrum disorder using frequency-specific resting-state functional connectivity—A multi-center study</article-title>
          <source>Prog. Neuro-Psychopharmacol. Biol. Psychiatry</source>
          <year>2016</year>
          <volume>64</volume>
          <fpage>1</fpage>
          <lpage>9</lpage>
          <pub-id pub-id-type="doi">10.1016/j.pnpbp.2015.06.014</pub-id>
        </element-citation>
      </ref>
      <ref id="B17-sensors-21-05256">
        <label>17.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Abraham</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Di Martino</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Craddock</surname>
              <given-names>R.C.</given-names>
            </name>
            <name>
              <surname>Samaras</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Deriving reproducible biomarkers from multi-site resting-state data: An Autism-based example</article-title>
          <source>NeuroImage</source>
          <year>2017</year>
          <volume>147</volume>
          <fpage>736</fpage>
          <lpage>745</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.045</pub-id>
          <pub-id pub-id-type="pmid">27865923</pub-id>
        </element-citation>
      </ref>
      <ref id="B18-sensors-21-05256">
        <label>18.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chaitra</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Vijaya</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Deshpande</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Diagnostic prediction of autism spectrum disorder using complex network measures in a machine learning framework</article-title>
          <source>Biomed. Signal Process. Control</source>
          <year>2020</year>
          <volume>62</volume>
          <fpage>102099</fpage>
          <pub-id pub-id-type="doi">10.1016/j.bspc.2020.102099</pub-id>
        </element-citation>
      </ref>
      <ref id="B19-sensors-21-05256">
        <label>19.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bernas</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Aldenkamp</surname>
              <given-names>A.P.</given-names>
            </name>
            <name>
              <surname>Zinger</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Wavelet coherence-based classifier: A resting-state functional MRI study on neurodynamics in adolescents with high-functioning autism</article-title>
          <source>Comput. Methods Programs Biomed.</source>
          <year>2018</year>
          <volume>154</volume>
          <fpage>143</fpage>
          <lpage>151</lpage>
          <pub-id pub-id-type="doi">10.1016/j.cmpb.2017.11.017</pub-id>
          <pub-id pub-id-type="pmid">29249338</pub-id>
        </element-citation>
      </ref>
      <ref id="B20-sensors-21-05256">
        <label>20.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yu</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>T.R.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>X.</given-names>
            </name>
          </person-group>
          <article-title>Simulation data driven weakly supervised adversarial domain adaptation approach for intelligent cross-machine fault diagnosis</article-title>
          <source>Struct. Health Monit.</source>
          <year>2021</year>
          <volume>20</volume>
          <pub-id pub-id-type="doi">10.1177/1475921720980718</pub-id>
        </element-citation>
      </ref>
      <ref id="B21-sensors-21-05256">
        <label>21.</label>
        <element-citation publication-type="confproc">
          <person-group person-group-type="author">
            <name>
              <surname>Al-Hiyali</surname>
              <given-names>M.I.</given-names>
            </name>
            <name>
              <surname>Yahya</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Faye</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Alsaih</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Classification of BOLD FMRI signals using wavelet transform and transfer learning for detection of autism spectrum disorder</article-title>
          <source>Proceedings of the 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES)</source>
          <conf-loc>Langkawi Island, Malaysia</conf-loc>
          <conf-date>1–3 March 2021</conf-date>
          <fpage>94</fpage>
          <lpage>98</lpage>
          <pub-id pub-id-type="doi">10.1109/IECBES48179.2021.9398803</pub-id>
        </element-citation>
      </ref>
      <ref id="B22-sensors-21-05256">
        <label>22.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhai</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Koriche</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Tracking sparse linear classifiers</article-title>
          <source>IEEE Trans. Neural Netw. Learn. Syst.</source>
          <year>2018</year>
          <volume>30</volume>
          <fpage>2079</fpage>
          <lpage>2092</lpage>
          <pub-id pub-id-type="doi">10.1109/TNNLS.2018.2877433</pub-id>
          <pub-id pub-id-type="pmid">30442619</pub-id>
        </element-citation>
      </ref>
      <ref id="B23-sensors-21-05256">
        <label>23.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Billings</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Eder</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Flood</surname>
              <given-names>W.C.</given-names>
            </name>
            <name>
              <surname>Dhami</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Natarajan</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Whitlow</surname>
              <given-names>C.T.</given-names>
            </name>
          </person-group>
          <article-title>Machine learning applications to resting-state functional (MR) imaging analysis</article-title>
          <source>Neuroimaging Clin.</source>
          <year>2017</year>
          <volume>27</volume>
          <fpage>609</fpage>
          <lpage>620</lpage>
          <pub-id pub-id-type="doi">10.1016/j.nic.2017.06.010</pub-id>
        </element-citation>
      </ref>
      <ref id="B24-sensors-21-05256">
        <label>24.</label>
        <element-citation publication-type="web">
          <person-group person-group-type="author">
            <name>
              <surname>Craddock</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Benhajali</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Chu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Chouinard</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Evans</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Jakab</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Khundrakpam</surname>
              <given-names>B.S.</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>M.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>The neuro bureau preprocessing initiative: Open sharing of preprocessed neuroimaging data and derivatives</article-title>
          <source>Front. Neuroinform.</source>
          <year>2013</year>
          <comment>Available online: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/10.3389/conf.fninf.2013.09.00041/event_abstract">https://www.frontiersin.org/10.3389/conf.fninf.2013.09.00041/event_abstract</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-07-28">(accessed on 28 July 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B25-sensors-21-05256">
        <label>25.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yan</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Zang</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>(DPARSF): A MATLAB toolbox for pipeline data analysis of resting-state (fMRI)</article-title>
          <source>Front. Syst. Neurosci.</source>
          <year>2010</year>
          <volume>4</volume>
          <fpage>13</fpage>
          <pub-id pub-id-type="doi">10.3389/fnsys.2010.00013</pub-id>
          <pub-id pub-id-type="pmid">20577591</pub-id>
        </element-citation>
      </ref>
      <ref id="B26-sensors-21-05256">
        <label>26.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yuan</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Huang</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Yang</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Quantification of the power changes in BOLD signals using Welch spectrum method during different single-hand motor imageries</article-title>
          <source>Magn. Reson. Imaging</source>
          <year>2014</year>
          <volume>32</volume>
          <fpage>1307</fpage>
          <lpage>1313</lpage>
          <pub-id pub-id-type="doi">10.1016/j.mri.2014.08.018</pub-id>
          <pub-id pub-id-type="pmid">25159473</pub-id>
        </element-citation>
      </ref>
      <ref id="B27-sensors-21-05256">
        <label>27.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cribben</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Haraldsdottir</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Atlas</surname>
              <given-names>L.Y.</given-names>
            </name>
            <name>
              <surname>Wager</surname>
              <given-names>T.D.</given-names>
            </name>
            <name>
              <surname>Lindquist</surname>
              <given-names>M.A.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic connectivity regression: Determining state-related changes in brain connectivity</article-title>
          <source>Neuroimage</source>
          <year>2012</year>
          <volume>61</volume>
          <fpage>907</fpage>
          <lpage>920</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.070</pub-id>
          <pub-id pub-id-type="pmid">22484408</pub-id>
        </element-citation>
      </ref>
      <ref id="B28-sensors-21-05256">
        <label>28.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Torrence</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Compo</surname>
              <given-names>G.P.</given-names>
            </name>
          </person-group>
          <article-title>A practical guide to wavelet analysis</article-title>
          <source>Bull. Am. Meteorol. Soc.</source>
          <year>1998</year>
          <volume>79</volume>
          <fpage>61</fpage>
          <lpage>78</lpage>
          <pub-id pub-id-type="doi">10.1175/1520-0477(1998)079&lt;0061:APGTWA&gt;2.0.CO;2</pub-id>
        </element-citation>
      </ref>
      <ref id="B29-sensors-21-05256">
        <label>29.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morabito</surname>
              <given-names>F.C.</given-names>
            </name>
            <name>
              <surname>Campolo</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Mammone</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Versaci</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Franceschetti</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tagliavini</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Sofia</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Fatuzzo</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Gambardella</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Labate</surname>
              <given-names>A.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Deep learning representation from electroencephalography of early-stage Creutzfeldt-Jakob disease and features for differentiation from rapidly progressive dementia</article-title>
          <source>Int. J. Neural Syst.</source>
          <year>2017</year>
          <volume>27</volume>
          <fpage>1650039</fpage>
          <pub-id pub-id-type="doi">10.1142/S0129065716500398</pub-id>
          <pub-id pub-id-type="pmid">27440465</pub-id>
        </element-citation>
      </ref>
      <ref id="B30-sensors-21-05256">
        <label>30.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yahya</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Musa</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Ong</surname>
              <given-names>Z.Y.</given-names>
            </name>
            <name>
              <surname>Elamvazuthi</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Classification of Motor Functions from Electroencephalogram (EEG) Signals Based on an Integrated Method Comprised of Common Spatial Pattern and Wavelet Transform Framework</article-title>
          <source>Sensors</source>
          <year>2019</year>
          <volume>19</volume>
          <elocation-id>4878</elocation-id>
          <pub-id pub-id-type="doi">10.3390/s19224878</pub-id>
          <pub-id pub-id-type="pmid">31717412</pub-id>
        </element-citation>
      </ref>
      <ref id="B31-sensors-21-05256">
        <label>31.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rodríguez-Murillo</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Filella</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Significance and Causality in Continuous Wavelet and Wavelet Coherence Spectra Applied to Hydrological Time Series</article-title>
          <source>Hydrology</source>
          <year>2020</year>
          <volume>7</volume>
          <elocation-id>82</elocation-id>
          <pub-id pub-id-type="doi">10.3390/hydrology7040082</pub-id>
        </element-citation>
      </ref>
      <ref id="B32-sensors-21-05256">
        <label>32.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Grinsted</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Moore</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Jevrejeva</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Application of the cross wavelet transform and wavelet coherence to geophysical time series</article-title>
          <source>Nonlinear Process. Geophys.</source>
          <year>2004</year>
          <volume>11</volume>
          <fpage>561</fpage>
          <lpage>566</lpage>
          <pub-id pub-id-type="doi">10.5194/npg-11-561-2004</pub-id>
        </element-citation>
      </ref>
      <ref id="B33-sensors-21-05256">
        <label>33.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Choe</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Do</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Seo</surname>
              <given-names>J.B.</given-names>
            </name>
          </person-group>
          <article-title>Deep Learning–based Image Conversion of CT Reconstruction Kernels Improves Radiomics Reproducibility for Pulmonary Nodules or Masses</article-title>
          <source>Radiology</source>
          <year>2019</year>
          <volume>292</volume>
          <fpage>365</fpage>
          <lpage>373</lpage>
          <pub-id pub-id-type="doi">10.1148/radiol.2019181960</pub-id>
          <pub-id pub-id-type="pmid">31210613</pub-id>
        </element-citation>
      </ref>
      <ref id="B34-sensors-21-05256">
        <label>34.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Albahri</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Zaidan</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Albahri</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Zaidan</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Abdulkareem</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Al-Qaysi</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Alamoodi</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Aleesa</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Chyad</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Alesa</surname>
              <given-names>R.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Systematic review of artificial intelligence techniques in the detection and classification of COVID-19 medical images in terms of evaluation and benchmarking: Taxonomy analysis, challenges, future solutions and methodological aspects</article-title>
          <source>J. Infect. Public Health</source>
          <year>2020</year>
          <volume>13</volume>
          <fpage>1381</fpage>
          <lpage>1396</lpage>
          <pub-id pub-id-type="doi">10.1016/j.jiph.2020.06.028</pub-id>
          <pub-id pub-id-type="pmid">32646771</pub-id>
        </element-citation>
      </ref>
      <ref id="B35-sensors-21-05256">
        <label>35.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sato</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Kubota</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Kochiyama</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Uono</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Yoshimura</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Sawada</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sakihama</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Toichi</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Increased putamen volume in adults with autism spectrum disorder</article-title>
          <source>Front. Hum. Neurosci.</source>
          <year>2014</year>
          <volume>8</volume>
          <fpage>957</fpage>
          <pub-id pub-id-type="doi">10.3389/fnhum.2014.00957</pub-id>
          <pub-id pub-id-type="pmid">25505401</pub-id>
        </element-citation>
      </ref>
      <ref id="B36-sensors-21-05256">
        <label>36.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Luo</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Mao</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Shi</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>C.S.R.</given-names>
            </name>
          </person-group>
          <article-title>Putamen gray matter volumes in neuropsychiatric and neurodegenerative disorders</article-title>
          <source>World J. Psychiatry Ment. Health Res.</source>
          <year>2019</year>
          <volume>3</volume>
          <fpage>1020</fpage>
          <pub-id pub-id-type="pmid">31328186</pub-id>
        </element-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig id="sensors-21-05256-f001" orientation="portrait" position="float">
      <label>Figure 1</label>
      <caption>
        <p>Methods for development of binary and multi-class classification of BOLD fMRI signals using wavelet coherence and CNN.</p>
      </caption>
      <graphic xlink:href="sensors-21-05256-g001"/>
    </fig>
    <fig id="sensors-21-05256-f002" orientation="portrait" position="float">
      <label>Figure 2</label>
      <caption>
        <p>Wavelet coherence of pairwise BOLD signals between top-ranked node and 115 brain nodes.</p>
      </caption>
      <graphic xlink:href="sensors-21-05256-g002"/>
    </fig>
    <fig id="sensors-21-05256-f003" orientation="portrait" position="float">
      <label>Figure 3</label>
      <caption>
        <p>Training parameters: Batch size = 32, Epochs = 20, Learning rate = 0.0005. 3-layer CNN architecture for wavelet coherence scalogram classification into three ASD subtypes and normal control.</p>
      </caption>
      <graphic xlink:href="sensors-21-05256-g003"/>
    </fig>
    <fig id="sensors-21-05256-f004" orientation="portrait" position="float">
      <label>Figure 4</label>
      <caption>
        <p>Top-three ranked brain nodes for classification of 3-level ASD subtypes and NC, determined using ANOVA analysis of mean value of PDC.</p>
      </caption>
      <graphic xlink:href="sensors-21-05256-g004"/>
    </fig>
    <fig id="sensors-21-05256-f005" orientation="portrait" position="float">
      <label>Figure 5</label>
      <caption>
        <p>Statistical comparison of 3 ASD subtypes and NC based on PSD of putamen nodes.</p>
      </caption>
      <graphic xlink:href="sensors-21-05256-g005"/>
    </fig>
    <fig id="sensors-21-05256-f006" orientation="portrait" position="float">
      <label>Figure 6</label>
      <caption>
        <p>Confusion matrix for classification of WCT images of ASD subtypes and NC using ADAM optimizer.</p>
      </caption>
      <graphic xlink:href="sensors-21-05256-g006"/>
    </fig>
    <table-wrap id="sensors-21-05256-t001" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t001_Table 1</object-id>
      <label>Table 1</label>
      <caption>
        <p>Details fMRI ASD subtypes and NC dataset from ABIDE database, acquired using 3T MRI scanner.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Site</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Country</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Vendor</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Voxel Size<break/>
(mm<inline-formula><mml:math id="mm22"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msup><mml:mrow/><mml:mn>3</mml:mn></mml:msup></mml:mstyle></mml:mrow></mml:math></inline-formula>)</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Flip Angle<break/>
(deg)</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">TR<break/>
(sec)</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Time Points<break/>
(sec)</th>
            <th colspan="4" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Subjects</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Total-per Site</th>
          </tr>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ASD</th>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">APD</th>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PDD-NOS</th>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">NC</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">NYU</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">USA</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Siemens</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1.3</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">7</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">175</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">31</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">SBL</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Netherlands</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Philips</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2.2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">195</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">29</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">SDSU</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">USA</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">GE</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">4.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">175</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">26</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Trinity</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Ireland</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Philips</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">145</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">4</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">7</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">11</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Yale</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">USA</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Siemens</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">195</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">14</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">37</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">USM</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">USA</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Siemens</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">235</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">KKI</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">USA</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Philips</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">2.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">151</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">UM1</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">USA</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">GE</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.2</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">15</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">295</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">-</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1</td>
          </tr>
          <tr>
            <td colspan="7" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">
<bold>Total</bold>
</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">36</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">144</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn>
          <p>Legend: NYU: New York University, SBL: Social Brain lab, SDSU: San Diego State University, Trinity: Trinity College Institute of Neuroscience, Yale: Yale School of Medicine, USM: University of Utah School of Medicine, KKI: Kennedy Krieger Institute, UM: University of Michigan, TR:Repetition Time.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap id="sensors-21-05256-t002" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t002_Table 2</object-id>
      <label>Table 2</label>
      <caption>
        <p>Performance of proposed CNN for binary classification using WCT of significant node(s) as the input images, where the number of subjects is ASD = NC = 36.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1"> Node for WCT</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Number of WCT <break/>
Images per Class</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Accuracy <break/>
(%)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">1st-node</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">4140</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.2</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">2nd-node</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">4140</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.9</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">3rd-node</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">4140</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">83.1</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">1st + 2nd-nodes</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8280</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.5</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">1st + 3rd-nodes</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">8280</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.7</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1st + 2nd + 3rd-nodes</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12,420</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">81.7</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="sensors-21-05256-t003" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t003_Table 3</object-id>
      <label>Table 3</label>
      <caption>
        <p>Percentage of accuracy, sensitivity, specificity, precision, and F-score (±standard deviation) of 10-folds cross-validation for binary classification.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Optimizer</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Accuracy</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Sensitivity</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Specificity</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Precision</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">F-Score</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">RMSPROP</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.5 ± 1.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.1 ± 2.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.3 ± 2.2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.2 ± 2.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.6 ± 1.9</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">SGDM</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.2 ± 0.9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.1 ± 1.4</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.4 ± 1.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.4 ± 1.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.2 ± 0.9</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ADAM</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.2 ± 0.7</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.1 ± 2.5</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.5 ± 1.9</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.5 ± 2.5</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.2 ± 0.5</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="sensors-21-05256-t004" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t004_Table 4</object-id>
      <label>Table 4</label>
      <caption>
        <p>Percentage of accuracy, sensitivity, specificity, precision, and F-score (±standard deviation) for binary classification of ASD vs. NC using k-fold cross-validation.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">k-Folds</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Accuracy</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Sensitivity</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Specificity</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Precision</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">F-Score</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">5-fold</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.6 ± 1.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.7 ± 2.3</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.7 ± 2.3</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.6 ± 2.6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.6 ± 1.5</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">10-fold</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.2 ± 0.7</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.1 ± 2.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.5 ± 1.9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.5 ± 2.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.2 ± 0.5</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">15-fold</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.6 ± 1.6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.9 ± 2.4</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">90.5 ± 1.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">90.6 ± 2.1</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">89.7 ± 1.5</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">20-fold</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.8 ± 1.7</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">90.1 ± 2.6</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.7 ± 2.2</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.6 ± 2.5</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.8 ± 1.7</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="sensors-21-05256-t005" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t005_Table 5</object-id>
      <label>Table 5</label>
      <caption>
        <p>Percentage of accuracy, sensitivity and specificity (in%) for binary classification, ASD vs. NC using leave-one site validation.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Site</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Accuracy</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Sensitivity</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Specificity</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Precision</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">F-Score</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">NYU</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.3</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.5</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.4</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">SBL</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">87.6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.7</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">SDSU</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">88.4</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.4</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">84.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.5</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Yale</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.4</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.2</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">86.3</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">85.8</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Mean</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.8</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">87.4</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.1</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">85.9</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">86.6</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="sensors-21-05256-t006" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t006_Table 6</object-id>
      <label>Table 6</label>
      <caption>
        <p>Comparison of the proposed ASD binary classification with previous papers.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Paper</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Classifier</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">FC Modelling</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Method</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Subject</th>
            <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Accuracy (%)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Chen et al. 2016 [<xref rid="B16-sensors-21-05256" ref-type="bibr">16</xref>]</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">SVM</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Static FC</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Pearson correlation</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">240</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">79.2</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Abraham et al. 2017 [<xref rid="B17-sensors-21-05256" ref-type="bibr">17</xref>]</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">SVM</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Static FC</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Covariance matrix</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">871</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">67</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Heinsfeld et al. 2018 [<xref rid="B12-sensors-21-05256" ref-type="bibr">12</xref>]</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">DNN</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Static FC</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Pearson correlation</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">1035</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">70</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Bernas et al. 2018 [<xref rid="B19-sensors-21-05256" ref-type="bibr">19</xref>]</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">SVM</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Dynamic FC</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Wavelet coherence</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">54</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">80</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">Sherkatghanad et al. 2020 [<xref rid="B10-sensors-21-05256" ref-type="bibr">10</xref>]</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">DNN</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Static FC</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">Pearson correlation</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">871</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">70.2</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Our proposed method</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">CNN</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Dynamic FC</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Wavelet coherence</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">72</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">89.8</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="sensors-21-05256-t007" orientation="portrait" position="float">
      <object-id pub-id-type="pii">sensors-21-05256-t007_Table 7</object-id>
      <label>Table 7</label>
      <caption>
        <p>Macro-accuracy (in %) of multi-class classification using three optimization methods.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="2" colspan="1">Optimizer</th>
            <th colspan="3" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">F1-Score(%)</th>
            <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1" colspan="1">Accuracy (%)</th>
          </tr>
          <tr>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ASD</th>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">APD</th>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">PDD-NOS</th>
            <th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Overall</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">RMSPROP</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">79.6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">80.7</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">81.7</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">80.2</td>
          </tr>
          <tr>
            <td align="center" valign="middle" rowspan="1" colspan="1">SGDM</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">80.9</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">79.8</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">80.6</td>
            <td align="center" valign="middle" rowspan="1" colspan="1">80.3</td>
          </tr>
          <tr>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">ADAM</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">81.7</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.3</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">83.6</td>
            <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">82.1</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </floats-group>
</article>
