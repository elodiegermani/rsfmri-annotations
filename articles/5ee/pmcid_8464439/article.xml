<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" article-type="research-article">
  <?properties open_access?>
  <?properties manuscript?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-journal-id">9215515</journal-id>
      <journal-id journal-id-type="pubmed-jr-id">20498</journal-id>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>NeuroImage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">34390875</article-id>
      <article-id pub-id-type="pmc">8464439</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2021.118469</article-id>
      <article-id pub-id-type="manuscript">NIHMS1741416</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Mapping individual differences across brain network structure to function and behavior with connectome embedding</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Levakov</surname>
            <given-names>Gidon</given-names>
          </name>
          <xref ref-type="aff" rid="A1">a</xref>
          <xref ref-type="aff" rid="A2">b</xref>
          <xref rid="CR1" ref-type="corresp">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Faskowitz</surname>
            <given-names>Joshua</given-names>
          </name>
          <xref ref-type="aff" rid="A3">c</xref>
          <xref ref-type="aff" rid="A4">d</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Avidan</surname>
            <given-names>Galia</given-names>
          </name>
          <xref ref-type="aff" rid="A1">a</xref>
          <xref ref-type="aff" rid="A2">b</xref>
          <xref ref-type="aff" rid="A5">e</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <xref ref-type="aff" rid="A3">c</xref>
          <xref ref-type="aff" rid="A4">d</xref>
        </contrib>
      </contrib-group>
      <aff id="A1"><label>a</label>Department of Cognitive and Brain Sciences, Ben-Gurion University of the Negev, Israel</aff>
      <aff id="A2"><label>b</label>Zlotowski Center for Neuroscience, Ben-Gurion University of the Negev, Israel</aff>
      <aff id="A3"><label>c</label>Department of Psychological and Brain Sciences, Indiana University, USA</aff>
      <aff id="A4"><label>d</label>Program in Neuroscience, Indiana University, USA</aff>
      <aff id="A5"><label>e</label>Department of Psychology, Ben-Gurion University of the Negev, Israel</aff>
      <author-notes>
        <fn fn-type="con" id="FN1">
          <p id="P1">Credit authorship contribution statement</p>
          <p id="P2"><bold>Gidon Levakov:</bold> Conceptualization, Methodology, Investigation, Formal analysis, Software, Visualization, Writing – original draft, Writing – review &amp; editing. <bold>Joshua Faskowitz:</bold> Methodology, Software, Writing – review &amp; editing. <bold>Galia Avidan:</bold> Conceptualization, Methodology, Writing – original draft, Writing – review &amp; editing, Supervision. <bold>Olaf Sporns:</bold> Conceptualization, Methodology, Writing – original draft, Writing – review &amp; editing, Supervision.</p>
        </fn>
        <corresp id="CR1"><label>*</label>Corresponding author at: Department of Cognitive and Brain Sciences, Ben-Gurion University of the Negev, Israel. <email>gidonle@post.bgu.ac.il</email> (G. Levakov).</corresp>
      </author-notes>
      <pub-date pub-type="nihms-submitted">
        <day>21</day>
        <month>9</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>11</day>
        <month>8</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <day>15</day>
        <month>11</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>15</day>
        <month>11</month>
        <year>2021</year>
      </pub-date>
      <volume>242</volume>
      <fpage>118469</fpage>
      <lpage>118469</lpage>
      <!--elocation-id from pubmed: 10.1016/j.neuroimage.2021.118469-->
      <permissions>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
          <license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>)</license-p>
        </license>
      </permissions>
      <abstract id="ABS1">
        <p id="P3">The connectome, a comprehensive map of the brain’s anatomical connections, is often summarized as a matrix comprising all dyadic connections among pairs of brain regions. This representation cannot capture higher-order relations within the brain graph. Connectome embedding (CE) addresses this limitation by creating compact vectorized representations of brain nodes capturing their context in the global network topology. Here, nodes “context” is defined as random walks on the brain graph and as such, represents a generative model of diffusive communication around nodes. Applied to group-averaged structural connectivity, CE was previously shown to capture relations between inter-hemispheric homologous brain regions and uncover putative missing edges from the network reconstruction. Here we extend this framework to explore individual differences with a novel embedding alignment approach. We test this approach in two lifespan datasets (NKI: <italic>n</italic> = 542; Cam-CAN: <italic>n</italic> = 601) that include diffusion-weighted imaging, resting-state fMRI, demographics and behavioral measures. We demonstrate that modeling functional connectivity with CE substantially improves structural to functional connectivity mapping both at the group and subject level. Furthermore, age-related differences in this structure-function mapping, are preserved and enhanced. Importantly, CE captures individual differences by out-of-sample prediction of age and intelligence. The resulting predictive accuracy was higher compared to using structural connectivity and functional connectivity. We attribute these findings to the capacity of the CE to incorporate aspects of both anatomy (the structural graph) and function (diffusive communication). Our novel approach allows mapping individual differences in the connectome through structure to function and behavior.</p>
      </abstract>
      <kwd-group>
        <kwd>Connectome</kwd>
        <kwd>Structural connectivity</kwd>
        <kwd>Functional connectivity</kwd>
        <kwd>Behavior</kwd>
        <kwd>Individual differences</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <label>1.</label>
      <title>Introduction</title>
      <p id="P4">Understanding the neural basis of behavior is a fundamental goal in neuroscience. Traditionally, it has been addressed by relating the structure and activation patterns of individual brain regions to behavioral phenotypes or cognitive tasks. However, most complex behaviors are mediated not by a single, localized brain area, but rather by the integrated contribution of multiple regions forming a coherent, distributed network (<xref rid="R54" ref-type="bibr">Sporns, 2011</xref>). The connectome, a comprehensive map of the brain’s anatomical connections, can be described and studied using methods and tools from network science. Research has gained valuable insight as to how individual nodes or modules in the network are organized to support specialized functional cognitive systems (<xref rid="R38" ref-type="bibr">Medaglia et al., 2015</xref>; <xref rid="R40" ref-type="bibr">Mišić and Sporns, 2016</xref>). In the past, most studies have aimed to detect differences in brain-behavior relations between groups of individuals. Increasingly, the focus has shifted to studying individual variations in connectome topology and its association with individual differences in brain function and behavior (<xref rid="R2" ref-type="bibr">Abdelnour et al., 2018</xref>; <xref rid="R37" ref-type="bibr">Lin et al., 2020</xref>).</p>
      <p id="P5">The connectome is represented as a matrix comprising all dyadic connections among pairs of brain regions. Accordingly, a natural description of a single brain region would be a vector in this matrix, incorporating all its direct pairwise connections (a connectivity “fingerprint”; <xref rid="R42" ref-type="bibr">Passingham et al., 2002</xref>). Such representation is limited as it fails to capture relations of higher-order within the network (<xref rid="R28" ref-type="bibr">Goyal and Ferrara, 2018</xref>). While multiple graph descriptive measures have been proposed to capture local or global network attributes (<xref rid="R49" ref-type="bibr">Rubinov and Sporns, 2010</xref>), most are limited to describing only a specific network feature. Connectome embedding (CE) is an alternative approach for finding compact vectorized representations of nodes that capture their local and global topological attributes (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). This approach, drawing from the field of natural language processing, is based on the Word2Vec algorithm (<xref rid="R39" ref-type="bibr">Mikolov et al., 2013</xref>) in which words are embedded in a low dimensional space that preserves their context as found in a given corpus of text. These representations were shown to capture semantic relations among words by applying simple vector arithmetic. For example, the result of combining vec(“King”) - vec(“Man”) + vec(“Woman”) was closer to vec(“Queen”) than to any other word in terms of its cosine similarity. Inspired by an adaptation of this approach to graph embedding (<xref rid="R29" ref-type="bibr">Grover and Leskovec, 2016</xref>; <xref rid="R45" ref-type="bibr">Perozzi et al., 2014</xref>), CEs are created by capturing a node’s “context” defined by its neighbors in a sequence of random walks on the brain graph. The resulting vectors were shown to capture relations between inter-hemispheric homologous brain regions and uncover putative edges that were missing from the structural network reconstruction (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). This ability of the CE approach to capture meaningful topological attributes suggests that it could be used to improve the mapping of structural to functional connectivity and ultimately to behavior.</p>
      <p id="P6">It has long been argued in neuroscience that structure determines function (<xref rid="R36" ref-type="bibr">Kristan and Katz, 2006</xref>). Accordingly, the nature of the correspondence between structural and functional brain connectivity is one of the core questions in the study of connectomes (<xref rid="R33" ref-type="bibr">Honey et al., 2010</xref>; <xref rid="R58" ref-type="bibr">Suárez et al., 2020</xref>). The two are distinct but complementary measures of brain connectivity. Structural connectivity quantifies the physical connections among neuronal elements, while statistical dependence between their time course is measured in functional connectivity. Although functional connectivity depends on the structural backbone, the observed correlation between the two is only moderate (<xref rid="R32" ref-type="bibr">Honey et al., 2009</xref>; <xref rid="R58" ref-type="bibr">Suárez et al., 2020</xref>). This, in part, can be attributed to higher-order interactions that drive functional connectivity but are missing in dyadic structural connectivity (<xref rid="R3" ref-type="bibr">Adachi et al., 2012</xref>). Such higher-order relations are captured in CE and indeed they were shown to account for a larger portion of the observed variance in functional connectivity (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). These previous attempts were conducted at the group-level and it is crucial to examine whether such mapping could also be applied at the individual subject level and whether it would preserve inter-subject variability in structure-function relation.</p>
      <p id="P7">Large scale data sharing initiatives have enabled applications of predictive modeling to study individual differences and validate them within and across large cohorts. Nevertheless, employing such techniques to connectivity data remains challenging due to their high complexity and dimensionality. CE offers a promising complementary framework that addresses these challenges by representing nodes in low-dimensional space while preserving their context in the global network topology. However, utilizing these nodal representations for predicting function and behavior requires their mutual alignment to the same latent space to allow comparison across individuals. Multiple fitting iterations of the Word2Vec algorithm, even on the same brain graph, result in sets of vectors with similar relative positions among each other but with different absolute values (<xref rid="R17" ref-type="bibr">Dev et al., 2019</xref>; for the stability of the relations among embeddings see <xref rid="R61" ref-type="bibr">Wang et al., 2020</xref>). In the domain of machine translation, this is typically addressed by finding a transformation that minimizes word distances from one language to another (<xref rid="R53" ref-type="bibr">Smith et al., 2017</xref>). However, such an approach could not be easily adopted to align brain nodes across individuals as it also eliminates parts of the variability associated with differences in the underlining structural connectivity. Hence, applying the CE framework to explore individual differences requires an alignment method that preserves this structural variability.</p>
      <p id="P8">In the current work, we advance the CE framework by presenting a novel approach which enables us to align separately learned embeddings to a common latent space (<xref rid="F1" ref-type="fig">Fig. 1</xref>). The alignment is based on a closed-form solution that utilizes parameters identified during the embedding fitting process. We validate this approach using two large lifespan cohorts (<xref rid="R41" ref-type="bibr">Nooner et al., 2012</xref>; <xref rid="R60" ref-type="bibr">Taylor et al., 2015</xref>) that include diffusion-weighted imaging, resting-state fMRI, as well as demographics and cognitive performance measures. We align CE within and between individuals and test the alignment effect on the similarity of nodes and the relations between nodes across embeddings. We then demonstrate that CE can improve the mapping of structural to functional connectivity at the individual level as previously done at the group-level (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). We further examine whether this mapping preserves age-related variance in structure-function correspondence at the network-level and at the edge-level. Interpreting the CE as a generative model of diffusive communication around nodes, we test the effect of the random walk parameters on structure-function mapping. Finally, we examine whether the aligned embeddings could be used to predict age and intelligence in a held-out sample. We include an in-depth derivation of the CE fitting and alignment process and share a set of interactive notebooks reproducing the main findings and a python package implementation (Cepy; <ext-link ext-link-type="uri" xlink:href="https://github.com/gidlev/cepy">https://github.com/gidlev/cepy</ext-link>).</p>
    </sec>
    <sec id="S2">
      <label>2.</label>
      <title>Materials and methods</title>
      <sec id="S3">
        <label>2.1.</label>
        <title>Participants</title>
        <p id="P9">The data were taken from two lifespan large-scale cross-sectional studies that included functional, structural, and diffusion brain magnetic resonance imaging (MRI) along with demographics and behavioral data. The first dataset is the enhanced Nathan Kline Institute-Rockland Sample (eNKI-RS; <xref rid="R41" ref-type="bibr">Nooner et al., 2012</xref>) and the second is the Cambridge Centre for Ageing and Neuroscience dataset (Cam-CAN; <xref rid="R52" ref-type="bibr">Shafto et al., 2014</xref>; <xref rid="R60" ref-type="bibr">Taylor et al., 2015</xref>) referred here as dataset 1 (DS1) and dataset 2 (DS2), respectively. DS1 is composed of 542 subjects (305 females, 192 males) aged 7–84 recruited from Rock-land County, USA. All participants provided informed consent and the study was approved by the Institutional Review Board at the Nathan Kline Institute (#226781 and #239708) and Montclair State University (#000983 A and #000983B). The data is openly available online at <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/enhanced/neurodata.html">http://fcon_1000.projects.nitrc.org/indi/enhanced/neurodata.html</ext-link>. DS2 includes 601 subjects aged 18–87 roughly uniformly distributed from Cambridge City, UK. All participants provided informed consent and the study was approved by the local ethics committee, Cambridgeshire 2 Research Ethics Committee (reference: 10/H0308/50). The data is freely available upon online access request <ext-link ext-link-type="uri" xlink:href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/</ext-link>. Additional information on the recruitment, eligibility criteria and demographics of both samples are available in the relevant publications (<xref rid="R41" ref-type="bibr">Nooner et al., 2012</xref>; <xref rid="R52" ref-type="bibr">Shafto et al., 2014</xref>). Exclusion criteria included successful completion of the preprocessing and quality control stages and are specified in the methods (2.3) and in the supplementary information (<xref rid="SD1" ref-type="supplementary-material">SI 2</xref>).</p>
      </sec>
      <sec id="S4">
        <label>2.2.</label>
        <title>MRI acquisition</title>
        <p id="P10">DS1 and DS2 were both acquired on 3T Siemens scanners. For each subject of each dataset, a T1-weighted image (T1w), diffusion-weighted image (DWI), and resting-state functional MRI (rsfMRI) were acquired. Both datasets include standard T1w anatomical acquisitions. DS1 includes DWI with 128 directions in one shell with a b-value of 1500 s/mm<sup>2</sup>, and DS2 includes DWI with 60 directions over two shells of 1000 and 2000 s/mm<sup>2</sup>. DS1 includes a rsfMRI acquisition with a relatively short repetition time of 0.645 s with a scan time of 9.68 min, and DS2 includes a more standard acquisition scheme with a repetition time of approximately 2 s with a scan time of 8.56 min. The specific parameters of each acquisition in each dataset can be found in <xref rid="SD1" ref-type="supplementary-material">SI Table 1</xref>.</p>
      </sec>
      <sec id="S5">
        <label>2.3.</label>
        <title>MRI preprocessing</title>
        <p id="P11">Here we report a general overview of the independent preprocessing pipelines applied for DS1 and DS2. Given recent reports of the effect of processing strategies on MRI analysis (<xref rid="R12" ref-type="bibr">Botvinik-Nezer et al., 2020</xref>), we intend to show converging results across two datasets employing different processing pipelines. Complete preprocessing details for both datasets are included in <xref rid="SD1" ref-type="supplementary-material">SI Section 1</xref>.</p>
        <p id="P12">T1w scans from both datasets were preprocessed through FreeSurfer’s (version 6.0) recon-all processing stream. FreeSurfer’s cortical segmentation and spherical warp were used to transfer parcellations to each subject’s volumetric anatomical space. In the case of DS1, the Schaefer 200-node cortical parcellation was rendered (<xref rid="R50" ref-type="bibr">Schaefer et al., 2018</xref>), whereas, in DS2, the Connectome Mapping toolkit was used to render the Lausanne 233 node parcellation (219 cortical, 14 subcortical; <xref rid="R23" ref-type="bibr">Gerhard et al., 2011</xref>).</p>
        <p id="P13">DWI of both datasets were preprocessed with pipelines that included the following steps: denoising, motion and eddy current distortion correction, and alignment to the T1w using FreeSurfer’s white matter segmentation (<xref rid="R4" ref-type="bibr">Ades-Aron et al., 2018</xref>; <xref rid="R7" ref-type="bibr">Bathelt et al., 2017</xref>). For both datasets, local orientation modeling and tractography was run via the Dipy package (<xref rid="R22" ref-type="bibr">Garyfallidis et al., 2014</xref>). Constrained spherical devolution was used to fit a local orientation model at each voxel, with a spherical harmonic order of 8 in DS1 and 6 in DS2. For DS1, probabilistic streamline tractography was conducted after seeding each white matter voxel five times. For DS2, deterministic streamline tractography was conducted with a seeding density of 27. In both datasets, streamlines shorter than 10mm or ones that did not terminate in grey matter were discarded.</p>
        <p id="P14">Functional images of DS1 were preprocessed with fMRIPrep (version 1.1.8; <xref rid="R18" ref-type="bibr">Esteban et al., 2019</xref>) and images of DS2 were preprocessed with the Configurable Pipeline for the Analysis of Connectomes (C-PAC; <xref rid="R13" ref-type="bibr">Cameron et al., 2013</xref>). Briefly, both pipelines included the following steps: slice-timing correction, motion correction, skull stripping, and estimation of motion parameters and other nuisance signal time series. For DS1, preprocessed images were rendered in the subject’s T1w space, at the original resolution of the rsfMRI. For DS2, preprocessed images were rendered in rsfMRI space.</p>
        <p id="P15">For DS1 and DS2, structural connectivity matrices were constructed by counting the number of streamlines between regions normalized by the volume of these regions, rendering a streamline density. For DS1 and DS2, subjects for which more than 10 nodes in the structural connectivity matrix had a degree of 0 were excluded and were not used in subsequent analysis (DS1: none omitted, 542 left; DS2: 6% omitted, 601 left). The samples of both datasets were divided into a training (67%) and test set (33%) for subsequent analyses that required out-of-sample accuracy estimation (DS1: 361 and 181, DS2: 401 and 200; training and test subjects, respectively).</p>
        <p id="P16">For DS1 and DS2, functional connectivity matrices were rendered after filtering the functional volumes for nuisance signals. For DS1 rsfMRI, the first four frames were dropped. These data were then bandpass filtered (0.008–0.08Hz) and confound regressed in a manner orthogonal to the temporal filters using 6 motion estimates, the mean time series derived in CSF, WM, and whole brain masks, the derivatives of these nine regressors, and the squares of these 18 terms. Spike regressors were added for each frame with framewise displacement above 0.5mm. Data were linearly detrended and standardized. Exclusion criteria included greater than 15% spike frames and outlier image quality metrics (4% omitted; 542 subjects left; for more details, see <xref rid="SD1" ref-type="supplementary-material">SI 6.2</xref>). For DS2 rsfMRI, regression of the first 5 principal components of signal from white matter and CSF (<xref rid="R8" ref-type="bibr">Behzadi et al., 2007</xref>), 6 motion parameters and linear and quadratic trends, global signal regression, followed by temporal filtering between 0.1 and 0.01 Hz and. Finally, a scrubbing threshold of 0.5 mm frame-wise displacement was applied (<xref rid="R46" ref-type="bibr">Power et al., 2014</xref>; removal of 1 TR before and 2 TR after excessive movement). Exclusion criterion for excessive movements was determined a priori to less than 50% (4 min and 20 s) of the resting-state session after the scrubbing procedure (25% omitted; 452 subjects left). For DS1 and DS2, functional connectivity as used in all analyses, was defined as the Pearson correlation among pairs of ROIs’ time series followed by Fisher’s r-to-z transformation.</p>
      </sec>
      <sec id="S6">
        <label>2.4.</label>
        <title>Intelligence assessment</title>
        <p id="P17">Structural connectivity was previously associated with behavioral measures of intelligence (<xref rid="R11" ref-type="bibr">Booth et al., 2013</xref>; <xref rid="R44" ref-type="bibr">Penke et al., 2012</xref>), and here was used to test the ability of the CE approach to capture individual differences in behavior. In DS1 general intelligence was assessed using the full scale of the Wechsler Abbreviated Scale of Intelligence (WASI-II; <xref rid="R62" ref-type="bibr">Wechsler, 1999</xref>). Subjects in DS2 underwent the Cattell Culture Fair test, Scale 2 Form <italic>A</italic> that aims to measure fluid intelligence independently of cultural differences (CFIT; <xref rid="R14" ref-type="bibr">Cattell and Cattell, 1973</xref>). In the relevant analyses, we used a sample of subjects in training and test sets for whom we had the structural connectivity matrices and intelligence behavioral scores (DS1: 528; d2: 587). Next, to remove outliers, participants with intelligence scores larger than 2 standard deviations from the mean were omitted from the analyses (DS1: 0% omitted, 528 left; DS2: 4% omitted, 565 left). The WASI-II full scale in DS1 produced age-adjusted scores that were uncorrelated with age within the sample (<italic>r</italic> (526) = 038, <italic>p</italic> = 386). CFIT appeared in DS2 as the raw accuracy score for all test items. This score was significantly correlated with age (<italic>r</italic> (563) = −0.652, <italic>p</italic> &lt; 2.2e-16) and hence constitutes an age-related measure of intelligence.</p>
      </sec>
      <sec id="S7">
        <label>2.5.</label>
        <title>Node embedding-general outline and the random walk sampling</title>
        <p id="P18">As in previous work (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>), we used the word2vec algorithm (<xref rid="R39" ref-type="bibr">Mikolov et al., 2013</xref>) to create a vectorized representation of brain nodes based on their high-level topological relations. Originally, the word2vec algorithm was used to create word embeddings that preserve their context as it typically appears in a sentence. Specifically, the model is given a corpus of words <italic>w</italic> and their context <italic>c</italic>. Its goal is to learn a set of parameters <italic>θ</italic> by maximizing the conditional probability p(c|w; <italic>θ</italic>) for the skip-gram model or p(w|c; <italic>θ</italic>) for the continuous bag of words (CBOW) model (<xref rid="R25" ref-type="bibr">Goldberg and Levy, 2014</xref>). Simply put, the model’s goal is to predict the context given the target word or a target word given its context. The former is used in the current work. Recently, word2vec has been applied for embedding graph nodes instead of text (node2vec: <xref rid="R29" ref-type="bibr">Grover and Leskovec, 2016</xref>; Deepwalk: <xref rid="R45" ref-type="bibr">Perozzi et al., 2014</xref>). Here, for embedding brain graphs, we used a sliding, fixed-size window <italic>s</italic> taken from a sequence of a parameterized random walk on the brain structural graph (<italic>s</italic> = 3). In each training sample, the center node in the sequence is the target <italic>w</italic> and the surrounding nodes are the context <italic>c</italic>. The surrounding nodes are defined as the <italic>s</italic> nodes that appeared before and <italic>s</italic> nodes that appeared after the target node <italic>w</italic> within the walk sequence. The ordering of the context nodes within a window is not preserved. Training samples were produced by initiating <italic>o</italic> parameterized random walk sequences of length <italic>l</italic> from each node (<italic>o</italic> = 800, <italic>l</italic> = 20). We further elaborate on the parameterized random walk procedure in <xref rid="S13" ref-type="sec">section 2.11</xref>. All the model’s parameters were set to be identical to those used by <xref rid="R48" ref-type="bibr">Rosenthal et al. (2018)</xref>.</p>
      </sec>
      <sec id="S8">
        <label>2.6.</label>
        <title>Node embedding-model implementation and parameters estimation</title>
        <p id="P19">In its simplest form, the model represents a fully connected artificial neural network (ANN) with one hidden layer, <italic>i.e.</italic> the embedding layer, with no activation function. Both the context {c<sub>1</sub>, …, c<sub>2×s</sub>} and target <italic>w</italic> nodes are represented using a “one-hot encoding”, meaning that node <italic>i</italic> is encoded as a vector with zero in all its entries except the <italic>i</italic>th position that is equal to one. The number of neurons in the input and output layers is the number of nodes in the graph <italic>k</italic> and the number of neurons in the embedding layer is set to <italic>k</italic>’, when typically, <italic>k</italic>’ &lt; <italic>k</italic> (here <italic>k</italic>’ = 30). The transformation between the input, embedding and output layers, denoted here as <italic>v</italic><sup><italic>input</italic></sup>, <italic>v</italic><sup><italic>embed</italic></sup>, <italic>v</italic><sup><italic>output</italic></sup>, are defined using two weight matrices. A <italic>k</italic> × <italic>k</italic>’ matrix <italic>W</italic> between the input and the embedding layer, and a <italic>k</italic>’ × <italic>k</italic> matrix <italic>W</italic>’ between the embedding layer and the output layer:
<disp-formula id="FD1"><label>(1)</label><mml:math display="block" id="M1"><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mtext mathvariant="italic">embed</mml:mtext></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mstyle><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mtext>T</mml:mtext></mml:msup><mml:mo>⋅</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD2"><label>(2)</label><mml:math display="block" id="M2"><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mtext>T</mml:mtext></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mtext mathvariant="italic">embed</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p>
        <p id="P20">Notice that the embedding layer is computed as the average of all vector-matrix product of the context node vectors with the <italic>W</italic> matrix. Both <italic>W</italic> and <italic>W</italic>’ are learned by fitting the model on a given sample of random walks. Effectively the model performs a classification task in which the input is the context nodes {c<sub>1</sub>, …, c<sub>2×s</sub>} and the goal is to predict the target node <italic>w</italic>. This is done by first applying a Softmax function to the output layer which normalizes its entries into a probability distribution that sums to one. Here for the <italic>i</italic><sup>th</sup> entry:
<disp-formula id="FD3"><label>(3)</label><mml:math display="block" id="M3"><mml:mrow><mml:mtext mathvariant="italic">softmax</mml:mtext><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
        <p id="P21">Next, the model’s loss is computed by taking the negative log, <italic>i.e.</italic> the logarithmic loss, of the target node <italic>w</italic> entry, its index marked here as *:
<disp-formula id="FD4"><label>(4)</label><mml:math display="block" id="M4"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p id="P22">Here in simplified form:
<disp-formula id="FD5"><label>(5)</label><mml:math display="block" id="M5"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mstyle><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p>
        <p id="P23">Finally, for a given training sample, we update the model’s parameters <italic>θ</italic>, i.e. the weight matrices W and W’, by taking the derivative of the loss with respect to each matrix. The parameters are iteratively updated after each observation of a single sample or a batch of training samples, i.e. using stochastic gradient descent. For a more in-depth review of the model and training procedure including implementational details that are beyond the scope of the current work such as negative sampling, see <xref rid="R47" ref-type="bibr">Rong (2014)</xref>.</p>
      </sec>
      <sec id="S9">
        <label>2.7.</label>
        <title>CE alignment</title>
        <p id="P24">Independent fitting iterations of the node2vec algorithm resulted in sets of vectors with similar cosine angle between each node pairs, but not necessarily similar absolute values (<xref rid="R17" ref-type="bibr">Dev et al., 2019</xref>). Here we demonstrate our novel approach which enables us to align separately learned CE to the same latent space (see <xref rid="F1" ref-type="fig">Fig. 1. b.</xref>). As outlined in <xref rid="S7" ref-type="sec">section 2.5</xref>, the ANN model includes two distinct representations. The first, which appears in the input and output layers, is defined by the one-hot encoding in which each entry corresponds to a particular node (see <xref rid="S8" ref-type="sec">section 2.6</xref>). The second is a latent representation, the representation of the embedding layer, that is unique to each trained model. Notice that the learned matrices <italic>W</italic> and <italic>W</italic>’ encode the transformation between these two representations and for this reason, we refer to them here as <italic>transformations</italic>. The first transformation <italic>W</italic> reduces the input dimensions from <italic>k</italic> to <italic>k</italic>’ and effectively contains the embedding of each node. The second transformation <italic>W</italic>’ increases the dimensions of the embedding layer <italic>k</italic>’ again to the number of dimensions in the output layer <italic>k</italic>. While typically after fitting the algorithm on the data, only the first matrix <italic>W</italic> is retained, we suggest utilizing the second matrix <italic>W</italic>’ as a transformation from one latent space to another. Specifically, given two separately trained models with different latent embedding spaces <italic>a</italic> and <italic>b,</italic> we want to transform the latent representation of node <italic>i</italic> from space <italic>a</italic> to <italic>b</italic>. In each of the models, a separate <italic>W</italic>’ transformation was learned, <italic>W</italic>’<sub>a</sub> and <italic>W</italic>’<sub>b,</sub> respectively. First, the embedding of node <italic>i</italic> in space <italic>a</italic> could be derived by taking the <italic>i</italic><sup><italic>th</italic></sup> row of <italic>W</italic><sub>a</sub>, or equivalently multiply the one-hot encoding of node <italic>i, v</italic><sup><italic>input</italic></sup>
<sub><italic>i</italic></sub>, with <italic>W</italic><sub>a</sub>:
<disp-formula id="FD6"><label>(6)</label><mml:math display="block" id="M6"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">embed</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>a</mml:mi><mml:mtext>T</mml:mtext></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p>
        <p id="P25">Note that for the embedding and output layers the first subscript denotes the node’s index and the second the source and current latent or output space. Next, the vector is multiplied with <italic>W</italic>’<sub>a</sub> to transform it to the ANN output representation:
<disp-formula id="FD7"><label>(7)</label><mml:math display="block" id="M7"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mtext>i</mml:mtext><mml:mrow><mml:mtext>a</mml:mtext><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext>output </mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mtext>W</mml:mtext><mml:mi>a</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mtext>i</mml:mtext><mml:mrow><mml:mtext>a</mml:mtext><mml:mo>,</mml:mo><mml:mtext>a</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext>embed</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p>
        <p id="P26">We assume that since the one-hot representational constraint exists in all fitting iterations, this representation is similar across separately trained models. Stemming from this, we can apply the inverse of transformation <italic>W</italic>’<sub>b,</sub> to move to latent space <italic>b</italic>. Since W’ is non-square we apply the pseudo-inverse transformation <italic>W</italic>’<sub>b</sub><sup>+</sup>:
<disp-formula id="FD8"><label>(8)</label><mml:math display="block" id="M8"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">embed</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>+</mml:mo><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">output</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p>
        <p id="P27">(<xref rid="FD7" ref-type="disp-formula">7</xref>) and (<xref rid="FD8" ref-type="disp-formula">8</xref>) could be summarized to a single step, incorporating the transformation of the embedding of node <italic>i</italic> from latent space <italic>a</italic> to latent space <italic>b</italic>:
<disp-formula id="FD9"><label>(9)</label><mml:math display="block" id="M9"><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">embed</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>+</mml:mo><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mtext>T</mml:mtext></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">embed</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p id="P28">This alignment method does not require any additional learning or optimization process and relies on the transformation already learned within the ANN. This method could be used to align embeddings originated from separate fitting iterations. These could be fitted on the same structural connectivity matrices, from matrices taken from different individuals, or matrices of the same individual across time. As an additional step to improve embedding stability over fitting iterations (<xref rid="R61" ref-type="bibr">Wang et al., 2020</xref>), in the subsequent analysis we averaged multiple embeddings of the same individual after aligning them to the same space (100 times, unless stated otherwise). Python notebooks are available online to demonstrate the random walk sampling, word2vec model, model fitting, and the alignment process-<ext-link ext-link-type="uri" xlink:href="https://github.com/gidlev/cepy/tree/master/examples">https://github.com/gidlev/cepy/tree/master/examples</ext-link>.</p>
      </sec>
      <sec id="S10">
        <label>2.8.</label>
        <title>Intra-individual CE similarity evaluation</title>
        <p id="P29">We examine the effect of embedding alignment on the similarity of identical nodes across separate embedding iterations. For a random sample of subjects (<italic>n</italic> = 100) we ran the node2vec algorithm multiple times (<italic>m</italic> = 50), then aligned the resulting vectors to a common space and averaged them. The common reference space was created by applying the node2vec algorithm on the group consensus structural connectivity matrix. This procedure was repeated twice and the node’s embedding similarity across the two learned CE was quantified using cosine similarity. The similarity measure was averaged across all nodes (DS1: 200, DS2: 233) and calculated for all subjects. Next, we evaluated the similarity of the cosine angle among pairs of nodes across CEs that resulted from independent fitting iterations. This was done by calculating the displacement vector, <italic>i.e.</italic> the result of vector subtraction, among all possible pairs of nodes (DS1: 19900, DS2: 27028). Similarly, the cosine angle among the displacement vector obtained from the two separate learned CE was taken. The similarity measure was averaged across all node pairs and calculated for all subjects. In both tests, the similarity measures were compared to a case where the alignment step was omitted (“not-aligned” condition).</p>
      </sec>
      <sec id="S11">
        <label>2.9.</label>
        <title>Inter-individual CE similarity evaluation</title>
        <p id="P30">To test the quality of the alignment, we applied the embedding ranking test (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). First, multiple node2vec iterations (<italic>m</italic> = 100) were fitted to each subject, the resulting embeddings were aligned to a common space (see <xref rid="S9" ref-type="sec">section 2.7</xref>) and averaged. Then, for every node in one individual, we obtained its cosine similarity to all nodes in a second individual. A ranking test score of <italic>k</italic> meant that for a particular node, its corresponding node in the second individual was the <italic>k</italic> -closest node. The test was conducted for each node and every possible subject pair (<italic>n</italic> = 100; 9,950 pairs). Finally, we tested the similarity of relations among pairs of nodes across individuals. This was done using an analogy ranking test. The test measured whether the displacement vector from node <italic>a</italic> to <italic>b</italic> in one individual would express the same relation in another individual. Here, the ranking score was conducted by adding the displacement vector from node <italic>a</italic> to <italic>b</italic> taken from one individual to node <italic>a</italic> of another individual. The query, in this case, was how close is the resulting vector to node <italic>b</italic> of the second individual. This test was repeated for every subject and node pairs resulting in <italic>k</italic> -times more computations (DS1: <italic>k</italic> = 200, DS2: <italic>k</italic> = 233). Thus, due to computational time considerations, the analysis was conducted on a smaller, randomly selected, set of subjects (<italic>n</italic> = 30). Both tests were compared to a condition in which the alignment step was omitted.</p>
      </sec>
      <sec id="S12">
        <label>2.10.</label>
        <title>Group-level structure to function mapping</title>
        <p id="P31">Analyses on the group-level structure to function mapping were conducted on the consensus structural and functional connectivity matrices derived from all subjects in the test set. The functional group connectivity matrix was calculated by averaging the Fisher-r-to-z transformed correlations across all subjects. The structural group consensus connectivity matrix in each dataset was derived by averaging over all edge values that were present in at least 25% of subjects (<xref rid="R15" ref-type="bibr">de Reus and van den Heuvel, 2013</xref>). Structural edges on all other node pairs were assumed to be absent and set to zero in the consensus average. The group-level CE was created by applying the node2vec algorithm to the structural group consensus matrix. Structure-function correlation was quantified as Spearman’s correlation between all unique direct edges, <italic>i.e</italic>. edges that exist in the consensus matrix, for the structural connectivity. The same correlation measure was used for the CE cosine edges but applied to all edges, both direct and indirect. We used Spearman’s rank correlation because of the exponential distribution of the structural connectivity values. This measure was used in all subsequent connectome-level structure-function correlation assessments. To examine the contribution of individual edges to the increased CE-based structure-function mapping, we adopted the Leave-One-Trial-Out scheme (<xref rid="R24" ref-type="bibr">Gluth and Meiran, 2019</xref>). This was done by calculating Spearman’s rank correlation between the CE cosine similarity edges and their corresponding functional edges. This was followed by computing the difference in this correlation after removal of each of the edges. The correlation before minus after the removal, or Δ correlation, could inform us about the effect of a given edge on the overall correlation by examining its sign and relative magnitude.</p>
      </sec>
      <sec id="S13">
        <label>2.11.</label>
        <title>Parameters of the random walk and their relation to structure to function mapping</title>
        <p id="P32">In a fully diffusive communication process, signals propagate on the network structure driven only by local connectivity properties (<xref rid="R6" ref-type="bibr">Avena-Koenigsberger et al., 2018</xref>). In the node2vec algorithm, random walks are biased and assume some information about the node’s local neighborhoods. Two parameters guided the biased random walk, the return parameter <italic>p</italic> and the in-out parameter <italic>q</italic> (<xref rid="R29" ref-type="bibr">Grover and Leskovec, 2016</xref>). Specifically, the parameter <italic>p</italic> sets the likelihood for a random walker to immediately revisit a node, <underline><italic toggle="yes">i.e</italic></underline>. that at time <italic>t</italic> + <italic>1</italic> it would occupy the same node visited at time <italic>t−1</italic>. The parameter <italic>q</italic> controls the likelihood of a random walker to visit nodes that are not directly linked to the node visited in the previous step, <italic>i.e.</italic> that its step in time <italic>t</italic> + <italic>1</italic> would be to a node with edge = 0 with the node visited in time <italic>t−1</italic>. While high <italic>p</italic> and low <italic>q</italic> would guide the walk to remain in the vicinity of the initial starting point (local bias), the opposite would promote exploration of distant nodes (global bias). The unnormalized transition probability from node <italic>t</italic> to <italic>t</italic> + <italic>1</italic> is computed as the weight among nodes, divided by the p (if <italic>t</italic>−<italic>1</italic> = <italic>t</italic> + +<italic>1</italic>) or q (if <italic>t</italic>−<italic>1</italic> is unconnected to <italic>t</italic> + <italic>1</italic>). In all analyses reported here, we used a locally biased random walk (<italic>p</italic> = 0.1, <italic>q</italic> = 1.6; <xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). Additionally, we examined the effect of manipulating <italic>p</italic> and <italic>q</italic> on the observed correlation between the CE cosine similarity matrix and the functional connectivity matrix. We report this correlation for randomly selected subjects from the training set (<italic>n</italic> = 25) with functional and structural connectivity measures. We report this correlation separately for direct and indirect edges. Parameterized random walks were produced using the reference node2vec Python implementation (<ext-link ext-link-type="uri" xlink:href="https://github.com/aditya-grover/node2vec">https://github.com/aditya-grover/node2vec</ext-link>).</p>
      </sec>
      <sec id="S14">
        <label>2.12.</label>
        <title>Predicting group-level functional from structural connectivity with deep learning</title>
        <p id="P33">Previous work (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>) has shown that a CE-based structure to function mapping could be further improved using a deep neural network. Here we adopted the same methodology in which the element-wise multiplications of any pair of node embeddings were used as input and the functional connectivity between the two as the target label. We used a fully connected, 4-layer network with 256 neurons in each layer. The network was implemented in Keras (<xref rid="R19" ref-type="bibr">François Chollet and contributors, 2015</xref>) and Tensorflow (<xref rid="R1" ref-type="bibr">Abadi et al., 2016</xref>). The training was conducted using an Adam optimizer, a learning rate of 0.001, and 250 epochs. We used 3-fold cross-validation by randomly dividing the edges of the mean functional connectivity matrix into 3 folds. In each iteration, two folds were used for fitting and the remaining fold was used for prediction. We additionally applied cross-validation on the group matrices such that edges and CEs used for fitting were taken from subjects within the training set and CE used for the prediction was taken from subjects within the test set. Finally, we wanted to account for the fact that nodes from the same community, defined by the 7 canonical resting-state networks (<xref rid="R64" ref-type="bibr">Yeo et al., 2011</xref>), have similar functional connectivity patterns. For this reason, we divided the 3-folds such that each intersection of two communities would not be repeated across folds. For example, all edges connecting a visual node to a motor node appeared only in one of the folds. This scheme was used for the created CE-based predictions for all possible functional edges, both direct and indirect.</p>
      </sec>
      <sec id="S15">
        <label>2.13.</label>
        <title>Individual-level structure to function mapping</title>
        <p id="P34">CE could be further utilized to map structural to functional connectivity at the individual subject-level. The following analyses were conducted for individuals that underwent DWI and a resting-state session, and were not excluded at the preprocessing stage (see <xref rid="S5" ref-type="sec">section 2.3</xref>; DS1: 307 and 145, DS2: 361 and 181; subjects left in the training and test set, respectively). Structure-function correspondence was evaluated using subjects within the test set both for structural connectivity values and for the CE cosine similarity measure. Differences in structure-function mapping between CE and the connectivity values were examined using a paired-sample t-test between the correlation coefficient values. Finally, a deep learning model for structure-function mapping was applied using the same architecture and hyper-parameters described in <xref rid="S12" ref-type="sec">section 2.10</xref>. Cross-validation was conducted both at the edge and subjects levels. On the edge-level, we used the same 3-fold strategy as described in <xref rid="S14" ref-type="sec">section 2.12</xref>. At the subjects-level, model fitting was conducted only on within the training set and testing on test set. We reported structure-function connectivity correlation separately for direct edges, indirect edges, and all edges.</p>
      </sec>
      <sec id="S16">
        <label>2.14.</label>
        <title>Age-related changes in individual-level structure-function correspondence</title>
        <p id="P35">Age was previously found to be associated with a decrease in the strength of structure-function connectivity correlation (<xref rid="R65" ref-type="bibr">Zimmermann et al., 2016</xref>). Here we wanted to examine whether this negative correlation between age and structure-function relation is preserved when relating CE to functional connectivity. The correlation was calculated for all the subjects within the test set. Structure-function correspondence was evaluated using Spearman’s rank correlation only on direct edges. Comparing the magnitude of the aging effect on the structure-function correspondence was evaluated using Steiger’s t-test for comparing dependent correlation values (<xref rid="R56" ref-type="bibr">Steiger, 1980</xref>; python implementation: <ext-link ext-link-type="uri" xlink:href="https://github.com/psinger/CorrelationStats/">https://github.com/psinger/CorrelationStats/</ext-link>). To test how age relates to edgewise structure-function correspondence we used the Leave-One-Trial-Out scheme described in <xref rid="S12" ref-type="sec">section 2.10</xref>. The derived contribution score that measures the effect of a single node on the overall structure-function relation was applied for the same group of subjects. We then measured the Pearson correlation of each edge with age across subjects. Finally, we adapted the network contingency analysis method (<xref rid="R55" ref-type="bibr">Sripada et al., 2014</xref>). This method examines whether sub-blocks derived from each of seven canonical resting state networks (<xref rid="R64" ref-type="bibr">Yeo et al., 2011</xref>) present a larger number of edges correlated with age above a predetermined threshold than expected by chance, with chance defined through permutation testing. We repeated our analysis for a wide range of thresholds (|r| &gt; 0.25, 0.3, 0.35, 0.4). To establish the null distribution, we used 10,000 permutations of ages and only accepted cells for which none of the correlations obtained after permutation was larger than the empirical value (see <xref rid="SD1" ref-type="supplementary-material">SI 8</xref> for a full description of the analysis). Finally, we examined whether within the 7 canonical functional networks, within or between hemispheres, the supra-threshold edges were significantly larger or smaller than zero. We used a one sample t-test were the null hypothesis was that the population mean is zero.</p>
      </sec>
      <sec id="S17">
        <label>2.15.</label>
        <title>Modeling individual differences in age and intelligence using CE</title>
        <p id="P36">To test the ability of the CE framework to predict individual differences, we trained a linear model to predict age and intelligence. First, a separate model was trained for each node and each input type, i.e. the CE, the CE cosine similarity matrix, the structural or the functional connectivity values as input. We used the rows of the CE cosine, structural and functional connectivity matrices and the nodal CE representations as the node-level inputs. The performance measure of the model was compared to the one obtained by fitting the same model to the structural or functional connectivity values. We used linear regression to predict age and intelligence. The performance was quantified as the Pearson correlation between the observed and predicted age or intelligence. We additionally report the mean absolute error (MAE) along with <italic>p</italic>-values based on non-parametric permutation test created by shuffling the data labels 1000 times (<xref rid="R31" ref-type="bibr">Hilger et al., 2020</xref>). MAE for age and intelligence predictions are reported in years and the intelligence test scores respectively. The connectome-level model was created by taking the mean of all nodal-level predictions or training a second-level ensemble model on them. Due to the high multicollinearity of the first-level prediction, an L2 regularized linear model trained with SGD was used as the ensemble model. As in the first-level model, the ensemble was trained within the training set and tested on the test set. The models were implemented in Statsmodels and Scikit-learn (linear_model.OLS; <xref rid="R51" ref-type="bibr">Seabold and Perktold, 2010</xref>; SGDRegressor; <xref rid="R43" ref-type="bibr">Fabian et al., 2011</xref>) with the default parameters. We additionally examined whether our results are confounded by a possible effect of gender, for age prediction, and gender and age, for intelligence prediction. We controlled for the two variables using linear regression by predicting the desired outcome, age and intelligence, with the covariates, gender or age and gender, as predictors, keeping only the residual.</p>
      </sec>
    </sec>
    <sec id="S18">
      <label>3.</label>
      <title>Results</title>
      <sec id="S19">
        <label>3.1.</label>
        <title>Individual CE alignment evaluation</title>
        <p id="P37">The Node2vec algorithm was previously shown to capture high-order structural relations within group-averaged representations of the human connectome (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). Extending the approach to individual brain networks requires that individual connectome embeddings are mutually aligned to allow an assessment of individual differences. Fitting the CE algorithm on a given individual graph results in an embedded vector representation for each brain node. Multiple fitting iterations result in sets of vectors with similar relative positions among each other, <italic>i.e.</italic> similar cosine angles between node pairs, but they generally do not retain their absolute values (<xref rid="R17" ref-type="bibr">Dev et al., 2019</xref>; for the stability of the relations among embeddings see <xref rid="R61" ref-type="bibr">Wang et al., 2020</xref>). As a result, utilizing the CE framework to explore individual differences among subjects requires a method which would align different CEs to the same latent space (<xref rid="F1" ref-type="fig">Fig. 1</xref>). The following sections evaluate our proposed embedding alignment method. For the sake of brevity, in all following sections, we report the results for the NKI dataset (DS1), then provide an abbreviated report of the Cam-CAN dataset (DS2) leaving only the statistics while excluding the text (see the <xref rid="SD1" ref-type="supplementary-material">SI</xref> for the complete report of DS2).</p>
        <sec id="S20">
          <label>3.1.1.</label>
          <title>Intra-individual CE similarity evaluation</title>
          <p id="P38">We examined the effect of embedding alignment on the similarity of two independent CE fitting iterations of the same subject. This was done by testing the cosine similarity among pairs of identical nodes (<xref rid="SD1" ref-type="supplementary-material">SI Fig. 1a</xref>,<xref rid="SD1" ref-type="supplementary-material">i</xref>). Next, we examined embedding alignment effects on the similarity of the relations among pairs of different nodes, again, across two independent fittings of the same subject. The relations were quantified as the cosine similarity between their displacement vectors (<xref rid="SD1" ref-type="supplementary-material">SI Fig. 2b</xref>,<xref rid="SD1" ref-type="supplementary-material">i</xref>). <bold>DS1</bold>: For every subject (<italic>n</italic> = 100) the effect of embedding alignment on the mean cosine similarity of pairs of identical nodes (200 pairs) was tested. Significant improvement in node pair similarity (<italic>t</italic> (199) = 111.14, <italic>p</italic> &lt; 2.2e-16) was observed after applying embedding alignment (cos(<italic>θ</italic>) = 0.98 ± 0.001) compared to before alignment (cos(<italic>θ</italic>) = 0.92 ± 0.005). In contrast, the relations among pairs of different nodes, were highly consistent across independent fitting iterations both before (cos(<italic>θ</italic>) = 0.99998 ± 2.7e-6) and after embedding alignment (cos(<italic>θ</italic>) = 0.99992 ± 2.4e-5; <xref rid="SD1" ref-type="supplementary-material">SI Fig. 1b</xref>). Applying the same approach to <bold>DS2</bold> resulted in a similar outcome (<italic>t</italic> (232) = 118.31, <italic>p</italic> &lt; 2.2e-16; cos(<italic>θ</italic>) = 0.96 ± 0.004; cos(<italic>θ</italic>) = 0.90 ± 0.005; cos(<italic>θ</italic>) = 0.9999 ± 8.7e-5; cos(<italic>θ</italic>) = 0.9998 ± 9.1e-5; see <xref rid="SD1" ref-type="supplementary-material">SI 2</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 2a</xref>,<xref rid="SD1" ref-type="supplementary-material">b</xref>). These findings show that the alignment procedure successfully reduces the intra-individual variance in the embeddings. This is a crucial step towards identifying differences in CE embeddings obtained from different individuals.</p>
        </sec>
        <sec id="S21">
          <label>3.1.2.</label>
          <title>Inter-individual CE similarity evaluation</title>
          <p id="P39">Embedding alignment is meant to reduce variance that resulted from the stochasticity in node2vec fitting process. However, we do not expect perfect correspondence across individuals due to inherent differences in their underlying brain anatomy. To take this into account, we applied a more lenient test for estimating inter-individual CE similarity, the embedding ranking test (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). Using the ranking test, we examined whether pairs of anatomically corresponding nodes across different individuals would be more similar than pairs of non-corresponding nodes, following embedding alignment. In this test, a given node would be ranked 0 if its closest neighbors in another individual, is the same anatomically corresponding node (<xref rid="SD1" ref-type="supplementary-material">SI Fig. 1c</xref>,<xref rid="SD1" ref-type="supplementary-material">i</xref>). In all analyses, query of the <italic>i-</italic>nearest node was done using cosine similarity.</p>
          <p id="P40"><bold>DS1</bold>: For every possible subject pair (<italic>n</italic> = 100; 9,950 pairs), we tested the effect of embedding alignment on the distribution of the node similarity rank. Before embedding alignment, 35.3% ± 37.1% of the nodes were ranked in the top 2 nodes, compared to 86.3% ± 4.6% following alignment. The percent of nodes ranked in the top 2 nodes was significantly higher following embedding alignment (<italic>t</italic> (9,949) = 135.7, <italic>p</italic> &lt; 2. 2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI Fig. 1c</xref> for the complete distribution). Similar results were found in <bold>DS2</bold> (<italic>n</italic> = 100; 9,950 pairs; 10.8% ± 16.7%; 52.7% ± 7.9%; <italic>t</italic> (9,949) = 246.6, <italic>p</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 3</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 2c</xref>).</p>
          <p id="P41">Next, to test the similarity of nodes’ relations we applied an analogy ranking test. This test measures whether the displacement vector from node <italic>a</italic> to <italic>b</italic> in one individual would express the same relation in another individual. We take the vectors of the right anterior cingulate cortex (rACC) and the right insula (rINS) as an example. In this case, a rank of 0 means that the rACC of subject <italic>a</italic> minus the rINS of subject <italic>a</italic> plus the rINS of subject <italic>b</italic> was closest to the rACC of subject <italic>b</italic>. <bold>DS1</bold>: The analogy test was conducted for every subject pair (a subset of n=30) and node pair (870 and 39,800 pairs respectively). Before embedding alignment 23.3% ± 26.6% of the nodes were ranked in the top 2 nodes compared to 71.0% ± 6.7% following alignment. This difference was significant (<italic>t</italic> (869) = 52.2, <italic>p</italic> &lt; 2.2e-16; <xref rid="SD1" ref-type="supplementary-material">SI Fig. 1d</xref>). Similarly in <bold>DS2</bold> (870 and 49,506 respectively; 4.1% ± 6.5%; 31.2% ± 5.2%; <italic>t</italic> (869) = 104.7, <italic>p</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 3</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 2d</xref>).</p>
        </sec>
      </sec>
      <sec id="S22">
        <label>3.2.</label>
        <title>Mapping structural to functional connectivity using CE</title>
        <p id="P42">Resting-state functional connectivity refers to the temporal statistical dependence among activations in different brain nodes measured in the absence of an explicit task. While these patterns of coactivations depend on the structural connectivity, the observed correlation between the strengths of structural and functional connections is moderate, capturing only a fraction of the observed variance (<xref rid="R33" ref-type="bibr">Honey et al., 2010</xref>; <xref rid="R58" ref-type="bibr">Suárez et al., 2020</xref>). Testing this relation on the individual level, rather than the group level, further weaken the observed structure-function correspondence (<xref rid="R57" ref-type="bibr">Straathof et al., 2019</xref>). The CE framework was shown to improve the mapping of structural to functional connectivity at the group-level, presumably due to its ability to capture high-order graph relations (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>). Here we first reproduce those findings and extend the approach to structure-function relations within individuals.</p>
        <sec id="S23">
          <label>3.2.1.</label>
          <title>Group-level structure to function mapping</title>
          <p id="P43">The relation between the group-level structural connectivity and the functional connectivity was quantified using Spearman’s rank correlation among corresponding functional and structural edges. The structural consensus connectivity matrix is typically sparse and accordingly, 38.9 and 18.9% of the group-level structural edges in DS1 and DS2, respectively, were larger than zero. For this reason, the correlation was taken only for node pairs linked by a structural edge, i.e. direct edges, in comparison to edges not linked by a structural connection, <italic>i.e.</italic> indirect. An additional measure of structural relation among nodes could be derived by taking the cosine angle among each pair of node embeddings. The CE cosine similarity was previously shown to substantially improve structure-function mapping (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>) and allowed to estimate this relation for both direct and indirect edges, as the cosine angle could be quantified even for pairs of nodes for which no connecting tracts were reconstructed. <bold>DS1</bold>: A significant correlation between the raw, direct structural edges and their corresponding functional connectivity edges was found (<italic>ρ</italic>(7782) =. 311, <italic>p</italic> &lt; 2.2e-16; <xref rid="F4" ref-type="fig">Fig. 4 a</xref>). This structure-function correlation was higher when using the CE cosine similarity instead of the structural edges (<italic>ρ</italic>(7782, 12114, 19898) =. 345,.137,.282; all p’s <italic>p</italic> &lt; 2.2e-16; for the direct, indirect and all edges respectively; <xref rid="F4" ref-type="fig">Fig. 4 b</xref>). Similar results were found in <bold>DS2</bold> (<italic>ρ</italic>(5032) = 0.287, <italic>p</italic> &lt; 2.2e-16; <italic>ρ</italic>(5032, 21992, 27026) =. 389,.256,.340; all <italic>p</italic> ‘s <italic>p</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 4</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 5a</xref>,<xref rid="SD1" ref-type="supplementary-material">b</xref>).</p>
          <p id="P44">Next, we explored the contribution of individual edges to the CE-based structure-function mapping. Such estimation could be done on each unique edge since the CE cosine matrix is dense compared to the sparse raw structural connectivity matrix. We computed the structure-function correlation before minus after the removal of individual nodes. The result, the Δ correlation, informs us about the sign and relative magnitude of the contribution of each edge to the overall correlation (<xref rid="R24" ref-type="bibr">Gluth and Meiran, 2019</xref>; <xref rid="F3" ref-type="fig">Figs. 3 a</xref>, <xref rid="SD1" ref-type="supplementary-material">SI a</xref>). To test whether the Δ correlation could be solely attributed to the functional or the CE cosine edge values, we reported its correlation to the latter two. We compared the Δ correlation for direct versus indirect edges and for edges within the 7 canonical resting-states networks (<xref rid="R64" ref-type="bibr">Yeo et al., 2011</xref>) compared to between (see <xref rid="SD1" ref-type="supplementary-material">SI 4</xref> for each of the networks). We additionally tested Δ correlation relation to Euclidian distance among node. <bold>DS1</bold>: A significant, weak correlation was found between the Δ correlation and the CE cosine (<italic>ρ</italic>(19898) = 0.242, <italic>p</italic> &lt; 2.2e-16) and the functional connectivity (<italic>ρ</italic>(19898) = 0.167, <italic>p</italic> &lt; 2.2e-16) values. The Δ correlation was significantly larger for direct compared to indirect edges (Δ direct = −5.34e-06 ± 3.7e-05, Δ indirect = −5.34e-06 ± 3.7e-05;t(19898) = 19.418, <italic>p</italic> &lt; 2.2e-16), and for edges within, compared to between canonical networks (Δ within = 2.26e-05 ± 6.1e-05, Δ between = −4.09e-06 ± 4.5e-05;t(19898) = 28.303, <italic>p</italic> &lt; 2.2e-16). Additionally, we found a significant interaction between the two factors (F(3,19896) = 1018.535, <italic>p</italic> &lt; 2.2e-16) such that, within compared to between networks’ edges were larger for direct edges (t(19898) = 39.943, <italic>p</italic> &lt; 2.2e-16) and a smaller, opposite effect was found for indirect edges (t(19898) = −16.586, <italic>p</italic> = 1.0e-08; <xref rid="F3" ref-type="fig">Fig. 3 b</xref>). A small correlation was found between the Euclidian distance and Δ correlation (r(19898) = 0.057, <italic>p</italic> &lt; 1.2e-15). Similar results were found in <bold>DS2</bold> (r(27026) = 0.107, <italic>p</italic> = &lt; 2.2e-16, r(27026) = 0.097, <italic>p</italic> &lt; 2.2e-16; Δ direct = 6.47e-06 ± 4.3e-05, Δ indirect = −1.48e-06 ± 3.5e-05; t(27026) = 13.897, <italic>p</italic> &lt; 2.2e-16; Δ within = 1.21e-05 ± 4.7e-05, Δ between = −2.21e-06 ± 3.4e-05; t(27026) = 23.446, <italic>p</italic> &lt; 2.2e-16; F(3,27024) = 762.826, <italic>p</italic> &lt; 2.2e-16; t(27026) = 28.650, <italic>p</italic> &lt; 2.2e-16; t(27026) = −8.132, <italic>p</italic> = 4.4e-16; r(27026) = 0.115, <italic>p</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 4</xref>, <xref rid="SD1" ref-type="supplementary-material">SI Figs. 3c</xref> and <xref rid="SD1" ref-type="supplementary-material">SI 4b</xref>). These results suggest that structure-function correspondence is largely driven by direct, within network edges.</p>
        </sec>
        <sec id="S24">
          <label>3.2.2.</label>
          <title>Predicting group-level functional from structural connectivity with deep learning</title>
          <p id="P45">The improvement in structure to function mapping using the CE cosine similarity was obtained without attempting to optimize this measure to match functional connectivity. In previous work (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>), this mapping was further improved using a deep learning model in which CEs were utilized as features to predict the functional edges. Specifically, the element-wise multiplication of pairs of nodes embeddings was used as input, and the predicted label was the observed functional connectivity among the two. We implemented a 4-layer, fully connected neural network, and the prediction was evaluated using cross-validation (see <xref rid="S2" ref-type="sec">Method</xref> section). DS1: The Spearman’s rank correlation coefficient between the predicted and observed functional connectivity values were <italic>ρ</italic>(7782) =. 641, <italic>ρ</italic>(12114) =. 527 and <italic>ρ</italic>(19898) =. 599, for the direct, indirect and all edges respectively, all p’s <italic>p</italic> &lt; 2.2e-16 (see <xref rid="F2" ref-type="fig">Fig. 2 c</xref>). Similar results were found in DS2 (<italic>ρ</italic>(5032) =. 542, <italic>ρ</italic>(21992) =. 488 and <italic>ρ</italic>(27026) =. 527; all p’s <italic>p</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 5</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 5c</xref>).</p>
        </sec>
        <sec id="S25">
          <label>3.2.3.</label>
          <title>Individual-level structure to function mapping</title>
          <p id="P46">Next, we tested whether the CE framework could be similarly utilized to map structural to functional connectivity within individuals. Structure-function correspondence was evaluated using Spearman’s rank correlation in each subject. We report this correlation using the structural connectivity values for direct edges and then again using the CE cosine similarity measure for direct and indirect edges. <bold>DS1</bold>: A significant correlation between the direct structural edges and their corresponding functional connectivity edges was found for all subjects (<italic>ρ</italic> =. 197 ± .031, all p’ <italic>s</italic> &lt; 2.2e-16; <xref rid="F2" ref-type="fig">Fig. 2 d</xref>). Similar matching to the CE cosine similarities values of direct edges revealed a significantly higher correlation (t(180) = 16.7, <italic>p</italic> &lt; 2.2e-16). The mean and standard deviation across subjects was <italic>ρ</italic> =. 228 ± 048, <italic>ρ</italic> =. 066 ± .035, <italic>ρ</italic> =. 185 ± .037 for the direct, indirect and all edges, respectively. We found similar results in <bold>DS2</bold> (<italic>ρ</italic> =. 152 ± .028, all p’ <italic>s</italic> &lt; 2.2e-16; t(144) = 34.4, <italic>p</italic> &lt; 2.2e-16; <italic>ρ</italic> =. 245 ± .040, <italic>ρ</italic> =. 102 ± .035, <italic>ρ</italic> =. 181 ± .344; see <xref rid="SD1" ref-type="supplementary-material">SI 6</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 5d</xref>).</p>
          <p id="P47">Finally, as in the group-level, we trained a deep learning neural network for predicting functional connectivity values from aligned CE, this time within individuals. <bold>DS1</bold>: A significant increase in the observed correlation for the direct edges was evident both compared to the structural edges (t(180) = 66.0, <italic>p</italic> &lt; 2.2e-16) and the CE cosine similarity measures (t(180) = 53.4, <italic>p</italic> &lt; 2.2e-16; <xref rid="SD1" ref-type="supplementary-material">SI Fig. 3d</xref>). The mean and standard deviation of the predicted, compared to the observed FC correlation was <italic>ρ</italic> =. 397 ± .051, <italic>ρ</italic> =. 253 ± .059, <italic>ρ</italic> =. 337 ± .051, all p’ <italic>s</italic> &lt; 2.2e-16, for the direct, indirect and all edges respectively. The same results were also obtained in <bold>DS2</bold> (t(144) = 52.8, <italic>p</italic> &lt; 2.2e-16; t(144) = 34.5, <italic>p</italic> &lt; 2.2e-16; <italic>ρ</italic> =. 312 ± .043, <italic>ρ</italic> =. 210 ± .051, <italic>ρ</italic> =. 265 ± .046, all p’ <italic>s</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 6</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 5d</xref>).</p>
        </sec>
        <sec id="S26">
          <label>3.2.4.</label>
          <title>Parameters of the random walk and their relation to structure to function</title>
          <p id="P48">The use of random walks to learn embeddings of brain nodes is strongly related to diffusive models of communication in the brain (<xref rid="R6" ref-type="bibr">Avena-Koenigsberger et al., 2018</xref>). Here we examine how such a diffusive process, as captured by the node2vec embedding algorithm, can model the relation between structural connectivity and functional connectivity. We adjusted the parameters of the random walk to be more globally or locally biased and measured the observed correlation between the CE cosine matrix and the functional connectivity. The parameters of the random walk were shifted from locally biased (<italic>p</italic> = 10<sup>−3</sup>, <italic>q</italic> = 4.096) through unbiased (<italic>p</italic> = 1, q = 1) to globally biased (<italic>p</italic> = 10<sup>3</sup>, <italic>q</italic> = 0.244) random walks in 20 equal-spaced steps on a logarithmic scale. All results are present for the direct, indirect and all edges, respectively. <bold>DS1</bold>: Shifting from most locally biased (<italic>ρ</italic> = 0.128 ± 0.128, <italic>ρ</italic> = 0.007 ± 0.007, <italic>ρ</italic> = 0.061 ± 0.061) to the unbiased random walk (<italic>ρ</italic> = 0.253 ± 0.253, 0.082 ± 0.082, 0.200 ± 0.200) we observed a significant increase in structure to function mapping (t(11.5) = −17.033, −7.987, −18.184; all p’s &lt; 3.25e-08). Moving to the most globally biased random walk (<italic>ρ</italic> = 0.245 ± 0.245, 0.068 ± 0.068, 0.192 ± 0.192) revealed a smaller but significant decrease in structure to function mapping (t(11.5) = −4.651, −5.564, −6.137; all p’ <italic>s</italic> &lt; 1.01e-04; <xref rid="F4" ref-type="fig">Fig. 4</xref>). In <bold>DS2,</bold> we found a similar increase when shifting from the most local to an unbiased random walk, but no significant difference moving to the most globally biased random walk (<italic>ρ</italic> = 0.202 ± 0.202, 0.002 ± 0.002, 0.049 ± 0.049; <italic>ρ</italic> = 0.267 ± 0.267, 0.122 ± 0.122, 0.202 ± 0.202; t(11.5) = −12.207, −20.914, −28.666; all p’ <italic>s</italic> &lt; 8.76e-12; <italic>ρ</italic> = 0.262 ± 0.262, 0.119 ± 0.119, 0.200 ± 0.200; t(11.5) = −2.789, −1.402, −1.267; <italic>p</italic> = 0.010, 0.174, 0.217; see <xref rid="SD1" ref-type="supplementary-material">SI 7</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 6</xref>).</p>
        </sec>
        <sec id="S27">
          <label>3.2.5.</label>
          <title>Age-related changes in individual-level structure-function correspondence</title>
          <p id="P49">Previous work reported age-related changes in structure-function coupling, but these were quantified at the whole connectome (<xref rid="R9" ref-type="bibr">Betzel et al., 2014</xref>) or the nodal (<xref rid="R65" ref-type="bibr">Zimmermann et al., 2016</xref>) levels. Here we examine whether the CE framework could be utilized to explore these alterations by testing the relation of aging to structure-function correlation. Importantly, the analysis was conducted both at the network level and at the edge-level by applying our edgewise contribution score (<xref rid="S23" ref-type="sec">section 3.2.1</xref>) for each subject. <bold>DS1</bold>: A significant Pearson correlation was found between subjects’ age and structure-function correlation when using the structural edges (r(179) = −.406, <italic>p</italic> = 1.4e-8) and the CE cosine similarity r(179) = −.487, <italic>p</italic> = 3.6e-12; <xref rid="F5" ref-type="fig">Fig. 5 a</xref>). The observed increase in the correlation for the CE cosine similarity was significant (<italic>t</italic> = 2.621, <italic>p</italic> = 0.009). Next, we aimed to identify edges whose contribution to the structure-function correlation increases or decreases with age. We computed the edgewise contribution score for all subjects and correlated each edge with age (<xref rid="F5" ref-type="fig">Fig. 5 b</xref>). Using network contingency analysis, we revealed significant widespread age-related alteration in the structure-function contribution score (<xref rid="F5" ref-type="fig">Fig. 5 c</xref>). Examining edges within the 7 canonical functional networks (<xref rid="R64" ref-type="bibr">Yeo et al., 2011</xref>), we found a general decrease with age within hemispheres (t’s = 6.94, 5.58, 3.02, 1.66; p’s = 5.9e-12, 2.82e-08, 0.002, 0.097; for |r| threshold of. 25,. 3,. 35,. 4 respectively) and increase between hemispheres (t’ <italic>s</italic> = 6.34, 6.04, 3.54, 1.73; p’ <italic>s</italic> = 3.03e-10, 1.87e-09, 4.14e-04, 0.084; for |r| threshold of. 25,. 3,. 35,. 4). A mixed pattern was found between functional networks. Similar results were obtained in <bold>DS2</bold>: (r(144) = −.240, <italic>p</italic> =. 003; r(144) = −.533, <italic>p</italic> = 5.3e-12; <italic>t</italic> = 4.9, <italic>p</italic> = 1.4e-5; t’ <italic>s</italic> = 3.83, 2.48, 2.09, 1.19; p’<italic>s</italic> = 1.3e-4, 0.013, 0.037, 0.233; t’<italic>s</italic> = 14.7, 12.9, 11.1, 9.04; all p’ <italic>s</italic> &lt; 2.2e-16; see <xref rid="SD1" ref-type="supplementary-material">SI 8</xref>, <xref rid="SD1" ref-type="supplementary-material">SI Figs. 7</xref> and <xref rid="SD1" ref-type="supplementary-material">SI 9</xref>).</p>
        </sec>
      </sec>
      <sec id="S28">
        <label>3.3.</label>
        <title>Modeling individual differences in age and intelligence using CE</title>
        <p id="P50">Producing individual-level CE requires learning a compact vectorized representation of brain nodes and aligning the representations obtained from different individuals to the same latent space. We wanted to examine whether these transformations preserve variance associated with individual differences and whether representing connectomes with CE improves our ability to estimate those individual differences. Specifically, we used CE for out-of-sample prediction of age and intelligence in two separate datasets. In the previous section we focused on age-related individual differences in structural-functional correspondence. Here, age was directly predicted from CE.</p>
        <sec id="S29">
          <label>3.3.1.</label>
          <title>Capturing individual differences with CE</title>
          <p id="P51">To predict age and intelligence we used a linear regression with CE and the CE cosine matrix as input (see <xref rid="SD1" ref-type="supplementary-material">SI 9.5</xref> for results with not-aligned CE). First, within the training set, we used 5-fold cross-validation to predict each of the two outcomes using each node as an input (see <xref rid="F6" ref-type="fig">Figs. 6</xref>; and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 10</xref>). Then, individual nodes’ predictions were combined both by fitting a second-level model or by taking their mean, and testing on the left-out test set (<xref rid="SD1" ref-type="supplementary-material">SI Figs. 11</xref>, <xref rid="SD1" ref-type="supplementary-material">12</xref>). The performance of the models was quantified as the correlation between the observed and predicted age or intelligence and the mean absolute error (MAE). <bold>DS1</bold>: For age, the mean observed-predicted correlation across all nodes was <italic>r</italic> =. 464(± .078), MAE = 15.4(± 1.0) for CE and <italic>r</italic> = 0.468(± 0.057), MAE = 19.6 (± 1.4) for the CE cosine matrix. Similarly, for intelligence <italic>r</italic> =. 090(± .074), MAE = 24.0(± 0.5) for CE, and <italic>r</italic> = 0.084(± 0.066), MAE = 38.3(± 2.4) for the CE cosine matrix. The connectome-level model, validated on the left-out test set, revealed a significant correlation of the observed-predicted age (CE: r(188) = 0.769, 0.760, MAE = 10.5, 13.6; cosine CE: r(188) = 0.826, 0.746, MAE = 11.5, 9.5; for the second-level model and the mean respectively; all p’ <italic>s</italic> &lt; 2.2e-16) and intelligence (CE: r(188) = 0.377, 0.230, MAE = 22.2, 21.5; cosine CE: r(188) = 0.230, 0.339, MAE = 26.5, 20.9; for the second-level model and the mean respectively, all p’ <italic>s</italic> &lt; 0.008 except the CE cosine second-level model MAE that was nonsignificant). Applying the same analysis to <bold>DS2</bold> yielded similar results (r =. 410(± .087), MAE = 14.1(± 0.8); r =. 336(± 0.059), MAE = 21.0(± 1.5); r =. 219(± 0.075), MAE = 37.2(± 0.1); r = 0.128(± 0.068), MAE = 8.8(± 0.7); CE: r(199) = 0.717, 0.787, MAE = 15.3, 11.6; r(199) = 0.614, 0.831, MAE = 15.6, 8.8; all p’ <italic>s</italic> &lt; 2.2e-16; r(199) = 0.547, 0.586, MAE = 5.2, 4.7, r = 0.434, 0.576, MAE = 5.3, 4.3; all p’ <italic>s</italic> &lt; 0.008 except for the second-level model with cosine CE which was nonsignificant; see <xref rid="SD1" ref-type="supplementary-material">SI 9.1</xref>). In both datasets all results were reproduced for age prediction after controlling for gender. Controlling for age and gender in intelligence prediction reproduced all results in DS1, while the observed effects were reduced in DS2, such that a small, yet significant effect was found for the ensemble model only for the CE cosine matrix as input (see <xref rid="SD1" ref-type="supplementary-material">SI 9.3</xref>).</p>
        </sec>
        <sec id="S30">
          <label>3.3.2.</label>
          <title>Predictive accuracy of CE compared to structural and functional connectivity</title>
          <p id="P52">Next, we examined whether predictive accuracy gained with CE would be superior compared to using only structural or functional connectivity as input. We repeated the same steps for the two additional inputs and compared the resulting performance to CE across all nodes using a paired t-test. <bold>DS1</bold>: For age, the mean observed-predicted correlation across all nodes was <italic>r</italic> =. 155(± .097), MAE = 132.2(± 1417.4) for structural connectivity and <italic>r</italic> = 0.326(± 0.085), MAE = 22.9(± 2.3) for functional connectivity. Similarly, for intelligence <italic>r</italic> =. 027(± .059), MAE = 176.6 (± 1792.0) for structural connectivity, and <italic>r</italic> = 0.044(± 0.069), MAE = 40.3(± 2.6) for functional connectivity. Using both CE and the CE cosine matrix resulted in significantly higher observed-predicted correlation than functional and structural connectivity for age (all t’s(199) &gt; 17.0, p’ <italic>s</italic> &lt; 2.2e-16) and intelligence (all t’ <italic>s</italic> (199) &gt; 6.91, all p’ <italic>s</italic> &lt; 6.6e-11). The structural connectivity connectome-level model, validated on the left-out test set, resulted in a significant correlation for the age connectome-level (r(188) = 0.582, MAE = 13.8, p’ <italic>s</italic> &lt; 2.2e-16) while all other model were nonsignificant (all r’s(188) &lt; 0.084, p’ <italic>s</italic> &gt; 0.267). Functional connectivity resulted in significant correlation when taking the mean of the nodal predictions (age: r(188) = 0.817, MAE = 9.3, p’ <italic>s</italic> &lt; 2.2e-16; intelligence: r(188) = 0.339, MAE = 20.9, <italic>p</italic> &lt; 4.1e-06) but not for the second-level model (all r’s(188) &lt; 0.000; see <xref rid="F6" ref-type="fig">Fig. 6</xref>). Applying the same analysis to <bold>DS2</bold> yielded similar results (<italic>r</italic> =. 026(± .062), MAE = 264.8(± 906.7); <italic>r</italic> = 0.133(± 0.066), MAE = 58.1(± 10.1); <italic>r</italic> =. 007(± .059), MAE = 1217.9(± 15592.0); <italic>r</italic> = 0.029(± 0.064), MAE = 30.6(± 5.5); all t’s(232) &gt; 16.7, all p’ <italic>s</italic> &lt; 2.2e-16), except for CE and functional connectivity: t(232) = 34.4, <italic>p</italic> &lt; 2.2e-16; all t’s (232) &gt; 3.27, all p’ <italic>s</italic> &lt; 0.002, except for cosine embedding and functional connectivity: t(232) = −0.329, <italic>p</italic> = 0.743; all r’s(137) &lt; −.005, p’ <italic>s</italic> &gt; 0.953; see <xref rid="SD1" ref-type="supplementary-material">SI 9.2</xref> and <xref rid="SD1" ref-type="supplementary-material">SI Fig. 10</xref>). In both datasets all results were reproduced for age prediction after controlling for gender. Controlling for age and gender for intelligence prediction reproduced all results in DS1 but not in DS2 (see <xref rid="SD1" ref-type="supplementary-material">SI 9.4</xref>). This might result from a smaller sample size of individuals who had both structure and functional data in DS2 (425 compared to 601 subjects). In <xref rid="SD1" ref-type="supplementary-material">SI 9.6</xref> we include additional analyses examining possible causes for the lower performance obtained with structural connectivity compared to CE and its relation to structural connectivity sparsity.</p>
        </sec>
      </sec>
    </sec>
    <sec id="S31">
      <label>4.</label>
      <title>Discussion</title>
      <p id="P53">Studies of the human connectome have added to our understanding of the organizing principles of neural processing and communication in the brain. However, the relation between observed individual differences in connectome topology and individual differences in function and behavior is still poorly understood. In the current work, we lever-age the CE framework for modeling individual differences by aligning embeddings of different individuals to a common space. We empirically evaluated our alignment scheme and found a large increase in node’s similarity across subjects, indicating successful alignment of individual connectome embeddings. We then demonstrated two contributions of applying the CE framework at the individual subject level. The first is the improvement in subject-level mapping of structural to functional connectivity while preserving age-related variance associated with this structure-function correspondence. The second contribution is the successful use of aligned CE in predicting demographic and behavioral variables. CE resulted in significantly improved prediction of age and intelligence compared to structural or functional connectivity alone, suggesting that CE not only preserves variability related to demographics and behavior, but also accentuates this variability such that it is more accessible for prediction-based models.</p>
      <sec id="S32">
        <label>4.1.</label>
        <title>CE alignment</title>
        <p id="P54">Enabling the mutual alignment of CEs is a necessary step to utilize machine learning techniques for subsequent tasks such as prediction of functional connectivity or the presence of a neurological condition. Here we consider two problems that may be aided by proper CE alignment. The first is to find an optimal one-to-one mapping between nodes taken from one connectome to another based on their topological attributes. Such mapping could be used, for example, to find homologous brain structures among different species. The second involves aligning vectorized representations of connectomes in the same latent space to allow their comparison. Here, the mapping of corresponding nodes across connectomes is known <italic>a priori</italic> and we are interested in the subtle variations in these vectorized representations that arise due to differences in the sampled random walks. The goal is to remove variability related to the stochasticity in the CE fitting process and the different latent spaces, and preserve variability related to variations in the underlining network topology. While the first problem has been previously addressed in applications such as translation among languages (<xref rid="R53" ref-type="bibr">Smith et al., 2017</xref>), to the best of our knowledge, the second has not been addressed before. We suggest that our CE alignment method could additionally be used in linguistic tasks such as authorship attribution (<xref rid="R35" ref-type="bibr">Kocher and Savoy, 2018</xref>) or examining differences in word semantics among different cultures (<xref rid="R34" ref-type="bibr">Karimi et al., 2015</xref>). Notably, our method is computationally efficient as it does not require the co-learning of all embeddings when encountering a new sample (<xref rid="R63" ref-type="bibr">Wolf et al., 2014</xref>) making it more desirable for clinical applications.</p>
      </sec>
      <sec id="S33">
        <label>4.2.</label>
        <title>Mapping structural to functional connectivity</title>
        <p id="P55">The observed correlation between group-level structural and functional connectivity is typically moderate (<italic>r</italic> = 0.3–0.5; <xref rid="R58" ref-type="bibr">Suárez et al., 2020</xref>). In part, moderate correlations may reflect limits on acquisition and reconstruction, as well as the fact that the same structural backbone supports a large and dynamic repertoire of functional interactions (<xref rid="R16" ref-type="bibr">Deco et al., 2013</xref>; <xref rid="R21" ref-type="bibr">Fukushima et al., 2018</xref>). Nevertheless, considering high-level structural interactions among nodes might explain a larger portion of the functional connectivity variance. In the current work, we demonstrate that using a deep learning model, functional connectivity could be predicted from CE, while substantially improving structure-function mapping at the group-level (DS1: <italic>ρ</italic> = 0.64, DS2: <italic>ρ</italic> = 0.54). The observed structure-function correlation at the individual subject level is often more modest than group-level estimates (<italic>r</italic> = 0.02–0.25; <xref rid="R57" ref-type="bibr">Straathof et al., 2019</xref>) possibly due to noise associated with the acquisition of the different imaging modalities, under-sampling of resting-state dynamics in short scans (<xref rid="R10" ref-type="bibr">Birn et al., 2013</xref>), and variation in functional boundaries among individuals (<xref rid="R27" ref-type="bibr">Gordon et al., 2017</xref>). Applying the CE approach to similar mapping at the individual-level resulted in significant improvements of structure-function correlations (DS1: <italic>ρ</italic> = 0.397, DS2: <italic>ρ</italic> = 0.312). Additionally, CE produced an edge-wise similarity measure even for pairs of nodes for which no connecting tracts were found. This allows a more comprehensive estimate of edge-wise contribution to structure-function correspondence. Our results suggest that a specific subset of edges (direct edges within canonical resting-state networks) drive the observed structure-function correlation. Finally, we showed that CE preserved, and even enhanced age-related individual differences in structure-function mapping.</p>
      </sec>
      <sec id="S34">
        <label>4.3.</label>
        <title>CE as a model of communication linking structure to function</title>
        <p id="P56">CE may advance our understanding of the nature of communication in the brain. Communication or information flow in brain networks could be seen as the complete set of dynamic causal influences among pairs of neuronal elements (<xref rid="R6" ref-type="bibr">Avena-Koenigsberger et al., 2018</xref>). According to this view, communication is constrained by the structural connectivity scaffold and gives rise to the observed co-fluctuations among pairs of brain regions (functional connectivity), and hence it offers a link between the two. Models of communication processes among brain regions range from diffusive flow of information, as in random walks, to routing mechanisms, such as schemes based on shortest paths. CE, fitted based on a set of random walks, can be viewed as a generative model of diffusive communication around nodes. Their success implies that diffusive models might better capture the observed functional connectivity (<xref rid="R26" ref-type="bibr">Goni et al., 2014</xref>). Further manipulation of the specific random walk parameters used to fit the CE model, suggest that an unbiased, or a slightly locally biased random walk best accounts for the observed functional connectivity. In future work the sampled walks could be generated based on different mechanisms (<italic>e.g.</italic> shortest paths) and their relation of corresponding embeddings to static or dynamic connectivity could be tested.</p>
      </sec>
      <sec id="S35">
        <label>4.4.</label>
        <title>Prediction of individual differences using aligned CE</title>
        <p id="P57">Cross-subject alignment, whether conducted based on anatomy (<xref rid="R20" ref-type="bibr">Frost and Goebel, 2012</xref>) or function (<xref rid="R30" ref-type="bibr">Haxby et al., 2020</xref>), is a critical step for highlighting individual differences in brain mapping. Here we consider the characterization of individual differences as an ideal test case for the CE alignment approach. Indeed, we found that aligned CE, as well as CE cosine similarity matrices show a robust increase in prediction accuracy compared to structural connectivity for age and intelligence both at the individual node and the whole connectome levels. This observed increase in predictive accuracy could be attributed to the sparsity and dimensionality of the structural connectivity matrix, and its inability to capture high-order topological relations. These might explain how despite a growing trend in studies focusing on individual differences (<xref rid="R59" ref-type="bibr">Sui et al., 2020</xref>), fewer studies so far have applied a predictive modeling on structural connectivity data as compared to other modalities, such as functional connectivity (<xref rid="R5" ref-type="bibr">Arbabshirani et al., 2017</xref>). Our CE framework addresses these issues by learning node representations that are low dimensional and preserves nodes’ topological context, rather than its mere direct connections. When depicted in the form of a cosine similarity matrix it captures all pair-wise relations among nodes resulting in a dense matrix representation. In addition to this advantage in representing structural connectivity, CE can be viewed as a model of brain communication. Thus, it represents a functional aspect of brain connectivity in addition to structure. This might explain the advantage at nodal-level or the similarity for the connectome-level model of CE compared to functional connectivity in predictive accuracy. Note that functional connectivity exhibits comparable results only for one of the connectome level models (nodal mean). Thus, the CE framework might hold promise to advance the application of connectome mapping to such predictive models. Future work can utilize the CE predictive framework to study connectome alterations in neurodevelopmental conditions. Furthermore, we can explore the effect of “lesioning” of the network by for example, zeroing out connections or entire nodes before the embedding process. Then, the effect of these “lesions” on the predicted outcome in such prediction models could be tested (<xref rid="R48" ref-type="bibr">Rosenthal et al., 2018</xref>).</p>
      </sec>
      <sec id="S36">
        <label>4.5.</label>
        <title>Conclusions</title>
        <p id="P58">Our findings suggest that learned connectome representations and their mutual alignment are a powerful tool for conducting individual-level mapping of structural connectivity to function and behavior. We suggest two complementary views on CE. The first, is an improved structural connectivity representation, allowing to quantify structural relations that are missing from the network reconstruction. The second, as a proxy for diffusive communication on the structural backbone, hence incorporating aspects of structure (the structural graph) as well as function (the diffusive process). The advancements made here in the CE framework support current efforts in neuroscience to better understand and address individual differences.</p>
      </sec>
    </sec>
    <sec sec-type="supplementary-material" id="SM1">
      <title>Supplementary Material</title>
      <supplementary-material content-type="local-data" id="SD1">
        <label>1</label>
        <media xlink:href="NIHMS1741416-supplement-1.docx" orientation="portrait" id="d40e2299" position="anchor"/>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack id="S38">
      <title>Acknowledgment</title>
      <p id="P60">This research was supported by the U.S.-Israel Binational Science Foundation (BSF), Grant 2017242 to GA and OS. OS was partially supported by NIH Grant R01MH122957. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1342962 (J.F.).</p>
    </ack>
    <fn-group>
      <fn id="FN2">
        <p id="P61">Supplementary materials</p>
        <p id="P62">Supplementary material associated with this article can be found, in the online version, at doi:<ext-link ext-link-type="doi" xlink:href="10.1016/j.neuroimage.2021.118469">10.1016/j.neuroimage.2021.118469</ext-link>.</p>
      </fn>
    </fn-group>
    <sec id="S37" sec-type="data-availability">
      <title>Data availability</title>
      <p id="P59">The unprocessed data is openly available online at <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/enhanced/neurodata.html">http://fcon_1000.projects.nitrc.org/indi/enhanced/neurodata.html</ext-link> for DS1and available upon online access request <ext-link ext-link-type="uri" xlink:href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/</ext-link> for DS2. A python package implementation of CE framework (<ext-link ext-link-type="uri" xlink:href="https://github.com/GidLev/cepy">https://github.com/GidLev/cepy</ext-link>) and set of interactive notebooks reproducing the main results of the paper (<ext-link ext-link-type="uri" xlink:href="https://github.com/GidLev/cepy/tree/master/examples">https://github.com/GidLev/cepy/tree/master/examples</ext-link>) were made available online.</p>
    </sec>
    <ref-list>
      <title>Reference</title>
      <ref id="R1">
        <mixed-citation publication-type="journal"><name><surname>Abadi</surname><given-names>M</given-names></name>, <name><surname>Agarwal</surname><given-names>A</given-names></name>, <name><surname>Barham</surname><given-names>P</given-names></name>, <name><surname>Brevdo</surname><given-names>E</given-names></name>, <name><surname>Chen</surname><given-names>Z</given-names></name>, <name><surname>Citro</surname><given-names>C</given-names></name>, <name><surname>Corrado</surname><given-names>GS</given-names></name>, <name><surname>Davis</surname><given-names>A</given-names></name>, <name><surname>Dean</surname><given-names>J</given-names></name>, <name><surname>Devin</surname><given-names>M</given-names></name>, <name><surname>Ghemawat</surname><given-names>S</given-names></name>, <name><surname>Goodfellow</surname><given-names>I</given-names></name>, <name><surname>Harp</surname><given-names>A</given-names></name>, <name><surname>Irving</surname><given-names>G</given-names></name>, <name><surname>Isard</surname><given-names>M</given-names></name>, <name><surname>Jia</surname><given-names>Y</given-names></name>, <name><surname>Jozefowicz</surname><given-names>R</given-names></name>, <name><surname>Kaiser</surname><given-names>L</given-names></name>, <name><surname>Kudlur</surname><given-names>M</given-names></name>, <name><surname>Zheng</surname><given-names>X</given-names></name>, <year>2016</year>. <source>Tensorflow large scale machine learning on heterogeneous distributed systems</source>. doi:<pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R2">
        <mixed-citation publication-type="journal"><name><surname>Abdelnour</surname><given-names>F</given-names></name>, <name><surname>Dayan</surname><given-names>M</given-names></name>, <name><surname>Devinsky</surname><given-names>O</given-names></name>, <name><surname>Thesen</surname><given-names>T</given-names></name>, <name><surname>Raj</surname><given-names>A</given-names></name>, <year>2018</year>. <article-title>Functional brain connectivity is predictable from anatomic network’s Laplacian eigen-structure</article-title>. <source>NeuroImage</source><volume>172</volume>, <fpage>728</fpage>–<lpage>739</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.02.016</pub-id><comment>.</comment><pub-id pub-id-type="pmid">29454104</pub-id></mixed-citation>
      </ref>
      <ref id="R3">
        <mixed-citation publication-type="journal"><name><surname>Adachi</surname><given-names>Y</given-names></name>, <name><surname>Osada</surname><given-names>T</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <name><surname>Watanabe</surname><given-names>T</given-names></name>, <name><surname>Matsui</surname><given-names>T</given-names></name>, <name><surname>Miyamoto</surname><given-names>K</given-names></name>, <name><surname>Miyashita</surname><given-names>Y</given-names></name>, <year>2012</year>. <article-title>Functional connectivity between anatomically unconnected areas is shaped by collective network-level effects in the macaque cortex</article-title>. <source>Cereb. Cortex</source><volume>22</volume> (<issue>7</issue>), <fpage>1586</fpage>–<lpage>1592</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhr234</pub-id><comment>.</comment><pub-id pub-id-type="pmid">21893683</pub-id></mixed-citation>
      </ref>
      <ref id="R4">
        <mixed-citation publication-type="journal"><name><surname>Ades-Aron</surname><given-names>B</given-names></name>, <name><surname>Veraart</surname><given-names>J</given-names></name>, <name><surname>Kochunov</surname><given-names>P</given-names></name>, <name><surname>McGuire</surname><given-names>S</given-names></name>, <name><surname>Sherman</surname><given-names>P</given-names></name>, <name><surname>Kellner</surname><given-names>E</given-names></name>, <name><surname>Novikov</surname><given-names>DS</given-names></name>, <name><surname>Fieremans</surname><given-names>E</given-names></name>, <year>2018</year>. <article-title>Evaluation of the accuracy and precision of the diffusion parameter estimation with gibbs and noise removal pipeline</article-title>. <source>NeuroImage</source><volume>183</volume>, <fpage>532</fpage>–<lpage>543</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.07.066</pub-id><comment>.</comment><pub-id pub-id-type="pmid">30077743</pub-id></mixed-citation>
      </ref>
      <ref id="R5">
        <mixed-citation publication-type="journal"><name><surname>Arbabshirani</surname><given-names>MR</given-names></name>, <name><surname>Plis</surname><given-names>S</given-names></name>, <name><surname>Sui</surname><given-names>J</given-names></name>, <name><surname>Calhoun</surname><given-names>VD</given-names></name>, <year>2017</year>. <article-title>Single subject prediction of brain disorders in neuroimaging: promises and pitfalls</article-title>. <source>NeuroImage</source><volume>145</volume>, <fpage>137</fpage>–<lpage>165</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.02.079</pub-id><comment>.</comment><pub-id pub-id-type="pmid">27012503</pub-id></mixed-citation>
      </ref>
      <ref id="R6">
        <mixed-citation publication-type="book"><name><surname>Avena-Koenigsberger</surname><given-names>A</given-names></name>, <name><surname>Misic</surname><given-names>B</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2018</year>. <part-title>Communication dynamics in complex brain networks</part-title>. In: <source>Nature Reviews Neuroscience</source>, <volume>19</volume>. <publisher-name>Nature Publishing Group</publisher-name>, pp. <fpage>17</fpage>–<lpage>33</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn.2017.149</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R7">
        <mixed-citation publication-type="journal"><name><surname>Bathelt</surname><given-names>J</given-names></name>, <name><surname>Barnes</surname><given-names>J</given-names></name>, <name><surname>Raymond</surname><given-names>FL</given-names></name>, <name><surname>Baker</surname><given-names>K</given-names></name>, <name><surname>Astle</surname><given-names>D</given-names></name>, <year>2017</year>. <article-title>Global and local connectivity differences converge with gene expression in a neurodevelopmental disorder of known genetic origin</article-title>. <source>Cereb. Cortex</source><volume>27</volume> (<issue>7</issue>), <fpage>3806</fpage>–<lpage>3817</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhx027</pub-id><comment>.</comment><pub-id pub-id-type="pmid">28168288</pub-id></mixed-citation>
      </ref>
      <ref id="R8">
        <mixed-citation publication-type="journal"><name><surname>Behzadi</surname><given-names>Y</given-names></name>, <name><surname>Restom</surname><given-names>K</given-names></name>, <name><surname>Liau</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>TT</given-names></name>, <year>2007</year>. <article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title>. <source>NeuroImage</source><volume>37</volume> (<issue>1</issue>), <fpage>90</fpage>–<lpage>101</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id><comment>.</comment><pub-id pub-id-type="pmid">17560126</pub-id></mixed-citation>
      </ref>
      <ref id="R9">
        <mixed-citation publication-type="journal"><name><surname>Betzel</surname><given-names>RF</given-names></name>, <name><surname>Byrge</surname><given-names>L</given-names></name>, <name><surname>He</surname><given-names>Y</given-names></name>, <name><surname>Goñi</surname><given-names>J</given-names></name>, <name><surname>Zuo</surname><given-names>XN</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2014</year>. <article-title>Changes in structural and functional connectivity among resting-state networks across the human lifespan</article-title>. <source>NeuroImage</source><volume>102</volume> (<issue>P2</issue>), <fpage>345</fpage>–<lpage>357</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.07.067</pub-id><comment>.</comment><pub-id pub-id-type="pmid">25109530</pub-id></mixed-citation>
      </ref>
      <ref id="R10">
        <mixed-citation publication-type="journal"><name><surname>Birn</surname><given-names>RM</given-names></name>, <name><surname>Molloy</surname><given-names>EK</given-names></name>, <name><surname>Patriat</surname><given-names>R</given-names></name>, <name><surname>Parker</surname><given-names>T</given-names></name>, <name><surname>Meier</surname><given-names>TB</given-names></name>, <name><surname>Kirk</surname><given-names>GR</given-names></name>, <name><surname>Nair</surname><given-names>VA</given-names></name>, <name><surname>Meyerand</surname><given-names>ME</given-names></name>, <name><surname>Prabhakaran</surname><given-names>V</given-names></name>, <year>2013</year>. <article-title>The effect of scan length on the reliability of resting-state fMRI connectivity estimates</article-title>. <source>NeuroImage</source><volume>83</volume>, <fpage>550</fpage>–<lpage>558</lpage>. doi:<pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2013.05.099</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23747458</pub-id></mixed-citation>
      </ref>
      <ref id="R11">
        <mixed-citation publication-type="journal"><name><surname>Booth</surname><given-names>T</given-names></name>, <name><surname>Murray</surname><given-names>C</given-names></name>, <name><surname>Gow</surname><given-names>AJ</given-names></name>, <name><surname>Valdés Hernández</surname><given-names>M</given-names></name>, <name><surname>del</surname><given-names>C</given-names></name>, <name><surname>Wardlaw Joanna</surname><given-names>M</given-names></name>, <name><surname>Bastin Mark</surname><given-names>E</given-names></name>, <comment>M., E.</comment>, <name><surname>Penke</surname><given-names>L</given-names></name>, <name><surname>Maniega</surname><given-names>SM</given-names></name>, <name><surname>Royle</surname><given-names>NA</given-names></name>, <name><surname>Corley</surname><given-names>J</given-names></name>, <name><surname>Henderson</surname><given-names>RD</given-names></name>, <name><surname>Starr</surname><given-names>JM</given-names></name>, <name><surname>Deary</surname><given-names>IJ</given-names></name>, <year>2013</year>. <article-title>Brain white matter tract integrity and cognitive abilities in community-dwelling older people: The lothian birth cohort, 1936</article-title>. <source>Neuropsychology</source><volume>27</volume> (<issue>5</issue>), <fpage>595</fpage>–<lpage>607</lpage>. doi:<pub-id pub-id-type="doi">10.1037/a0033354</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23937481</pub-id></mixed-citation>
      </ref>
      <ref id="R12">
        <mixed-citation publication-type="journal"><name><surname>Botvinik-Nezer</surname><given-names>R</given-names></name>, <name><surname>Holzmeister</surname><given-names>F</given-names></name>, <name><surname>Camerer</surname><given-names>CF</given-names></name>, <name><surname>Dreber</surname><given-names>A</given-names></name>, <name><surname>Huber</surname><given-names>J</given-names></name>, <name><surname>Johannesson</surname><given-names>M</given-names></name>, <name><surname>Kirchler</surname><given-names>M</given-names></name>, <name><surname>Iwanir</surname><given-names>R</given-names></name>, <name><surname>Mumford</surname><given-names>JA</given-names></name>, <name><surname>Adcock</surname><given-names>RA</given-names></name>, <name><surname>Avesani</surname><given-names>P</given-names></name>, <name><surname>Baczkowski</surname><given-names>BM</given-names></name>, <name><surname>Bajracharya</surname><given-names>A</given-names></name>, <name><surname>Bakst</surname><given-names>L</given-names></name>, <name><surname>Ball</surname><given-names>S</given-names></name>, <name><surname>Barilari</surname><given-names>M</given-names></name>, <name><surname>Bault</surname><given-names>N</given-names></name>, <name><surname>Beaton</surname><given-names>D</given-names></name>, <name><surname>Beitner</surname><given-names>J</given-names></name>, <name><surname>Schonberg</surname><given-names>T</given-names></name>, <year>2020</year>. <article-title>Variability in the analysis of a single neuroimaging dataset by many teams</article-title>. <source>Nature</source><volume>582</volume> (<issue>7810</issue>), <fpage>84</fpage>–<lpage>88</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-020-2314-9</pub-id><comment>.</comment><pub-id pub-id-type="pmid">32483374</pub-id></mixed-citation>
      </ref>
      <ref id="R13">
        <mixed-citation publication-type="journal"><name><surname>Cameron</surname><given-names>C</given-names></name>, <name><surname>Sharad</surname><given-names>S</given-names></name>, <name><surname>Brian</surname><given-names>C</given-names></name>, <name><surname>Ranjeet</surname><given-names>K</given-names></name>, <name><surname>Satrajit</surname><given-names>G</given-names></name>, <name><surname>Chaogan</surname><given-names>Y</given-names></name>, <name><surname>Qingyang</surname><given-names>L</given-names></name>, <name><surname>Daniel</surname><given-names>L</given-names></name>, <name><surname>Joshua</surname><given-names>V</given-names></name>, <name><surname>Randal</surname><given-names>B</given-names></name>, <name><surname>Stanley</surname><given-names>C</given-names></name>, <name><surname>Maarten</surname><given-names>M</given-names></name>, <name><surname>Clare</surname><given-names>K</given-names></name>, <name><surname>Adriana</surname><given-names>DM</given-names></name>, <name><surname>Francisco</surname><given-names>C</given-names></name>, <name><surname>Michael</surname><given-names>M</given-names></name>, <year>2013</year>. <article-title>Towards automated analysis of connectomes: the configurable pipeline for the analysis of connectomes (C-PAC)</article-title>. <source>Neuroinformatics</source><volume>7</volume>. doi:<pub-id pub-id-type="doi">10.3389/conf.fninf.2013.09.00042</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R14">
        <mixed-citation publication-type="book"><name><surname>Cattell</surname><given-names>RB</given-names></name>, <name><surname>Cattell</surname><given-names>A</given-names></name>, <year>1973</year>. <source>Measuring Intelligence with the Culture Fair Tests</source>. <publisher-name>Institute for Personality and Ability Testing</publisher-name>.</mixed-citation>
      </ref>
      <ref id="R15">
        <mixed-citation publication-type="journal"><name><surname>de Reus</surname><given-names>MA</given-names></name>, <name><surname>van den Heuvel</surname><given-names>MP</given-names></name>, <year>2013</year>. <article-title>Estimating false positives and negatives in brain networks</article-title>. <source>NeuroImage</source><volume>70</volume>, <fpage>402</fpage>–<lpage>409</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.12.066</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23296185</pub-id></mixed-citation>
      </ref>
      <ref id="R16">
        <mixed-citation publication-type="book"><name><surname>Deco</surname><given-names>G</given-names></name>, <name><surname>Jirsa</surname><given-names>VK</given-names></name>, <name><surname>McIntosh</surname><given-names>AR</given-names></name>, <year>2013</year>. <part-title>Resting brains never rest: computational insights into potential cognitive architectures</part-title>. In: <source>Trends in Neurosciences</source>, <volume>36</volume>. <publisher-name>Elsevier Ltd</publisher-name>, pp. <fpage>268</fpage>–<lpage>274</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2013.03.001</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23561718</pub-id></mixed-citation>
      </ref>
      <ref id="R17">
        <mixed-citation publication-type="book"><name><surname>Dev</surname><given-names>S</given-names></name>, <name><surname>Hassan</surname><given-names>S</given-names></name>, <name><surname>Phillips</surname><given-names>JM</given-names></name>, <year>2019</year>. <part-title>Closed form word embedding alignment</part-title>. In: <source>Proceedings of the IEEE International Conference on Data Mining</source>, <publisher-name>ICDM</publisher-name>, <comment>2019</comment>-<month>11</month>, pp. <fpage>130</fpage>–<lpage>139</lpage>. doi:<pub-id pub-id-type="doi">10.1109/ICDM.2019.00023</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R18">
        <mixed-citation publication-type="journal"><name><surname>Esteban</surname><given-names>O</given-names></name>, <name><surname>Markiewicz</surname><given-names>CJ</given-names></name>, <name><surname>Blair</surname><given-names>RW</given-names></name>, <name><surname>Moodie</surname><given-names>CA</given-names></name>, <name><surname>Isik</surname><given-names>AI</given-names></name>, <name><surname>Erramuzpe</surname><given-names>A</given-names></name>, <name><surname>Kent</surname><given-names>JD</given-names></name>, <name><surname>Goncalves</surname><given-names>M</given-names></name>, <name><surname>DuPre</surname><given-names>E</given-names></name>, <name><surname>Snyder</surname><given-names>M</given-names></name>, <name><surname>Oya</surname><given-names>H</given-names></name>, <name><surname>Ghosh</surname><given-names>SS</given-names></name>, <name><surname>Wright</surname><given-names>J</given-names></name>, <name><surname>Durnez</surname><given-names>J</given-names></name>, <name><surname>Poldrack</surname><given-names>RA</given-names></name>, <name><surname>Gorgolewski</surname><given-names>KJ</given-names></name>, <year>2019</year>. <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat. Methods</source><volume>16</volume> (<issue>1</issue>), <fpage>111</fpage>–<lpage>116</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><comment>.</comment><pub-id pub-id-type="pmid">30532080</pub-id></mixed-citation>
      </ref>
      <ref id="R19">
        <mixed-citation publication-type="web"><name><surname>Chollet</surname><given-names>François</given-names></name> and <etal>contributors</etal>, <year>2015</year>. <source>Keras</source>. <comment><ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R20">
        <mixed-citation publication-type="journal"><name><surname>Frost</surname><given-names>MA</given-names></name>, <name><surname>Goebel</surname><given-names>R</given-names></name>, <year>2012</year>. <article-title>Measuring structural-functional correspondence: Spatial variability of specialised brain regions after macro-anatomical alignment</article-title>. <source>NeuroImage</source><volume>59</volume> (<issue>2</issue>), <fpage>1369</fpage>–<lpage>1381</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.035</pub-id><comment>.</comment><pub-id pub-id-type="pmid">21875671</pub-id></mixed-citation>
      </ref>
      <ref id="R21">
        <mixed-citation publication-type="journal"><name><surname>Fukushima</surname><given-names>M</given-names></name>, <name><surname>Betzel</surname><given-names>RF</given-names></name>, <name><surname>He</surname><given-names>Y</given-names></name>, <name><surname>van den Heuvel</surname><given-names>MP</given-names></name>, <name><surname>Zuo</surname><given-names>XN</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2018</year>. <article-title>Structure–function relationships during segregated and integrated network states of human brain functional connectivity</article-title>. <source>Brain Struct. Funct</source><volume>223</volume> (<issue>3</issue>), <fpage>1091</fpage>–<lpage>1106</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00429-017-1539-3</pub-id><comment>.</comment><pub-id pub-id-type="pmid">29090337</pub-id></mixed-citation>
      </ref>
      <ref id="R22">
        <mixed-citation publication-type="journal"><name><surname>Garyfallidis</surname><given-names>E</given-names></name>, <name><surname>Brett</surname><given-names>M</given-names></name>, <name><surname>Amirbekian</surname><given-names>B</given-names></name>, <name><surname>Rokem</surname><given-names>A</given-names></name>, <name><surname>van der Walt</surname><given-names>S</given-names></name>, <name><surname>Descoteaux</surname><given-names>M</given-names></name>, <name><surname>Nimmo-Smith</surname><given-names>I</given-names></name>, <year>2014</year>. <article-title>Dipy, a library for the analysis of diffusion MRI data</article-title>. <source>Front. Neuroinform</source><volume>8</volume> (<issue>FEB</issue>), <fpage>8</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fninf.2014.00008</pub-id><comment>.</comment><pub-id pub-id-type="pmid">24600385</pub-id></mixed-citation>
      </ref>
      <ref id="R23">
        <mixed-citation publication-type="journal"><name><surname>Gerhard</surname><given-names>S</given-names></name>, <name><surname>Daducci</surname><given-names>A</given-names></name>, <name><surname>Lemkaddem</surname><given-names>A</given-names></name>, <name><surname>Meuli</surname><given-names>R</given-names></name>, <name><surname>Thiran</surname><given-names>J-P</given-names></name>, <name><surname>Hagmann</surname><given-names>P</given-names></name>, <year>2011</year>. <article-title>The connectome viewer toolkit: an open source framework to manage, analyze, and visualize connectomes</article-title>. <source>Front. Neuroinform</source><volume>5</volume>, <fpage>3</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fninf.2011.00003</pub-id><comment>.</comment><pub-id pub-id-type="pmid">21713110</pub-id></mixed-citation>
      </ref>
      <ref id="R24">
        <mixed-citation publication-type="journal"><name><surname>Gluth</surname><given-names>S</given-names></name>, <name><surname>Meiran</surname><given-names>N</given-names></name>, <year>2019</year>. <article-title>Leave-one-trial-out, LOTO, a general approach to link single-trial parameters of cognitive models to neural data</article-title>. <source>ELife</source><volume>8</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.42607</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R25">
        <mixed-citation publication-type="web"><name><surname>Goldberg</surname><given-names>Y</given-names></name>, <name><surname>Levy</surname><given-names>O</given-names></name>, <year>2014</year>. <source>word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method</source>. <comment>arXiv <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1402.3722">http://arxiv.org/abs/1402.3722</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R26">
        <mixed-citation publication-type="journal"><name><surname>Goni</surname><given-names>J</given-names></name>, <name><surname>Van Den Heuvel</surname><given-names>MP</given-names></name>, <name><surname>Avena-Koenigsberger</surname><given-names>A</given-names></name>, <name><surname>De Mendizabal</surname><given-names>NV</given-names></name>, <name><surname>Betzel</surname><given-names>RF</given-names></name>, <name><surname>Griffa</surname><given-names>A</given-names></name>, <name><surname>Hagmann</surname><given-names>P</given-names></name>, <name><surname>Corominas-Murtra</surname><given-names>B</given-names></name>, <name><surname>Thiran</surname><given-names>JP</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2014</year>. <article-title>Resting-brain functional connectivity predicted by analytic measures of network communication</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A</source><volume>111</volume> (<issue>2</issue>), <fpage>833</fpage>–<lpage>838</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1315529111</pub-id><comment>.</comment><pub-id pub-id-type="pmid">24379387</pub-id></mixed-citation>
      </ref>
      <ref id="R27">
        <mixed-citation publication-type="journal"><name><surname>Gordon</surname><given-names>EM</given-names></name>, <name><surname>Laumann</surname><given-names>TO</given-names></name>, <name><surname>Gilmore</surname><given-names>AW</given-names></name>, <name><surname>Newbold</surname><given-names>DJ</given-names></name>, <name><surname>Greene</surname><given-names>DJ</given-names></name>, <name><surname>Berg</surname><given-names>JJ</given-names></name>, <name><surname>Ortega</surname><given-names>M</given-names></name>, <name><surname>Hoyt-Drazen</surname><given-names>C</given-names></name>, <name><surname>Gratton</surname><given-names>C</given-names></name>, <name><surname>Sun</surname><given-names>H</given-names></name>, <name><surname>Hampton</surname><given-names>JM</given-names></name>, <name><surname>Coalson</surname><given-names>RS</given-names></name>, <name><surname>Nguyen</surname><given-names>AL</given-names></name>, <name><surname>McDermott</surname><given-names>KB</given-names></name>, <name><surname>Shimony</surname><given-names>JS</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <name><surname>Nelson</surname><given-names>SM</given-names></name>, <name><surname>Dosenbach</surname><given-names>NUF</given-names></name>, <year>2017</year>. <article-title>Precision functional mapping of individual human brains</article-title>. <source>Neuron</source><volume>95</volume> (<issue>4</issue>), <fpage>791</fpage>–<lpage>807</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.011</pub-id>, <fpage>e7</fpage>.<pub-id pub-id-type="pmid">28757305</pub-id></mixed-citation>
      </ref>
      <ref id="R28">
        <mixed-citation publication-type="journal"><name><surname>Goyal</surname><given-names>P</given-names></name>, <name><surname>Ferrara</surname><given-names>E</given-names></name>, <year>2018</year>. <article-title>Graph embedding techniques, applications, and performance: a survey</article-title>. <source>Knowl. Based Syst</source><volume>151</volume>, <fpage>78</fpage>–<lpage>94</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.knosys.2018.03.022</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R29">
        <mixed-citation publication-type="book"><name><surname>Grover</surname><given-names>A</given-names></name>, <name><surname>Leskovec</surname><given-names>J</given-names></name>, <year>2016</year>. <part-title>Node2vec: scalable feature learning for networks</part-title>. In: <source>KDD: Proceedings of the International Conference on Knowledge Discovery &amp; Data Mining, 2016</source>, pp. <fpage>855</fpage>–<lpage>864</lpage>. doi:<pub-id pub-id-type="doi">10.1145/2939672.2939754</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R30">
        <mixed-citation publication-type="journal"><name><surname>Haxby</surname><given-names>JV</given-names></name>, <name><surname>Guntupalli</surname><given-names>JS</given-names></name>, <name><surname>Nastase</surname><given-names>SA</given-names></name>, <name><surname>Feilong</surname><given-names>M</given-names></name>, <year>2020</year>. <article-title>Hyperalignment: Modeling shared information encoded in idiosyncratic cortical topographies</article-title>. <source>eLife Sci</source><volume>9</volume>, <fpage>1</fpage>–<lpage>26</lpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.56601</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R31">
        <mixed-citation publication-type="journal"><name><surname>Hilger</surname><given-names>K</given-names></name>, <name><surname>Winter</surname><given-names>NR</given-names></name>, <name><surname>Leenings</surname><given-names>R</given-names></name>, <name><surname>Sassenhagen</surname><given-names>J</given-names></name>, <name><surname>Hahn</surname><given-names>T</given-names></name>, <name><surname>Basten</surname><given-names>U</given-names></name>, <name><surname>Fiebach</surname><given-names>CJ</given-names></name>, <year>2020</year>. <article-title>Predicting intelligence from brain gray matter volume</article-title>. <source>Brain Struct. Funct</source><volume>225</volume>(<issue>7</issue>), <fpage>2111</fpage>–<lpage>2129</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00429-020-02113-7</pub-id><comment>.</comment><pub-id pub-id-type="pmid">32696074</pub-id></mixed-citation>
      </ref>
      <ref id="R32">
        <mixed-citation publication-type="journal"><name><surname>Honey</surname><given-names>CJ</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <name><surname>Cammoun</surname><given-names>L</given-names></name>, <name><surname>Gigandet</surname><given-names>X</given-names></name>, <name><surname>Thiran</surname><given-names>JP</given-names></name>, <name><surname>Meuli</surname><given-names>R</given-names></name>, <name><surname>Hagmann</surname><given-names>P</given-names></name>, <year>2009</year>. <article-title>Predicting human resting-state functional connectivity from structural connectivity</article-title>. In: <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>106</volume>, pp. <fpage>2035</fpage>–<lpage>2040</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0811168106</pub-id><comment>.</comment><pub-id pub-id-type="pmid">19188601</pub-id></mixed-citation>
      </ref>
      <ref id="R33">
        <mixed-citation publication-type="journal"><name><surname>Honey</surname><given-names>CJ</given-names></name>., <name><surname>Thivierge</surname><given-names>JP</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2010</year>. <article-title>Can structure predict function in the human brain?</article-title><source>NeuroImage</source><volume>52</volume> (<issue>3</issue>), <fpage>766</fpage>–<lpage>776</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.071</pub-id><comment>.</comment><pub-id pub-id-type="pmid">20116438</pub-id></mixed-citation>
      </ref>
      <ref id="R34">
        <mixed-citation publication-type="journal"><name><surname>Karimi</surname><given-names>F</given-names></name>, <name><surname>Bohlin</surname><given-names>L</given-names></name>, <name><surname>Samoilenko</surname><given-names>A</given-names></name>, <name><surname>Rosvall</surname><given-names>M</given-names></name>, <name><surname>Lancichinetti</surname><given-names>A</given-names></name>, <year>2015</year>. <article-title>Mapping bilateral information interests using the activity of Wikipedia editors</article-title>. <source>Palgrave Commun</source><volume>1</volume> (<issue>1</issue>), <fpage>15041</fpage>. doi:<pub-id pub-id-type="doi">10.1057/palcomms.2015.41</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R35">
        <mixed-citation publication-type="journal"><name><surname>Kocher</surname><given-names>M</given-names></name>, <name><surname>Savoy</surname><given-names>J</given-names></name>, <year>2018</year>. <article-title>Distributed language representation for authorship attribution</article-title>. <source>Dig. Scholarsh. Humanit</source><volume>33</volume> (<issue>2</issue>), <fpage>425</fpage>–<lpage>441</lpage>. doi:<pub-id pub-id-type="doi">10.1093/llc/fqx046</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R36">
        <mixed-citation publication-type="journal"><name><surname>Kristan</surname><given-names>WB</given-names></name>, <name><surname>Katz</surname><given-names>P</given-names></name>, <year>2006</year>. <article-title>Form and function in systems neuroscience</article-title>. <source>Curr. Biol</source><volume>16</volume>(<issue>19</issue>), <fpage>R828</fpage>–<lpage>R831</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2006.08.079</pub-id><comment>.</comment><pub-id pub-id-type="pmid">17027473</pub-id></mixed-citation>
      </ref>
      <ref id="R37">
        <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Y</given-names></name>, <name><surname>Baete</surname><given-names>SH</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Boada</surname><given-names>FE</given-names></name>, <year>2020</year>. <article-title>Mapping brain–behavior networks using functional and structural connectome fingerprinting in the HCP dataset</article-title>. <source>Brain Behav</source> (<issue>6</issue>) <fpage>10</fpage>. doi:<pub-id pub-id-type="doi">10.1002/brb3.1647</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R38">
        <mixed-citation publication-type="journal"><name><surname>Medaglia</surname><given-names>JD</given-names></name>, <name><surname>Lynall</surname><given-names>ME</given-names></name>, <name><surname>Bassett</surname><given-names>DS</given-names></name>, <year>2015</year>. <article-title>Cognitive network neuroscience</article-title>. <source>J. Cognit. Neurosci</source><volume>27</volume> (<issue>8</issue>), <fpage>1471</fpage>–<lpage>1491</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00810</pub-id><comment>.</comment><pub-id pub-id-type="pmid">25803596</pub-id></mixed-citation>
      </ref>
      <ref id="R39">
        <mixed-citation publication-type="journal"><name><surname>Mikolov</surname><given-names>T</given-names></name>, <name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Chen</surname><given-names>K</given-names></name>, <name><surname>Corrado</surname><given-names>GS</given-names></name>, &amp; <name><surname>Dean</surname><given-names>J</given-names></name> (<year>2013</year>). <article-title>Distributed representations of words and phrases and their compositionality</article-title>. In <source>Advances in neural information processing systems</source> (pp. <fpage>3111</fpage>–<lpage>3119</lpage>). ‏</mixed-citation>
      </ref>
      <ref id="R40">
        <mixed-citation publication-type="journal"><name><surname>Mišić</surname><given-names>B</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2016</year>. <article-title>From regions to connections and networks: New bridges between brain and behavior</article-title>. <source>Curr. Op. Neurobiol</source><volume>40</volume>, <fpage>1</fpage>–<lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2016.05.003</pub-id><comment>.</comment><pub-id pub-id-type="pmid">27209150</pub-id></mixed-citation>
      </ref>
      <ref id="R41">
        <mixed-citation publication-type="journal"><name><surname>Nooner</surname><given-names>KB</given-names></name>, <name><surname>Colcombe</surname><given-names>SJ</given-names></name>, <name><surname>Tobe</surname><given-names>RH</given-names></name>, <name><surname>Mennes</surname><given-names>M</given-names></name>, <name><surname>Benedict</surname><given-names>MM</given-names></name>, <name><surname>Moreno</surname><given-names>AL</given-names></name>, <name><surname>Panek</surname><given-names>LJ</given-names></name>, <name><surname>Brown</surname><given-names>S</given-names></name>, <name><surname>Zavitz</surname><given-names>ST</given-names></name>, <name><surname>Li</surname><given-names>Q</given-names></name>, <name><surname>Sikka</surname><given-names>S</given-names></name>, <name><surname>Gutman</surname><given-names>D</given-names></name>, <name><surname>Bangaru</surname><given-names>S</given-names></name>, <name><surname>Schlachter</surname><given-names>RT</given-names></name>, <name><surname>Kamiel</surname><given-names>SM</given-names></name>, <name><surname>Anwar</surname><given-names>AR</given-names></name>, <name><surname>Hinz</surname><given-names>CM</given-names></name>, <name><surname>Kaplan</surname><given-names>MS</given-names></name>, <name><surname>Rachlin</surname><given-names>AB</given-names></name>, <name><surname>Milham</surname><given-names>MP</given-names></name>, <year>2012</year>. <article-title>The NKI-Rockland sample: a model for accelerating the pace of discovery science in psychiatry</article-title>. <source>Front. Neurosci</source><volume>6</volume>, <fpage>152</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2012.00152</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23087608</pub-id></mixed-citation>
      </ref>
      <ref id="R42">
        <mixed-citation publication-type="journal"><name><surname>Passingham</surname><given-names>RE</given-names></name>, <name><surname>Stephan</surname><given-names>KE</given-names></name>, <name><surname>Kötter</surname><given-names>R</given-names></name>, <year>2002</year>. <article-title>The anatomical basis of functional localization in the cortex</article-title>. <source>Nat. Rev. Neurosci</source><volume>3</volume> (<issue>8</issue>), <fpage>606</fpage>–<lpage>616</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn893</pub-id><comment>.</comment><pub-id pub-id-type="pmid">12154362</pub-id></mixed-citation>
      </ref>
      <ref id="R43">
        <mixed-citation publication-type="journal"><name><surname>Fabian</surname><given-names>P</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <name><surname>Blondel</surname><given-names>M</given-names></name>, <name><surname>Prettenhofer</surname><given-names>P</given-names></name>, <name><surname>Weiss</surname><given-names>R</given-names></name>, <name><surname>Vanderplas</surname><given-names>J</given-names></name>, <name><surname>Cournapeau</surname><given-names>D</given-names></name>, <name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <name><surname>Dubourg</surname><given-names>V</given-names></name>, <name><surname>Passos</surname><given-names>A</given-names></name>, <name><surname>Brucher</surname><given-names>M</given-names></name>, <name><surname>Perrot</surname><given-names>M</given-names></name>, <name><surname>Duchesnay</surname><given-names>É</given-names></name>, <year>2011</year>. <article-title>Scikit-learn: machine learning in python</article-title>. <source>J. Mach. Learn. Res</source><volume>12</volume> (<issue>Oct</issue>), <fpage>2825</fpage>–<lpage>2830</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s13398-014-0173-7.2</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R44">
        <mixed-citation publication-type="journal"><name><surname>Penke</surname><given-names>L</given-names></name>, <name><surname>Maniega</surname><given-names>SM</given-names></name>, <name><surname>Bastin</surname><given-names>ME</given-names></name>, <name><surname>Valdés Hernández</surname><given-names>MC</given-names></name>, <name><surname>Murray</surname><given-names>C</given-names></name>, <name><surname>Royle</surname><given-names>NA</given-names></name>, <name><surname>Starr</surname><given-names>JM</given-names></name>, <name><surname>Wardlaw</surname><given-names>JM</given-names></name>, <name><surname>Deary</surname><given-names>IJ</given-names></name>, <year>2012</year>. <article-title>Brain white matter tract integrity as a neural foundation for general intelligence</article-title>. <source>Mol. Psychiatry</source><volume>17</volume> (<issue>10</issue>), <fpage>1026</fpage>–<lpage>1030</lpage>. doi:<pub-id pub-id-type="doi">10.1038/mp.2012.66</pub-id><comment>.</comment><pub-id pub-id-type="pmid">22614288</pub-id></mixed-citation>
      </ref>
      <ref id="R45">
        <mixed-citation publication-type="journal"><name><surname>Perozzi</surname><given-names>B</given-names></name>, <name><surname>Al-Rfou</surname><given-names>R</given-names></name>, <name><surname>Skiena</surname><given-names>S</given-names></name>, <year>2014</year>. <article-title>Deepwalk: online learning of social representations</article-title>. In: <source>Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>, pp. <fpage>701</fpage>–<lpage>710</lpage>. doi:<pub-id pub-id-type="doi">10.1145/2623330.2623732</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R46">
        <mixed-citation publication-type="journal"><name><surname>Power</surname><given-names>JD</given-names></name>, <name><surname>Mitra</surname><given-names>A</given-names></name>, <name><surname>Laumann</surname><given-names>TO</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <year>2014</year>. <article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title>. <source>NeuroImage</source><volume>84</volume>, <fpage>320</fpage>–<lpage>341</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id><comment>.</comment><pub-id pub-id-type="pmid">23994314</pub-id></mixed-citation>
      </ref>
      <ref id="R47">
        <mixed-citation publication-type="web"><name><surname>Rong</surname><given-names>X</given-names></name>, <year>2014</year>. <source>Word2vec Parameter Learning Explained</source>. <comment>arXiv <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1411.2738">http://arxiv.org/abs/1411.2738</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R48">
        <mixed-citation publication-type="journal"><name><surname>Rosenthal</surname><given-names>G</given-names></name>, <name><surname>Váš a</surname><given-names>F</given-names></name>, <name><surname>Griffa</surname><given-names>A</given-names></name>, <name><surname>Hagmann</surname><given-names>P</given-names></name>, <name><surname>Amico</surname><given-names>E</given-names></name>, <name><surname>Goñi</surname><given-names>J</given-names></name>, <name><surname>Avidan</surname><given-names>G</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2018</year>. <article-title>Mapping higher-order relations between brain structure and function with embedded vector representations of connectomes</article-title>. <source>Nat. Commun</source><volume>9</volume> (<issue>1</issue>), <fpage>2178</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-018-04614-w</pub-id><comment>.</comment><pub-id pub-id-type="pmid">29872218</pub-id></mixed-citation>
      </ref>
      <ref id="R49">
        <mixed-citation publication-type="journal"><name><surname>Rubinov</surname><given-names>M</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2010</year>. <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>NeuroImage</source><volume>52</volume> (<issue>3</issue>), <fpage>1059</fpage>–<lpage>1069</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id><comment>.</comment><pub-id pub-id-type="pmid">19819337</pub-id></mixed-citation>
      </ref>
      <ref id="R50">
        <mixed-citation publication-type="journal"><name><surname>Schaefer</surname><given-names>A</given-names></name>, <name><surname>Kong</surname><given-names>R</given-names></name>, <name><surname>Gordon</surname><given-names>EM</given-names></name>, <name><surname>Laumann</surname><given-names>TO</given-names></name>, <name><surname>Zuo</surname><given-names>X-N</given-names></name>, <name><surname>Holmes</surname><given-names>AJ</given-names></name>, <name><surname>Eickhoff</surname><given-names>SB</given-names></name>, <name><surname>Yeo</surname><given-names>BTT</given-names></name>, <year>2018</year>. <article-title>Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title>. <source>Cereb. Cortex</source><volume>28</volume> (<issue>9</issue>), <fpage>3095</fpage>–<lpage>3114</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id><comment>.</comment><pub-id pub-id-type="pmid">28981612</pub-id></mixed-citation>
      </ref>
      <ref id="R51">
        <mixed-citation publication-type="journal"><name><surname>Seabold</surname><given-names>S</given-names></name>, <name><surname>Perktold</surname><given-names>J</given-names></name>, <year>2010</year>. <article-title>Statsmodels: econometric and statistical modeling with python. In: Proceedings of the 9th</article-title><source>Python in Science Conference</source>, pp. <fpage>92</fpage>–<lpage>96</lpage>. doi:<pub-id pub-id-type="doi">10.25080/majora-92bf1922-011</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R52">
        <mixed-citation publication-type="journal"><name><surname>Shafto</surname><given-names>MA</given-names></name>, <name><surname>Tyler</surname><given-names>LK</given-names></name>, <name><surname>Dixon</surname><given-names>M</given-names></name>, <name><surname>Taylor</surname><given-names>JR</given-names></name>, <name><surname>Rowe</surname><given-names>JB</given-names></name>, <name><surname>Cusack</surname><given-names>R</given-names></name>, <name><surname>Calder</surname><given-names>AJ</given-names></name>, <name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name>, <name><surname>Duncan</surname><given-names>J</given-names></name>, <name><surname>Dalgleish</surname><given-names>T</given-names></name>, <name><surname>Henson</surname><given-names>RN</given-names></name>, <name><surname>Brayne</surname><given-names>C</given-names></name>, <name><surname>Matthews</surname><given-names>FE</given-names></name>, <year>2014</year>. <article-title>The cambridge centre for ageing and neuroscience (cam-can) study protocol: a cross-sectional, lifespan, multidisciplinary examination of healthy cognitive ageing</article-title>. <source>BMC Neurol</source><volume>14</volume> (<issue>1</issue>), <fpage>204</fpage>. doi:<pub-id pub-id-type="doi">10.1186/s12883-014-0204-1</pub-id><comment>.</comment><pub-id pub-id-type="pmid">25412575</pub-id></mixed-citation>
      </ref>
      <ref id="R53">
        <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>SL</given-names></name>, <name><surname>Turban</surname><given-names>DHP</given-names></name>, <name><surname>Hamblin</surname><given-names>S</given-names></name>, <name><surname>Hammerla</surname><given-names>NY</given-names></name>, <year>2017</year>. <article-title>Offline Bilingual Word Vectors, Orthogonal Transformations and the Inverted Softmax</article-title>. <source>arXiv</source><comment><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1702.03859">http://arxiv.org/abs/1702.03859</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R54">
        <mixed-citation publication-type="journal"><name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2011</year>. <article-title>Discovering the Human Connectome Discovering the human connectome</article-title>. <source>Mit Press</source> doi:<pub-id pub-id-type="doi">10.7551/mitpress/9266.001.0001</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R55">
        <mixed-citation publication-type="journal"><name><surname>Sripada</surname><given-names>C</given-names></name>, <name><surname>Kessler</surname><given-names>D</given-names></name>, <name><surname>Fang</surname><given-names>Y</given-names></name>, <name><surname>Welsh</surname><given-names>RC</given-names></name>, <name><surname>Prem Kumar</surname><given-names>K</given-names></name>, <name><surname>Angstadt</surname><given-names>M</given-names></name>, <year>2014</year>. <article-title>Disrupted network architecture of the resting brain in attention-deficit/hyperactivity disorder</article-title>. <source>Hum. Brain Mapp</source><volume>35</volume> (<issue>9</issue>), <fpage>4693</fpage>–<lpage>4705</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.22504</pub-id><comment>.</comment><pub-id pub-id-type="pmid">24668728</pub-id></mixed-citation>
      </ref>
      <ref id="R56">
        <mixed-citation publication-type="journal"><name><surname>Steiger</surname><given-names>JH</given-names></name>, <year>1980</year>. <article-title>Tests for comparing elements of a correlation matrix</article-title>. <source>Psychol. Bull</source><volume>87</volume> (<issue>2</issue>), <fpage>245</fpage>–<lpage>251</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0033-2909.87.2.245</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R57">
        <mixed-citation publication-type="journal"><name><surname>Straathof</surname><given-names>M</given-names></name>, <name><surname>Sinke</surname><given-names>MRT</given-names></name>, <name><surname>Dijkhuizen</surname><given-names>RM</given-names></name>, <name><surname>Otte</surname><given-names>WM</given-names></name>, <year>2019</year>. <article-title>A systematic review on the quantitative relationship between structural and functional network connectivity strength in mammalian brains</article-title>. <source>J. Cereb. Blood Flow Metab</source><volume>39</volume> (<issue>2</issue>), <fpage>189</fpage>–<lpage>209</lpage>. doi:<pub-id pub-id-type="doi">10.1177/0271678X18809547</pub-id><comment>.</comment><pub-id pub-id-type="pmid">30375267</pub-id></mixed-citation>
      </ref>
      <ref id="R58">
        <mixed-citation publication-type="journal"><name><surname>Suárez</surname><given-names>LE</given-names></name>, <name><surname>Markello</surname><given-names>RD</given-names></name>, <name><surname>Betzel</surname><given-names>RF</given-names></name>, <name><surname>Misic</surname><given-names>B</given-names></name>, <year>2020</year>. <article-title>Linking structure and function in macroscale brain networks</article-title>. <source>Trends Cognit. Sci</source><volume>24</volume> (<issue>4</issue>), <fpage>302</fpage>–<lpage>315</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2020.01.008</pub-id><comment>.</comment><pub-id pub-id-type="pmid">32160567</pub-id></mixed-citation>
      </ref>
      <ref id="R59">
        <mixed-citation publication-type="journal"><name><surname>Sui</surname><given-names>J</given-names></name>, <name><surname>Jiang</surname><given-names>R</given-names></name>, <name><surname>Bustillo</surname><given-names>J</given-names></name>, <name><surname>Calhoun</surname><given-names>V</given-names></name>, <year>2020</year>. <article-title>Neuroimaging-based individualized prediction of cognition and behavior for mental disorders and health: methods and promises</article-title>. <source>Biol. Psychiatry</source><volume>88</volume> (<issue>11</issue>), <fpage>818</fpage>–<lpage>828</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.biopsych.2020.02.016</pub-id><comment>.</comment><pub-id pub-id-type="pmid">32336400</pub-id></mixed-citation>
      </ref>
      <ref id="R60">
        <mixed-citation publication-type="journal"><name><surname>Taylor</surname><given-names>JR</given-names></name>, <name><surname>Williams</surname><given-names>N</given-names></name>, <name><surname>Cusack</surname><given-names>R</given-names></name>, <name><surname>Auer</surname><given-names>T</given-names></name>, <name><surname>Shafto</surname><given-names>MA</given-names></name>, <name><surname>Dixon</surname><given-names>M</given-names></name>, <name><surname>Tyler</surname><given-names>LK</given-names></name>, <name><surname>Cam-CAN</surname><given-names>X</given-names></name>, <name><surname>Henson</surname><given-names>RN</given-names></name>, <year>2015</year>. <article-title>The Cambridge centre for ageing and neuroscience (Cam-CAN) data repository: structural and functional MRI, MEG, and cognitive data from a cross-sectional adult lifespan sample</article-title>. <source>NeuroImage</source> doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.018</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R61">
        <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>C</given-names></name>, <name><surname>Rao</surname><given-names>W</given-names></name>, <name><surname>Guo</surname><given-names>W</given-names></name>, <name><surname>Wang</surname><given-names>P</given-names></name>, <name><surname>Liu</surname><given-names>J</given-names></name>, <name><surname>Guan</surname><given-names>X</given-names></name>, <year>2020</year>. <article-title>Towards understanding the Instability of network embedding</article-title>. <source>IEEE Trans. Know. Data Eng</source><volume>1</volume>. doi:<pub-id pub-id-type="doi">10.1109/tkde.2020.2989512</pub-id><comment>.</comment></mixed-citation>
      </ref>
      <ref id="R62">
        <mixed-citation publication-type="book"><name><surname>Wechsler</surname><given-names>D</given-names></name>, <year>1999</year>. <source>Wechsler Abbreviated Scale of Intelligence</source>. <publisher-name>Psychological Corporation</publisher-name>, <publisher-loc>San Antonio, TX</publisher-loc>.</mixed-citation>
      </ref>
      <ref id="R63">
        <mixed-citation publication-type="journal"><name><surname>Wolf</surname><given-names>L</given-names></name>, <name><surname>Hanani</surname><given-names>Y</given-names></name>, <name><surname>Bar</surname><given-names>K</given-names></name>, <name><surname>Dershowitz</surname><given-names>N</given-names></name>, <year>2014</year>. <article-title>Joint word2vec networks for bilingual semantic representations</article-title>. <source>Int. J. Comput. Linguist. Appl</source><volume>5</volume> (<issue>1</issue>), <fpage>27</fpage>–<lpage>44</lpage>. <comment><ext-link ext-link-type="uri" xlink:href="https://pdfs.semanticscholar.org/85ae/68cc78b42a540fca7a81e399e5dc125a258f.pdf">https://pdfs.semanticscholar.org/85ae/68cc78b42a540fca7a81e399e5dc125a258f.pdf</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R64">
        <mixed-citation publication-type="journal"><name><surname>Yeo</surname><given-names>BTT</given-names></name>, <name><surname>Krienen</surname><given-names>FM</given-names></name>, <name><surname>Sepulcre</surname><given-names>J</given-names></name>, <name><surname>Sabuncu</surname><given-names>MR</given-names></name>, <name><surname>Lashkari</surname><given-names>D</given-names></name>, <name><surname>Hollinshead</surname><given-names>M</given-names></name>, <name><surname>Roffman</surname><given-names>JL</given-names></name>, <name><surname>Smoller</surname><given-names>JW</given-names></name>, <name><surname>Zöllei</surname><given-names>L</given-names></name>, <name><surname>Polimeni</surname><given-names>JR</given-names></name>, <name><surname>Fischl</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>H</given-names></name>, <name><surname>Buckner</surname><given-names>RL</given-names></name>, <name><surname>Ahn</surname><given-names>Y</given-names></name>, <name><surname>Bagrow</surname><given-names>J</given-names></name>, <name><surname>Lehmann</surname><given-names>S</given-names></name>, <name><surname>Amano</surname><given-names>K</given-names></name>, <name><surname>Wandell</surname><given-names>B</given-names></name>, <name><surname>Dumoulin</surname><given-names>S</given-names></name>, <name><surname>Roland</surname><given-names>P</given-names></name>, <year>2011</year>. <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>J. Neurophysiol</source><volume>106</volume> (<issue>3</issue>), <fpage>1125</fpage>–<lpage>1165</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><comment>.</comment><pub-id pub-id-type="pmid">21653723</pub-id></mixed-citation>
      </ref>
      <ref id="R65">
        <mixed-citation publication-type="journal"><name><surname>Zimmermann</surname><given-names>J</given-names></name>, <name><surname>Ritter</surname><given-names>P</given-names></name>, <name><surname>Shen</surname><given-names>K</given-names></name>, <name><surname>Rothmeier</surname><given-names>S</given-names></name>, <name><surname>Schirner</surname><given-names>M</given-names></name>, <name><surname>McIntosh</surname><given-names>AR</given-names></name>, <year>2016</year>. <article-title>Structural architecture supports functional organization in the human aging brain at a regionwise and network level</article-title>. <source>Hum. Brain Mapp</source><volume>37</volume> (<issue>7</issue>), <fpage>2645</fpage>–<lpage>2661</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.23200</pub-id><comment>.</comment><pub-id pub-id-type="pmid">27041212</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig id="F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p id="P63">A general outline of the connectome embedding (CE) framework and its usage at the individual subject level. a.i. The structural connectome is the input to the CE model. Multiple random walks are sampled from the weighted structural connectivity graph. Letters represent all unique nodes in both hemispheres, dashed lines represent edges that exist in the connectome and colored line represent sampled random walks. a.ii. Sliding, fixed size windows are taken over random walk sequences. Within each window, the center node is used as the target (black) and the surroundings as context (white). a.iii. These context and target nodes are used as the input and target (respectively) of an artificial neural network with a single hidden layer. The input and output layers are <italic>k</italic> dimensional vectors, where <italic>k</italic> is the number of nodes in the brain graph. The hidden layer, i.e. the embedding layer, is a k’ dimensional vector, where <italic>k</italic>’ is set to be <italic>k</italic>’ &lt; <italic>k</italic>. The shading of the circles denote their values, either binary (black – one, white - zero) or continues (gray). <italic>W</italic> and <italic>W</italic>’ are the learned weight matrices that define the transformation between the input and embedding layer, and the embedding and output layer, respectively. The model parameters, <italic>W</italic> and <italic>W</italic>’, are iteratively updated using stochastic gradient descent. After the model was fitted, the embedding layer nodes representation constitute the nodes embedding. b.i. Independent fits of the model (<italic>e.g.</italic> in different subjects or independent embeddings of the same subject) results in nodes embeddings with similar angle among node pairs but different absolute values. Embedding alignment is required to allow a comparison of different CE. b.ii. Here, embeddings are transformed from the latent space of subject <italic>a</italic> (yellow) to the latent of subject <italic>b</italic> (blue) to allow their comparison. For node embedding <italic>v</italic> the first subscript <italic>i</italic>, denotes the node’s index and the second the source and current subject’s latent space. Similarly, the subscript in the transformation matrices denotes their associated subject and <sup>+</sup> the pseudo-inverse. c.i. The similarities among node embeddings are used to map structural to functional connectivity. c.ii. The aligned embeddings are used for out-of-sample prediction of individual differences.</p>
      </caption>
      <graphic xlink:href="nihms-1741416-f0001"/>
    </fig>
    <fig id="F2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <p id="P64">Correspondence between structural-functional connectivity at the group and individual levels in DS1. (a,b,c) Scatter plots and marginal univariate distributions of functional compared to structural-based edges at the group level. The structure-based edges are the entries of the streamline density matrix (a), the CE cosine similarities (b) and the deep learning based predicted functional edges. Direct edges are presented in dark blue and indirect edges in gray. The Spearman’s rank correlations and the corresponding p values for the group-level direct edges are depicted in the bottom right corner of each scatter plot. The correlations for the indirect edges were. 137,. 51 for the CE cosine similarities and the deep learning based predicted functional edges respectively. (d) Individual-level structure-function Spearman’s correlation values for direct edges of all three structure-based connectivity measures. Each line represents the correlation values of a single subject (<italic>n</italic> = 181). A significant increase in correlation was found for the CE cosine similarities compared to the structural edges and for the CE-based predicted functional edges compared to the CE cosine similarities.</p>
      </caption>
      <graphic xlink:href="nihms-1741416-f0002"/>
    </fig>
    <fig id="F3" orientation="portrait" position="float">
      <label>Fig. 3.</label>
      <caption>
        <p id="P65">The contribution of individual edges to the CE-based structure-function mapping in DS1. Individual edges are assessed based on the difference in the measured structure-function correlation after removing each of the edges. (a) All edges are depicted in a matrix form. Nodes are ordered according to their affiliation to the 7 canonical resting-state networks (<xref rid="R64" ref-type="bibr">Yeo et al., 2011</xref>) separately for the left and right hemispheres. Edges with positive contribution to the overall correlation (blue) are those whose elimination results in lower correlation, while edges with negative contribution (red) have the opposite effect. (c) The distribution of Δ correlation for the edges is depicted for all 4 combinations of direct versus indirect and within versus between the 7 networks.</p>
      </caption>
      <graphic xlink:href="nihms-1741416-f0003"/>
    </fig>
    <fig id="F4" orientation="portrait" position="float">
      <label>Fig. 4.</label>
      <caption>
        <p id="P66">Effect of random walk parameters on structure-function correspondence in DS1. Testing the effect of random walks parameters on the Spearman’s rank correlation between direct (blue) or indirect edges (gray) to their corresponding functional connectivity edges. The random walk parameters were shifted from local (p = 10 <sup>−3</sup>, q = 4.096) through an unbiased (<italic>p</italic> = 1, <italic>q</italic> = 1) to global (<italic>p</italic> = 10<sup>3</sup>, <italic>q</italic> = 0.244) random walk in 20 equal bins on a logarithmic scale. Error bar represents the standard deviation across subjects (<italic>N</italic> = 25).</p>
      </caption>
      <graphic xlink:href="nihms-1741416-f0004"/>
    </fig>
    <fig id="F5" orientation="portrait" position="float">
      <label>Fig. 5.</label>
      <caption>
        <p id="P67">Age-related changes in individual-level structure-function correspondence in DS1. (a) A regression plot for age and the measured connectome-level structure-function correlation. The values of each subject are presented both for the structural edges (SC”, gray) and the CE cosine edges (CE, yellow). The observed correlation to age is indicated on the bottom. The difference in the structure-function correspondence to age is significantly larger for the CE cosine connectivity measure. (b) The correlation of age to the edgewise contribution score of structure-function correspondence depicted in matrix form. Positive edges are ones that increase the overall correlation with age (blue) and negative edges are ones that decrease the overall correlation with age (red). (c) The result of the network contingency analysis for |r| &gt; 0.25 (see <xref rid="SD1" ref-type="supplementary-material">SI Fig. 8</xref> for all thresholds) in matrix form. Colored cells had a larger number of edges correlated with age than expected by chance. The cells’ background color is determined by the ratio between edges that are positively (blue) or negatively (red) correlated with age.</p>
      </caption>
      <graphic xlink:href="nihms-1741416-f0005"/>
    </fig>
    <fig id="F6" orientation="portrait" position="float">
      <label>Fig. 6.</label>
      <caption>
        <p id="P68">Comparing predictive accuracy of CE, CE cosine similarity matrix, structural and functional connectivity as input within DS1. Correlation between the observed and predicted age (a) and intelligence (b) with CE (blue), CE cosine matrix (blue-gray), structural (brown) and functional (yellow) connectivity (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.). On the left panel of each subplot, dots represent the predictive accuracy of each node within each of the 7 resting state networks (<xref rid="R64" ref-type="bibr">Yeo et al., 2011</xref>). Nodes are grouped by their resting state network affiliation. The right panel depicts the predictive accuracy of a model combining all individual nodes by taking their mean (plus symbol) or aggregates them using a second-level linear model (diamond symbol). The dashed line represents the FDR-corrected significance level for single nodal prediction.</p>
      </caption>
      <graphic xlink:href="nihms-1741416-f0006"/>
    </fig>
  </floats-group>
</article>
