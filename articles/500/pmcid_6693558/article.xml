<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>Neuroimage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
      <publisher>
        <publisher-name>Academic Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">31158478</article-id>
      <article-id pub-id-type="pmc">6693558</article-id>
      <article-id pub-id-type="publisher-id">S1053-8119(19)30394-5</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.011</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Effective degrees of freedom of the Pearson's correlation coefficient under autocorrelation</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Afyouni</surname>
            <given-names>Soroosh</given-names>
          </name>
          <email>soroosh.afyouni@bdi.ox.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>Stephen M.</given-names>
          </name>
          <email>steve@fmrib.ox.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Nichols</surname>
            <given-names>Thomas E.</given-names>
          </name>
          <email>thomas.nichols@bdi.ox.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="aff2" ref-type="aff">b</xref>
          <xref rid="aff3" ref-type="aff">c</xref>
          <xref rid="cor1" ref-type="corresp">∗</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>a</label>Oxford Big Data Institute, Li Ka Shing Centre for Health Information and Discovery, Nuffield Department of Population Health, University of Oxford, UK</aff>
      <aff id="aff2"><label>b</label>The Wellcome Centre for Integrative Neuroimaging, University of Oxford, UK</aff>
      <aff id="aff3"><label>c</label>Department of Statistics, University of Warwick, UK</aff>
      <author-notes>
        <corresp id="cor1"><label>∗</label>Corresponding author. The Big Data Institute, University of Oxford, UK. <email>thomas.nichols@bdi.ox.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>01</day>
        <month>10</month>
        <year>2019</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="ppub">.-->
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>10</month>
        <year>2019</year>
      </pub-date>
      <volume>199</volume>
      <fpage>609</fpage>
      <lpage>625</lpage>
      <history>
        <date date-type="received">
          <day>5</day>
          <month>11</month>
          <year>2018</year>
        </date>
        <date date-type="rev-recd">
          <day>2</day>
          <month>5</month>
          <year>2019</year>
        </date>
        <date date-type="accepted">
          <day>6</day>
          <month>5</month>
          <year>2019</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2019 The Authors</copyright-statement>
        <copyright-year>2019</copyright-year>
        <license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/">
          <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
        </license>
      </permissions>
      <abstract id="abs0010">
        <p>The dependence between pairs of time series is commonly quantified by Pearson's correlation. However, if the time series are themselves dependent (i.e. exhibit temporal autocorrelation), the effective degrees of freedom (EDF) are reduced, the standard error of the sample correlation coefficient is biased, and Fisher's transformation fails to stabilise the variance. Since fMRI time series are notoriously autocorrelated, the issue of biased standard errors – before or after Fisher's transformation – becomes vital in individual-level analysis of resting-state functional connectivity (rsFC) and must be addressed anytime a standardised <italic>Z</italic>-score is computed. We find that the severity of autocorrelation is highly dependent on spatial characteristics of brain regions, such as the size of regions of interest and the spatial location of those regions. We further show that the available EDF estimators make restrictive assumptions that are not supported by the data, resulting in biased rsFC inferences that lead to distorted topological descriptions of the connectome on the individual level. We propose a practical “xDF” method that accounts not only for distinct autocorrelation in each time series, but instantaneous and lagged cross-correlation. We find the xDF correction varies substantially over node pairs, indicating the limitations of global EDF corrections used previously. In addition to extensive synthetic and real data validations, we investigate the impact of this correction on rsFC measures in data from the Young Adult Human Connectome Project, showing that accounting for autocorrelation dramatically changes fundamental graph theoretical measures relative to no correction.</p>
      </abstract>
      <abstract abstract-type="author-highlights" id="abs0015">
        <title>Highlights</title>
        <p>
          <list list-type="simple" id="ulist0010">
            <list-item id="u0010">
              <label>•</label>
              <p id="p0010">Autocorrelation is a problem for sample correlation, breaking the variance-stabilising property of Fisher's transformation.</p>
            </list-item>
            <list-item id="u0015">
              <label>•</label>
              <p id="p0015">We show that fMRI autocorrelation varies systematically with region of interest size, and is heterogeneous over subjects.</p>
            </list-item>
            <list-item id="u0020">
              <label>•</label>
              <p id="p0020">Existing adjustment methods are themselves biased when true correlation is non-zero due to a confounding effect.</p>
            </list-item>
            <list-item id="u0025">
              <label>•</label>
              <p id="p0025">Our “xDF” method provides accurate Z-scores based on either of Pearson's or Fisher's transformed correlations.</p>
            </list-item>
            <list-item id="u0030">
              <label>•</label>
              <p id="p0030">Resting state fMRI autocorrelation considerably alters the graph theoretical description of human connectome.</p>
            </list-item>
          </list>
        </p>
      </abstract>
      <kwd-group id="kwrds0010">
        <title>Keywords</title>
        <kwd>Autocorrelation</kwd>
        <kwd>Serial correlation</kwd>
        <kwd>Cross correlation</kwd>
        <kwd>Time-series</kwd>
        <kwd>Pearson correlation coefficient</kwd>
        <kwd>Variance</kwd>
        <kwd>Resting state</kwd>
        <kwd>fMRI</kwd>
        <kwd>Functional connectivity</kwd>
        <kwd>Quadratic covariance</kwd>
        <kwd>Toeplitz matrix</kwd>
        <kwd>Graph theory</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec1">
      <label>1</label>
      <title>Introduction</title>
      <p id="p0035">Resting-state functional connectivity (rsFC), defined as similarity between measured brain activity between brain regions in absence of any external instructed task, has become an essential technique for understanding the human brain. Many rsFC methods make use of correlation estimated with the Pearson's product-moment correlation coefficient (<inline-formula><mml:math id="M1" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>), often after Fisher's transformation (<italic>F</italic>) and standardised to a <italic>Z</italic>-score (<italic>Z</italic>). These <italic>Z</italic>-scores are used to find significant correlation or are used as a standardised measure, for example, in graph analysis where they are used to create weighted networks or are thresholded to create binary networks. However, standard results for the variance of Pearson's correlation (before or after Fisher's transformation) depends on independence between successive observations. Blood Oxygen Level Dependent (BOLD) time series exhibit autocorrelation which can in turn inflate the sampling variance of <inline-formula><mml:math id="M2" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. Ignoring this variance inflation – equivalently, reduction in effective degrees of freedom (EDF) – will inflate <italic>Z</italic>-scores and produce excess false positives when testing <inline-formula><mml:math id="M3" altimg="si2.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, and corrupt the interpretation of <italic>Z</italic> as a standardised effect. These biases can vary both over individuals and pairs of brain regions under consideration.</p>
      <p id="p0040">Although the impact of autocorrelation has been thoroughly investigated in task fMRI analysis (<xref rid="bib24" ref-type="bibr">Friston et al., 2000</xref>; <xref rid="bib62" ref-type="bibr">Woolrich et al., 2001</xref>; <xref rid="bib35" ref-type="bibr">Lund et al., 2006</xref>), there is much less work on resting-state analyses. The first reference we are aware of directly addressing the issue in resting-state is <xref rid="bib23" ref-type="bibr">Fox et al. (2005)</xref> which refers to ”Bartlett's Theory”, citing <xref rid="bib61" ref-type="bibr">Watts and Jenkins (1968)</xref>. Later, <xref rid="bib59" ref-type="bibr">Van Dijk et al. (2010)</xref> uses the same approach, labeled “Bartlett's Correction Factor”, describing it as the “integral across time of the square of the autocorrelation function”; as discussed below, this “integral” is of course a sum for discretely sampled fMRI data and, while not necessarily implied, must include both positive and negative lags of the autocorrelation function (ACF). The nominal <italic>N</italic> is divided by this BCF to give an EDF (see Section 2.2.1).</p>
      <p id="p0045">While these previous works use an arbitrary ACF, other authors have used an order-1 autoregressive (AR(1)) model. For example, the FSLnets toolbox (<xref rid="bib55" ref-type="bibr">Smith et al., 2011</xref>) uses a Monte Carlo approach to estimate the variance of sample correlation coefficients (see Section 2.2.2). However, it only considers a single autocorrelation parameter over all nodes. More recently, <xref rid="bib2" ref-type="bibr">Arbabshirani et al. (2014)</xref> made a thorough study of Pearson's correlation variance for AR(1) time series, where, crucially, the AR(1) coefficient can vary between the pair of variables and non-null correlations were considered.<xref rid="fn1" ref-type="fn">1</xref></p>
      <p id="p0050">Other authors have used a Wavelet representation of time series to handling autocorrelation, as <xref rid="bib44" ref-type="bibr">Patel and Bullmore (2015)</xref> and <xref rid="bib60" ref-type="bibr">Váša et al. (2018)</xref> use wavelet EDF-estimators initially proposed by <xref rid="bib45" ref-type="bibr">Percival and Walden (2006)</xref> in analysis of functional connectomes obtained via wavelet transformation coefficients (<xref rid="bib33" ref-type="bibr">Leonardi and Van De Ville, 2011</xref>).</p>
      <p id="p0055">Further, <xref rid="bib20" ref-type="bibr">Fiecas et al. (2017)</xref> proposes an inference framework for group-level analysis of functional connectomes which accounts for the autocorrelation via the variance estimator of <xref rid="bib51" ref-type="bibr">Roy (1989)</xref>. Roy's estimator is unique among the previous methods as it directly accounts for dependence within and between the time series, and is closely related to our method (see Section 2.2).</p>
      <p id="p0060">Alternatively, other studies have proposed pre-whitening on the resting-state BOLD time series (<xref rid="bib16" ref-type="bibr">Christova et al., 2011</xref>; <xref rid="bib34" ref-type="bibr">Lewis et al., 2012</xref>; <xref rid="bib11" ref-type="bibr">Bright et al., 2017</xref>). For example, <xref rid="bib11" ref-type="bibr">Bright et al. (2017)</xref> used pre-whitening methods, inherited from task fMRI analysis (<xref rid="bib13" ref-type="bibr">Bullmore et al., 1996</xref>), to account for autocorrelation in resting-state analysis. Although pre-whitening is a well-established technique in task fMRI, its application in rsFC is yet to be fully investigated. Firstly, pre-whitening flattens the power spectrum which, in case of fMRI, means low frequency components are attenuated while high frequencies are amplified (<xref rid="bib15" ref-type="bibr">Chatfield, 2016</xref>); this seems poorly suited to the resting-state analysis were the natural focus of the frequencies are on low bands, more specifically on 0.01HZ to 0.1HZ (<xref rid="bib8" ref-type="bibr">Biswal et al., 1995</xref>). Secondly, choosing an optimal model for autocorrelation, in absence of a task paradigm, appears to be troublesome (see <xref rid="bib11" ref-type="bibr">Bright et al. (2017)</xref>). Finally, spatial regularisation used in some neuroimaging toolboxes (e.g. FSL's FILM) are designed for voxelwise or vertex wise analyses and would need to be adapted to Region of Interests (ROIs) data.</p>
      <p id="p0065">The concern about effect of autocorrelation on Pearson's correlation has a long history in spatial statistics (<xref rid="bib26" ref-type="bibr">Haining, 1991</xref>), econometrics (<xref rid="bib42" ref-type="bibr">Orcutt and James, 1948</xref>) and climate sciences (<xref rid="bib10" ref-type="bibr">Bretherton et al., 1999</xref>), but the fundamental work is <xref rid="bib3" ref-type="bibr">Bartlett (1935)</xref>, who first asserted that the lack of independence (between observations) is a bigger challenge than non-Gaussianity. In his 1935 paper, Bartlett proposes a variance estimator of sample correlation coefficients based on a AR(1) model, but he acknowledges that a limitation of the work is that it assumes zero cross-correlation. In later work he proposed a more general estimator which accounts for higher order AR models (<xref rid="bib4" ref-type="bibr">Bartlett, 1946</xref>) but still fails to account for cross-correlation. Two extensions to the work has been proposed by <xref rid="bib49" ref-type="bibr">Quenouille (1947)</xref> and <xref rid="bib6" ref-type="bibr">Bayley and Hammersley (1946)</xref> where the former adapts the estimator to the cases where the autocorrelation functions are different for the two time series and the latter down weights the autocorrelation of long lags. Several years later <xref rid="bib17" ref-type="bibr">Clifford et al. (1989)</xref> also proposed a reformulation of <xref rid="bib6" ref-type="bibr">Bayley and Hammersley (1946)</xref>. We have found little comparative evaluation of these methods in the literature, save <xref rid="bib48" ref-type="bibr">Pyper and Peterman (1998)</xref> that compared False Positive Rates on low order autoregressive models of uncorrelated time series.</p>
      <p id="p0070">Importantly, save for the work of <xref rid="bib51" ref-type="bibr">Roy (1989)</xref>, all of the methods we have discussed so far have been derived under the rsFC null hypothesis (i.e. independence <italic>between</italic> the two series). This null encompasses both zero instantaneous and lagged cross-correlations. This is problematic for rsFC, as typically the challenge is not only to detect edges but also to measure the strength of the connectivity.</p>
      <p id="p0075">In this work we show how autocorrelation strongly influences the variance of Pearson's correlation, breaking the variance-stabilising properties of Fisher's transformation. We show that existing methods to adjust the variance of Pearson's correlation for autocorrelation fail when <inline-formula><mml:math id="M4" altimg="si3.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, and can be severely biased if there is no or only very weak autocorrelation. To address these problems we propose a variance estimator for Pearson's correlation that imposes no assumptions aside from stationarity, and that accounts for both autocorrelation within each time series and instantaneous and lagged cross-correlations between the time series. We call this approach “xDF”, as it comprises an effective degrees of freedom estimator that accounts for cross-correlations.</p>
      <p id="p0080">To motivate and introduce our results, as an example, we fist show how ignoring the autocorrelation may corrupt inference of correlation coefficients. <xref rid="fig1" ref-type="fig">Fig. 1</xref> shows the correlation of a BOLD time series in the Left Dorsal Prefrontal Cortex (PCFd) from one HCP subject to all 114 ROIs of the Yeo atlas of a <italic>different</italic> HCP subject (we call this inter-subject scrambling; see Section S3.6 of Supplementary Materials). Due to the random nature of resting-state BOLD time series between subjects, we expect up to 5% of the 114 correlation coefficients turn out significant (i.e. <inline-formula><mml:math id="M5" altimg="si4.svg"><mml:mrow><mml:mo>≈</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> regions) on average; instead, the Naive <italic>Z</italic>-scores (see Section 2.4) finds <inline-formula><mml:math id="M6" altimg="si5.svg"><mml:mrow><mml:mo>≈</mml:mo><mml:mn>35</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula> of the regions (i.e. 40 regions) significant while xDF-corrected <italic>Z</italic>-scores only finds 2.6% of the regions significant (i.e. 3 regions; <xref rid="fig1" ref-type="fig">Fig. 1</xref>.D). After application of our xDF correction, no regions survive FDR correction (2.6% significant at level 5% uncorrected). A plot of xDF-adjusted <italic>Z</italic>-scores against Naive <italic>Z</italic>-scores shows the dramatic difference in values (<xref rid="fig1" ref-type="fig">Fig. 1</xref>.D). Observe how the connection with L-SoMotCent (blue marker) is incorrectly detected; this ROI is highly auto- and cross-correlated (blue ACF, <xref rid="fig1" ref-type="fig">Fig. 1</xref>.E), and results in a strong correction and the <italic>Z</italic>-score being greatly reduced. In contrast, R-Insula (red marker) connection has essentially the same Naive and xDF-adjusted <italic>Z</italic>-score due to its nearly zero autocorrelation (red ACF, <xref rid="fig1" ref-type="fig">Fig. 1</xref>.E).<fig id="fig1"><label>Fig. 1</label><caption><p>Analysis of null resting state functional connectivity to illustrate the problem of inflated correlation coefficient significance. <bold>Panel A</bold> shows standardised BOLD data for the Left Dorsal Prefrontal Cortex (PFCd; 421 voxles) of HCP one subject (HCP-1). <bold>Panel B</bold> illustrates the standardised BOLD time series of R-Insula (red; 35 voxels) and L-SomMotCent (blue; 773 voxels), illustrating the dramatically different degree of autocorrelation. <bold>Panel C</bold> maps the <italic>Z</italic>-scores of correlation between this PCFd region and time series from a <italic>different</italic> HCP subject (HCP-2), parcellated with the Yeo's atlas and overlaid on an MNI standard volume. <bold>Panel D</bold> compares <italic>Z</italic>-scores accounting for autocorrelation vs. naive <italic>Z</italic>-scores, showing apparent significance (in this null data) with naive <italic>Z</italic>-scores and expected chance significance with xDF-adjusted <italic>Z</italic>-scores. On the horizontal axis are naive <italic>Z</italic>-scores that ignore autocorrelation, while on the vertical axis are <italic>Z</italic>-scores adjusted according to xDF. Uncorrected critical values (<inline-formula><mml:math id="M7" altimg="si6.svg"><mml:mrow><mml:mo>±</mml:mo><mml:mn>1.96</mml:mn></mml:mrow></mml:math></inline-formula>) are plotted in dashed lines. <bold>Panel E</bold> shows autocorrelation of each time series (left). Horizontal solid lines indicate the confidence intervals calculated as described in Section 2.3. The difference in magnitude and form of autocorrelation among the three time series is evident, with PFCd exhibiting strong, long-range autocorrelation and R-Insula showing virtually no autocorrelation. Also shown is the cross-correlation (right panels) between HCP-1's PCFd and HCP-2's Left Central SomatoMotor Cortex (L-SomMotCent) (top), and HCP-1's PCFd and HCP-2's Right Insula (R-Insula) (bottom).</p></caption><alt-text id="alttext0015">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
      <p id="p0085">The remainder of the work is as follows. We first present a concise overview of the model and the proposed estimator. Second, we demonstrate the importance of accounting for unequal autocorrelation between each pair of variables, i.e. node-specific autocorrelation, by showing how the autocorrelation structures are spatially heterogeneous and dependent on each parcellation scheme. Third, we discuss how ignoring such effects may result in spurious significant correlations and topological features. Fourth, using Monte Carlo simulations and real data, we show how xDF outperforms all existing available variance estimators. And finally, we show how using xDF may change the interpretation of the rsFC of the human brain. The potential impact of such corrections on interpretation of rsFC is investigated for conventional thresholding method (i.e. statistical and proportional) as well as un-thresholded functional connectivity for binary and weighted networks.</p>
    </sec>
    <sec id="sec2">
      <label>2</label>
      <title>Methods</title>
      <sec id="sec2.1">
        <label>2.1</label>
        <title>Notation</title>
        <p id="p0090">Without loss of generality, we assume to have mean zero and unit variance time series <inline-formula><mml:math id="M8" altimg="si7.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M9" altimg="si8.svg"><mml:mrow><mml:mi>Y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, each of length <italic>N</italic>, with <inline-formula><mml:math id="M10" altimg="si9.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M11" altimg="si10.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>; we write the cross-correlation matrix between <italic>X</italic> and <italic>Y</italic> as <inline-formula><mml:math id="M12" altimg="si11.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. We assume stationarity, and thus have Toeplitz <inline-formula><mml:math id="M13" altimg="si12.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M14" altimg="si13.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M15" altimg="si14.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and denote autocorrelation of <italic>X</italic><disp-formula id="ufd1"><mml:math id="M16" altimg="si15.svg"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p>
        <p id="p0095">Let <italic>i</italic> and <italic>j</italic> be row and column of the covariance matrix, then <inline-formula><mml:math id="M17" altimg="si16.svg"><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>, and likewise for <italic>Y</italic>. The cross-correlations between <italic>X</italic>'s time point <italic>i</italic> and <italic>Y</italic>'s time point <italic>j</italic> is<disp-formula id="ufd2"><mml:math id="M18" altimg="si17.svg"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="p0100">The key rsFC parameter is <inline-formula><mml:math id="M19" altimg="si18.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the cross-correlation at lag 0, which we refer to as simply <italic>ρ</italic> going forward. Note that the cross-correlation matrix is not symmetric, and so <inline-formula><mml:math id="M20" altimg="si19.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M21" altimg="si20.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are distinct.</p>
      </sec>
      <sec id="sec2.2">
        <label>2.2</label>
        <title>Variance of sample correlation coefficients</title>
        <p id="p0105">For the sample correlation coefficient of mean zero data, <inline-formula><mml:math id="M22" altimg="si21.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>Y</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>, we can derive a general expression for its variance (<xref rid="appsec2" ref-type="sec">Appendix B</xref>):<disp-formula id="fd1"><label>(1)</label><mml:math id="M23" display="block" altimg="si22.svg" alttext="Equation 1."><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo linebreak="badbreak">+</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>ρ</mml:mi><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>ρ</mml:mi><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>ρ</mml:mi><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
        <p id="p0110">For a stationary covariance (see <xref rid="appsec3" ref-type="sec">Appendix C</xref>), we can rewrite Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref> as<disp-formula id="fd2"><label>(2)</label><mml:math id="M24" display="block" altimg="si23.svg" alttext="Equation 2."><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo linebreak="badbreak">+</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn><mml:mi>ρ</mml:mi><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mspace width="1em"/><mml:mo linebreak="badbreak">+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula><mml:math id="M25" altimg="si24.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>2</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>. While Eq. <xref rid="fd2" ref-type="disp-formula">(2)</xref> takes the same form as the estimator of <xref rid="bib51" ref-type="bibr">Roy (1989)</xref>, we obtain our result from finite sample as opposed to asymptotic arguments (see <xref rid="appsec2" ref-type="sec">Appendix B</xref>).</p>
        <p id="p0115">It is also useful to discuss two special cases of Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref>. First, suppose two time series <italic>X</italic> &amp; <italic>Y</italic> are both white but correlated such that <inline-formula><mml:math id="M26" altimg="si25.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M27" altimg="si26.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mi>ρ</mml:mi></mml:mrow></mml:math></inline-formula>. Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref> then reduces to<disp-formula id="fd3"><label>(3)</label><mml:math id="M28" display="block" altimg="si27.svg" alttext="Equation 3."><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>the well-known result for the variance of the sample correlation coefficients between two white noise time series (see <xref rid="bib32" ref-type="bibr">Lehmann (1999b)</xref>, §5.4).</p>
        <p id="p0120">Second, suppose <italic>X</italic> and <italic>Y</italic> are autocorrelated but are uncorrelated of each other, with non-trivial <inline-formula><mml:math id="M29" altimg="si12.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M30" altimg="si13.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> but <inline-formula><mml:math id="M31" altimg="si28.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Then, Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref> reduces to<disp-formula id="fd4"><label>(4)</label><mml:math id="M32" display="block" altimg="si29.svg" alttext="Equation 4."><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="p0125">a result on the variance inflation of <inline-formula><mml:math id="M33" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> proposed by <xref rid="bib17" ref-type="bibr">Clifford et al. (1989)</xref> and also discussed as the variance of the inner product of two random vectors in <xref rid="bib12" ref-type="bibr">Brown and Rutemiller (1977)</xref>. Written in summation form (see <xref rid="appsec3" ref-type="sec">Appendix C</xref>) this expression is<disp-formula id="fd5"><label>(5)</label><mml:math id="M34" display="block" altimg="si30.svg" alttext="Equation 5."><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="p0130">which is a result proposed much earlier by <xref rid="bib6" ref-type="bibr">Bayley and Hammersley (1946)</xref> and which has found use in neuroimaging (<xref rid="bib40" ref-type="bibr">Nicosia et al., 2013</xref>; <xref rid="bib57" ref-type="bibr">Valencia et al., 2009</xref>). A closely related form (<xref rid="bib19" ref-type="bibr">Dutilleul et al., 1993</xref>) that adjusts for mean centering has also been used in neuroimaging (<xref rid="bib38" ref-type="bibr">Nevado et al., 2012</xref>; <xref rid="bib43" ref-type="bibr">Pannunzi et al., 2018</xref>), though for typical time series lengths (i.e. <inline-formula><mml:math id="M35" altimg="si31.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≫</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>) there should be little difference from the original result.</p>
        <sec id="sec2.2.1">
          <label>2.2.1</label>
          <title>Effective degrees of freedom for the correlation coefficient</title>
          <p id="p0135">One way of dealing with autocorrelation is to modify a variance result that assumes no autocorrelation, replacing <italic>N</italic> with a deflated EDF <inline-formula><mml:math id="M36" altimg="si32.svg"><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. This can be done in terms of <inline-formula><mml:math id="M37" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> (e.g. Eq. <xref rid="fd3" ref-type="disp-formula">(3)</xref>) or after Fisher's transformation; here we consider EDFs for <inline-formula><mml:math id="M38" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and return Fisher's transformation in Section 2.4.</p>
          <p id="p0140">Different corrections have been proposed to estimate <inline-formula><mml:math id="M39" altimg="si32.svg"><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. One of the earliest results is due to <xref rid="bib3" ref-type="bibr">Bartlett (1935)</xref>, who proposed an EDF for uncorrelated (<inline-formula><mml:math id="M40" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) AR(1) time series:<disp-formula id="fd6"><label>(6)</label><mml:math id="M41" display="block" altimg="si34.svg" alttext="Equation 6."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi>N</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
          <p id="p0145">We refer to this EDF estimator as B35.</p>
          <p id="p0150">Building on work of <xref rid="bib4" ref-type="bibr">Bartlett (1946)</xref>, <xref rid="bib49" ref-type="bibr">Quenouille (1947)</xref> proposed a more general EDF that allowed for any form of autocorrelation,<disp-formula id="fd7"><label>(7)</label><mml:math id="M42" display="block" altimg="si35.svg" alttext="Equation 7."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi>N</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>though still assuming <inline-formula><mml:math id="M43" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. We refer to this EDF estimator as Q47.</p>
          <p id="p0155">In neuroimaging, a <italic>global</italic> form of Eq. <xref rid="fd7" ref-type="disp-formula">(7)</xref> has been used, where a single ACF <inline-formula><mml:math id="M44" altimg="si36.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is computed averaged across voxels or ROIs for each subject, or even over subjects (<xref rid="bib23" ref-type="bibr">Fox et al., 2005</xref>; <xref rid="bib59" ref-type="bibr">Van Dijk et al., 2010</xref>); it takes the form<disp-formula id="fd8"><label>(8)</label><mml:math id="M45" display="block" altimg="si37.svg" alttext="Equation 8."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi>N</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
          <p id="p0160">We refer to this EDF as G-Q47.</p>
          <p id="p0165">Finally, the variance result due originally <xref rid="bib6" ref-type="bibr">Bayley and Hammersley (1946)</xref> and <xref rid="bib17" ref-type="bibr">Clifford et al. (1989)</xref> (Eqs. <xref rid="fd4" ref-type="disp-formula">(4)</xref>, <xref rid="fd5" ref-type="disp-formula">(5)</xref>)), gives EDF<disp-formula id="fd9"><label>(9)</label><mml:math id="M46" display="block" altimg="si38.svg" alttext="Equation 9."><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi>N</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>still under an independence assumption <inline-formula><mml:math id="M47" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. We refer to this EDF as BH.</p>
          <p id="p0170">Whether defined with infinite or finite sums, some sort of truncation or ACF regularisation is required to use these results in practice, which we consider in Section 2.3.</p>
        </sec>
        <sec id="sec2.2.2">
          <label>2.2.2</label>
          <title>Monte Carlo parametric simulations</title>
          <p id="p0175">The one other approach we evaluate is Monte Carlo parametric simulation (MCPS) (<xref rid="bib50" ref-type="bibr">Ripley, 2009</xref>). In this approach the variance of the sample correlation is estimated from surrogate data, simulated to match the original data in some way. If a common autocorrelation model and parameters are assumed over variables and subjects, this can be a computationally efficient approach. For example, the FSLnets<xref rid="fn2" ref-type="fn">2</xref> toolbox for analysis of the functional connectivity assumes an AR(1) model with the AR coefficient chosen globally for all subjects and node pairs. While MCPS avoids any approximations for a given model, it can only be as accurate as the assumed model.</p>
          <p id="p0180">We evaluate the method used by FSLnets, which chooses the number of realisations set equal to the number of nodes. We refer to this as AR1MCPS.</p>
        </sec>
      </sec>
      <sec id="sec2.3">
        <label>2.3</label>
        <title>Regularising autocorrelation estimates</title>
        <p id="p0185">All of the advanced correction methods described depend on the true ACFs <inline-formula><mml:math id="M48" altimg="si40.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M49" altimg="si41.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and some on the cross-correlations <inline-formula><mml:math id="M50" altimg="si19.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. We expect true ACFs and cross-correlations to diminish to zero with increasing lags, but sampling variability means that non-zero ACF estimates will occur even when the true values are zero. Thus all ACF-based methods use a strategy to regularise the ACF, by zeroing or reducing ACF estimates at large lags.</p>
        <p id="p0190">Several arbitrary rules have been suggested for truncating ACF's, zeroing the ACF above a certain lag. For example, <xref rid="bib1" ref-type="bibr">Anderson (1983)</xref> suggests that the estimators should only consider the first <inline-formula><mml:math id="M51" altimg="si42.svg"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> lags or <xref rid="bib48" ref-type="bibr">Pyper and Peterman (1998)</xref> has found that truncating at <inline-formula><mml:math id="M52" altimg="si43.svg"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> lags is optimal. Since the latter study provides a thorough empirical evaluation, we choose <inline-formula><mml:math id="M53" altimg="si43.svg"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> as the cut-off lag for methods Q47 and B46.</p>
        <p id="p0195">For the xDF method we considered a range of regularisation approaches. Smoothly scaling ACF estimates to zero with increasing lag is known as tapering. <xref rid="bib15" ref-type="bibr">Chatfield (2016)</xref> suggests tapering methods using Tukey or Parzen windows. For example, for Tukey tapering, the raw ACF estimate is scaled by <inline-formula><mml:math id="M54" altimg="si44.svg"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="M55" altimg="si45.svg"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula> and zeroed for <inline-formula><mml:math id="M56" altimg="si46.svg"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>. Similar to truncating, finding the optimal <italic>M</italic> appears to be cumbersome; <xref rid="bib15" ref-type="bibr">Chatfield (2016)</xref> suggests an <italic>M</italic> of <inline-formula><mml:math id="M57" altimg="si47.svg"><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> while <xref rid="bib62" ref-type="bibr">Woolrich et al. (2001)</xref> propose the more stringent <inline-formula><mml:math id="M58" altimg="si48.svg"><mml:mrow><mml:msqrt><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>; for a detailed comparison of tapering methods in fMRI see <xref rid="bib62" ref-type="bibr">Woolrich et al. (2001)</xref>.</p>
        <p id="p0200">For computation of the xDF correction we consider fixed truncation and Tukey tapering, as well as an adaptive truncation method. For our adaptive method, we zero the ACF at lags <inline-formula><mml:math id="M59" altimg="si49.svg"><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≥</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math></inline-formula>, where <italic>M</italic> is the smallest lag where the null hypothesis is not rejected at uncorrected level <inline-formula><mml:math id="M60" altimg="si50.svg"><mml:mrow><mml:mi>α</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>5</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula>, based on approximate normality of the ACF and sampling variance of <inline-formula><mml:math id="M61" altimg="si51.svg"><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>. We base the truncation of the cross-correlation <inline-formula><mml:math id="M62" altimg="si19.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> on the ACFs of <italic>X</italic> and <italic>Y</italic>, choosing the larger <italic>M</italic> found with either time series. Unless stated otherwise, the adaptive truncation method is used with xDF. For summary of regularisation methods, please see <xref rid="tbl2" ref-type="table">Table 2</xref>.<table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Summary of the regularisation methods for autocorrelation function of time series <italic>X</italic>.</p></caption><alt-text id="alttext0060">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Cut off lag</th><th>Window Type</th><th>Reference</th></tr></thead><tbody><tr><td align="left">Truncation</td><td align="left"><inline-formula><mml:math id="M63" altimg="si52.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> &amp;<break/><inline-formula><mml:math id="M64" altimg="si53.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left">N/A</td><td align="left"><xref rid="bib1" ref-type="bibr">Anderson (1983)</xref> &amp;<break/><xref rid="bib48" ref-type="bibr">Pyper and Peterman (1998)</xref></td></tr><tr><td align="left">Adaptive Truncation</td><td align="left"><inline-formula><mml:math id="M65" altimg="si54.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">Tapering</td><td align="left"><inline-formula><mml:math id="M66" altimg="si55.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msqrt><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> &amp;<break/><inline-formula><mml:math id="M67" altimg="si56.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula></td><td align="left">Parzen &amp; Single Tukey</td><td align="left"><xref rid="bib15" ref-type="bibr">Chatfield (2016)</xref> &amp;<break/><xref rid="bib62" ref-type="bibr">Woolrich et al. (2001)</xref></td></tr></tbody></table></table-wrap></p>
      </sec>
      <sec id="sec2.4">
        <label>2.4</label>
        <title>Fisher's transformation</title>
        <p id="p0205">It is typical to apply Fisher's transformation to correlation estimates, <inline-formula><mml:math id="M68" altimg="si57.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>arctanh</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which has approximate variance<disp-formula id="fd10"><label>(10)</label><mml:math id="M69" display="block" altimg="si58.svg" alttext="Equation 10."><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="p0210">Fisher's transformation is derived to cancel the effect of <italic>ρ</italic> on <inline-formula><mml:math id="M70" altimg="si59.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the <italic>absence of autocorrelation</italic>; recall <inline-formula><mml:math id="M71" altimg="si60.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">≈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> (Eq. <xref rid="fd3" ref-type="disp-formula">(3)</xref>) for the no-autocorrelation case. (Fisher derived a more precise variance in this setting, <inline-formula><mml:math id="M72" altimg="si61.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, but this is yet still an approximation (<xref rid="bib22" ref-type="bibr">Fouladi and Steiger, 2008</xref>).) In the presence of autocorrelation, the variance of <inline-formula><mml:math id="M73" altimg="si62.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> remains dependent on <italic>ρ</italic> (more generally <inline-formula><mml:math id="M74" altimg="si63.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, as well as <inline-formula><mml:math id="M75" altimg="si64.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M76" altimg="si65.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) and <inline-formula><mml:math id="M77" altimg="si62.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> cannot be regarded as a variance-stabilised quantity. Only with an accurate estimate of <inline-formula><mml:math id="M78" altimg="si66.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, that considers auto- and cross-correlation, can the final <italic>Z</italic>-score be considered “stabilised”.</p>
        <p id="p0215">We focus the remainder of our evaluations on <italic>Z</italic>-scores of the form<disp-formula id="fd11"><label>(11)</label><mml:math id="M79" display="block" altimg="si67.svg" alttext="Equation 11."><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>arctanh</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
        <p id="p0220">Each particular correction method used determines <inline-formula><mml:math id="M80" altimg="si59.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For xDF we use Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref>, while for all other methods we use the nominal variance with an EDF, i.e. <inline-formula><mml:math id="M81" altimg="si68.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>; Naive has <inline-formula><mml:math id="M82" altimg="si39.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>, and each other EDF method uses their respective estimate <inline-formula><mml:math id="M83" altimg="si32.svg"><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, as described in Section 2.2.1 and <xref rid="tbl1" ref-type="table">Table 1</xref>.<table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Summary of the EDF (<inline-formula><mml:math id="M84" altimg="si32.svg"><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>) estimators for sample correlation coefficients. For simplicity, we refer each method by initials of the authors.</p></caption><alt-text id="alttext0055">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Equation</th><th>Reference</th><th>Neuroimaging Applications</th></tr></thead><tbody><tr><td align="left">Naive</td><td align="left"><inline-formula><mml:math id="M85" altimg="si39.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left"><xref rid="bib21" ref-type="bibr">Fisher (1915)</xref></td><td align="left"><xref rid="bib5" ref-type="bibr">Bassett et al. (2011)</xref><break/>&amp; <xref rid="bib25" ref-type="bibr">Gonzalez-Castillo et al. (2014)</xref><break/>&amp; <xref rid="bib14" ref-type="bibr">Cao et al. (2014)</xref></td></tr><tr><td align="left">B35</td><td align="left">Eq. <xref rid="fd6" ref-type="disp-formula">(6)</xref></td><td align="left"><xref rid="bib3" ref-type="bibr">Bartlett (1935)</xref></td><td align="left">Not found</td></tr><tr><td align="left">BH</td><td align="left">Eq. <xref rid="fd4" ref-type="disp-formula">(4)</xref></td><td align="left"><xref rid="bib6" ref-type="bibr">Bayley and Hammersley (1946)</xref> &amp; <xref rid="bib17" ref-type="bibr">Clifford et al. (1989)</xref></td><td align="left"><xref rid="bib39" ref-type="bibr">Nicosia et al</xref>. (0000) &amp; <xref rid="bib57" ref-type="bibr">Valencia et al. (2009)</xref><break/><xref rid="bib38" ref-type="bibr">Nevado et al. (2012)</xref> &amp; <xref rid="bib43" ref-type="bibr">Pannunzi et al. (2018)</xref><break/><xref rid="bib54" ref-type="bibr">Simas et al. (2015)</xref></td></tr><tr><td align="left">Q47</td><td align="left">Eq. <xref rid="fd8" ref-type="disp-formula">(8)</xref></td><td align="left"><xref rid="bib49" ref-type="bibr">Quenouille (1947)</xref> &amp; <xref rid="bib4" ref-type="bibr">Bartlett (1946)</xref></td><td align="left"><xref rid="bib23" ref-type="bibr">Fox et al. (2005)</xref> &amp; <xref rid="bib63" ref-type="bibr">Zhang et al. (2008)</xref></td></tr><tr><td align="left">xDF</td><td align="left">Eqs. <xref rid="fd1" ref-type="disp-formula">(1)</xref>, <xref rid="fd2" ref-type="disp-formula">(2)</xref></td><td align="left"><xref rid="bib51" ref-type="bibr">Roy (1989)</xref> &amp; the current work</td><td align="left"><xref rid="bib20" ref-type="bibr">Fiecas et al. (2017)</xref></td></tr><tr><td align="left">AR1MCPS</td><td align="left">Sec. 2.2.2</td><td align="left"><xref rid="bib55" ref-type="bibr">Smith et al. (2011)</xref> &amp; <xref rid="bib50" ref-type="bibr">Ripley (2009)</xref></td><td align="left"><xref rid="bib41" ref-type="bibr">Nomi and Uddin (2015)</xref>; <xref rid="bib56" ref-type="bibr">Smith et al. (2015)</xref></td></tr></tbody></table></table-wrap></p>
      </sec>
      <sec id="sec2.5">
        <label>2.5</label>
        <title>Simulations and real data analysis</title>
        <p id="p0225">The xDF is validated and compared with other existing estimators via series of Monte Carlo simulations and real data experiments. We simulate time series with various autocorrelation structures (see Section S3.1), under both uncorrelated and correlated conditions, using ACF parameters estimated from one HCP subject (see Section 3.4). We generate null realisations with real data by randomly exchanging the nodes between subjects (see Section S3.6). From both of these sources of null data we evaluate the distribution of <italic>Z</italic>-scores and false positive rates.</p>
        <p id="p0230">To investigate sensitivity and specificity, we simulate correlation matrices, transformed to <italic>Z</italic>-scores with each method, with 15% of edges considered as signal (i.e. assigned with <inline-formula><mml:math id="M86" altimg="si69.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). Briefly, sensitivity refers to the proportion of true positives (i.e. edges which were assigned with a non-zero correlation and also rejected null hypothesis, <inline-formula><mml:math id="M87" altimg="si2.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) over all positives (i.e. all edges which have rejected <inline-formula><mml:math id="M88" altimg="si70.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>). Specificity is defined as proportion of true negatives (i.e. edges which were assigned with zero correlation and also failed to reject <inline-formula><mml:math id="M89" altimg="si70.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) over all negatives (i.e. all non-detected edges). Accuracy is defined as the summation of two measure described (see Section S3.5).</p>
        <p id="p0235">We consider graph metrics computed on real data, based on <italic>Z</italic>-scores from each method. We use one session of resting state data from each of the 100 unrelated HCP subjects. This data was pre-processed (Section S4) and we created <inline-formula><mml:math id="M90" altimg="si71.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula> resting-state functional connectivity matrices (<italic>Z</italic>-scores), where <italic>P</italic> is number of ROIs, depending on the choice of parcellation scheme; we use the Yeo, Power and Gordon atlas in their volumetric form and ICA200 and Multimodal Parcellation (MMP) in surface mode (see Section S4.1). The rsFC matrices were then thresholded using two conventional thresholding methods; statistical thresholding (where FDR corrected <inline-formula><mml:math id="M91" altimg="si50.svg"><mml:mrow><mml:mi>α</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>5</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula> is used to test the significance of each edge; see Section S4.3) and proportional thresholding (where matrices are thresholded on population cost-efficient density so all matrices have identical density; see Section S4.4). Finally, the effect of the autocorrelation corrections on two centrality measures (weighted degree and betweenness) and two efficiency measures (local and global) are investigated (see Section S4.5.3).</p>
        <p id="p0240">In all our evaluations we estimate the ACFs from the time series, incorporating this important source of uncertainty (Algorithm S2 in Supplementary Materials). An exception are “Oracle” simulations in which the true ACF parameter values are used when estimating the variance (see Algorithm S1 in Supplementary Materials).</p>
      </sec>
      <sec id="sec2.6">
        <label>2.6</label>
        <title>Autocorrelation index</title>
        <p id="p0245">To summarise the strength of autocorrelation in time series <italic>X</italic>, we use<disp-formula id="fd12"><label>(12)</label><mml:math id="M92" display="block" altimg="si72.svg" alttext="Equation 12."><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which we call the autocorrelation index (ACI).</p>
      </sec>
    </sec>
    <sec id="sec3">
      <label>3</label>
      <title>Results</title>
      <sec id="sec3.1">
        <label>3.1</label>
        <title>Autocorrelation and parcellation schemes</title>
        <p id="p0250">We find that the degree of autocorrelation of resting state data is highly heterogeneous over the brain. <xref rid="fig2" ref-type="fig">Fig. 2</xref>.A shows a maps of voxel-wise and ROI ACI, averaged across subjects (15 for voxelwise, 100 for ROIs), showing that ACI vary widely. We found that using parcellation schemes not only fails to reduce the spatial heterogeneity, but instead magnifies the autocorrelation effects: <xref rid="fig2" ref-type="fig">Fig. 2</xref>.B shows autocorrelation indices for three ROIs of Yeo's atlas, for each voxel in an ROI and as ROI averages: Left posterior cingulate (LH-PCC; 1091 voxels), Left somatosensory motor (LH-SomMot; 4103 voxels) and Left dorsal prefrontal cortex (LH-PFC; 19 voxels). We find a dramatic increase in autocorrelation with averaging within ROIs (see <xref rid="appsec5" ref-type="sec">Appendix E</xref> for the likely origin of this effect).<fig id="fig2"><label>Fig. 2</label><caption><p>Variation in strength of autocorrelation over space within an atlas, and between atlases. <bold>Panel A</bold> maps the autocorrelation index (ACI) voxelwise and for 3 different atlases, averaged over subjects (15 for voxel-wise, 100 for ROIs); variation is particularly evident for Yeo and Gordon; Power atlas is more homogeneous (but see Panel D). <bold>Panel B</bold> shows the impact of averaging within ROIs on autocorrelation. Left, shows ACI of individual voxels (blue dots) of a single subject across three regions of interests (ROIs) from the Yeo atlas. Right panel illustrates the ACI of ROI-averaged time series (blue dots) for 100 subjects, showing dramatic increase in ACI; red lines indicates the median. ROIs are Left Posterior Cingulate (LH-PCC), Left Somatosensory Motor (LH-SomMot) and Left Dorsal Prefrontal Cortex (LH-PFC). <bold>Panel C</bold> plots the ACI, averaged over subjects of the HCP 100 unrelated-subjects package, vs. region size for ACI time series and three atlases, where ICA and one atlas (MMP) are surface-based. There is a strong relationship between ACI and ROI size. The “ROI size” for ICA is defined as number of voxels in each component above an arbitrary threshold of 50. For MMP, the ROI size is defined as number of vertices comprising an ROI. <bold>Panel D</bold> considers the Power atlas, which has identically sized spherical ROIs, plotting ACI vs. distance to a voxel in the thalamus. Cortical ROIs have systematically larger ACI than subcortical ROIs. <bold>Panel E</bold> shows variance explained by inter-subject and inter-node ACI profiles for the Gordon, ICA200, Power and Yeo atlases; the large variance explained by inter-subject mean indicates substantial consistency in ACI over subjects.</p></caption><alt-text id="alttext0020">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p>
        <p id="p0255">More generally, we find that the size of ROIs predicts autocorrelation of the ROI in both volumetric and surface-based parcellation schemes (<xref rid="fig2" ref-type="fig">Fig. 2</xref>.C). Further, not only the size of the ROI, but the location of the ROI influences autocorrelation. Using the Power atlas, where all ROIs have identical volume (81 2 mm<sup>3</sup> voxels), the autocorrelation in subcortical structures is weaker than in cortical structures, as summarized by plotting autocorrelation index vs. distance to Thalamus (<xref rid="fig2" ref-type="fig">Fig. 2</xref>.D). While differences in BOLD characteristics between subcortical and cortical voxels could contribute to the autocorrelation structure, it is more likely the higher noise levels (far from the surface coils, and more susceptible to problems of acceleration-reconstruction, in this HCP data) explain the lower autocorrelation index in subcortical regions.</p>
        <p id="p0260">Using an ANOVA with either node or subject as the explanatory variable, we quantify the heterogeneity of autocorrelation index as the variance explained by variable (<xref rid="fig2" ref-type="fig">Fig. 2</xref>.E). For time series extracted using Power atlas, 36% of inter-subject ACI variance is explained, while for ICA200 time series up to 73% of inter-subject is explained, showing that the severity of autocorrelation is very subject-dependent regardless of atlas used. The ACI variance explained by node is smaller, but above 12% for all four parcellation schemes, suggesting the importance of node-specific autocorrelation adjustment.</p>
      </sec>
      <sec id="sec3.2">
        <label>3.2</label>
        <title>Real data and Monte Carlo evaluations</title>
        <p id="p0265">We use inter-subject scrambling of 100 HCP subjects, parcellated with Yeo atlas, to create null realisations with realistic autocorrelation structure. Using these realisations we compare different EDF methods in terms of FPR and distribution of Fisher's <italic>Z</italic>-scores, both visually via QQ plots and by Kolmogorov-Smirnov (KS) statistics of observed <italic>Z</italic>-scores vs. a standard normal distribution. Results on node-specific autocorrelation corrections in <xref rid="fig3" ref-type="fig">Fig. 3</xref>A show that Naive and B35 have greatly inflated FPR, while BH and its approximation, Q47, successfully preserve the FPR level at the 5% level while distribution of the both methods closely follow normal distribution (i.e. -<inline-formula><mml:math id="M93" altimg="si73.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>(KS) <inline-formula><mml:math id="M94" altimg="si74.svg"><mml:mrow><mml:mo>=</mml:mo><mml:mn>2.54</mml:mn></mml:mrow></mml:math></inline-formula>). Similar results for other FPR levels (%1 and 10%) are also illustrated in <xref rid="appsec1" ref-type="sec">Fig. S4</xref>.<fig id="fig3"><label>Fig. 3</label><caption><p>Evaluation of false positive rate control for testing <inline-formula><mml:math id="M95" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> with different autocorrelation correction methods. <bold>Panel A</bold> shows results using real data and inter-subject scrambling of HCP 100 unrelated subjects with the Yeo atlas ROIs, comprising 235,500 distinct <italic>Z</italic>-scores (see <xref rid="appsec1" ref-type="sec">Fig. S6</xref> for same results with other atlases). Left shows the QQ plot of <italic>Z</italic>-scores of each method, top right shows the <inline-formula><mml:math id="M96" altimg="si76.svg"><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> KS statistics (larger is better, more similar to Gaussian), and bottom right the FPR, all of which show that Naive and B35 have very poor performance. <bold>Panel B</bold> depicts a similar evaluation with simulated data, where a single ACF is used to simulate all time series with identical autocorrelation (see Section S3.5), again under the null; we additionally consider two “global” correction methods that assume common ACF between the nodes, G-Q47 and AR1MCPS. Here the Naive and the two global methods have poor false positive control. <bold>Panel C</bold> shows the FPR at the nominal 5% <italic>α</italic> level across five methods (columns) for identical (top row) and different (bottom row) ACFs, over a range of time series lengths. Naive (note different y-axis limits) and B35 have poor FPR control, while BH, Q47 and xDF all have good performance for long time series, with xDF having some inflation for the most severe autocorrelation structures with short time series. The setting of each simulation is coded by plotting symbol and colour, as shown at the bottom of the figure.</p></caption><alt-text id="alttext0025">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
        <p id="p0270">Since the majority of methods used are not node-specific but instead consider the autocorrelation as a global effect (<xref rid="bib23" ref-type="bibr">Fox et al., 2005</xref>; <xref rid="bib63" ref-type="bibr">Zhang et al., 2008</xref>; <xref rid="bib27" ref-type="bibr">Hale et al., 2016</xref>), we evaluate them under their homogeneity assumption using simulated correlation matrices comprised of uncorrelated time series with strong autocorrelation measured from one particular HCP subject (see Section S3.5 for details). <xref rid="fig3" ref-type="fig">Fig. 3</xref>.B shows comparison of node-specific methods (B35 excepted, due to its poor FPR control) to global methods AR1MCPS and G-Q47. Both global correction methods fail to achieve the desired FPR level and the KS statistics of the two methods are also amongst the lowest; this poor performance is likely due to the simple AR correlation model used by each of these methods. On the other hand, the node-specific methods (xDF, BH and Q47) remarkably improves the FPR and KS statistics. However, for uncorrelated time series, BH and GQ47 outperform the xDF. Similar results for other FPR levels (%1 and 10%) are illustrated in <xref rid="appsec1" ref-type="sec">Fig. S5</xref>.</p>
        <p id="p0275">We also repeated the FPR and KS analysis of correlation matrices for another set of simulated correlation matrices, this time with autocorrelation structures drawn from a different subject than above. Results suggest similar FPR and KS statistics except for AR1MCPS which almost meet the FPR-level. This clearly suggests that the performance of the global measures, especially AR1MCPS, are subject-dependent.</p>
        <p id="p0280">We further complement the validation methods with FPR and ROC analysis. Using the same simulation techniques, discussed in section S3.1, we compare the FPR levels for pair-wise uncorrelated time series. <xref rid="fig3" ref-type="fig">Fig. 3</xref>.C illustrates the FPR of each method for level <inline-formula><mml:math id="M97" altimg="si50.svg"><mml:mrow><mml:mi>α</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>5</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula>. <xref rid="fig3" ref-type="fig">Fig. 3</xref>.C suggests that the Naive correction (first column) can only maintain the desired FPR level when at least one of the time series are white, otherwise, the FPR level can approach 50%, in cases where the both time series are highly autocorrelated. Second and third columns of <xref rid="fig3" ref-type="fig">Fig. 3</xref>.C shows the FPR levels after the degrees of freedom are corrected via BH and Q47 methods where results suggest a remarkable improvement. Despite both methods having a conservative FPR level on short time series, both successfully maintain the FPR level on larger <italic>N</italic>. The FPR results for xDF suggest that for short time series, the method fails to contain the FPR level, especially on highly autocorrelated time series, however as <italic>N</italic> grows, the FPR levels approaches the nominal level <italic>α</italic> until <inline-formula><mml:math id="M98" altimg="si75.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>2000</mml:mn></mml:mrow></mml:math></inline-formula> where the xDF has the closest FPR level. We finally, evaluate the FPR of B35 where, for majority of the autocorrelation structures, the method has failed to control the FPR level regardless of the sample size. For example, for time series with AR1-AR14 structure, the FPR level is as conservative as 2% while for AR14-AR20 the level exceeds 7%.</p>
        <p id="p0285">Results presented in <xref rid="fig3" ref-type="fig">Fig. 3</xref> are for highly autocorrelated, yet uncorrelated, time series (<inline-formula><mml:math id="M99" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). However, in rsFC, it is the highly correlated time series that are of interest. This motivates us to investigate the accuracy of standard errors for <inline-formula><mml:math id="M100" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> for highly autocorrelated time series, with non-zero cross-correlation, simulated following the model described in Section S3.1.</p>
        <p id="p0290">The bias for estimating Pearson's correlation standard deviation (<inline-formula><mml:math id="M101" altimg="si77.svg"><mml:mrow><mml:msqrt><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>) by the Naive method is severe and varies with <italic>ρ</italic> when the ACF's are unequal (<xref rid="appsec1" ref-type="sec">Fig. S2</xref>). For the other methods, <xref rid="fig4" ref-type="fig">Fig. 4.A, 4.B &amp; 4.</xref>C show percent bias for existing methods, B35, BH and Q47, respectively. While BH and Q47 corrections give mostly unbiased standard errors in case of independence (<inline-formula><mml:math id="M102" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) there is substantial bias as correlation <italic>ρ</italic> grows, for both short and long time series length. For example, for <inline-formula><mml:math id="M103" altimg="si78.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, BH and Q47 corrections overestimates <inline-formula><mml:math id="M104" altimg="si77.svg"><mml:mrow><mml:msqrt><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> by more than <inline-formula><mml:math id="M105" altimg="si79.svg"><mml:mrow><mml:mn>30</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula>. The bias for the B35 standard errors show a similar pattern but with particular sensitivity to the autocorrelation structure.<fig id="fig4"><label>Fig. 4</label><caption><p>Percentage bias of estimated standard deviation of <inline-formula><mml:math id="M106" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> for different autocorrelation correction methods. <bold>Panel A</bold> plots the bias of the B35 method for <inline-formula><mml:math id="M107" altimg="si83.svg"><mml:mrow><mml:mi>T</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> (top) and <inline-formula><mml:math id="M108" altimg="si84.svg"><mml:mrow><mml:mi>T</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1200</mml:mn></mml:mrow></mml:math></inline-formula> (bottom) for equal (left) and unequal (right) ACF's. <bold>Panel B</bold> plots the same for BH, and <bold>Panel C</bold> for Q47. <bold>Panel D</bold> plots the same information for a wider range of time series lengths <italic>T</italic>. These results show the dramatic standard error bias in BH35, BH and Q47 with increasing <italic>ρ</italic>. All results here are for our adaptive truncation method; see <xref rid="appsec1" ref-type="sec">Figs. S8 and S9</xref> for percent bias of different tapering methods. The setting of each simulation is coded by plotting symbol and colour, as shown at the bottom of the figure. Details of simulations and bias computation are found in Supplementary Materials; see Algorithm S2 and Eq. S(10). We exclude the results for biases of Naive standard error as they often exceed up to <inline-formula><mml:math id="M109" altimg="si85.svg"><mml:mrow><mml:mtext>%</mml:mtext><mml:mn>60</mml:mn></mml:mrow></mml:math></inline-formula> for autocorrelated time series; see <xref rid="appsec1" ref-type="sec">Fig. S2</xref>.</p></caption><alt-text id="alttext0030">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
        <p id="p0295">A notable finding from these <inline-formula><mml:math id="M110" altimg="si3.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> results is for white time series (“W–W” for <inline-formula><mml:math id="M111" altimg="si80.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, blue triangles). For B35, BH and Q47 methods, this ‘easy’ case of no autocorrelation gives just as bad performance as severe autocorrelation. We identified the source of this problem as a confounding of the product of sample autocorrelation functions with sample cross-correlation; see <xref rid="appsec4" ref-type="sec">Appendix D</xref> for details.</p>
        <p id="p0300">For xDF (<xref rid="fig4" ref-type="fig">Fig. 4</xref>.D), the performance is dramatically better, with less <inline-formula><mml:math id="M112" altimg="si77.svg"><mml:mrow><mml:msqrt><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> bias over all and no notable dependence on <italic>ρ</italic>. The worst performance is for short time series and high-order AR autocorrelation, but for <inline-formula><mml:math id="M113" altimg="si81.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">≥</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> bias is mostly within <inline-formula><mml:math id="M114" altimg="si82.svg"><mml:mrow><mml:mo>±</mml:mo><mml:mn>5</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula> and improves with <italic>N</italic>.</p>
        <p id="p0305">Results for Oracle simulation (<xref rid="appsec1" ref-type="sec">Figure S3.A</xref>) also confirm the confounding of autocorrelation with cross-correlations, as Q47 and BH are both biased even when the true parameters are used, while xDF shows negligible biases across different autocorrelation structures and sample sizes.</p>
        <p id="p0310">We also use the simulations to evaluate <inline-formula><mml:math id="M115" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> xDF's standard error bias across different tapering methods (see section 2.3). <xref rid="appsec1" ref-type="sec">Fig. S8</xref> suggests that despite similarities between the tapering methods on low- and mid-range correlations, they differ on higher correlation coefficients where unregularised, Tukey tapered (<inline-formula><mml:math id="M116" altimg="si86.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msqrt><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>) and truncation (<inline-formula><mml:math id="M117" altimg="si53.svg"><mml:mrow><mml:mi>M</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> lags) autocorrelation functions overestimate the variances while the shrinking and Tukey of <inline-formula><mml:math id="M118" altimg="si47.svg"><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> lags maintain the lowest biases. Although the two methods, Tukey taper with cut-off at <inline-formula><mml:math id="M119" altimg="si48.svg"><mml:mrow><mml:msqrt><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> lags and adaptive truncation, appear to have very similar biases we notice that adaptive truncation has less bias for short time series. Moreover, adaptive truncation is immune from arbitrary choice of lag cut-off. We therefore use adaptive truncation as the ACF regularisation method for remainder of this work.</p>
        <p id="p0315">The FPR analysis presented in <xref rid="fig3" ref-type="fig">Fig. 3</xref>.C concern only the null case of uncorrelated time series. To summarise performance in the presence of correlation <inline-formula><mml:math id="M120" altimg="si69.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> we evaluate the sensitivity and specificity of each method, via ROC analysis, on simulated correlation matrices, discussed in section S3.5, where the time series are highly dependent and autocorrelated. <xref rid="fig5" ref-type="fig">Fig. 5</xref> illustrates the sensitivity, specificity and accuracy measures for each of the methods across three different sample sizes. For correlation matrices comprised of both short and long sample sizes, the xDF outperforms other methods in terms of accuracy. While other measures have higher sensitivity than xDF, they suffer from worse specificity. AUC analyses showed virtually no difference between the methods for FPR &lt;10% (<xref rid="appsec1" ref-type="sec">Fig. S7</xref>).<fig id="fig5"><label>Fig. 5</label><caption><p>Performance of testing <inline-formula><mml:math id="M121" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> at level <inline-formula><mml:math id="M122" altimg="si87.svg"><mml:mrow><mml:mi>α</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> on 5000 simulated correlation matrices (<inline-formula><mml:math id="M123" altimg="si88.svg"><mml:mrow><mml:mn>114</mml:mn><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mn>114</mml:mn></mml:mrow></mml:math></inline-formula>, matching Yeo atlas) with 15% non-null edges (see Section S3.5). From top to bottom, specificity, sensitivity and accuracy (sum of detections at non-null edges and non-detections at null edges) are shown. Specificity (i.e. FPR control) is good for xDF, BH, Q47 and G-Q47, and sensitivity increases with time series length; accuracy is best for xDF, closely followed by BH and Q47.</p></caption><alt-text id="alttext0035">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
      </sec>
      <sec id="sec3.3">
        <label>3.3</label>
        <title>Effect of autocorrelation correction on functional connectivity</title>
        <p id="p0320"><xref rid="fig6" ref-type="fig">Fig. 6</xref>.A suggests that, as expected, the <italic>Z</italic>-score of the functional connections either remained unchanged or has been reduced due to unbiased estimation of variance using xDF correction. For example, the functional connection between node 37 and 94 (i.e. both series are almost white; see <xref rid="fig1" ref-type="fig">Fig. 1</xref>.E) has experienced almost no changes; <inline-formula><mml:math id="M124" altimg="si89.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mtext>xDF</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>37,94</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> = 3.61 and <inline-formula><mml:math id="M125" altimg="si90.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mtext>Naive</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>37,94</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> = 3.65, while functional connection between nodes 23 and 13 (i.e. both series are highly autocorrelated; see <xref rid="fig1" ref-type="fig">Fig. 1</xref>.E) was reduced for 200%; <inline-formula><mml:math id="M126" altimg="si91.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mtext>xDF</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>13,25</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> = 2.08, <inline-formula><mml:math id="M127" altimg="si92.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mtext>Naive</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>13,25</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> = 6.02.</p>
        <p id="p0325">Naturally, such drastic changes in <italic>Z</italic>-scores are also reflected in p-values of statistical inferences for each connection. <xref rid="fig6" ref-type="fig">Fig. 6</xref>.C illustrate these changes (i.e. orange dots) between FDR-corrected p-values (i.e. q-values) of Naive correction (y-axis) and similar statistics of xDF correction (x-axis) where, broadly speaking, large number of the connections with significant q-values no longer meet the 5% <italic>α</italic> level.<fig id="fig6"><label>Fig. 6</label><caption><p>Impact of Naive, xDF and BH corrections on rsFC in one HCP subject parcellated with the Yeo atlas. <bold>Panel A</bold> plots rsFC <italic>Z</italic>-scores of xDF-corrected connectivity vs. Naive, showing that the significance of edges with Naive computation of <inline-formula><mml:math id="M128" altimg="si59.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is almost always inflated, but to varying degrees. Solid lines are the critical values corresponding to the cost-efficient (CE) density. Dashed lines illustrates the critical values of FDR-corrected q-values. Taking xDF as reference, edges that are incorrectly detected with Naive are coloured green (FDR but not CE) and blue (CE). The black point marks edge (37,94) and red point (13,25), discussed in body text. <bold>Panel B</bold> plots rsFC <italic>Z</italic>-scores of xDF-corrected connectivity vs. BH, same conventions as Panel A, showing deflated significance of <italic>Z</italic>-scores computed with the BH method. The green point marks edge (103,104). <bold>Panel C</bold> pp-plot of p-values of <italic>Z</italic>-scores from xDF (green), BH (blue) and Naive (red) corrections. Dashed line is %5 Bonferroni threshold for 6441 edges. <bold>Panel D</bold> shows the differences in mean functional connectivity (mFC) of each correction method across statistical (FDR) and proportional (CE) thresholding. See <xref rid="appsec1" ref-type="sec">Fig. S10</xref> for a similar plot for a different HCP Subject.</p></caption><alt-text id="alttext0040">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig></p>
        <p id="p0330">Since the changes in <italic>Z</italic>-scores due to xDF are spatially heterogeneous, both statistical and proportional thresholding methods are dramatically affected. In statistical thresholding (ST), after xDF correction, the FDR critical values (shown as dotted lines on <xref rid="fig6" ref-type="fig">Fig. 6</xref>.A) are slightly increases from 2.064 to 2.14. With the use of xDF, 13.66% of the edges change from being marked FDR-significant to being non-significant; i.e. over 10% of the edges would be incorrectly selected with the Naive method. Similarly, proportional thresholding (PT) is also affected since the cost-efficient densities (shown as solid lines on <xref rid="fig6" ref-type="fig">Fig. 6</xref>.A, see section S4.4 for more details on cost-efficient densities) are decreased from 35% to 27.5%. These changes in cost-efficient density result in 16.61% false positive edges meaning that they were found to be significant merely due to the autocorrelation effect.</p>
        <p id="p0335">The same analysis on another HCP subject finds very similar changes in functional connectivity (<xref rid="appsec1" ref-type="sec">Fig. S10</xref>) as in ST and PT, the critical values and cost-efficiencies were reduced by more than <inline-formula><mml:math id="M129" altimg="si93.svg"><mml:mrow><mml:mn>50</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M130" altimg="si94.svg"><mml:mrow><mml:mn>26</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula>, respectively, due to xDF correction. This results in 16% FP edges in ST and 19% FP edges in PT.</p>
        <p id="p0340">While <xref rid="fig6" ref-type="fig">Fig. 6</xref>.A shows that there is a profound effect of xDF relative to no correction (Naive), it is of interest to see how xDF compares to an existing methods that does attempt to correct for autocorrelation. For this we compare xDF <italic>Z</italic>-scores to BH <italic>Z</italic>-scores (<xref rid="fig6" ref-type="fig">Fig. 6</xref>.A); recall that BH correction does not account for cross-correlation <inline-formula><mml:math id="M131" altimg="si63.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and, due to confounding of cross-correlation and autocorrelation, can over-estimate <inline-formula><mml:math id="M132" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> standard errors. When the <italic>Z</italic>-scores are low (corresponding to weak correlation) there is little difference between the approaches, while for stronger effects the difference between the two correction methods become clearer. For example, the <italic>Z</italic>-score for the edge between node 103 and node 104 (green dot in <xref rid="fig6" ref-type="fig">Fig. 6</xref>.B; <inline-formula><mml:math id="M133" altimg="si95.svg"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>103,104</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>) with BH and xDF correction is 6.93 and 15.30, respectively; suggesting that the confounding in autocorrelation estimates (see <xref rid="appsec4" ref-type="sec">Appendix D</xref>) has reduced the functional strength of this edge for more than 50%. Similarly, we also follow changes in rsFC of another HCP subject for nodes 23 and 88 (green dot in <xref rid="appsec1" ref-type="sec">Figure S10.B</xref>; <inline-formula><mml:math id="M134" altimg="si96.svg"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>23,88</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0.67</mml:mn></mml:mrow></mml:math></inline-formula>) where the confounding effect produces a similar effect; <inline-formula><mml:math id="M135" altimg="si97.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mtext>BH</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>23,88</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>9.95</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M136" altimg="si98.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mtext>xDF</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>23,88</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> = 14.26.</p>
        <p id="p0345">Further, in <xref rid="fig6" ref-type="fig">Fig. 6</xref>.D we show the impact of autocorrelation correction on mean value of rsFC <italic>Z</italic>-scores for edges included in proportional (left) and FDR-based statistical (right) thresholding. Reflecting the findings of the simulations, autocorrelation correction reduces <italic>Z</italic>-scores (suggesting Naive's under estimation of <inline-formula><mml:math id="M137" altimg="si59.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), but the BH method has appreciably smaller <italic>Z</italic>-scores (attributable to the statistical confounding problem discussed in <xref rid="appsec4" ref-type="sec">Appendix D</xref>).</p>
      </sec>
      <sec id="sec3.4">
        <label>3.4</label>
        <title>Effect of autocorrelation correction on graph theoretical measures</title>
        <p id="p0350">Graph measures are notorious for their sensitivity to changes in functional connectivity (<xref rid="bib58" ref-type="bibr">van den Heuvel et al., 2017</xref>). Using subjects from 100 HCP unrelated package, we show how accounting for autocorrelation can influence basic graph theoretical measures such as centrality and efficiency in weighted and binary networks. In weighted networks we use xDF-corrected standardised <italic>Z</italic>-scores as edge weights while in binary networks we set supra-threshold edges to one, zero otherwise.</p>
        <p id="p0355">The graph theoretical measures are discussed for both proportional (PT) and FDR-based statistical thresholding (ST) methods. In the former we use universal density (obtained from averaging cost-efficient densities across the three method under the investigation) to threshold rsFC across subjects while in latter we use hypothesis testing (<inline-formula><mml:math id="M138" altimg="si99.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) for each pair of nodes. It is important to note that PT is a equi-density method while ST is equi-threshold method, meaning that the in proportionally thresholded matrices the number of edges is identical across all subjects and correction methods, while in statistically thresholded matrices the number of edges varies across subjects and correction method. For more information on each of the thresholding method, see Section S4.3 of the Supplementary Materials. We further repeat these analysis for the case of unthresholded rsFC, see <xref rid="appsec1" ref-type="sec">Fig. S11</xref> for results of unthresholded functional connectomes.</p>
        <p id="p0360"><xref rid="fig7" ref-type="fig">Fig. 7</xref> A uses Bland-Altman plots to show the changes in graph measures of rsFC obtained using proportional thresholding. The left column of <xref rid="fig7" ref-type="fig">Fig. 7</xref>.A shows the impact of xDF relative to no correction: Most dramatic is the overall reduction in weighted degree, with the degree hubs having the highest rate of losing weighted degrees; these nodes are parts of the Default Mode Network (DMN; i.e. DefaultABC) and Saliency Ventral Attention Network (SVAN; i.e. SalVenAtt). Similarly, the local efficiency of more than 98% of nodes were changed after xDF correction. Parts of DMN and SVAN in addition to parts of the Visual network are among the nodes which have been affected the most. In contrast, betweenness centrality has experienced modest changes of only <inline-formula><mml:math id="M139" altimg="si100.svg"><mml:mrow><mml:mo>≈</mml:mo></mml:mrow></mml:math></inline-formula>5% in their values.<fig id="fig7"><label>Fig. 7</label><caption><p>Overall changes in global and local graph theoretical measures with the 100 unrelated HCP package parcellated by Yeo atlas. <bold>Panel A,</bold> Bland Altman plots of xDF vs. Naive for weighted degree (top), betweenness (middle) and local efficiency (bottom) computed with a cost-efficient threshold. There is one point for each of 114 nodes, the particular measure averaged over subjects, and the nodes are colour coded according to their resting-state network assignment. <bold>Panel B</bold> Shows the same graph measures, but with statistical thresholding (corrected via FDR correction). <bold>Panel C</bold> shows the differences in weighted CE density (left) and Global efficiency (right), and <bold>Panel D</bold> illustrates the same results statistical FDR thresholding. There is a dramatic impact of correction method on all graph metrics considered. Similar results for Gordon (<xref rid="appsec1" ref-type="sec">Fig. S12</xref>), Power (<xref rid="appsec1" ref-type="sec">Fig. S13</xref>) and ICA200 (<xref rid="appsec1" ref-type="sec">Fig. S14</xref>) is available in Supplementary Materials.</p></caption><alt-text id="alttext0045">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
        <p id="p0365">The left column of <xref rid="fig7" ref-type="fig">Fig. 7</xref>.B illustrates the changes in local graph measures of FDR-based statistical thresholded rsFC. Similar to ST results, the weighted degree of nodes suggests a significant reduction, with degree hubs (parts of DMN and SVAN) having the largest reduction. Local efficiency of almost every node (<inline-formula><mml:math id="M140" altimg="si101.svg"><mml:mrow><mml:mo>≈</mml:mo><mml:mn>99</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula>) were affected, especially highly efficient nodes appear to be mostly influenced by xDF correction with parts of the DMN, SVAN and Visual network among them. Although the pattern of changes in betweenness centrality suggest almost no relation to the betweenness value of nodes before the correction, betweenness centrality of <inline-formula><mml:math id="M141" altimg="si102.svg"><mml:mrow><mml:mo>≈</mml:mo><mml:mn>22</mml:mn><mml:mtext>%</mml:mtext></mml:mrow></mml:math></inline-formula> of nodes are yet affected.</p>
        <p id="p0370">The right columns of <xref rid="fig7" ref-type="fig">Fig. 7</xref>.A and 7.B reflect how the BH estimator is a more conservative correction (due to correlation-autocorrelation confounding effect; see <xref rid="appsec4" ref-type="sec">Appendix D</xref>). <xref rid="tbl3" ref-type="table">Table 3</xref> summaries changes due to the confounding effect; Visual network, DMN and SVAN are among the nodes which are most impacted.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Percent of nodes that their weighted graph measures have significantly affected, for xDF vs. Naive and xDF vs. BH (see <xref rid="fig7" ref-type="fig">Fig. 7</xref>). This quantifies the dramatic impact of correction method on each graph metric across all parcellation schemes and correction methods. For similar results for other parcellation schemes, see <xref rid="appsec1" ref-type="sec">Tables S2–S5</xref>.</p></caption><alt-text id="alttext0065">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Comparison</th><th>Thresholding</th><th>Weighted Degree</th><th>Weighted Betweenness</th><th>Local Efficiency</th></tr></thead><tbody><tr><td align="left">Naive <inline-formula><mml:math id="M142" altimg="si103.svg"><mml:mrow><mml:mo>&gt;</mml:mo></mml:mrow></mml:math></inline-formula> xDF</td><td align="left">PT (CE)</td><td align="left">95.61%</td><td align="left">63.16%</td><td align="left">98.24%</td></tr><tr><td/><td align="left">ST (FDR)</td><td align="left">95.61%</td><td align="left">61.40%</td><td align="left">99.12%</td></tr><tr><td align="left">BH <inline-formula><mml:math id="M143" altimg="si103.svg"><mml:mrow><mml:mo>&gt;</mml:mo></mml:mrow></mml:math></inline-formula> xDF</td><td align="left">PT (CE)</td><td align="left">85.08%</td><td align="left">1%</td><td align="left">95.62%</td></tr><tr><td/><td align="left">ST (FDR)</td><td align="left">92.98%</td><td align="left">1.75%</td><td align="left">95.61%</td></tr></tbody></table></table-wrap></p>
        <p id="p0375">We also evaluate changes in the global measures. <xref rid="fig7" ref-type="fig">Fig. 7</xref>.C shows the changes in network density (left) where the density of networks with Naively corrected network were significantly reduced after xDF and BH correction however there is a slight, yet significant, difference between density of xDF-corrected and BH-corrected networks. Similarly, the global efficiency of networks (<xref rid="fig7" ref-type="fig">Fig. 7</xref>.C) are significantly reduced after accounting for autocorrelation. <xref rid="fig7" ref-type="fig">Fig. 7</xref>.C also suggests that overestimation of variance due to correlation-autocorrelation confounding may yet reduce the local efficiency.</p>
        <p id="p0380">In the global measures a similar pattern of changes is also found for CE-based proportional thresholded networks, as the density (<xref rid="fig7" ref-type="fig">Fig. 7</xref>.D) of xDF-corrected networks are significantly reduced. However, in spite of changes in weighted degree, the confounding effect may not affect the network densities. Finally, global efficiency of xDF-corrected networks suggests a significant reduction. Despite a small difference, the confounding effect has also reduced the global efficiency.</p>
        <p id="p0385">We repeat this analysis for the Gordon and the Power atlas. For the Power atlas, <xref rid="appsec1" ref-type="sec">Fig. S13</xref> suggests that the autocorrelation leaves a very similar pattern of changes for both PT and ST. The highest changes take place in nodes with highest degree and efficiency measures; nodes comprising Visual, Fronto-parietal and Default Mode Network (DMN). For Gordon atlas (<xref rid="appsec1" ref-type="sec">Fig. S12</xref>), we found very similar results where the changes suggest that nodes from DMN, Fronto-parietal and Sensory-Motor (i.e. SMHand) networks experienced the highest changes in their weighted degree and local efficiency. Interestingly, similar to the Yeo atlas, Betweenness centrality has shown the highest resilience towards these changes. Finally, <xref rid="appsec1" ref-type="sec">Fig. S14</xref> shows similar results for subjects parcellated using ICA200.</p>
        <p id="p0390">In <xref rid="fig8" ref-type="fig">Fig. 8</xref> we show the results of the comparison among Naive, xDF and BH repeated for <italic>binary</italic> graph measures derived from Yeo atlas. In absence of edge weights, any differences found are solely attributable to topological changes. The results suggest that the changes are still prominent between Naive and xDF for both proportionally and statistically thresholded rsFC maps, while there are no differences detected in graph metrics of binary networks corrected with xDF vs. BH. In <xref rid="tbl4" ref-type="table">Table 4</xref> we summarise changes after correcting for autocorrelation with xDF and BH. These changes were tested across nodes between the two methods and corrected via FDR. For similar analysis with different parcellation schemes, see <xref rid="appsec1" ref-type="sec">Figs. S15 and S16</xref>.<fig id="fig8"><label>Fig. 8</label><caption><p>Overall changes in global and local graph theoretical measures with the 100 unrelated HCP package parcellated by Yeo atlas. <bold>Panel A,</bold> Bland Altman plots of xDF vs. Naive for binary degree (top), betweenness (middle) and local efficiency (bottom) computed with a cost-efficient threshold. There is one point for each of 114 nodes, the particular measure averaged over subjects, and the nodes are colour coded according to their resting-state network assignment. <bold>Panel B</bold> Shows the same graph measures, but with statistical thresholding (corrected via FDR correction). <bold>Panel C</bold> shows the differences in weighted CE density (left) and Global efficiency (right), and <bold>Panel D</bold> illustrates the same results statistical FDR thresholding. There is a dramatic impact of correction method on all graph metrics considered. Similar results for Gordon (<xref rid="appsec1" ref-type="sec">Fig. S15</xref>), Power (<xref rid="appsec1" ref-type="sec">Fig. S16</xref>) and ICA200 (<xref rid="appsec1" ref-type="sec">Fig. S17</xref>) is available in Supplementary Materials.</p></caption><alt-text id="alttext0050">Fig. 8</alt-text><graphic xlink:href="gr8"/></fig><table-wrap position="float" id="tbl4"><label>Table 4</label><caption><p>Percent of nodes that their binary graph measures have significantly affected, for xDF vs. Naive and xDF vs. BH (see <xref rid="fig8" ref-type="fig">Fig. 8</xref>) in Yeo atlas. In xDF vs. Naive all graph measures were found to be significantly affected while in xDF vs. BH none of the measures suggest a change. For similar results for other parcellation schemes, see <xref rid="appsec1" ref-type="sec">Tables S6–S9</xref>.</p></caption><alt-text id="alttext0070">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Comparison</th><th>Thresholding</th><th>Binary Degree</th><th>Binary Betweenness</th><th>Local Efficiency</th></tr></thead><tbody><tr><td align="left">Naive <inline-formula><mml:math id="M144" altimg="si103.svg"><mml:mrow><mml:mo>&gt;</mml:mo></mml:mrow></mml:math></inline-formula> xDF</td><td align="left">PT (CE)</td><td align="left">95.61%</td><td align="left">63.16%</td><td align="left">98.24%</td></tr><tr><td/><td align="left">ST (FDR)</td><td align="left">95.61%</td><td align="left">48.24%</td><td align="left">28.07%</td></tr><tr><td align="left">BH <inline-formula><mml:math id="M145" altimg="si103.svg"><mml:mrow><mml:mo>&gt;</mml:mo></mml:mrow></mml:math></inline-formula> xDF</td><td align="left">PT (CE)</td><td align="left">85.087%</td><td align="left">0.877%</td><td align="left">95.61%</td></tr><tr><td/><td align="left">ST (FDR)</td><td align="left">0%</td><td align="left">0%</td><td align="left">0%</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
    <sec id="sec4">
      <label>4</label>
      <title>Discussion</title>
      <p id="p0395">We have developed an improved estimator of the variance of the Pearson's correlation coefficient, xDF, that accounts for the impact of autocorrelation in each variable pair as well as the instantaneous and lagged cross-correlation. On the basis of extensive simulations under the null setting (<inline-formula><mml:math id="M146" altimg="si33.svg"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) using simulated data and real data with inter-subject scrambling, the xDF, BH and Q47 methods have good control of false positives, with xDF showing only slight FPR inflation on real null data (5.7%) and, on simulated data, only inflated with strong autocorrelation for short time series. Naive (no correction) has severe inflation of FPR as do other methods based on simplistic AR(1) autocorrelation models (G-Q47, AR1MCPS) or common ACF for each pair of variables have poor FPR control. Simulations with realistic autocorrelation and non-null cross-correlation find that Naive severely under-estimates variance while BH and Q47 over-estimates variance, likely due to a confounding of auto- and cross-correlation in those corrections; xDF, in contrast, has negligible bias for long time series and for short time series has low bias for all but the strongest forms for autocorrelation.</p>
      <p id="p0400">On real data (non-null) rsFC we replicate the simulation findings, with Naive <italic>Z</italic>-scores dramatically inflated relative to xDF, BH and Q47 <italic>Z</italic>-scores smaller in magnitude. The differences between the methods, however, are node specific, reflecting how xDF adjusts for autocorrelation in each node pair. We recommend that all rsFC analyses that are based on <italic>Z</italic>-scores, whether thresholded arbitrarily or or, say, use a mixture modelling approach (<xref rid="bib7" ref-type="bibr">Bielczyk et al., 2018</xref>), use the xDF correction to obtain the most accurate inferences possible.</p>
      <p id="p0405">We show that graph analysis measures are dramatically impacted by use of xDF, relative to either Naive or BH corrections. Broadly speaking, accounting for autocorrelation results in lower <italic>Z</italic>-scores and lower rsFC densities. These heterogeneous changes alter the topological features of the functional connectome, however the changes are not similar across resting-state networks; in the HCP data, we find nodal strengths and local efficiencies in parts of the subcortical regions experience lower changes compared to nodes from the frontoparietal and default mode networks, which are among the highly affected areas. The pattern of changes suggest that the nodal degree and efficiency hubs are among the most affected. In contrast, results for betweenness centrality suggest no systematic pattern with relatively lower changes.</p>
      <p id="p0410">We provide a comprehensive review of the literature on autocorrelation corrections for the variance of the sample correlation, usually cast as estimation of the effective degrees of freedom. In the neuroimaging community this is sometimes referenced as “Bartlett Correction Factor (BCF)”, though it has been only informally defined and used as a global correction over subjects and ROIs (<xref rid="bib27" ref-type="bibr">Hale et al., 2016</xref>). We emphasize the importance of truncation or tapering of ACF's and computing a correction for each node pair.</p>
      <p id="p0415">We note the strong influence of ROI size on the strength of autocorrelation, with, at one extreme, voxel-level data having the weakest correlation, increasing in strength as the size of the ROI increases; an effect that is often ignored in rsFC studies (<xref rid="bib30" ref-type="bibr">Lee and Xue, 2017</xref>) or indirectly by regressing out the volume of the ROIs (<xref rid="bib53" ref-type="bibr">Sethi et al., 2017</xref>). We also showed that, even for an ROI atlas with identically sized regions (i.e. Power atlas), autocorrelation can vary substantially over the brain depending on their location. These factors, along with inter-subject heterogeneity of the autocorrelation effect (<xref rid="fig2" ref-type="fig">Fig. 2</xref>.E), could become a significant source of bias in any rsFC analysis using <italic>Z</italic>-scores if not otherwise corrected. And we note that our findings hold for both volumetric and surface-based analysis (<xref rid="fig2" ref-type="fig">Fig. 2</xref>.C).</p>
      <p id="p0420">We stress that our work does not invalidate use of correlation entirely, as our derivation shows that Pearson's correlation is approximately unbiased for the correlation <italic>ρ</italic> in the data (<xref rid="appsec2" ref-type="sec">Appendix B</xref>). For between-subject analyses, the varying intra-subject standard deviation of Pearson's correlations is analogous to fMRI, where some methods ignore first-level standard errors, which has been shown to be valid for simple models (<xref rid="bib37" ref-type="bibr">Mumford and Nichols, 2009</xref>) (e.g. in SPM and AFNI's 3dDeconvolve), while other methods account for these standard errors (FSL's FLAME and AFNI's 3dMEMA). For group level inference on correlations, we are only aware of the work of <xref rid="bib20" ref-type="bibr">Fiecas et al. (2017)</xref> that provides an analogous 2-level model that accounts for intra-subject standard errors. One way forward is a hybrid approach, where any thresholding is done on xDF <italic>Z</italic>-scores, and then subsequent analyses are done on surviving <inline-formula><mml:math id="M147" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> values (see, e.g. <xref rid="bib5" ref-type="bibr">Bassett et al. (2011)</xref>, that uses such an approach but with Naive Z).</p>
      <p id="p0425">In short, any rsFC analysis based on <italic>Z</italic>-scores must ensure that the calculation of those <italic>Z</italic>-scores account for the impact of temporal autocorrelation in a subject- and edge-specific manner, as with our xDF method.</p>
      <p id="p0430">As an aside, we note that our statement on the unbiasedness of correlation is at odds with other recent work (<xref rid="bib2" ref-type="bibr">Arbabshirani et al., 2014</xref>; <xref rid="bib18" ref-type="bibr">Davey et al., 2013</xref>). This is not inconsistent: Both of these works start their analysis with a pair of white noise variables with instantaneous correlation <italic>ρ</italic> and then assess the impact of inducing autocorrelation on those variables. In particular, they note that if different autocorrelation structures are induced then a bias in estimate of <italic>ρ</italic> can arise. Instead, we study the auto- and cross-correlation of the presented data <inline-formula><mml:math id="M148" altimg="si104.svg"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, without reference to an (unobserved) autocorrelation-free signal; in this setting Pearson's correlation is (approximately) unbiased regardless of differential autocorrelation. We believe our empirical approach is more appropriate, as the BOLD signal is not white and hence inference on the correlation of presented (and not latent white) signals is of primary interest.</p>
      <p id="p0435">We note that other authors have proposed pre-whitening as a solution to improve inference on correlation (<xref rid="bib11" ref-type="bibr">Bright et al., 2017</xref>), and that pre-whitening is recommended when conducting system identification of the cross-correlation function <inline-formula><mml:math id="M149" altimg="si19.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<xref rid="bib47" ref-type="bibr">Priestley, 1983</xref>). However, we still see the value of the no-whitening plus xDF correction approach. First, pre-whitening requires accurate estimation of <inline-formula><mml:math id="M150" altimg="si64.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M151" altimg="si65.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, and careful evaluation is required to see if the FPR is controlled and the standard error unbiased over a range of settings. Second, pre-whitening changes the definition of <italic>ρ</italic>, from concerning the instantaneous correlation of the observed time series to that of the (unobserved, latent) white time series. And, perhaps most important for sliding window time-varying rsFC, pre-whitening mixes data from distant time points with neighbouring ones, challenging the interpretation of the individual time points as pertaining to a precise moment in time.</p>
      <p id="p0440">Pre-whitening is also used with voxelwise linear modelling using a seed region predictor. This is again different, in that the same whitening – based on voxelwise residuals – is applied to both response and predictor, perhaps improving the interpretability of this approach over the case of separate whitening for each <italic>X</italic> and <italic>Y</italic>. It is difficult to predict how this approach will differ from correlation inference with xDF, as xDF considers autocorrelation of both time series as well as cross-correlation, while this approach only considers voxelwise residual autocorrelation.</p>
      <p id="p0445">One immediate extension to the current work is to adapt the xDF estimator to partial correlations. Partial correlations have recently drawn substantial attention after they were shown to be effective in resting-state analysis (<xref rid="bib36" ref-type="bibr">Marrelec et al., 2006</xref>; <xref rid="bib55" ref-type="bibr">Smith et al., 2011</xref>). Further, recent studies have shown that accounting for autocorrelation is remarkably sensitive to sampling rates of the fMRI BOLD time series (<xref rid="bib9" ref-type="bibr">Bollmann et al., 2018</xref>), therefore evaluating the proposed methods on different sampling rates would be useful. We have not attempted to investigate how the changes in <italic>Z</italic>-scores we describe would affect the inter-group changes, but this would be a useful extension, as <xref rid="bib60" ref-type="bibr">Váša et al. (2018)</xref> did for Schizophrenia in context of wavelet EDF. Finally, it is important to note that application of the xDF is not confined to rsFC of fMRI time series as it can be used in other modalities such as EEG and MEG as both modalities were shown to suffer from dependencies amongst their data-points.</p>
    </sec>
    <sec id="sec5">
      <label>5</label>
      <title>Software availability and reproducibility</title>
      <p id="p0450">Analysis presented in this paper have been done in MATLAB 2015b and R 3.1.0. Graph theoretical analysis were done using Brain Connectivity Toolbox (accessed: 15/1/2017) (<xref rid="bib52" ref-type="bibr">Rubinov and Sporns, 2010</xref>).</p>
      <p id="p0455">Variance of Pearson's correlation, <italic>Z</italic>-scores and p-values of such correlation matrices can be estimated via xDF.m available in <ext-link ext-link-type="uri" xlink:href="https://github.com/asoroosh/xDF" id="intref0015">https://github.com/asoroosh/xDF</ext-link>. The script is a standalone function and is executable using Statistics and Machine Learning Toolbox in MATLAB 2016 or later. The repository also contains six other variance estimators discussed in this work.</p>
      <p id="p0460">The autocorrelation (AC_fft.m) and cross-correlation (xC_fft.m) functions are estimated using Wiener-Khinchin theorem which involves discrete Fourier transformation of time series. We also used an algorithm proposed by <xref rid="bib28" ref-type="bibr">Higham (1988)</xref> to find the nearest positive semi-definite covariance matrices for simulations described in Section S3.</p>
      <p id="p0465">Scripts and instructions to reproduce all the figures and results, are also available via <ext-link ext-link-type="uri" xlink:href="http://www.github.com/asoroosh/xDF_Paper18" id="intref0020">http://www.github.com/asoroosh/xDF_Paper18</ext-link>. For details regarding the reproduciblity of the figures see section S6 of the supplementary materials.</p>
    </sec>
  </body>
  <back>
    <ref-list id="cebib0010">
      <title>References</title>
      <ref id="bib1">
        <element-citation publication-type="book" id="sref1">
          <person-group person-group-type="author">
            <name>
              <surname>Anderson</surname>
              <given-names>O.D.</given-names>
            </name>
          </person-group>
          <series>Time Series Analysis, Theory and Practice</series>
          <volume>vol. 7</volume>
          <year>1983</year>
          <publisher-name>North-Holland</publisher-name>
        </element-citation>
      </ref>
      <ref id="bib2">
        <element-citation publication-type="book" id="sref2">
          <person-group person-group-type="author">
            <name>
              <surname>Arbabshirani</surname>
              <given-names>M.R.</given-names>
            </name>
            <name>
              <surname>Damaraju</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Phlypo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Plis</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Allen</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Ma</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Mathalon</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Preda</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Vaidya</surname>
              <given-names>J.G.</given-names>
            </name>
            <name>
              <surname>Adali</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>V.D.</given-names>
            </name>
          </person-group>
          <chapter-title>Impact of Autocorrelation on Functional Connectivity</chapter-title>
          <year>2014</year>
          <publisher-name>NeuroImage</publisher-name>
          <comment>ISSN 1053-8119</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.07.045</pub-id>
        </element-citation>
      </ref>
      <ref id="bib3">
        <element-citation publication-type="journal" id="sref3">
          <person-group person-group-type="author">
            <name>
              <surname>Bartlett</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <article-title>Some aspects of the time-correlation problem in regard to tests of significance</article-title>
          <source>J. R. Stat. Soc.</source>
          <volume>98</volume>
          <issue>3</issue>
          <year>1935</year>
          <fpage>536</fpage>
          <comment>ISSN 09528385</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2342284?origin=crossref" id="intref0035">http://www.jstor.org/stable/2342284?origin=crossref</ext-link>
        </element-citation>
      </ref>
      <ref id="bib4">
        <element-citation publication-type="journal" id="sref4">
          <person-group person-group-type="author">
            <name>
              <surname>Bartlett</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <article-title>On the theoretical specification and sampling properties of autocorrelated time-series</article-title>
          <source>Suppl. J. R. Stat. Soc.</source>
          <volume>8</volume>
          <issue>1</issue>
          <year>1946</year>
          <fpage>27</fpage>
          <comment>ISSN 14666162</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2983611?origin=crossref" id="intref0040">http://www.jstor.org/stable/2983611?origin=crossref</ext-link>
        </element-citation>
      </ref>
      <ref id="bib5">
        <element-citation publication-type="journal" id="sref5">
          <person-group person-group-type="author">
            <name>
              <surname>Bassett</surname>
              <given-names>D.S.</given-names>
            </name>
            <name>
              <surname>Wymbs</surname>
              <given-names>N.F.</given-names>
            </name>
            <name>
              <surname>Porter</surname>
              <given-names>M. a.</given-names>
            </name>
            <name>
              <surname>Mucha</surname>
              <given-names>P.J.</given-names>
            </name>
            <name>
              <surname>Carlson</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Grafton</surname>
              <given-names>S.T.</given-names>
            </name>
          </person-group>
          <article-title>Dynamic reconfiguration of human brain networks during learning</article-title>
          <source>Proc. Natl. Acad. Sci. U.S.A.</source>
          <volume>108</volume>
          <issue>18</issue>
          <year>May 2011</year>
          <fpage>7641</fpage>
          <lpage>7646</lpage>
          <comment>ISSN 1091-6490</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3088578&amp;tool=pmcentrez&amp;rendertype=abstract" id="intref0045">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3088578&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>
          <pub-id pub-id-type="pmid">21502525</pub-id>
        </element-citation>
      </ref>
      <ref id="bib6">
        <element-citation publication-type="journal" id="sref6">
          <person-group person-group-type="author">
            <name>
              <surname>Bayley</surname>
              <given-names>G.V.</given-names>
            </name>
            <name>
              <surname>Hammersley</surname>
              <given-names>J.M.</given-names>
            </name>
          </person-group>
          <article-title>The “effective” number of independent observations in an autocorrelated time series</article-title>
          <source>Suppl. J. R. Stat. Soc.</source>
          <volume>8</volume>
          <issue>2</issue>
          <year>1946</year>
          <fpage>184</fpage>
          <comment>ISSN 14666162</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2983560?origin=crossref" id="intref0050">http://www.jstor.org/stable/2983560?origin=crossref</ext-link>
        </element-citation>
      </ref>
      <ref id="bib7">
        <element-citation publication-type="journal" id="sref7">
          <person-group person-group-type="author">
            <name>
              <surname>Bielczyk</surname>
              <given-names>N.Z.</given-names>
            </name>
            <name>
              <surname>Walocha</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Ebel</surname>
              <given-names>P.W.</given-names>
            </name>
            <name>
              <surname>Haak</surname>
              <given-names>K.V.</given-names>
            </name>
            <name>
              <surname>Llera</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Buitelaar</surname>
              <given-names>J.K.</given-names>
            </name>
            <name>
              <surname>Glennon</surname>
              <given-names>J.C.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
          </person-group>
          <article-title>Thresholding functional connectomes by means of mixture modeling</article-title>
          <source>Neuroimage</source>
          <year>2018</year>
          <comment>ISSN 10538119</comment>
          <ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S105381191830003X" id="intref0055">http://linkinghub.elsevier.com/retrieve/pii/S105381191830003X</ext-link>
        </element-citation>
      </ref>
      <ref id="bib8">
        <element-citation publication-type="journal" id="sref8">
          <person-group person-group-type="author">
            <name>
              <surname>Biswal</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Yetkin</surname>
              <given-names>F.Z.</given-names>
            </name>
            <name>
              <surname>Haughton</surname>
              <given-names>V.M.</given-names>
            </name>
            <name>
              <surname>Hyde</surname>
              <given-names>J.S.</given-names>
            </name>
          </person-group>
          <article-title>Functional connectivity in the motor cortex of resting</article-title>
          <source>MRM</source>
          <volume>34</volume>
          <issue>9</issue>
          <year>1995</year>
          <fpage>537</fpage>
          <lpage>541</lpage>
          <pub-id pub-id-type="pmid">8524021</pub-id>
        </element-citation>
      </ref>
      <ref id="bib9">
        <element-citation publication-type="journal" id="sref9">
          <person-group person-group-type="author">
            <name>
              <surname>Bollmann</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Puckett</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Cunnington</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Barth</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Serial correlations in single-subject fMRI with sub-second TR</article-title>
          <source>Neuroimage</source>
          <volume>166</volume>
          <issue>October 2017</issue>
          <year>2018</year>
          <fpage>152</fpage>
          <lpage>166</lpage>
          <comment>ISSN 10959572</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.043</pub-id>
          <pub-id pub-id-type="pmid">29066396</pub-id>
        </element-citation>
      </ref>
      <ref id="bib10">
        <element-citation publication-type="journal" id="sref10">
          <person-group person-group-type="author">
            <name>
              <surname>Bretherton</surname>
              <given-names>C.S.</given-names>
            </name>
            <name>
              <surname>Widmann</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Dymnikov</surname>
              <given-names>V.P.</given-names>
            </name>
            <name>
              <surname>Wallace</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Bladé</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>The effective number of spatial degrees of freedom of a time-varying field</article-title>
          <source>J. Clim.</source>
          <volume>12</volume>
          <issue>7</issue>
          <year>1999</year>
          <fpage>1990</fpage>
          <lpage>2009</lpage>
          <comment>ISSN 08948755</comment>
        </element-citation>
      </ref>
      <ref id="bib11">
        <element-citation publication-type="journal" id="sref11">
          <person-group person-group-type="author">
            <name>
              <surname>Bright</surname>
              <given-names>M.G.</given-names>
            </name>
            <name>
              <surname>Tench</surname>
              <given-names>C.R.</given-names>
            </name>
            <name>
              <surname>Murphy</surname>
              <given-names>K.</given-names>
            </name>
          </person-group>
          <article-title>Potential pitfalls when denoising resting state fMRI data using nuisance regression</article-title>
          <source>Neuroimage</source>
          <volume>154</volume>
          <issue>December 2016</issue>
          <year>2017</year>
          <fpage>159</fpage>
          <lpage>168</lpage>
          <comment>ISSN 10959572</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.12.027</pub-id>
          <pub-id pub-id-type="pmid">28025128</pub-id>
        </element-citation>
      </ref>
      <ref id="bib12">
        <element-citation publication-type="journal" id="sref12">
          <person-group person-group-type="author">
            <name>
              <surname>Brown</surname>
              <given-names>G.G.</given-names>
            </name>
            <name>
              <surname>Rutemiller</surname>
              <given-names>H.C.</given-names>
            </name>
          </person-group>
          <article-title>Means and variances of stochastic vector products with applications to random linear models</article-title>
          <source>Manag. Sci.</source>
          <volume>24</volume>
          <issue>2</issue>
          <year>1977</year>
          <fpage>210</fpage>
          <lpage>216</lpage>
          <comment>ISSN 0025-1909</comment>
        </element-citation>
      </ref>
      <ref id="bib13">
        <element-citation publication-type="journal" id="sref13">
          <person-group person-group-type="author">
            <name>
              <surname>Bullmore</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Brammer</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Williams</surname>
              <given-names>S.C.R.</given-names>
            </name>
            <name>
              <surname>Rabe-Hesketh</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Janot</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>David</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Mellers</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Howard</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sham</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Statistical methods of estimation and inference for functional MR image analysis</article-title>
          <source>Magn. Reson. Med.</source>
          <volume>35</volume>
          <issue>2</issue>
          <year>1996</year>
          <fpage>261</fpage>
          <lpage>277</lpage>
          <pub-id pub-id-type="pmid">8622592</pub-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <element-citation publication-type="journal" id="sref14">
          <person-group person-group-type="author">
            <name>
              <surname>Cao</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>J.-H.</given-names>
            </name>
            <name>
              <surname>Dai</surname>
              <given-names>Z.-J.</given-names>
            </name>
            <name>
              <surname>Cao</surname>
              <given-names>X.-Y.</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>L.-L.</given-names>
            </name>
            <name>
              <surname>Fan</surname>
              <given-names>F.-M.</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>X.-W.</given-names>
            </name>
            <name>
              <surname>Xia</surname>
              <given-names>M.-R.</given-names>
            </name>
            <name>
              <surname>Shu</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Dong</surname>
              <given-names>Q.</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>Castellanos</surname>
              <given-names>F.X.</given-names>
            </name>
            <name>
              <surname>Zuo</surname>
              <given-names>X.-N.</given-names>
            </name>
            <name>
              <surname>He</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Topological organization of the human brain functional connectome across the lifespan</article-title>
          <source>Developmental cognitive neuroscience</source>
          <volume>7</volume>
          <issue>16</issue>
          <year>Jan 2014</year>
          <fpage>76</fpage>
          <lpage>93</lpage>
          <comment>ISSN 1878-9307</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/24333927" id="intref0070">http://www.ncbi.nlm.nih.gov/pubmed/24333927</ext-link>
          <pub-id pub-id-type="pmid">24333927</pub-id>
        </element-citation>
      </ref>
      <ref id="bib15">
        <element-citation publication-type="book" id="sref15">
          <person-group person-group-type="author">
            <name>
              <surname>Chatfield</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <chapter-title>The Analysis of Time Series: an Introduction</chapter-title>
          <year>2016</year>
          <publisher-name>CRC press</publisher-name>
        </element-citation>
      </ref>
      <ref id="bib16">
        <element-citation publication-type="journal" id="sref16">
          <person-group person-group-type="author">
            <name>
              <surname>Christova</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Jerde</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Lynch</surname>
              <given-names>J.K.</given-names>
            </name>
            <name>
              <surname>Georgopoulos</surname>
              <given-names>A.P.</given-names>
            </name>
          </person-group>
          <article-title>True associations between resting fMRI time series based on innovations</article-title>
          <source>J. Neural Eng.</source>
          <volume>8</volume>
          <issue>4</issue>
          <year>2011</year>
          <comment>ISSN 17412560</comment>
        </element-citation>
      </ref>
      <ref id="bib17">
        <element-citation publication-type="journal" id="sref17">
          <person-group person-group-type="author">
            <name>
              <surname>Clifford</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Richardson</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Hemon</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Assessing the significance of the correlation between two spatial processes</article-title>
          <source>Biometrics</source>
          <volume>45</volume>
          <issue>1</issue>
          <year>march 1989</year>
          <fpage>123</fpage>
          <comment>ISSN 0006341X</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2532039?origin=crossref" id="intref0075">http://www.jstor.org/stable/2532039?origin=crossref</ext-link>
          <pub-id pub-id-type="pmid">2720048</pub-id>
        </element-citation>
      </ref>
      <ref id="bib18">
        <element-citation publication-type="journal" id="sref18">
          <person-group person-group-type="author">
            <name>
              <surname>Davey</surname>
              <given-names>C.E.</given-names>
            </name>
            <name>
              <surname>Grayden</surname>
              <given-names>D.B.</given-names>
            </name>
            <name>
              <surname>Egan</surname>
              <given-names>G.F.</given-names>
            </name>
            <name>
              <surname>Johnston</surname>
              <given-names>L. a.</given-names>
            </name>
          </person-group>
          <article-title>Filtering induces correlation in fMRI resting state data</article-title>
          <source>Neuroimage</source>
          <volume>64</volume>
          <issue>1</issue>
          <year>2013</year>
          <fpage>728</fpage>
          <lpage>740</lpage>
          <comment>ISSN 10538119</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.08.022</pub-id>
          <pub-id pub-id-type="pmid">22939874</pub-id>
        </element-citation>
      </ref>
      <ref id="bib19">
        <element-citation publication-type="journal" id="sref19">
          <person-group person-group-type="author">
            <name>
              <surname>Dutilleul</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Clifford</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Richardson</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Hemon</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Modifying the t test for assessing the correlation between two spatial processes</article-title>
          <source>Biometrics</source>
          <volume>49</volume>
          <issue>1</issue>
          <year>March 1993</year>
          <fpage>305</fpage>
          <comment>ISSN 0006341X</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2532625?origin=crossref" id="intref0085">http://www.jstor.org/stable/2532625?origin=crossref</ext-link>
        </element-citation>
      </ref>
      <ref id="bib20">
        <element-citation publication-type="journal" id="sref20">
          <person-group person-group-type="author">
            <name>
              <surname>Fiecas</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Cribben</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Bahktiari</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Cummine</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>A variance components model for statistical inference on functional connectivity networks</article-title>
          <source>Neuroimage</source>
          <volume>149</volume>
          <issue>June 2016</issue>
          <year>2017</year>
          <fpage>256</fpage>
          <lpage>266</lpage>
          <comment>ISSN 10959572</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.01.051</pub-id>
          <pub-id pub-id-type="pmid">28130192</pub-id>
        </element-citation>
      </ref>
      <ref id="bib21">
        <element-citation publication-type="journal" id="sref21">
          <person-group person-group-type="author">
            <name>
              <surname>Fisher</surname>
              <given-names>R.A.</given-names>
            </name>
          </person-group>
          <article-title>Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population</article-title>
          <source>Biometrika</source>
          <volume>10</volume>
          <issue>4</issue>
          <year>may 1915</year>
          <fpage>507</fpage>
          <comment>ISSN 00063444</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2331838?origin=crossref" id="intref0095">http://www.jstor.org/stable/2331838?origin=crossref</ext-link>
        </element-citation>
      </ref>
      <ref id="bib22">
        <element-citation publication-type="journal" id="sref22">
          <person-group person-group-type="author">
            <name>
              <surname>Fouladi</surname>
              <given-names>R.T.</given-names>
            </name>
            <name>
              <surname>Steiger</surname>
              <given-names>J.H.</given-names>
            </name>
          </person-group>
          <article-title>The Fisher transform of the pearson product moment correlation coefficient and its square: cumulants, moments, and applications</article-title>
          <source>Commun. Stat. Simulat. Comput.</source>
          <volume>37</volume>
          <issue>5</issue>
          <year>2008</year>
          <fpage>928</fpage>
          <lpage>944</lpage>
          <comment>ISSN 03610918</comment>
        </element-citation>
      </ref>
      <ref id="bib23">
        <element-citation publication-type="journal" id="sref23">
          <person-group person-group-type="author">
            <name>
              <surname>Fox</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Snyder</surname>
              <given-names>A.Z.</given-names>
            </name>
            <name>
              <surname>Vincent</surname>
              <given-names>J.L.</given-names>
            </name>
            <name>
              <surname>Corbetta</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>D.C.</given-names>
            </name>
            <name>
              <surname>Raichle</surname>
              <given-names>M.E.</given-names>
            </name>
          </person-group>
          <article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks</article-title>
          <source>Proc. Natl. Acad. Sci. U.S.A.</source>
          <volume>102</volume>
          <issue>27</issue>
          <year>July 2005</year>
          <fpage>9673</fpage>
          <lpage>9678</lpage>
          <comment>ISSN 0027-8424</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1157105&amp;tool=pmcentrez&amp;rendertype=abstract" id="intref0100">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1157105&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>
          <pub-id pub-id-type="pmid">15976020</pub-id>
        </element-citation>
      </ref>
      <ref id="bib24">
        <element-citation publication-type="journal" id="sref24">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Josephs</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Zarahn</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Rouquette</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>J.-B.</given-names>
            </name>
          </person-group>
          <article-title>To smooth or not to smooth?</article-title>
          <source>Neuroimage</source>
          <volume>12</volume>
          <issue>2</issue>
          <year>Augest 2000</year>
          <fpage>196</fpage>
          <lpage>208</lpage>
          <comment>ISSN 10538119</comment>
          <ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S1053811900906098" id="intref0105">http://linkinghub.elsevier.com/retrieve/pii/S1053811900906098</ext-link>
          <pub-id pub-id-type="pmid">10913325</pub-id>
        </element-citation>
      </ref>
      <ref id="bib25">
        <element-citation publication-type="journal" id="sref25">
          <person-group person-group-type="author">
            <name>
              <surname>Gonzalez-Castillo</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Handwerker</surname>
              <given-names>D.A.</given-names>
            </name>
            <name>
              <surname>Robinson</surname>
              <given-names>M.E.</given-names>
            </name>
            <name>
              <surname>Hoy</surname>
              <given-names>C.W.</given-names>
            </name>
            <name>
              <surname>Buchanan</surname>
              <given-names>L.C.</given-names>
            </name>
            <name>
              <surname>Saad</surname>
              <given-names>Z.S.</given-names>
            </name>
            <name>
              <surname>Bandettini</surname>
              <given-names>P.A.</given-names>
            </name>
          </person-group>
          <article-title>The spatial structure of resting state connectivity stability on the scale of minutes</article-title>
          <source>Front. Neurosci.</source>
          <volume>8</volume>
          <issue>8 JUN</issue>
          <year>2014</year>
          <fpage>1</fpage>
          <lpage>19</lpage>
          <comment>ISSN 1662453X</comment>
          <pub-id pub-id-type="pmid">24478622</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <element-citation publication-type="journal" id="sref26">
          <person-group person-group-type="author">
            <name>
              <surname>Haining</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Bivariate correlation with spatial data</article-title>
          <source>Geogr. Anal.</source>
          <volume>23</volume>
          <issue>3</issue>
          <year>1991</year>
          <fpage>210</fpage>
          <lpage>227</lpage>
          <comment>ISSN 15384632</comment>
        </element-citation>
      </ref>
      <ref id="bib27">
        <element-citation publication-type="journal" id="sref27">
          <person-group person-group-type="author">
            <name>
              <surname>Hale</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>White</surname>
              <given-names>T.P.</given-names>
            </name>
            <name>
              <surname>Mayhew</surname>
              <given-names>S.D.</given-names>
            </name>
            <name>
              <surname>Wilson</surname>
              <given-names>R.S.</given-names>
            </name>
            <name>
              <surname>Rollings</surname>
              <given-names>D.T.</given-names>
            </name>
            <name>
              <surname>Khalsa</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Arvanitis</surname>
              <given-names>T.N.</given-names>
            </name>
            <name>
              <surname>Bagshaw</surname>
              <given-names>A.P.</given-names>
            </name>
          </person-group>
          <article-title>Altered thalamocortical and intra-thalamic functional connectivity during light sleep compared with wake</article-title>
          <source>Neuroimage</source>
          <volume>125</volume>
          <year>Jan 2016</year>
          <fpage>657</fpage>
          <lpage>667</lpage>
          <comment>ISSN 10538119</comment>
          <ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S1053811915009520" id="intref0110">http://linkinghub.elsevier.com/retrieve/pii/S1053811915009520</ext-link>
          <pub-id pub-id-type="pmid">26499809</pub-id>
        </element-citation>
      </ref>
      <ref id="bib28">
        <element-citation publication-type="journal" id="sref28">
          <person-group person-group-type="author">
            <name>
              <surname>Higham</surname>
              <given-names>N.J.</given-names>
            </name>
          </person-group>
          <article-title>Computing a nearest symmetric positive semidefinite matrix</article-title>
          <source>Linear Algebra Appl.</source>
          <volume>103</volume>
          <issue>C</issue>
          <year>1988</year>
          <fpage>103</fpage>
          <lpage>118</lpage>
          <comment>ISSN 00243795</comment>
        </element-citation>
      </ref>
      <ref id="bib29">
        <element-citation publication-type="book" id="sref29">
          <person-group person-group-type="author">
            <name>
              <surname>Hunter</surname>
              <given-names>D.R.</given-names>
            </name>
          </person-group>
          <chapter-title>Notes for a Graduate-Level Course in Asymptotics for Statisticians</chapter-title>
          <year>2014</year>
          <publisher-name>Penn State University</publisher-name>
          <publisher-loc>Pennsylvania</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib30">
        <element-citation publication-type="journal" id="sref30">
          <person-group person-group-type="author">
            <name>
              <surname>Lee</surname>
              <given-names>T.W.</given-names>
            </name>
            <name>
              <surname>Xue</surname>
              <given-names>S.W.</given-names>
            </name>
          </person-group>
          <article-title>Linking graph features of anatomical architecture to regional brain activity: a multi-modal MRI study</article-title>
          <source>Neurosci. Lett.</source>
          <volume>651</volume>
          <issue>19</issue>
          <year>2017</year>
          <fpage>123</fpage>
          <lpage>127</lpage>
          <comment>ISSN 18727972</comment>
          <pub-id pub-id-type="doi">10.1016/j.neulet.2017.05.005</pub-id>
          <pub-id pub-id-type="pmid">28479103</pub-id>
        </element-citation>
      </ref>
      <ref id="bib31">
        <element-citation publication-type="book" id="sref31">
          <person-group person-group-type="author">
            <name>
              <surname>Lehmann</surname>
              <given-names>E.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Elements of Large-Sample Theory</chapter-title>
          <year>1999</year>
          <comment>ISBN 0387985956</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.loc.gov/catdir/enhancements/fy0817/98034429-d.html%255Cnhttp://www.loc.gov/catdir/enhancements/fy0817/98034429-t.html" id="intref0120">http://www.loc.gov/catdir/enhancements/fy0817/98034429-d.html%5Cnhttp://www.loc.gov/catdir/enhancements/fy0817/98034429-t.html</ext-link>
        </element-citation>
      </ref>
      <ref id="bib32">
        <element-citation publication-type="book" id="sref32">
          <person-group person-group-type="author">
            <name>
              <surname>Lehmann</surname>
              <given-names>E.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Elements of Large-Sample Theory</chapter-title>
          <year>1999</year>
          <comment>ISBN 0387985956</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.loc.gov/catdir/enhancements/fy0817/98034429-d.html%255Cnhttp://www.loc.gov/catdir/enhancements/fy0817/98034429-t.html" id="intref0125">http://www.loc.gov/catdir/enhancements/fy0817/98034429-d.html%5Cnhttp://www.loc.gov/catdir/enhancements/fy0817/98034429-t.html</ext-link>
        </element-citation>
      </ref>
      <ref id="bib33">
        <element-citation publication-type="book" id="sref33">
          <person-group person-group-type="author">
            <name>
              <surname>Leonardi</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Van De Ville</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <chapter-title>Wavelet frames on graphs defined by fmri functional connectivity</chapter-title>
          <source>Biomedical Imaging: from Nano to Macro, 2011 IEEE International Symposium on</source>
          <year>2011</year>
          <publisher-name>IEEE</publisher-name>
          <fpage>2136</fpage>
          <lpage>2139</lpage>
        </element-citation>
      </ref>
      <ref id="bib34">
        <element-citation publication-type="journal" id="sref34">
          <person-group person-group-type="author">
            <name>
              <surname>Lewis</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Christova</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Jerde</surname>
              <given-names>T.A.</given-names>
            </name>
            <name>
              <surname>Georgopoulos</surname>
              <given-names>A.P.</given-names>
            </name>
          </person-group>
          <article-title>A compact and realistic cerebral cortical layout derived from prewhitened resting-state fMRI time series: cherniak's adjacency rule, size law, and metamodule grouping upheld</article-title>
          <source>Front. Neuroanat.</source>
          <volume>6</volume>
          <year>2012</year>
          <fpage>1</fpage>
          <lpage>11</lpage>
          <comment>(September) ISSN 1662-5129</comment>
          <ext-link ext-link-type="uri" xlink:href="http://journal.frontiersin.org/article/10.3389/fnana.2012.00036/abstract" id="intref0130">http://journal.frontiersin.org/article/10.3389/fnana.2012.00036/abstract</ext-link>
          <pub-id pub-id-type="pmid">22291620</pub-id>
        </element-citation>
      </ref>
      <ref id="bib35">
        <element-citation publication-type="journal" id="sref35">
          <person-group person-group-type="author">
            <name>
              <surname>Lund</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Madsen</surname>
              <given-names>K.H.</given-names>
            </name>
            <name>
              <surname>Sidaros</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Luo</surname>
              <given-names>W.-l.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
          </person-group>
          <article-title>Non-white noise in fMRI: does modelling have an impact?</article-title>
          <volume>29</volume>
          <year>2006</year>
          <fpage>54</fpage>
          <lpage>66</lpage>
        </element-citation>
      </ref>
      <ref id="bib36">
        <element-citation publication-type="journal" id="sref36">
          <person-group person-group-type="author">
            <name>
              <surname>Marrelec</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Krainik</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Duffau</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Pélégrini-Issac</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Lehéricy</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Doyon</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Benali</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Partial correlation for functional brain interactivity investigation in functional MRI</article-title>
          <source>Neuroimage</source>
          <volume>32</volume>
          <issue>1</issue>
          <year>2006</year>
          <fpage>228</fpage>
          <lpage>237</lpage>
          <comment>ISSN 1053-8119</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/16777436" id="intref0135">http://www.ncbi.nlm.nih.gov/pubmed/16777436</ext-link>
          <pub-id pub-id-type="pmid">16777436</pub-id>
        </element-citation>
      </ref>
      <ref id="bib37">
        <element-citation publication-type="journal" id="sref37">
          <person-group person-group-type="author">
            <name>
              <surname>Mumford</surname>
              <given-names>J.A.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
          </person-group>
          <article-title>Simple group fMRI modeling and inference</article-title>
          <source>Neuroimage</source>
          <volume>47</volume>
          <issue>4</issue>
          <year>Oct 2009</year>
          <fpage>1469</fpage>
          <lpage>1475</lpage>
          <comment>ISSN 1095-9572</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/19463958" id="intref0140">http://www.ncbi.nlm.nih.gov/pubmed/19463958</ext-link>
          <pub-id pub-id-type="pmid">19463958</pub-id>
        </element-citation>
      </ref>
      <ref id="bib38">
        <element-citation publication-type="journal" id="sref38">
          <person-group person-group-type="author">
            <name>
              <surname>Nevado</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Hadjipapas</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Kinsey</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Moratti</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Barnes</surname>
              <given-names>G.R.</given-names>
            </name>
            <name>
              <surname>Holliday</surname>
              <given-names>I.E.</given-names>
            </name>
            <name>
              <surname>Green</surname>
              <given-names>G.G.</given-names>
            </name>
          </person-group>
          <article-title>Estimation of functional connectivity from electromagnetic signals and the amount of empirical data required</article-title>
          <source>Neurosci. Lett.</source>
          <volume>513</volume>
          <issue>1</issue>
          <year>2012</year>
          <fpage>57</fpage>
          <lpage>61</lpage>
          <comment>ISSN 03043940</comment>
          <pub-id pub-id-type="doi">10.1016/j.neulet.2012.02.007</pub-id>
          <pub-id pub-id-type="pmid">22329975</pub-id>
        </element-citation>
      </ref>
      <ref id="bib39">
        <mixed-citation publication-type="other" id="sref39">V. Nicosia, J. Tang, C. Mascolo, and M. Musolesi. Graph Metrics for Temporal Networks. pages 1–26.</mixed-citation>
      </ref>
      <ref id="bib40">
        <element-citation publication-type="journal" id="sref40">
          <person-group person-group-type="author">
            <name>
              <surname>Nicosia</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Valencia</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Chavez</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Díaz-Guilera</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Latora</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Remote synchronization reveals network symmetries and functional modules</article-title>
          <source>Phys. Rev. Lett.</source>
          <volume>110</volume>
          <issue>17</issue>
          <year>2013</year>
          <fpage>1</fpage>
          <lpage>5</lpage>
          <comment>ISSN 00319007</comment>
        </element-citation>
      </ref>
      <ref id="bib41">
        <element-citation publication-type="journal" id="sref41">
          <person-group person-group-type="author">
            <name>
              <surname>Nomi</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Uddin</surname>
              <given-names>L.Q.</given-names>
            </name>
          </person-group>
          <article-title>Developmental changes in large-scale network connectivity in autism</article-title>
          <source>Neuroimage: Clinic</source>
          <volume>7</volume>
          <year>2015</year>
          <fpage>732</fpage>
          <lpage>741</lpage>
          <comment>ISSN 22131582</comment>
          <pub-id pub-id-type="doi">10.1016/j.nicl.2015.02.024</pub-id>
        </element-citation>
      </ref>
      <ref id="bib42">
        <element-citation publication-type="journal" id="sref42">
          <person-group person-group-type="author">
            <name>
              <surname>Orcutt</surname>
              <given-names>G.H.</given-names>
            </name>
            <name>
              <surname>James</surname>
              <given-names>S.F.</given-names>
            </name>
          </person-group>
          <article-title>Testing the significance of correlation between time series</article-title>
          <source>Biometrika</source>
          <volume>35</volume>
          <issue>3/4</issue>
          <year>Dec 1948</year>
          <fpage>397</fpage>
          <comment>ISSN 00063444</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2332358?origin=crossref" id="intref0155">http://www.jstor.org/stable/2332358?origin=crossref</ext-link>
        </element-citation>
      </ref>
      <ref id="bib43">
        <element-citation publication-type="journal" id="sref43">
          <person-group person-group-type="author">
            <name>
              <surname>Pannunzi</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Hindriks</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Bettinardi</surname>
              <given-names>R.G.</given-names>
            </name>
            <name>
              <surname>Wenger</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Lisofsky</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Martensson</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Butler</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Filevich</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Becker</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Lochstet</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Lindenberger</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Kühn</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Deco</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <article-title>Corrigendum to “Resting-state fMRI correlations: from link-wise unreliability to whole brain stability” [NeuroImage 157 (2017 Aug 15) 250-262](S1053811917304743)(10.1016/j.neuroimage.2017.06.006)</article-title>
          <source>Neuroimage</source>
          <volume>174</volume>
          <issue>December 2016</issue>
          <year>2018</year>
          <fpage>599</fpage>
          <lpage>604</lpage>
          <comment>ISSN 10959572</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.006</pub-id>
          <pub-id pub-id-type="pmid">29289426</pub-id>
        </element-citation>
      </ref>
      <ref id="bib44">
        <element-citation publication-type="book" id="sref44">
          <person-group person-group-type="author">
            <name>
              <surname>Patel</surname>
              <given-names>A.X.</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E.T.</given-names>
            </name>
          </person-group>
          <chapter-title>A Wavelet-Based Estimator of the Degrees of Freedom in Denoised fMRI Time Series for Probabilistic Testing of Functional Connectivity and Brain Graphs</chapter-title>
          <year>2015</year>
          <publisher-name>Neuroimage</publisher-name>
          <comment>ISSN 10538119</comment>
          <ext-link ext-link-type="uri" xlink:href="http://ac.els-cdn.com/S1053811915003523/1-s2.0-S1053811915003523-main.pdf?_tid=f12c2e52-f4b8-11e4-8f82-00000aacb360%26acdnat=1431003768_fe8bfeb76669cbcc0b9e8cd18265a3ac" id="intref0165">http://ac.els-cdn.com/S1053811915003523/1-s2.0-S1053811915003523-main.pdf?_tid=f12c2e52-f4b8-11e4-8f82-00000aacb360&amp;acdnat=1431003768_fe8bfeb76669cbcc0b9e8cd18265a3ac</ext-link>
        </element-citation>
      </ref>
      <ref id="bib45">
        <element-citation publication-type="book" id="sref45">
          <person-group person-group-type="author">
            <name>
              <surname>Percival</surname>
              <given-names>D.B.</given-names>
            </name>
            <name>
              <surname>Walden</surname>
              <given-names>A.T.</given-names>
            </name>
          </person-group>
          <series>Wavelet Methods for Time Series Analysis</series>
          <volume>vol. 4</volume>
          <year>2006</year>
          <publisher-name>Cambridge university press</publisher-name>
        </element-citation>
      </ref>
      <ref id="bib46">
        <element-citation publication-type="book" id="sref46">
          <person-group person-group-type="author">
            <name>
              <surname>Petersen</surname>
              <given-names>K.B.</given-names>
            </name>
            <name>
              <surname>Pedersen</surname>
              <given-names>M.S.</given-names>
            </name>
          </person-group>
          <series>The Matrix Cookbook</series>
          <volume>vol. 7</volume>
          <year>2008</year>
          <publisher-name>Technical University of Denmark</publisher-name>
          <fpage>510</fpage>
          <comment>15</comment>
        </element-citation>
      </ref>
      <ref id="bib47">
        <element-citation publication-type="book" id="sref47">
          <person-group person-group-type="author">
            <name>
              <surname>Priestley</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <chapter-title>Spectral Analysis and Time Series, Two-Volume Set: Volumes I and Ii (Probability and Mathematical Statistics)</chapter-title>
          <year>1983</year>
        </element-citation>
      </ref>
      <ref id="bib48">
        <element-citation publication-type="book" id="sref48">
          <person-group person-group-type="author">
            <name>
              <surname>Pyper</surname>
              <given-names>B.J.</given-names>
            </name>
            <name>
              <surname>Peterman</surname>
              <given-names>R.M.</given-names>
            </name>
          </person-group>
          <series>Comparison of Methods to Account for Autocorrelation in Correlation Analyses of Fish Data</series>
          <volume>vol. 2140</volume>
          <year>1998</year>
          <fpage>2127</fpage>
          <lpage>2140</lpage>
        </element-citation>
      </ref>
      <ref id="bib49">
        <element-citation publication-type="journal" id="sref49">
          <person-group person-group-type="author">
            <name>
              <surname>Quenouille</surname>
              <given-names>M.H.</given-names>
            </name>
          </person-group>
          <article-title>Notes on the calculation of autocorrelations of linear autoregressive schemes</article-title>
          <source>Biometrika</source>
          <volume>34</volume>
          <issue>3/4</issue>
          <year>Dec 1947</year>
          <fpage>365</fpage>
          <comment>ISSN 00063444</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2332450?origin=crossref" id="intref0170">http://www.jstor.org/stable/2332450?origin=crossref</ext-link>
          <pub-id pub-id-type="pmid">18918707</pub-id>
        </element-citation>
      </ref>
      <ref id="bib50">
        <element-citation publication-type="book" id="sref50">
          <person-group person-group-type="author">
            <name>
              <surname>Ripley</surname>
              <given-names>B.D.</given-names>
            </name>
          </person-group>
          <series>Stochastic Simulation</series>
          <volume>vol. 316</volume>
          <year>2009</year>
          <publisher-name>John Wiley &amp; Sons</publisher-name>
        </element-citation>
      </ref>
      <ref id="bib51">
        <element-citation publication-type="journal" id="sref51">
          <person-group person-group-type="author">
            <name>
              <surname>Roy</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Asymptotic covariance structure of serial correlations in multivariate time series</article-title>
          <source>Biometrika</source>
          <volume>76</volume>
          <issue>4</issue>
          <year>1989</year>
          <fpage>824</fpage>
          <lpage>827</lpage>
          <comment>ISSN 00063444</comment>
        </element-citation>
      </ref>
      <ref id="bib52">
        <element-citation publication-type="journal" id="sref52">
          <person-group person-group-type="author">
            <name>
              <surname>Rubinov</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sporns</surname>
              <given-names>O.</given-names>
            </name>
          </person-group>
          <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>
          <source>Neuroimage</source>
          <volume>52</volume>
          <issue>3</issue>
          <year>Sep 2010</year>
          <fpage>1059</fpage>
          <lpage>1069</lpage>
          <comment>ISSN 1095-9572</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/19819337" id="intref0175">http://www.ncbi.nlm.nih.gov/pubmed/19819337</ext-link>
          <pub-id pub-id-type="pmid">19819337</pub-id>
        </element-citation>
      </ref>
      <ref id="bib53">
        <element-citation publication-type="journal" id="sref53">
          <person-group person-group-type="author">
            <name>
              <surname>Sethi</surname>
              <given-names>S.S.</given-names>
            </name>
            <name>
              <surname>Zerbi</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Wenderoth</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Fornito</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Fulcher</surname>
              <given-names>B.D.</given-names>
            </name>
          </person-group>
          <article-title>Structural connectome topology relates to regional BOLD signal dynamics in the mouse brain</article-title>
          <source>Chaos</source>
          <volume>27</volume>
          <issue>4</issue>
          <year>2017</year>
          <comment>ISSN 10541500</comment>
        </element-citation>
      </ref>
      <ref id="bib54">
        <element-citation publication-type="book" id="sref54">
          <person-group person-group-type="author">
            <name>
              <surname>Simas</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Chavez</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Rodriguez</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Diaz-guilera</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>An Algebraic Topological Method for Multimodal Brain Networks Comparisons</chapter-title>
          <year>2015</year>
          <fpage>1</fpage>
          <lpage>19</lpage>
        </element-citation>
      </ref>
      <ref id="bib55">
        <element-citation publication-type="journal" id="sref55">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
            <name>
              <surname>Salimi-Khorshidi</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Webster</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>C.F.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Ramsey</surname>
              <given-names>J.D.</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
          </person-group>
          <article-title>Network modelling methods for FMRI</article-title>
          <source>Neuroimage</source>
          <volume>54</volume>
          <issue>2</issue>
          <year>1 2011</year>
          <fpage>875</fpage>
          <lpage>891</lpage>
          <comment>ISSN 1095-9572</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/20817103" id="intref0180">http://www.ncbi.nlm.nih.gov/pubmed/20817103</ext-link>
          <pub-id pub-id-type="pmid">20817103</pub-id>
        </element-citation>
      </ref>
      <ref id="bib56">
        <element-citation publication-type="journal" id="sref56">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
            <name>
              <surname>Nichols</surname>
              <given-names>T.E.</given-names>
            </name>
            <name>
              <surname>Vidaurre</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Winkler</surname>
              <given-names>A.M.</given-names>
            </name>
            <name>
              <surname>Behrens</surname>
              <given-names>T.E.J.</given-names>
            </name>
            <name>
              <surname>Glasser</surname>
              <given-names>M.F.</given-names>
            </name>
            <name>
              <surname>Ugurbil</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Barch</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Essen</surname>
              <given-names>D.C.V.</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>K.L.</given-names>
            </name>
          </person-group>
          <article-title>A positive-negative mode of population covariation links brain connectivity, demographics and behavior</article-title>
          <source>Nat. Neurosci.</source>
          <issue>1–7</issue>
          <year>2015</year>
          <comment>(September) ISSN 1097-6256</comment>
          <pub-id pub-id-type="doi">10.1038/nn.4125</pub-id>
        </element-citation>
      </ref>
      <ref id="bib57">
        <element-citation publication-type="journal" id="sref57">
          <person-group person-group-type="author">
            <name>
              <surname>Valencia</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Pastor</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Fernández-Seara</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Artieda</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Martinerie</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Chavez</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Complex modular structure of large-scale brain networks</article-title>
          <source>Chaos</source>
          <volume>19</volume>
          <issue>2</issue>
          <year>2009</year>
          <comment>ISSN 10541500</comment>
        </element-citation>
      </ref>
      <ref id="bib58">
        <element-citation publication-type="journal" id="sref58">
          <person-group person-group-type="author">
            <name>
              <surname>van den Heuvel</surname>
              <given-names>M.P.</given-names>
            </name>
            <name>
              <surname>de Lange</surname>
              <given-names>S.C.</given-names>
            </name>
            <name>
              <surname>Zalesky</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Seguin</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Yeo</surname>
              <given-names>B.T.</given-names>
            </name>
            <name>
              <surname>Schmidt</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Proportional thresholding in resting-state fMRI functional connectivity networks and consequences for patient-control connectome studies: issues and recommendations</article-title>
          <source>Neuroimage</source>
          <volume>152</volume>
          <issue>February</issue>
          <year>2017</year>
          <fpage>437</fpage>
          <lpage>449</lpage>
          <comment>ISSN 10959572</comment>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.005</pub-id>
          <pub-id pub-id-type="pmid">28167349</pub-id>
        </element-citation>
      </ref>
      <ref id="bib59">
        <element-citation publication-type="book" id="sref59">
          <person-group person-group-type="author">
            <name>
              <surname>Van Dijk</surname>
              <given-names>K.R.A.</given-names>
            </name>
            <name>
              <surname>Hedden</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Venkataraman</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Evans</surname>
              <given-names>K.C.</given-names>
            </name>
            <name>
              <surname>Lazar</surname>
              <given-names>S.W.</given-names>
            </name>
            <name>
              <surname>Buckner</surname>
              <given-names>R.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Intrinsic Functional Connectivity as a Tool for Human Connectomics: Theory, Properties, and Optimization</chapter-title>
          <year>2010</year>
          <fpage>297</fpage>
          <lpage>321</lpage>
          <comment>02138</comment>
        </element-citation>
      </ref>
      <ref id="bib60">
        <element-citation publication-type="journal" id="sref60">
          <person-group person-group-type="author">
            <name>
              <surname>Váša</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E.T.</given-names>
            </name>
            <name>
              <surname>Patel</surname>
              <given-names>A.X.</given-names>
            </name>
          </person-group>
          <article-title>Probabilistic thresholding of functional connectomes: application to schizophrenia</article-title>
          <source>Neuroimage</source>
          <volume>172</volume>
          <issue>December 2017</issue>
          <year>2018</year>
          <fpage>326</fpage>
          <lpage>340</lpage>
          <comment>ISSN 10959572</comment>
          <pub-id pub-id-type="pmid">29277403</pub-id>
        </element-citation>
      </ref>
      <ref id="bib61">
        <element-citation publication-type="book" id="sref61">
          <person-group person-group-type="author">
            <name>
              <surname>Watts</surname>
              <given-names>D.G.</given-names>
            </name>
            <name>
              <surname>Jenkins</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <chapter-title>Spectral Analysis and its Applications</chapter-title>
          <year>1968</year>
          <comment>San Francisco</comment>
        </element-citation>
      </ref>
      <ref id="bib62">
        <element-citation publication-type="journal" id="sref62">
          <person-group person-group-type="author">
            <name>
              <surname>Woolrich</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Ripley</surname>
              <given-names>B.D.</given-names>
            </name>
            <name>
              <surname>Brady</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S.M.</given-names>
            </name>
          </person-group>
          <article-title>Temporal autocorrelation in univariate linear modeling of FMRI data</article-title>
          <source>Neuroimage</source>
          <volume>14</volume>
          <issue>6</issue>
          <year>2001</year>
          <fpage>1370</fpage>
          <lpage>1386</lpage>
          <comment>ISSN 1053-8119</comment>
          <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/11707093" id="intref0195">http://www.ncbi.nlm.nih.gov/pubmed/11707093</ext-link>
          <pub-id pub-id-type="pmid">11707093</pub-id>
        </element-citation>
      </ref>
      <ref id="bib63">
        <element-citation publication-type="book" id="sref63">
          <person-group person-group-type="author">
            <name>
              <surname>Zhang</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Snyder</surname>
              <given-names>A.Z.</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>M.D.</given-names>
            </name>
            <name>
              <surname>Sansbury</surname>
              <given-names>M.W.</given-names>
            </name>
            <name>
              <surname>Shimony</surname>
              <given-names>J.S.</given-names>
            </name>
            <name>
              <surname>Raichle</surname>
              <given-names>M.E.</given-names>
            </name>
          </person-group>
          <chapter-title>Intrinsic Functional Relations between Human Cerebral Cortex and Thalamus</chapter-title>
          <year>2008</year>
          <fpage>1740</fpage>
          <lpage>1748</lpage>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="appsec1">
      <label>Appendix A</label>
      <title>Results for Joint Distribution of Time Series <italic>X</italic> and <italic>Y</italic></title>
      <p id="p0490">Here we provide basic results required for the next appendix, for moments of inner and cross produces of <italic>X</italic> and <italic>Y</italic>.<statement id="enun_Theorem_1"><label>Theorem 1</label><p id="p0495">(Covariance of Quadratic Form of Bivariate Gaussian Distribution).</p><p id="p0500">For fixed matrices <inline-formula><mml:math id="M152" altimg="si105.svg"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M153" altimg="si106.svg"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></inline-formula>, if G is a random vector such that <inline-formula><mml:math id="M154" altimg="si107.svg"><mml:mrow><mml:mi>G</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Φ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> then. <inline-formula><mml:math id="M155" altimg="si108.svg"><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">A</mml:mi><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtext>Φ</mml:mtext><mml:mi mathvariant="bold">A</mml:mi><mml:mtext>Φ</mml:mtext><mml:mi mathvariant="bold">B</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p></statement><statement id="enun_proff"><label>Proof</label><p id="p0505">The result follows from application of the definition of covariance,<disp-formula id="ufd3"><mml:math id="M156" altimg="si109.svg"><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">A</mml:mi><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">A</mml:mi><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">−</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">A</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="p0510">and expectation of a quadratic form for Gaussian variates (<xref rid="bib46" ref-type="bibr">Petersen and Pedersen, 2008</xref>),<disp-formula id="ufd4"><mml:math id="M157" altimg="si110.svg"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">A</mml:mi><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mi mathvariant="bold">Φ</mml:mi><mml:mi mathvariant="bold">B</mml:mi><mml:mi mathvariant="bold">Φ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mi mathvariant="bold">Φ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi mathvariant="bold">t</mml:mi><mml:mi mathvariant="bold">r</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mi mathvariant="bold">Φ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0515">and expectation of quadratic forms, <inline-formula><mml:math id="M158" altimg="si111.svg"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">A</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi><mml:mi mathvariant="bold">Φ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M159" altimg="si112.svg"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mi mathvariant="bold">Φ</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. ∎</p><p id="p0520">The Gaussian assumption can be relaxed, but then an additional term arises to account for departures from Gaussian kurtosis.</p><p id="p0525">The inner products of <italic>X</italic> and <italic>Y</italic> can now be represented in terms of a quadratic form of<disp-formula id="ufd5"><mml:math id="M160" altimg="si113.svg"><mml:mrow><mml:mi>G</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0530">for following maticies:<disp-formula id="ufd6"><mml:math id="M161" altimg="si114.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="ufd7"><mml:math id="M162" altimg="si115.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="ufd8"><mml:math id="M163" altimg="si116.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="p0535">such that <inline-formula><mml:math id="M164" altimg="si117.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mi>G</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M165" altimg="si118.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mi>G</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M166" altimg="si119.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mi>G</mml:mi></mml:mrow></mml:math></inline-formula>.</p></statement></p>
    </sec>
    <sec id="appsec2">
      <label>Appendix B</label>
      <title>xDF: Variance of Sample Correlation Coefficient for Arbitrary Dependence</title>
      <p id="p0540">For mean zero length-<italic>N</italic> random vectors <italic>X</italic> and <italic>X</italic> with (<inline-formula><mml:math id="M167" altimg="si120.svg"><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>) variance matrices <inline-formula><mml:math id="M168" altimg="si64.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M169" altimg="si65.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and cross-covariance <inline-formula><mml:math id="M170" altimg="si63.svg"><mml:mrow><mml:msub><mml:mrow><mml:mtext>Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, we develop the variance of the sample correlation. Following <xref rid="bib31" ref-type="bibr">Lehmann (1999a)</xref> and <xref rid="bib29" ref-type="bibr">Hunter (2014)</xref>, we derive an approximation for the sampling variance of Pearson's correlation. Starting with the 3-dimensional sufficient statistic<disp-formula id="ufd9"><mml:math id="M171" altimg="si121.svg"><mml:mrow><mml:mi>W</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>X</mml:mi><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0545">note that the function <inline-formula><mml:math id="M172" altimg="si122.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> generates the correlation coefficient <inline-formula><mml:math id="M173" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. Then the first order Taylor's series of <inline-formula><mml:math id="M174" altimg="si123.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> about <inline-formula><mml:math id="M175" altimg="si124.svg"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is<disp-formula id="ufd10"><mml:math id="M176" altimg="si125.svg"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo linebreak="badbreak">≈</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>so that <inline-formula><mml:math id="M177" altimg="si126.svg"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">≈</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi>ρ</mml:mi></mml:mrow></mml:math></inline-formula> and<disp-formula id="ufd11"><mml:math id="M178" altimg="si127.svg"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">≈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where the gradient of <inline-formula><mml:math id="M179" altimg="si128.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mo>⋅</mml:mo></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is<disp-formula id="ufd12"><mml:math id="M180" altimg="si129.svg"><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">/</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">/</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>evaluated at <inline-formula><mml:math id="M181" altimg="si130.svg"><mml:mrow><mml:mi>W</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>,<disp-formula id="ufd13"><mml:math id="M182" altimg="si131.svg"><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:msqrt><mml:mo linebreak="badbreak">/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>and, by <xref rid="enun_Theorem_1" ref-type="statement">Theorem 1</xref> in <xref rid="appsec1" ref-type="sec">Appendix A</xref>,<disp-formula id="ufd14"><mml:math id="M183" altimg="si132.svg"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold">Φ</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>2</mml:mn><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd/></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      <p id="p0555">Based on these expressions, evaluating the matrix product <inline-formula><mml:math id="M184" altimg="si133.svg"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="double-struck">V</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> gives the result in Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref>. While very similar, this derivation is not a standard delta method result as we do not have independent observations.</p>
    </sec>
    <sec id="appsec3">
      <label>Appendix C</label>
      <title>Trace of product of two Toeplitz Matrices</title>
      <p id="p0560">If <inline-formula><mml:math id="M185" altimg="si40.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M186" altimg="si41.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are autocorrelation coefficients of time series X and Y on lag <italic>k</italic>, the <inline-formula><mml:math id="M187" altimg="si134.svg"><mml:mrow><mml:mtext>diag</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be re-written as<disp-formula id="fd13"><label>(13)</label><mml:math id="M188" display="block" altimg="si135.svg" alttext="Equation 13."><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mo>⋯</mml:mo><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mo>⋯</mml:mo><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mo>⋯</mml:mo><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mo>⋯</mml:mo><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p id="p0565">Considering that the autocorrelation function of time series is symmetric (i.e. the negative and the positive lags are identical), for X and Y we can simply obtain the trace of the <inline-formula><mml:math id="M189" altimg="si136.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as,<disp-formula id="fd14"><label>(14)</label><mml:math id="M190" display="block" altimg="si137.svg" alttext="Equation 14."><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p>
      <p id="p0570">Similarly, the covariance matrix, <inline-formula><mml:math id="M191" altimg="si14.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, can be written as a Toeplitz matrix of form<disp-formula id="fd15"><label>(15)</label><mml:math id="M192" display="block" altimg="si138.svg" alttext="Equation 15."><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd><mml:mrow><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd><mml:mtd/><mml:mtd/><mml:mtd/><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="p0575">Knowing that the cross-covariance matrices are asymmetric but <inline-formula><mml:math id="M193" altimg="si11.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo>⊤</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, the trace of <inline-formula><mml:math id="M194" altimg="si139.svg"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and can be re-written as<disp-formula id="fd16"><label>(16)</label><mml:math id="M195" display="block" altimg="si140.svg" alttext="Equation 16."><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:mi>k</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:munder><mml:munder><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo linebreak="badbreak">−</mml:mo></mml:mrow></mml:munder><mml:mo linebreak="goodbreak">+</mml:mo><mml:munder><mml:munder><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">︸</mml:mo></mml:munder><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mo linebreak="badbreak">+</mml:mo></mml:mrow></mml:munder><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0580">Similarly, other terms of Eq. <xref rid="fd1" ref-type="disp-formula">(1)</xref> can be re-written as vector operations (see Eq. <xref rid="fd2" ref-type="disp-formula">(2)</xref>).</p>
    </sec>
    <sec id="appsec4">
      <label>Appendix D</label>
      <title>Confounding of Autocorrelation and Cross-correlation Estimates</title>
      <p id="p0585">A majority of the EDF estimators discussed have the term <inline-formula><mml:math id="M196" altimg="si141.svg"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> which depends on the product of autocorrelation functions, <inline-formula><mml:math id="M197" altimg="si142.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (see <xref rid="appsec3" ref-type="sec">Appendix C</xref>). Some unexpected results such as poor variance estimation for the seemingly easy case of time series with no autocorrelation (see Section 3.2) were found to be caused by confounding between estimates of autocorrelation and cross-correlation. Observe that for two white but dependent time series (<inline-formula><mml:math id="M198" altimg="si143.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="M199" altimg="si144.svg"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, but <inline-formula><mml:math id="M200" altimg="si145.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), the product of the sample autocorrelation functions are<disp-formula id="fd17"><label>(17)</label><mml:math id="M201" display="block" altimg="si146.svg" alttext="Equation 17."><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">≤</mml:mo><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">≠</mml:mo><mml:mi>t</mml:mi><mml:mo>'</mml:mo><mml:mo linebreak="badbreak">≤</mml:mo><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">−</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mtext>'</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p>
      <p id="p0590">In this last expression note that each term in the first sum has an expected value of <inline-formula><mml:math id="M202" altimg="si147.svg"><mml:mrow><mml:msup><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, while the second sum has an expected value of zero. As a result, even when there is no (or very light) autocorrelation, methods dependent on <inline-formula><mml:math id="M203" altimg="si141.svg"><mml:mrow><mml:mtext>tr</mml:mtext><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="M204" altimg="si142.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> alone can be substantially biased by non-zero cross-correlation. This includes BH and all its variations listed in <xref rid="bib48" ref-type="bibr">Pyper and Peterman (1998)</xref>. Our xDF, on the other hand, is immune of the effect thanks to the cancelling cross-covariance terms in Eq. <xref rid="fd2" ref-type="disp-formula">(2)</xref>.</p>
    </sec>
    <sec id="appsec5">
      <label>Appendix E</label>
      <title>Autocorrelation in Regions of Interests</title>
      <p id="p0595">We observed substantial differences in severity of autocorrelation in voxel-wise data as opposed to data derived from regions of interest (ROI); see <xref rid="fig2" ref-type="fig">Fig. 2</xref>. This section proposes a model that explains the effect.</p>
      <p id="p0600">Suppose that a ROI contains <italic>R</italic> voxels, and the data for time <italic>t</italic> and voxel <inline-formula><mml:math id="M205" altimg="si148.svg"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> can be modelled as,<disp-formula id="fd18"><label>(18)</label><mml:math id="M206" display="block" altimg="si149.svg" alttext="Equation 18."><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the <inline-formula><mml:math id="M207" altimg="si150.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> a common “signal” shared across all the voxels within the ROI (i.e. a ROI-specific global signal) and <inline-formula><mml:math id="M208" altimg="si151.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the voxel-specific component of data. Assuming that the two components are uncorrelated, the autocorrelation for the ROI is defined as,<disp-formula id="fd19"><label>(19)</label><mml:math id="M209" display="block" altimg="si152.svg" alttext="Equation 19."><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi><mml:mi mathvariant="double-struck">O</mml:mi><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mi mathvariant="double-struck">C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>where <inline-formula><mml:math id="M210" altimg="si153.svg"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M211" altimg="si154.svg"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> are the variances of <italic>V</italic> and <italic>S</italic>, respectively, and <inline-formula><mml:math id="M212" altimg="si155.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M213" altimg="si156.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the autocorrelation coefficient of <italic>V</italic> and <italic>S</italic> at lag <italic>k</italic>, specifically. This shows that the voxel-level correlation is a convex combination of the two ACFs, balanced according to the variances <inline-formula><mml:math id="M214" altimg="si154.svg"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M215" altimg="si153.svg"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
      <p id="p0605">Now, if we assume for this illustration that voxels are independent, then for the ROI-averaged time series, <inline-formula><mml:math id="M216" altimg="si157.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">/</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula>, the autocorrelation is:<disp-formula id="fd20"><label>(20)</label><mml:math id="M217" display="block" altimg="si158.svg" alttext="Equation 20."><mml:mrow><mml:mi mathvariant="double-struck">C</mml:mi><mml:mi mathvariant="double-struck">O</mml:mi><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0610">We again have a convex combination, but now balanced according to <inline-formula><mml:math id="M218" altimg="si159.svg"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M219" altimg="si153.svg"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
      <p id="p0615">If we make some reasonable assumptions we can make predictions of this correlation as <italic>R</italic> grows. Let us assume that <inline-formula><mml:math id="M220" altimg="si160.svg"><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> reflects a stronger autocorrelation of a (BOLD-related) common signal, and <inline-formula><mml:math id="M221" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> reflects less autocorrelation and more thermal noise contributions at individual voxels. Then as <italic>R</italic> grows the ACF of the ROI average converges to the ACF of the common signal, and this would explain the increased strength of autocorrelation with larger ROIs.</p>
    </sec>
    <sec id="appsec6" sec-type="supplementary-material">
      <title>Appendix FSupplementary data</title>
      <p id="p0620">The following is the supplementary data to this article:<supplementary-material content-type="local-data" id="mmc1"><caption><title>Multimedia component 1</title></caption><media xlink:href="mmc1.pdf"><alt-text>Multimedia component 1</alt-text></media></supplementary-material></p>
    </sec>
    <ack id="ack0010">
      <title>Acknowledgements</title>
      <p>We thank Andrew Zalesky at University of Melbourne, Mark Fiecas at University of Minnesota, Simon Schwab and Samuel Davenport at University of Oxford and Jeanette Mumford at University of Wisconsin-Madison for their useful input.</p>
      <p>T.E.N. is supported by the <funding-source id="gs1">Wellcome Trust</funding-source> (100309/Z/12/Z). S.M.S. is supported by the <funding-source id="gs2">Wellcome Trust Centre for Integrative Neuroimaging</funding-source> (203139/Z/16/Z) and the <funding-source id="gs3">Wellcome Trust Strategic Award</funding-source> “<funding-source id="gs4">Integrated Multimodal Brain Imaging for Neuroscience Research and Clinical Practice</funding-source>” (098369/Z/12/Z).</p>
      <p>Data were provided by the <funding-source id="gs5">Human Connectome Project</funding-source>, <funding-source id="gs6">WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil</funding-source>; 1U54MH091657) funded by the 16 <funding-source id="gs7">NIH Institutes and Centers</funding-source> that support the <funding-source id="gs8">NIH Blueprint for Neuroscience Research</funding-source>; and by the <funding-source id="gs9">McDonnell Center for Systems Neuroscience at Washington University</funding-source>.</p>
      <p>Computation used the BMRC facility, a joint development between the Wellcome Centre for Human Genetics and the Big Data Institute supported by the <funding-source id="gs10">NIHR Oxford BRC</funding-source>. The views expressed are those of the authors and not necessarily those of the <funding-source id="gs11">NHS</funding-source>, the <funding-source id="gs12">NIHR</funding-source> or the <funding-source id="gs13">Department of Health</funding-source>.</p>
    </ack>
    <fn-group>
      <fn id="fn1">
        <label>1</label>
        <p id="ntpara0010">While not the topic of this work, <xref rid="bib2" ref-type="bibr">Arbabshirani et al. (2014)</xref> also discuss bias in sample correlation coefficients (<inline-formula><mml:math id="M222" altimg="si1.svg"><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>) due to autocorrelation. In contrast, our derivation (<xref rid="appsec2" ref-type="sec">Appendix B</xref>) finds no such bias; see Section 4.</p>
      </fn>
      <fn id="fn2">
        <label>2</label>
        <p id="ntpara0015"><ext-link ext-link-type="uri" xlink:href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets" id="intref0010">http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets</ext-link>; visited on 18 September 2015.</p>
      </fn>
      <fn id="appsec7" fn-type="supplementary-material">
        <label>Appendix F</label>
        <p id="p0625">Supplementary data to this article can be found online at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2019.05.011" id="intref0025">https://doi.org/10.1016/j.neuroimage.2019.05.011</ext-link>.</p>
      </fn>
    </fn-group>
  </back>
</article>
