<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <?properties manuscript?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-journal-id">101604520</journal-id>
      <journal-id journal-id-type="pubmed-jr-id">41136</journal-id>
      <journal-id journal-id-type="nlm-ta">IEEE J Biomed Health Inform</journal-id>
      <journal-id journal-id-type="iso-abbrev">IEEE J Biomed Health Inform</journal-id>
      <journal-title-group>
        <journal-title>IEEE journal of biomedical and health informatics</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">2168-2194</issn>
      <issn pub-type="epub">2168-2208</issn>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">36201411</article-id>
      <article-id pub-id-type="pmc">10076451</article-id>
      <article-id pub-id-type="doi">10.1109/JBHI.2022.3212479</article-id>
      <article-id pub-id-type="manuscript">NIHMS1862735</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>A Novel Neighborhood Rough Set-Based Feature Selection Method and Its Application to Biomarker Identification of Schizophrenia</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-4479-686X</contrib-id>
          <name>
            <surname>Xing</surname>
            <given-names>Ying</given-names>
          </name>
          <aff id="A1">School of Computer and Information Technology, Shanxi University, Taiyuan 030006, China</aff>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Kochunov</surname>
            <given-names>Peter</given-names>
          </name>
          <aff id="A2">Maryland Psychiatric Research Center and Department of Psychiatry, University of Maryland, School of Medicine, Baltimore, MD 21201 USA</aff>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>van Erp</surname>
            <given-names>Theo G.M.</given-names>
          </name>
          <aff id="A3">Department of Psychiatry and Human Behavior, School of Medicine, University of California, Irvine, CA 92617 USA, and also with the Center for the Neurobiology of Learning and Memory, University of California, Irvine, CA 92617 USA</aff>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>Tianzhou</given-names>
          </name>
          <aff id="A4">Department of Epidemiology and Biostatistics, University of Maryland, College Park, MD 20740 USA</aff>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9058-0747</contrib-id>
          <name>
            <surname>Calhoun</surname>
            <given-names>Vince D.</given-names>
          </name>
          <aff id="A5">Tri-Institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS), Georgia State University, Georgia Institute of Technology, Emory University, Atlanta, GA 30030 USA</aff>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0079-8177</contrib-id>
          <name>
            <surname>Du</surname>
            <given-names>Yuhui</given-names>
          </name>
          <aff id="A6">School of Computer and Information Technology, Shanxi University, Taiyuan 030006, China</aff>
        </contrib>
      </contrib-group>
      <author-notes>
        <corresp id="CR1"><italic toggle="yes">Corresponding author: Yuhui Du</italic>, <email>duyuhui@sxu.edu.cn</email></corresp>
      </author-notes>
      <pub-date pub-type="nihms-submitted">
        <day>1</day>
        <month>2</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>1</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>04</day>
        <month>1</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>07</day>
        <month>4</month>
        <year>2023</year>
      </pub-date>
      <volume>27</volume>
      <issue>1</issue>
      <fpage>215</fpage>
      <lpage>226</lpage>
      <permissions>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
          <license-p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">https://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></license-p>
        </license>
      </permissions>
      <abstract id="ABS1">
        <p id="P1">Feature selection can disclose biomarkers of mental disorders that have unclear biological mechanisms. Although neighborhood rough set (NRS) has been applied to discover important sparse features, it has hardly ever been utilized in neuroimaging-based biomarker identification, probably due to the inadequate feature evaluation metric and incomplete information provided under a single-granularity. Here, we propose a new NRS-based feature selection method and successfully identify brain functional connectivity biomarkers of schizophrenia (SZ) using functional magnetic resonance imaging (fMRI) data. Specifically, we develop a new weighted metric based on NRS combined with information entropy to evaluate the capacity of features in distinguishing different groups. Inspired by multi-granularity information maximization theory, we further take advantage of the complementary information from different neighborhood sizes via a multi-granularity fusion to obtain the most discriminative and stable features. For validation, we compare our method with six popular feature selection methods using three public omics datasets as well as resting-state fMRI data of 393 SZ patients and 429 healthy controls. Results show that our method obtained higher classification accuracies on both omics data (100.0%, 88.6%, and 72.2% for three omics datasets, respectively) and fMRI data (93.9% for main dataset, and 76.3% and 83.8% for two independent datasets, respectively). Moreover, our findings reveal biologically meaningful substrates of SZ, notably involving the connectivity between the thalamus and superior temporal gyrus as well as between the postcentral gyrus and calcarine gyrus. Taken together, we propose a new NRS-based feature selection method that shows the potential of exploring effective and sparse neuroimaging-based biomarkers of mental disorders.</p>
      </abstract>
      <kwd-group>
        <kwd>Feature selection</kwd>
        <kwd>fMRI</kwd>
        <kwd>neighborhood rough set</kwd>
        <kwd>information entropy</kwd>
        <kwd>multi-granularity</kwd>
        <kwd>schizophrenia</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <label>I.</label>
      <title>Introduction</title>
      <p id="P2">Researchers in the neuroscience field inevitably suffer from the curse of dimensionality due to the high dimensionality of neuroimaging data. Consequently, feature selection that eliminates irrelevant and redundant features and only remains important features becomes a necessary step to mine the most useful information [<xref rid="R1" ref-type="bibr">1</xref>], [<xref rid="R2" ref-type="bibr">2</xref>]. Indeed, feature selection plays a key role in identifying meaningful biomarkers that characterize the brain impairments of mental disorders, thus providing insights on the neural substrates as well as the diagnosis and prediction of mental disorders [<xref rid="R3" ref-type="bibr">3</xref>].</p>
      <p id="P3">In recent years, various feature selection methods have been utilized to identify biomarkers of mental disorders using neuroimaging data. Widely applied feature selection methods are generally categorized into unsupervised and supervised methods based on whether the diagnosis labels are utilized or not. If the category label information is unavailable, unsupervised feature selection methods, such as unsupervised correlation-based feature selection (UCFS) [<xref rid="R4" ref-type="bibr">4</xref>], depend on statistical measures to remove the redundant features. However, the identified features from such methods could fail to indicate the stable group difference due to the lack of guidance from category labels. In contrast, supervised feature selection methods, primarily including similarity-based, information entropy-based, and hybrid methods [<xref rid="R5" ref-type="bibr">5</xref>], [<xref rid="R6" ref-type="bibr">6</xref>], can benefit from the guidance of category labels. Similarity-based feature selection methods, such as Fisher score (FiSc) [<xref rid="R7" ref-type="bibr">7</xref>], [<xref rid="R8" ref-type="bibr">8</xref>] and ReliefF [<xref rid="R9" ref-type="bibr">9</xref>], [<xref rid="R10" ref-type="bibr">10</xref>], evaluate feature importance through the ability of features to preserve data similarity which can be inferred from label information [<xref rid="R11" ref-type="bibr">11</xref>]. However, most similarity-based methods cannot handle feature redundancy [<xref rid="R5" ref-type="bibr">5</xref>]. Information entropy-based feature selection methods, such as minimum redundancy maximum relevance method [<xref rid="R8" ref-type="bibr">8</xref>], [<xref rid="R12" ref-type="bibr">12</xref>], are proposed to maximize relevance between features and labels and minimize redundancy among features. However, information entropy-based methods can only handle discrete data, hence data discretization processes are required beforehand for continuous features, which could result in information loss [<xref rid="R6" ref-type="bibr">6</xref>]. Hybrid feature selection methods, such as support vector machine with recursive feature elimination (SVM-RFE) [<xref rid="R13" ref-type="bibr">13</xref>], [<xref rid="R14" ref-type="bibr">14</xref>], aim to provide an aggregated result by ranking features based on classification accuracy. However, the features selected by hybrid methods are likely sensitive to the used classifiers [<xref rid="R6" ref-type="bibr">6</xref>]. In order to overcome the shortcomings of the above methods, more advanced techniques are demanded to obtain more powerful biomarkers.</p>
      <p id="P4">Neighborhood rough set (NRS) is a mathematical tool with a profound theoretical foundation and has been used for the goal of feature selection under different granularities (neighborhood sizes) [<xref rid="R15" ref-type="bibr">15</xref>], [<xref rid="R16" ref-type="bibr">16</xref>]. NRS-based feature selection is a supervised method with strong interpretability that can effectively reduce redundant and irrelevant features and is independent of specific classifiers. Hu first proposed the neighborhood dependency degree maximization (NDDM) feature selection method to assess feature importance using consistent samples whose neighbors belong to the same class, however, the remaining inconsistent samples were completely overlooked [<xref rid="R17" ref-type="bibr">17</xref>]. To overcome the limitation, several feature selection methods combined with information entropy, which is suitable for measuring data uncertainty, have emerged [<xref rid="R18" ref-type="bibr">18</xref>]. Chen et al. and Sun et al. proposed the entropy gain-based gene selection (EGGS) [<xref rid="R19" ref-type="bibr">19</xref>] and decision neighborhood entropy with fisher score-based feature selection algorithm (FSDNE) [<xref rid="R20" ref-type="bibr">20</xref>] by maximizing joint neighborhood entropy and decision neighborhood entropy, respectively. Although EGGS and FSDNE further introduced inconsistent samples to assess the importance of features, the dominant role of consistent samples was ignored. Moreover, determining the neighborhood size in the aforementioned NRS-based feature selection methods is challenging, and such single-granularity methods are prone to yield unstable features. To integrate various complementary information derived from different granularities, multi-granularity ideas were introduced in NRS-based feature selection methods [<xref rid="R21" ref-type="bibr">21</xref>], [<xref rid="R22" ref-type="bibr">22</xref>]. Based on multiple feature ranks obtained by the NDDM method at different granularities, an integrated feature order indicating feature importance was obtained via the cross-entropy Monte Carlo algorithm, which unfortunately lacks the guidance of label information [<xref rid="R22" ref-type="bibr">22</xref>]. Liu integrated discriminative features obtained by the NDDM at the finest and the coarsest granularities (i.e., the smallest and largest neighborhood sizes), however, such method inevitably missed some important features at remaining granularities [<xref rid="R23" ref-type="bibr">23</xref>]. In short, constructing an appropriate metric to measure the importance of features and determining the neighborhood size remain challenges for NRS-based feature selection methods.</p>
      <p id="P5">In response to the aforementioned challenges, in this paper, we propose a new multi-granularity NRS-based feature selection method and apply it to identify biomarkers of schizophrenia (SZ) using neuroimaging data. In detail, we first construct a new feature evaluation metric to balance the contribution of all samples in evaluating the discriminative ability of features and meanwhile emphasize the dominant role of consistent samples through a weighting strategy. And then, we come up with a weighted neighborhood rough set combined with entropy (WNRE) method based on the new metric to select important features under a certain granularity. More importantly, to avoid the unstable outcomes derived from a single-granularity method with a specific neighborhood size, we further extend WNRE and propose a multi-granularity WNRE-based (MGWNRE) feature selection method which integrates features under different neighborhood sizes according to their classification ability to obtain more stable and discriminative features. We first verify the effectiveness and superiority of MGWNRE method over six state-of-the-art methods on three main omics datasets since they are suitable for algorithm evaluation thanks to more accurate ground-truth class labels. Furthermore, we employ our method to explore biomarkers of schizophrenia using functional network connectivity (FNC) features derived from functional magnetic resonance imaging (fMRI) data. Importantly, we not only utilize a main fMRI dataset to explore the sparse and important FNC features in discriminating SZ patients from healthy controls (HCs) but also demonstrate the generalization ability of the selected features on two fully independent datasets. Our results show that our method yields more discriminative features and higher classification accuracies than the six competing methods on both the main datasets and the two independent datasets. Taken together, we propose a promising NRS-based feature selection method and identify potential biomarkers of SZ.</p>
    </sec>
    <sec id="S2">
      <label>II.</label>
      <title>Method and Materials</title>
      <p id="P6">In this section, we first briefly review the NRS theory and information entropy. Then, we propose a single-granularity WNRE feature selection method, which effectively evaluates the importance of features by taking advantage of all available samples to improve the discriminative performance of the selected features. To combine complementary predictive powers provided by different granularities, we further extend WNRE to the MGWNRE feature selection method to ensure the stability of selected features. To verify our method, we employ three omics datasets to evaluate the feasibility of our methods and also apply our method to fMRI datasets for discovering biomarkers of SZ. In the experiments, we compare our method with six competing feature selection methods.</p>
      <sec id="S3">
        <label>A.</label>
        <title>Preliminary Knowledge</title>
        <p id="P7">We first introduce some basic concepts about NRS theory [<xref rid="R17" ref-type="bibr">17</xref>], [<xref rid="R20" ref-type="bibr">20</xref>], which are the basis of the proposed methods. Let a neighborhood decision system is denoted as <italic toggle="yes">NS</italic> = ⟨<bold><italic toggle="yes">U, A,</italic></bold> {<bold><italic toggle="yes">d</italic></bold>}, <bold><italic toggle="yes">V</italic></bold>, <italic toggle="yes">f, δ</italic>⟩. Here, <bold><italic toggle="yes">U</italic></bold> is a nonempty finite set of all samples. <bold><italic toggle="yes">A</italic></bold> is a nonempty finite set of conditional features (i.e., features used for classification). <bold><italic toggle="yes">d</italic></bold> is a decision feature (i.e., class label in classification). <bold><italic toggle="yes">V</italic></bold> is the union set including both conditional and decision features’ values across all samples, so <inline-formula><mml:math id="M1" display="inline"><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mo>∪</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>∪</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo>}</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">f</italic>(<bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub>,<bold><italic toggle="yes">α</italic></bold>) represents the value of sample <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> with respect to feature <bold><italic toggle="yes">α</italic></bold>. <italic toggle="yes">δ</italic> is a neighborhood size used to reflect the relations between different samples according to conditional features. <bold><italic toggle="yes">B</italic></bold> (<bold><italic toggle="yes">B</italic></bold> ⊆ <bold><italic toggle="yes">A</italic></bold>) is a conditional feature subset.</p>
        <p id="P8">Equivalence class and neighborhood set are two key sample sets for any sample <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> ∈ <bold><italic toggle="yes">U</italic></bold>. Equivalence class of <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> (with respect to decision feature <bold><italic toggle="yes">d</italic></bold>) consists of samples with the same class label. And samples in the same equivalence class are indiscernible (equivalent) on <bold><italic toggle="yes">d.</italic></bold> Formally, the equivalence class of <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> can be defined by
<disp-formula id="FD1">
<label>(1)</label>
<mml:math id="M2" display="block"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P9">Given a feature subset <bold><italic toggle="yes">B</italic></bold>, neighborhood set of <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> contains its similar and indiscernible (close) samples whose distance from <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> are less than <italic toggle="yes">δ</italic>. Mathematically, the neighborhood set of <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> is defined as
<disp-formula id="FD2">
<label>(2)</label>
<mml:math id="M3" display="block"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mi>δ</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>
where Δ<sub><italic toggle="yes">B</italic></sub>(<bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub>, <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">j</italic></sub>)is a distance function to measure the distance (dissimilarity) between samples <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> and <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">j</italic></sub> on a feature subset <bold><italic toggle="yes">B</italic></bold>. In this paper, we use Euclidean distance [<xref rid="R24" ref-type="bibr">24</xref>].</p>
        <p id="P10">NRS-based feature selection aims to extract a conditional feature subset including discriminative and important features, so that the equivalence class can be approximately represented by neighborhood set. Thus, neighborhood dependency degree is proposed to evaluate the approximating ability by counting samples whose neighborhood set consistently belongs to its equivalence class. Such samples are called consistent samples because they accurately belong to a certain class using feature subset <bold><italic toggle="yes">B</italic></bold>, whereas the remaining inconsistent samples do not. Therefore, the significance of conditional feature subset <bold><italic toggle="yes">B</italic></bold> can be characterized by neighborhood dependency degree as
<disp-formula id="FD3">
<label>(3)</label>
<mml:math id="M4" display="block"><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msubsup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊆</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>|</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>
where the |·| indicates the cardinality of a set, and the value of <inline-formula><mml:math id="M5" display="inline"><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> ranges from 0 to 1. In our method, we propose to use the neighborhood dependency degree to weigh the importance of consistent samples.</p>
        <p id="P11">Information entropy [<xref rid="R5" ref-type="bibr">5</xref>] is an effective mathematical tool to determine whether a conditional feature should be retained according to the reduction of conditional entropy and is introduced to alleviate the defect that neighborhood dependency degree ignores the ability of features in distinguishing inconsistent samples. Conditional entropy [<xref rid="R25" ref-type="bibr">25</xref>] is widely utilized to take advantage of all samples to evaluate the discriminative ability of discrete value features. However, for continuous value features, the indispensable discretization processes may result in information loss. Neighborhood rough set theory is suitable for continuous and discrete value features but cannot leverage the inconsistent samples. Therefore, we aim to combine these two theories and propose a new metric to measure the importance of features according to all samples.</p>
        <p id="P12">More detailed information about NRS and information entropy can be found in literature [<xref rid="R5" ref-type="bibr">5</xref>], [<xref rid="R17" ref-type="bibr">17</xref>], [<xref rid="R20" ref-type="bibr">20</xref>], [<xref rid="R26" ref-type="bibr">26</xref>].</p>
      </sec>
      <sec id="S4">
        <label>B.</label>
        <title>Our Proposed Weighted Neighborhood Rough Set Combined With Entropy (WNRE) Feature Selection Method</title>
        <p id="P13">A key in feature selection is to select discriminative features according to a feature evaluation metric. Inspired by prior work (i.e., NDDM [<xref rid="R17" ref-type="bibr">17</xref>], EGGS [<xref rid="R19" ref-type="bibr">19</xref>], and FSDNE [<xref rid="R20" ref-type="bibr">20</xref>]), we define a new metric to characterize the discriminative ability of feature subsets using all samples and propose a new feature selection method named WNRE. Considering the dominant role of consistent samples, we take neighborhood dependency degree as a weight to emphasize the capability of feature subsets in yielding consistent samples.</p>
        <p id="P14">In our method, given neighborhood size <italic toggle="yes">δ</italic> and decision feature <bold><italic toggle="yes">d,</italic></bold> the importance of any conditional feature subset <bold><italic toggle="yes">B</italic></bold> is defined by
<disp-formula id="FD4">
<label>(4)</label>
<mml:math id="M6" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>J</mml:mi><mml:mi>δ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msubsup><mml:mi>γ</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:munderover><mml:mrow><mml:mi>log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mo>∩</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">U</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi>B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mo>∩</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>δ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
The two items in brackets, namely, neighborhood accuracy and neighborhood credibility degree, are used to assess the discriminative ability of <bold><italic toggle="yes">B</italic></bold> on all samples. The former item evaluates the approximation accuracy of the neighborhood set to the equivalence class using all samples. The latter reflects purity to assess the sample proportion of the same class in the neighborhood. In our method, the neighborhood dependency degree is used as a weight value to emphasize the discriminative ability of feature subsets on consistent samples. In sum, we propose a feature evaluation metric to comprehensively evaluate the capacity of feature subsets in distinguishing the whole sample set while highlighting the role of consistent samples.</p>
        <p id="P15">A larger <italic toggle="yes">J</italic><sub><italic toggle="yes">δ</italic></sub>(<bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>) means that the related features in <bold><italic toggle="yes">B</italic></bold> are more discriminative. Hence, we define a significance measurement of a given conditional feature <bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub> ∈ <bold><italic toggle="yes">A</italic></bold> − <bold><italic toggle="yes">B</italic></bold> as
<disp-formula id="FD5">
<label>(5)</label>
<mml:math id="M7" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>δ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mo>∪</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>δ</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="bold-italic">d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P16">Here, <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>) represents the increased contribution of feature subset <bold><italic toggle="yes">B</italic></bold> after adding a feature <bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>. If <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>) &gt; 0, it means that feature <bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub> is essential, otherwise, it is deleted because it is a redundant feature (when <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>) = 0) or irrelevant feature (when <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>) &lt; 0). The larger the value of <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>), the more important feature <bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub> is. In our method, we perform a heuristic algorithm to search for the discriminative feature subset. In the process, we start from an empty feature set and add features iteratively through maximizing <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>). This operation terminates when <italic toggle="yes">Sig</italic>(<bold><italic toggle="yes">a</italic></bold><sub><italic toggle="yes">j</italic></sub>, <bold><italic toggle="yes">B</italic></bold>, <bold><italic toggle="yes">d</italic></bold>) stops increasing.</p>
        <p id="P17">In addition, given that the feature selection process is time-consuming on high-dimensional data, we first employ the FiSc method [<xref rid="R7" ref-type="bibr">7</xref>] to preselect a candidate feature subset to speed up the subsequent feature selection process. Herein, we select the top <italic toggle="yes">l</italic> candidate discriminate features as input to the subsequent WNRE feature selection process. The WNRE algorithm is described in <xref rid="T4" ref-type="table">Algorithm 1</xref>.</p>
        <p id="P18">As shown in <xref rid="T4" ref-type="table">Algorithm 1</xref>, given the original conditional feature set <bold><italic toggle="yes">A</italic></bold>, decision feature <bold><italic toggle="yes">d</italic></bold>, and neighborhood size <italic toggle="yes">δ</italic>, we first initialize the excepted discriminative feature subset <bold><italic toggle="yes">B</italic></bold>* as an empty set. Then, we select the top <italic toggle="yes">l</italic> features to constitute the candidate feature subset <bold><italic toggle="yes">A′</italic></bold> based on the FiSc method. Next, the most important feature according to the evaluation metric (4–5) is iteratively added into the subset <bold><italic toggle="yes">B</italic></bold>* one by one. After incorporating a feature, <bold><italic toggle="yes">B</italic></bold>* is judged to see if it meets the terminal condition. If the condition is not satisfied, the algorithm continues to iterate and amalgamate the important features, otherwise outputs the selected feature subset <bold><italic toggle="yes">B</italic></bold>*.</p>
        <table-wrap position="anchor" id="T4">
          <label>Algorithm 1:</label>
          <caption>
            <p id="P19">WNRE.</p>
          </caption>
          <table frame="hsides" rules="none">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td colspan="2" align="left" valign="top" rowspan="1">Input: A neighborhood decision system <italic toggle="yes">NS</italic> = 〈<bold><italic toggle="yes">U, A</italic></bold>, {<italic toggle="yes"><bold>d</bold></italic>}, <bold><italic toggle="yes">V</italic></bold>, <italic toggle="yes">f, δ</italic>〉.</td>
              </tr>
              <tr>
                <td colspan="2" align="left" valign="top" rowspan="1"><bold>Output:</bold> Excepted feature subset <italic toggle="yes"><bold>B</bold></italic>*.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">1:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> Initialize <bold><italic toggle="yes">B</italic></bold>* = ∅.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">2:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> Select top-<italic toggle="yes">l</italic> features from <bold><italic toggle="yes">A</italic></bold> to constitute the candidate feature subset <bold><italic toggle="yes">A′</italic></bold> based on FiSc method.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">3:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> <bold>do {</bold></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">4:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  <bold>for</bold> ∀ <italic toggle="yes"><bold>a</bold><sub>j</sub></italic> ∈ <bold><italic toggle="yes">A′</italic></bold></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">5:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">   Compute <italic toggle="yes">Sig</italic>(<italic toggle="yes"><bold>a</bold><sub>j</sub></italic>, <bold><italic toggle="yes">B</italic></bold>*, <bold><italic toggle="yes">d</italic></bold>) according to formula (4–5).</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">6:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  <bold>end for</bold></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">7:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  Select the feature <italic toggle="yes"><bold>a</bold><sub>k</sub></italic> satisfying <italic toggle="yes">Sig</italic>(<italic toggle="yes"><bold>a</bold><sub>k</sub></italic>, <bold><italic toggle="yes">B</italic></bold>*, <bold><italic toggle="yes">d</italic></bold>) = max(<italic toggle="yes">Sig</italic>(<italic toggle="yes"><bold>a</bold><sub>j</sub></italic>, <bold><italic toggle="yes">B</italic></bold>*, <bold><italic toggle="yes">d</italic></bold>)).</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">8:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  <bold><italic toggle="yes">B</italic></bold>* = <bold><italic toggle="yes">B</italic></bold>* ∪{<italic toggle="yes"><bold>a</bold><sub>k</sub></italic>}, <bold><italic toggle="yes">A′</italic></bold> = <bold><italic toggle="yes">A′</italic></bold> − {<italic toggle="yes"><bold>a</bold><sub>k</sub></italic>}.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">9:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> <bold>} until</bold>
<italic toggle="yes">Sig</italic>(<italic toggle="yes"><bold>a</bold><sub>k</sub></italic>, <bold><italic toggle="yes">B</italic></bold>*, <bold><italic toggle="yes">d</italic></bold>) &lt; <italic toggle="yes">e</italic><sup>−10</sup></td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p id="P20">Since WNRE faces difficulty in determining neighborhood size, we further propose a multi-granularity fusion strategy to overcome its shortcoming.</p>
      </sec>
      <sec id="S5">
        <label>C.</label>
        <title>Our Proposed Multi-Granularity WNRE-Based (MGWNRE) Feature Selection Method</title>
        <p id="P21">Based on our proposed WNRE method, an extended feature selection method, abbreviated by MGWNRE, is proposed to merge the features selected by multiple WNRE processes under different neighborhood sizes and yield complementary and stable important features. The algorithm is outlined in <xref rid="T5" ref-type="table">Algorithm 2</xref>.</p>
        <p id="P22">As shown in <xref rid="T5" ref-type="table">Algorithm 2</xref>, given initial conditional feature set <bold><italic toggle="yes">A</italic></bold>, decision feature <bold><italic toggle="yes">d</italic></bold>, and a set of neighborhood sizes Θ, we perform multiple WNRE feature selection processes and merge the feature subsets that result in a satisfying performance. Specifically, for arbitrary <italic toggle="yes">δ</italic>, we can obtain a feature subset <bold><italic toggle="yes">B</italic></bold>* after executing WNRE algorithm. Then, we apply a classifier to evaluate the significance of <bold><italic toggle="yes">B</italic></bold>* and obtain associated comprehensive classification performance (CCP, i.e., mean of classification accuracy, sensitivity, and specificity). After performing this operation for each <italic toggle="yes">δ</italic>, we merge feature subsets whose CCP is better than the average level and output the final discriminative features.</p>
      </sec>
      <sec id="S6">
        <label>D.</label>
        <title>Performance Evaluation of MGWNRE and Comparisons With Other Methods</title>
        <p id="P23">In this section, we perform two experiments to verify the effectiveness of our methods and identify stable biomarkers of SZ. In the first experiment, we evaluate the effectiveness of our methods on three public omics datasets with classification labels to assess if the selected features are discriminative in classifying different classes. In the second experiment, our methods are applied to fMRI data to identify discriminative features (that indicate biomarkers) that can separate SZ patients from HCs. The generalization ability and stability of the identified biomarkers are further evaluated using fully independent fMRI datasets. Furthermore, we implement six competing feature selection methods for a comprehensive comparison in the two experiments.</p>
        <table-wrap position="anchor" id="T5">
          <label>Algorithm 2:</label>
          <caption>
            <p id="P24">MGWNRE.</p>
          </caption>
          <table frame="hsides" rules="none">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <tbody>
              <tr>
                <td colspan="2" align="left" valign="top" rowspan="1"><bold>Input:</bold> A neighborhood decision system <italic toggle="yes">NS</italic> = 〈<bold><italic toggle="yes">U, A,</italic></bold> {<bold><italic toggle="yes">d</italic></bold>}, <bold><italic toggle="yes">V</italic></bold>, <italic toggle="yes">f, δ</italic>〉, a set of neighborhood sizes Θ = {<italic toggle="yes">δ</italic><sub>1</sub>, <italic toggle="yes">δ</italic><sub>2</sub>, …, <italic toggle="yes">δ<sub>q</sub></italic>}, |<bold>Θ</bold>| = <italic toggle="yes">q</italic>.</td>
              </tr>
              <tr>
                <td colspan="2" align="left" valign="top" rowspan="1"><bold>Output:</bold> Excepted feature subset <bold><italic toggle="yes">B</italic></bold>**.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">1.</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> Initialize <bold><italic toggle="yes">B</italic></bold>** = ∅.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">2:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> <bold>for</bold> ∀ <italic toggle="yes">δ<sub>i</sub></italic> ∈ <bold>Θ</bold></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">3:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  Execute WNRE and obtain a feature subset <inline-formula><mml:math id="M8" display="inline"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> with current <italic toggle="yes">δ<sub>i</sub></italic>.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">4:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  Compute CCP<sub><italic toggle="yes">i</italic></sub> related to <inline-formula><mml:math id="M9" display="inline"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">5:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> <bold>end for</bold></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">6:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> Compute average <inline-formula><mml:math id="M10" display="inline"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mtext>CCP</mml:mtext></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>q</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mi>i</mml:mi><mml:mi>q</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mtext>CCP</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">7:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> <bold>for</bold> ∀ CCP<sub><italic toggle="yes">i</italic></sub></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">8:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  <bold>If</bold>
<inline-formula><mml:math id="M11" display="inline"><mml:mrow><mml:msub><mml:mrow><mml:mtext>CCP</mml:mtext></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mover accent="true"><mml:mrow><mml:mtext>CCP</mml:mtext></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">9:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">   <inline-formula><mml:math id="M12" display="inline"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mo>∪</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>.</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">10:</td>
                <td align="left" valign="top" rowspan="1" colspan="1">  <bold>end if</bold></td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">11:</td>
                <td align="left" valign="top" rowspan="1" colspan="1"> <bold>end for</bold></td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <sec id="S7">
          <label>1)</label>
          <title>Experimental Pipelines for Our Proposed Methods and Competing Methods:</title>
          <p id="P25"><xref rid="F1" ref-type="fig">Fig. 1</xref> shows the experimental pipelines for our proposed methods (i.e., WNRE and MGWNRE) and the competing methods (i.e., NDDM, EGGS, FSDNE, UCFS, ReliefF, and SVM-RFE). <xref rid="F1" ref-type="fig">Fig. 1(a)</xref> displays the experimental pipeline of each method using the main datasets, including three omics datasets and an fMRI dataset, which aims to validate the distinguishing ability of the features selected by each method. <xref rid="F1" ref-type="fig">Fig. 1(b)</xref> displays the experimental pipeline of each method on two fMRI independent datasets, which focuses on validating the generalization ability of the features selected by each method from the main fMRI dataset.</p>
          <p id="P26">As shown in <xref rid="F1" ref-type="fig">Fig. 1(a)</xref>, using each main dataset, each method is carried out under an outer 10-fold cross-validation with an embedded inner 5-fold cross-validation pipeline to ensure that the selected features are reliable and unbiased. Considering the existence of intrinsic parameters in each method, the inner cross-validation aims to search the optimal parameters and select discriminative features, and the outer cross-validation aims to evaluate the distinguishing ability of the selected features on unseen data. Specifically, we perform the following steps for each method on each main dataset. For the outer cross-validation, we divide data into ten equal folds randomly. Nine of ten folds are used as the outer training data to search for discriminative features and train an outer classifier. The remaining fold is used as the outer testing data to evaluate the features according to the classification performance of the trained classifier. It is worth pointing out that we first employ FiSc method on the outer training data to preselect features whose fisher scores are greater than the average score as the candidate features to improve computation efficiency. For the inner cross-validation, outer training data with candidate features are divided into five equal folds. Given specific parameters for each method, four of five folds are used as the inner training data to select features and train the inner classifier with the selected features, and the remaining inner one fold is used to evaluate the selected features via the above-mentioned comprehensive classification performance of the trained inner classifiers.</p>
          <p id="P27">To be fair, we search the optimal parameters according to the classification results of inner cross-validation to select the most discriminative features for each method. In detail, according to the comprehensive classification performance of the trained inner classifiers in the inner cross-validation, we use optimal neighborhood size for WNRE, NDDM, EGGS, and FSDNE, and optimal numbers of selected features for UCFS, ReliefF, and SVM-RFE. As such, for each method, we can obtain ten discriminative feature subsets and associated classification performance (i.e., accuracy, sensitivity, and specificity). Finally, the classification performances of our proposed methods and the competing methods are compared.</p>
          <p id="P28">To verify the generalization ability of the features selected by each method from the main fMRI dataset, the top-10 features with the highest occurring frequency in the ten discriminative feature subsets are utilized on independent fMRI datasets for a strict classification test, respectively, as shown in <xref rid="F1" ref-type="fig">Fig. 1(b)</xref>. In detail, we perform another classification experiment under 10-fold cross-validation using independent datasets based on the top-10 discriminative features selected by each method. In each run, nine folds are used to train a classifier, and the remaining one fold is used to test the performance based on the classifier. The classification performances from different methods are compared.</p>
          <p id="P29">Here, we employ SVM with a linear kernel [<xref rid="R14" ref-type="bibr">14</xref>], K nearest neighbor with K of 3 (3NN) [<xref rid="R19" ref-type="bibr">19</xref>], and AdaBoost [<xref rid="R27" ref-type="bibr">27</xref>] as the outer classifiers for separate tests to verify the classification performance and take SVM as the inner classifier.</p>
        </sec>
      </sec>
      <sec id="S8">
        <label>2)</label>
        <title>Performance Evaluation Experiment on Omics Datasets:</title>
        <p id="P30">Omics data that is helpful for tumor and cancer diagnosis have been widely used in evaluating the performance of feature selection methods [<xref rid="R19" ref-type="bibr">19</xref>], [<xref rid="R20" ref-type="bibr">20</xref>]. In the first experiment, we employ our two methods on three public omics datasets to examine if the features selected by our methods have powerful abilities in classifying different classes. Small-round-blue-cell tumor (SR-BCT) dataset involves 2308 features and 83 samples, including four childhood tumor subtypes [<xref rid="R20" ref-type="bibr">20</xref>]. Colon dataset involves 2000 features and 62 samples, including patients with colon cancer and healthy samples [<xref rid="R20" ref-type="bibr">20</xref>]. Breast invasive carcinoma (BRCA) dataset involves 6780 features and 305 samples, including four cancer subtypes [<xref rid="R28" ref-type="bibr">28</xref>].</p>
        <p id="P31">As shown in <xref rid="F1" ref-type="fig">Fig. 1(a)</xref>, using the three omics datasets, respectively, we perform our methods and competing methods under the unbiased 10-fold cross-validation pipeline to compare the average accuracy, sensitivity, specificity, and the number of selected features of each method.</p>
      </sec>
      <sec id="S9">
        <label>3)</label>
        <title>Performance Evaluation Experiment on fMRI Datasets:</title>
        <p id="P32">FNC features derived from fMRI data potentially can reveal the aberrant brain activity of mental disorders such as SZ, which is a common and serious illness [<xref rid="R29" ref-type="bibr">29</xref>]. Identifying biomarkers for SZ is expected to help understand the underlying mechanism of the disorder and assist in diagnosis.</p>
        <p id="P33">In the second experiment, FNC features derived from resting-state fMRI data of 100 SZ patients and 127 age-matched HCs collected from the Function Biomedical Informatics Research Network (FBIRN)<sup><xref rid="FN1" ref-type="fn">1</xref></sup> are taken as the main fMRI dataset which is used to validate that our methods can select the significant features in distinguishing HC and SZ groups. Then, 163 SZ patients and 149 age-matched HCs from Bipolar-Schizophrenia Network on Intermediate Phenotypes (BSNIP)<sup><xref rid="FN2" ref-type="fn">2</xref></sup> [<xref rid="R30" ref-type="bibr">30</xref>] and 130 SZ patients and 153 age-matched HCs from Maryland Psychiatric Research Center (MPRC)<sup><xref rid="FN3" ref-type="fn">3</xref></sup> are taken as two independent datasets which are separately utilized to evaluate the generalization ability of the features selected from the main fMRI dataset. Here, 1378 FNC features revealing interactions between brain networks are derived from the fMRI data as the initial features for each subject based on the previously developed NeuroMark method [<xref rid="R31" ref-type="bibr">31</xref>], [<xref rid="R32" ref-type="bibr">32</xref>] and toolbox (<ext-link xlink:href="http://www.yuhuidu.com/" ext-link-type="uri">http://www.yuhuidu.com/</ext-link>).</p>
        <p id="P34">Using the FNC features, we first carry out our methods on the FBIRN dataset under the 10-fold cross-validation pipeline (<xref rid="F1" ref-type="fig">Fig. 1(a)</xref>) to examine the ability of selected FNC features in distinguishing HC and SZ groups. In the pipeline, the outer cross-validation is leveraged to train and evaluate the outer classifier based on the discriminative FNC features selected from the associated inner cross-validation. In the experiment, we also evaluate the classification performance of the six competing methods using the same pipeline.</p>
        <p id="P35">Based on the respective top-10 discriminative FNC features selected by each method from FBIRN dataset, we perform another classification test on independent datasets (BSNIP and MPRC datasets) under a 10-fold cross-validation experimental pipeline (<xref rid="F1" ref-type="fig">Fig. 1(b)</xref>). In this pipeline, a classifier is trained using nine folds data, and the remaining one fold data is then used to test the classification performance based on the classifier. Finally, we compare the classification performance of our methods with that of the competing methods on the two datasets. Considering that we only use a small number (i.e., 10) of FNC features selected by each method from FBIRN dataset to perform the classification test on independent datasets, we would see which feature selection method is more stable according to the classification performance.</p>
        <p id="P36">The selected FNC features which work well in the HC-SZ classification may represent meaningful biomarkers for SZ. Therefore, using each fMRI dataset (both main and independent datasets), we summarize and analyze the top-10 high-frequency FNC features selected by our MGWNRE method. First, we perform a two-sample t-test to test if there are significant differences with respect to each selected FNC feature between the HC and SZ groups. Then, we compute the average connectivity strength of each selected FNC feature for each group (HC or SZ) to show the differences between the groups. We aim to investigate if the group differences are consistent across different datasets in terms of the ten FNC features.</p>
      </sec>
      <sec id="S10">
        <label>4)</label>
        <title>Competing Methods and Comprehensive Comparison of MGWNRE With Other Methods on All Datasets:</title>
        <p id="P37">For a comparison with our methods, we choose six popular feature selection methods, including three NRS-based methods (i.e., NDDM, EGGS, and FSDNE) and three non-NRS-based methods (i.e., UCFS, ReliefF, and SVM-RFE). Since there are multiple datasets and competing methods in our work, it is difficult to judge which method works best overall. Therefore, we compute an overall ranking on all used datasets for these methods. In detail, we first rank all methods according to the comprehensive classification performance for each dataset. Then, we calculate the average ranking for each method on the six datasets and obtain an overall ranking of these methods. Moreover, we compute the standard deviation of the comprehensive classification performance for each method on the six datasets to reflect the stability of classification performance.</p>
      </sec>
    </sec>
    <sec id="S11">
      <label>III.</label>
      <title>Results</title>
      <sec id="S12">
        <label>A.</label>
        <title>Results on Omics Datasets in the First Experiment</title>
        <p id="P38"><xref rid="F2" ref-type="fig">Fig. 2</xref> and <xref rid="T1" ref-type="table">Table I</xref> display the experimental results from the different feature selection methods on the omics datasets, including SRBCT, Colon, and BRCA. It should be noted that the number of candidate features preselected by FiSc method was 654, 629, and 2077 for SRBCT, Colon, and BRCA datasets, respectively. Using the SRBCT dataset, the classification results based on different classifiers (i.e., SVM, 3NN, and AdaBoost classifiers) are shown in <xref rid="F2" ref-type="fig">Fig. 2(a)</xref>–<xref rid="F2" ref-type="fig">(c)</xref>, and it can be seen that based on each classifier, the proposed MGWNRE consistently obtained superior classification results, and WNRE also reached promising results compared with the competing methods. As outlined in <xref rid="T1" ref-type="table">Table I</xref>, among the eight methods, MGWNRE achieved the best performance with an average accuracy of 100%, sensitivity of 100%, and specificity of 100% based on both SVM and 3NN classifiers. Based on AdaBoost classifier, MGWNRE also obtained the highest average accuracy (i.e., 95.4%) and highest average sensitivity (i.e., 97.5%). In addition, from the table, we can see that WNRE also achieved good classification results which were better than that of the most competing methods based on the three classifiers. In short, MGWNRE selected a small number of features (i.e., 53 features, only 2.3% of the entire features) and achieved satisfactory classification results.</p>
        <p id="P39">The experimental results using the Colon dataset based on the three classifiers are presented in <xref rid="F2" ref-type="fig">Fig. 2(d)</xref>–<xref rid="F2" ref-type="fig">(f)</xref> and <xref rid="T1" ref-type="table">Table I</xref>. From the figure, we can see that the classification results of MGWNRE were remarkably better than that of other competing methods based on SVM and 3NN classifiers. From the table, it can be seen specifically that among all methods, MGWNRE attained the highest average accuracy of 88.3% based on SVM classifier and 88.6% based on 3NN classifier, and its classification performance based on AdaBoost classifier was also better than that of most competing methods. In addition, WNRE obtained acceptable classification performances compared with other methods based on different classifiers. In summary, MGWNRE achieved an excellent distinguishing ability using relatively few features (i.e., 70 features, 3.5% of the entire features).</p>
        <p id="P40"><xref rid="F2" ref-type="fig">Fig. 2(g)</xref>–<xref rid="F2" ref-type="fig">(i)</xref> and <xref rid="T1" ref-type="table">Table I</xref> display the results on the BRCA dataset using the three classifiers. Compared with the competing methods, MGWNRE selected a small number of important features (i.e., 72 features, only 1% of the entire features) and obtained the highest average accuracy of 72.2%, sensitivity of 90.0%, and specificity of 68.4% when using SVM classifier, and satisfactory classification results when using other two classifiers. In addition, the proposed WNRE method also achieved promising results relative to the competing methods.</p>
      </sec>
      <sec id="S13">
        <label>B.</label>
        <title>Results on fMRI Datasets in the Second Experiment</title>
        <p id="P41">Using fMRI data of SZ patients and HCs, the classification results of the main dataset (i.e., FBIRN) based on the three classifiers are presented in <xref rid="F3" ref-type="fig">Fig. 3(a)</xref>–<xref rid="F3" ref-type="fig">(c)</xref> and <xref rid="T2" ref-type="table">Table II</xref>. It should be noted that the number of candidate features preselected by FiSc method was 430 for FBIRN dataset. The figure provides an overview of the classification performance for each feature selection method, and we can see that both MGWNRE and WNRE got outstanding results. From the table, it is seen that compared with the competing methods, MGWNRE identified the fewest features (i.e., 21 features, only 1.5% of the entire features) and reached the best average accuracy and specificity based on each classifier. Based on 3NN classifier, MGWNRE obtained the highest average accuracy of 93.9%, sensitivity of 93.8%, and specificity of 94.0%. In addition, WNRE also obtained outstanding classification results compared with the competing methods based on each classifier.</p>
        <p id="P42">Using the top-10 high-frequency FNC features selected by each method on the FBIRN dataset, the experimental results of the two independent datasets (i.e., BSNIP and MPRC datasets) are shown in <xref rid="F3" ref-type="fig">Fig. 3(d)</xref>–<xref rid="F3" ref-type="fig">(i)</xref> and <xref rid="T2" ref-type="table">Table II</xref>. As displayed in <xref rid="F3" ref-type="fig">Fig. 3(d)</xref>–<xref rid="F3" ref-type="fig">(f)</xref> and <xref rid="T2" ref-type="table">Table II</xref>, compared with the competing methods, MGWNRE obtained the best average accuracy and sensitivity based on 3NN and AdaBoost classifiers, and outperformed five of six competing methods based on SVM classifier which achieved an average accuracy of 76.3% on BSNIP dataset. Besides, WNRE also got an acceptable classification performance on BSNIP dataset. Regarding the results on MPRC dataset (<xref rid="F3" ref-type="fig">Fig. 3(g)</xref>–<xref rid="F3" ref-type="fig">(i)</xref> and <xref rid="T2" ref-type="table">Table II</xref>), MGWNRE got excellent classification results with an average accuracy of 83.8%, sensitivity of 84.3%, and specificity of 83.1% based on SVM classifier, which outperformed all six competing methods. Based on 3NN and AdaBoost classifiers, MGWNRE also obtained promising classification results. In addition, WNRE was superior to most competing methods based on each classifier on MPRC dataset. To summarize, using only the top-10 FNC features selected by our proposed methods on the main fMRI dataset, the SZ patients and HCs in the fully independent datasets can be effectively distinguished.</p>
        <p id="P43">To show the group difference of the top-10 high-frequency FNC features selected by MGWNRE from the main fMRI dataset, <xref rid="T3" ref-type="table">Table III</xref> includes the P-values and T-values of each FNC feature obtained by performing a two-sample t-test between the HC and SZ groups in the FBIRN, BSNIP, and MPRC datasets. For FBIRN and BSNIP datasets, our results suggest that there were significant differences (P-value &lt; 0.05) between the two groups for all the ten FNC features. For MPRC dataset, nine of ten FNC features showed significant differences between groups.</p>
        <p id="P44">More interestingly, <xref rid="F4" ref-type="fig">Fig. 4</xref> and <xref rid="T3" ref-type="table">Table III</xref> both support that the changes in the connectivity strengths of FNCs in the SZ group relative to the HC group were very consistent across the three datasets. Among the ten FNC features, the SZ group showed higher connectivity strengths than the HC group in four FNCs, including the connectivity between the thalamus and superior temporal gyrus, middle temporal gyrus and insula, middle temporal gyrus and anterior cingulate cortex, and right middle occipital gyrus and hippocampus. In contrast, the connectivity strengths of the remaining six FNCs were lower in the SZ group relative to the HC group. In sum, our method found the most significant FNCs that showed consistent changing trends in SZ across multiple datasets.</p>
      </sec>
      <sec id="S14">
        <label>C.</label>
        <title>Results of the Comprehensive Comparison of MGWNRE With Other Methods on All Datasets</title>
        <p id="P45">To compare the comprehensive classification performance of the feature selection methods based on the three classifiers, <xref rid="F5" ref-type="fig">Fig. 5</xref> shows the overall ranking of each method on the multiple datasets, including SRBCT, Colon, BRCA, FBIRN, BSNIP, and MPRC. The proposed MGWNRE not only ranked in the top but also had lower standard deviations than the other six competing methods based on each classifier. WNRE also obtained the suboptimal ranking based on the three classifiers. Taken together, the selected features by our methods are stable and discriminative in terms of classification performance.</p>
      </sec>
    </sec>
    <sec id="S15">
      <label>IV.</label>
      <title>Discussions</title>
      <p id="P46">In the neuroscience field, the identification of meaningful biomarkers of mental disorders from neuroimaging data is an important topic for the mission of precision diagnostics. Feature selection technologies help select meaningful features to construct an efficient and interpretable model with strong generalization capability [<xref rid="R5" ref-type="bibr">5</xref>]. Recently, feature selection has shown the potential in characterizing the aberrant brain functional connectivity of schizophrenia using fMRI data, however, the underlying neurological mechanism of the disorder remains unclear [<xref rid="R33" ref-type="bibr">33</xref>]. Neighborhood rough set-based feature selection methods have been shown to appropriately identify sparse and more discriminative features, but they are rarely used in biomarker exploration for brain disorders.</p>
      <p id="P47">Aiming at constructing a more effective feature evaluation metric and overcoming the shortcoming of the determination of neighborhood size in traditional NRS-based feature selection methods, we propose a new feature selection method, i.e., MGWNRE, to identify the sparse and important features that can distinguish different classes well. Herein, based on NRS theory and information entropy, we develop a feature evaluation metric that not only assesses the importance of features using both consistent and inconsistent samples but also highlights the dominant contribution of consistent samples. Based on the novel metric, we propose WNRE and extend it to a multi-granularity level (i.e., MGWNRE) to minimize the need in determining a prior neighborhood size, thus further ensuring the distinguishing capability as well as stability of the selected features. Moreover, we manifest the feasibility and effectiveness of the discriminative features selected by MGWNRE through comprehensive evaluations on omics and fMRI datasets. It is known that all supervised feature selection methods involved in the paper are for classification tasks in which the selected features are used for distinguishing different groups. However, sometimes a prediction task with continuous output also can be converted to a classification problem with discrete labels before using these methods [<xref rid="R34" ref-type="bibr">34</xref>].</p>
      <p id="P48">Comparing classification performance with the six state-of-the-art feature selection methods on the three omics datasets, our results demonstrated that MGWNRE can identify better discriminative features to separate different classes. In detail, the improved classification results using the features selected by MGWNRE indicated that the proposed method can effectively identify a small number of discriminative features to classify different groups, and present the superiority of MGWNRE over the competing methods. In addition, we found that the classification performances of compared NRS-based methods were generally inferior to non-NRS-based methods, although NRS-based methods can select fewer features. Impressively, our MGWNRE method not only outperformed the NRS-based methods, which indicated that the proposed feature importance metric more appropriately characterized the discriminative ability of features, but also outperformed non-NRS-based methods. In short, this experiment verified the practicability of MGWNRE in identifying the discriminative features.</p>
      <p id="P49">Findings from the fMRI datasets further support that the features detected by MGWNRE can distinguish SZ patients from HCs well. Specifically, MGWNRE method achieved a promising average accuracy of 93.9% based on 3NN classifier on the main fMRI dataset, whereas all competing methods had accuracies below 90%. Existing systematic reviews reported that using a sample size similar to our work, the classification accuracies of most previous studies classifying SZ patients and HCs were less than 90% [<xref rid="R35" ref-type="bibr">35</xref>], [<xref rid="R36" ref-type="bibr">36</xref>]. In addition, only using the top-10 high-frequency FNC features selected from the main fMRI dataset, MGWNRE also obtained satisfactory classification accuracies of 76.3% and 83.8% based on SVM classifier for the two independent cohorts, respectively. While the classification accuracies of the competing methods ranged from 65.1% to 81.7% based on SVM classifier on the independent cohorts. In previous studies differentiating SZ patients from HCs, the accuracies on completely independent datasets were around 70% [<xref rid="R37" ref-type="bibr">37</xref>]. The high classification accuracy on independent datasets in our work demonstrated the robustness and stability of the features selected by our MGWNRE. In short, our proposed feature importance metric in WNRE can efficiently represent the discriminative ability of features. In the meantime, MGWNRE further improves the single-granularity WNRE method by providing complementary information at different granularity levels.</p>
      <p id="P50">Furthermore, our work highlights a small number of discriminative functional connectivity that contributes to distinguish HCs and SZ patients. Based on our MGWNRE, we analyzed top-10 important FNC features, primarily including the thalamus, cerebellum, temporal (e.g., middle and superior temporal gyrus), parietal (e.g., left and right postcentral gyrus, and superior parietal lobule), occipital gyrus (e.g., right middle and inferior occipital gyrus), and calcarine gyrus regions, which showed abnormalities in SZ patients compared with HCs. Specifically, SZ patients showed significantly altered thalamus-related functional connectivity, including lower thalamic functional connectivity with the cerebellum and caudate, and significantly higher thalamic functional connectivity with the superior temporal gyrus. Indeed, it is well known that the thalamus plays a key role in information processing in the brain and shows significant abnormalities in SZ. Previous studies have reported the analogous aberrant functional connectivity in SZ patients. Using resting-state seed-based functional connectivity, Ferri et al. found that SZ patients had smaller thalamic connectivity with the cerebellum and greater thalamic connectivity with multiple sensory-motor regions, including the superior temporal gyrus [<xref rid="R29" ref-type="bibr">29</xref>]. Also using the seed-based functional connectivity, Huang et al. studied the functional dysconnectivity pattern of salience network in first-episode SZ patients which had shown a notable reduced functional connectivity between the thalamus and caudate head compared with HCs [<xref rid="R38" ref-type="bibr">38</xref>]. In addition, we found that SZ patients presented lower connectivity between the superior parietal lobule and inferior occipital gyrus compared with HCs, which is consistent with a previous study that also reported lower connectivity between the superior parietal and occipital cortex [<xref rid="R39" ref-type="bibr">39</xref>]. More importantly, new findings have been observed in our paper: (1) significantly lower connectivity between postcentral gyrus and calcarine gyrus in SZ patients (compared with HCs); (2) higher connectivity between middle temporal gyrus and insula, between middle temporal gyrus and anterior cingulate cortex, and between right middle occipital gyrus and hippocampus in SZ patients (compared with HCs). In terms of the first new finding, we have good reason to speculate that the interaction between sensory function and visual processing might be disrupted in SZ because of the reduced connectivity between the postcentral gyrus (the primary sensory receiving area of touch) and the calcarine gyrus (closely related to the visual processing) [<xref rid="R40" ref-type="bibr">40</xref>], [<xref rid="R41" ref-type="bibr">41</xref>]. In recent research, Ramsay et al. also highlighted the relationship between the low-level visual sensory discrimination impairments and the cognitive disruptions of mental disorders including SZ [<xref rid="R42" ref-type="bibr">42</xref>]. For the second new finding, as is well known that the middle temporal gyrus is involved in language and semantic memory processing, and the insula as well as anterior cingulate cortex are both closely linked to cognitive and emotional processing [<xref rid="R43" ref-type="bibr">43</xref>], [<xref rid="R44" ref-type="bibr">44</xref>], [<xref rid="R45" ref-type="bibr">45</xref>], our findings further indicated that the information communication between language and emotional processing might be extremely active in SZ. A study indirectly supporting our findings reported that SZ patients have shown a larger negative response to negative words than HCs, which indicated the anomalies in the interactions between semantic and emotion processing of SZ [<xref rid="R46" ref-type="bibr">46</xref>]. Additionally, studies have shown that the occipital cortex is associated with the maintenance of visuospatial information, and the hippocampus plays a crucial role in memory and learning [<xref rid="R39" ref-type="bibr">39</xref>], [<xref rid="R47" ref-type="bibr">47</xref>]. The higher connectivity between the occipital gyrus and hippocampus that we found in this paper would support that vision abnormality (e.g., hallucinations) in SZ may be associated with memory impairments. Taken together, we found important brain functional impairments in SZ by using our proposed method, as the few related features selected by our method can distinguish the SZ and HC groups well using different datasets.</p>
    </sec>
    <sec id="S16">
      <label>V.</label>
      <title>Conclusion</title>
      <p id="P51">In this paper, a new NRS-based feature selection method, named MGWNRE, is proposed to identify the sparse and important features that can distinguish different classes well and is applied to explore biomarkers revealing brain functional impairments in SZ. A new feature evaluation metric is developed in MGWNRE, which not only makes full use of all samples when assessing feature importance but also emphasizes the contribution of consistent samples in the assessment. The use of sufficient data in assessing the features’ importance ensures that more complete and reliable important features can be selected in our method. More importantly, the multi-granularity idea in MGWNRE incorporates complementarily important features selected at different granularities, further improving the stability and generalization ability of the selected features. We verify the effectiveness and superiority of the proposed MGWNRE method over six competing methods on three well-known omics datasets and three fMRI datasets. Furthermore, the reliable biomarkers of SZ are identified based on MGWNRE, which reveals brain functional impairments of SZ. However, it should be noted that more computation time is an inherent shortcoming of all NRS-based feature selection methods, although the computation efficiency of our proposed methods is comparable to previous NRS-based methods. In addition, single-modal data could not fully characterize all abnormalities of SZ, and we expect to further validate the proposed method by integrating multimodal data.</p>
    </sec>
  </body>
  <back>
    <ack id="S17">
      <p id="P52">This work was supported in part by the National Natural Science Foundation of China through YHD under Grants 62076157 and 61703253, in part by the Fund Program for the Scientific Activities of Selected Returned Overseas Professionals in Shanxi Province through YHD, in part by the 1331 Engineering Project of Shanxi Province of China, in part by the National Institutes of Health under Grants R01MH118695 and NIH R01MH123610, and in part by NSF under Grant 2112455 through VDC.</p>
    </ack>
    <fn-group>
      <fn id="FN1">
        <label>1</label>
        <p id="P53">The reference number of the IRB approval for FBIRN data is HS No.2009-7128.</p>
      </fn>
      <fn id="FN2">
        <label>2</label>
        <p id="P54">The original source of BSNIP data can be found at <ext-link xlink:href="https://nda.nih.gov/" ext-link-type="uri">https://nda.nih.gov/</ext-link>.</p>
      </fn>
      <fn id="FN3">
        <label>3</label>
        <p id="P55">The reference number of the IRB approval forMPRC data is HP-00045716.</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="R1">
        <label>[1]</label>
        <mixed-citation publication-type="journal"><name><surname>Rondina</surname><given-names>JM</given-names></name>
<etal/>, “<article-title>SCoRS—A method based on stability for feature selection and mapping in neuroimaging</article-title>,” <source>IEEE Trans. Med. Imag</source>, vol. <volume>33</volume>, no. <issue>1</issue>, pp. <fpage>85</fpage>–<lpage>98</lpage>, <month>Jan</month>. <year>2014</year>.</mixed-citation>
      </ref>
      <ref id="R2">
        <label>[2]</label>
        <mixed-citation publication-type="journal"><name><surname>Xia</surname><given-names>CH</given-names></name>
<etal/>, “<article-title>Linked dimensions of psychopathology and connectivity in functional brain networks</article-title>,” <source>Nature Commun</source>, vol. <volume>9</volume>, no. <issue>1</issue>, pp. <fpage>1</fpage>–<lpage>14</lpage>, <year>2018</year>.<pub-id pub-id-type="pmid">29317637</pub-id></mixed-citation>
      </ref>
      <ref id="R3">
        <label>[3]</label>
        <mixed-citation publication-type="journal"><name><surname>Rueda</surname><given-names>A</given-names></name>, <name><surname>González</surname><given-names>FA</given-names></name>, and <name><surname>Romero</surname><given-names>E</given-names></name>, “<article-title>Extracting salient brain patterns for imaging-based classification of neurodegenerative diseases</article-title>,” <source>IEEE Trans. Med. Imag</source>, vol. <volume>33</volume>, no. <issue>6</issue>, pp. <fpage>1262</fpage>–<lpage>1274</lpage>, <month>Jun</month>. <year>2014</year>.</mixed-citation>
      </ref>
      <ref id="R4">
        <label>[4]</label>
        <mixed-citation publication-type="journal"><name><surname>Zheng</surname><given-names>Q</given-names></name>, <name><surname>Delingette</surname><given-names>H</given-names></name>, <name><surname>Fung</surname><given-names>K</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, and <name><surname>Ayache</surname><given-names>N</given-names></name>, “<article-title>Pathological cluster identification by unsupervised analysis in 3,822 U.K. biobank cardiac MRIs</article-title>,” <source>Front. Cardiovasc. Med</source>, vol. <volume>7</volume>, <year>2020</year>, <comment>Art. no. 539788.</comment></mixed-citation>
      </ref>
      <ref id="R5">
        <label>[5]</label>
        <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>J</given-names></name>
<etal/>, “<article-title>Feature selection: A data perspective</article-title>,” <source>ACM Comput. Surv</source>, vol. <volume>50</volume>, no. <issue>6</issue>, pp. <fpage>1</fpage>–<lpage>45</lpage>, <year>2017</year>.</mixed-citation>
      </ref>
      <ref id="R6">
        <label>[6]</label>
        <mixed-citation publication-type="journal"><name><surname>Cai</surname><given-names>J</given-names></name> and <name><surname>Luo</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>S</given-names></name>, and <name><surname>Yang</surname><given-names>S</given-names></name>, “<article-title>Feature selection in machine learning: A new perspective</article-title>,” <source>Neurocomputing</source>, vol. <volume>300</volume>, pp. <fpage>70</fpage>–<lpage>79</lpage>, <year>2018</year>.</mixed-citation>
      </ref>
      <ref id="R7">
        <label>[7]</label>
        <mixed-citation publication-type="journal"><name><surname>Gu</surname><given-names>Q</given-names></name>, <name><surname>Li</surname><given-names>Z</given-names></name>, and <name><surname>Han</surname><given-names>J</given-names></name>, “<article-title>Generalized fisher score for feature selection</article-title>,” in <source>Proc. Conf. UAI</source>, <year>2012</year>, pp. <fpage>266</fpage>–<lpage>273</lpage>.</mixed-citation>
      </ref>
      <ref id="R8">
        <label>[8]</label>
        <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>T</given-names></name>, <name><surname>Zhao</surname><given-names>Z</given-names></name>, <name><surname>Zhang</surname><given-names>C</given-names></name>, <name><surname>Zhang</surname><given-names>J</given-names></name>, <name><surname>Jin</surname><given-names>Z</given-names></name>, and <name><surname>Li</surname><given-names>L</given-names></name>, “<article-title>Classification of early and late mild cognitive impairment using functional brain network of resting-state fMRI</article-title>,” <source>Front. Psychiatry</source>, vol. <volume>10</volume>, <year>2019</year>, <comment>Art. no. 572.</comment></mixed-citation>
      </ref>
      <ref id="R9">
        <label>[9]</label>
        <mixed-citation publication-type="confproc"><name><surname>Kira</surname><given-names>K</given-names></name> and <name><surname>Rendell</surname><given-names>LA</given-names></name>, “<source>A practical approach to feature selection</source>,” in <conf-name>Proc. Int. Conf. Mach. Learn.</conf-name>, <year>1992</year>, pp. <fpage>249</fpage>–<lpage>256</lpage>.</mixed-citation>
      </ref>
      <ref id="R10">
        <label>[10]</label>
        <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>Z</given-names></name>, <name><surname>Yang</surname><given-names>C</given-names></name>, <name><surname>Zhou</surname><given-names>X</given-names></name>, and <name><surname>Huang</surname><given-names>T</given-names></name>, “<article-title>A hybrid feature selection method based on binary state transition algorithm and ReliefF</article-title>,” <source>IEEE J. Biomed. Health Inform</source>, vol. <volume>23</volume>, no. <issue>5</issue>, pp. <fpage>1888</fpage>–<lpage>1898</lpage>, <month>Sep</month>. <year>2019</year>.<pub-id pub-id-type="pmid">30281502</pub-id></mixed-citation>
      </ref>
      <ref id="R11">
        <label>[11]</label>
        <mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>Z</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <name><surname>Liu</surname><given-names>H</given-names></name>, and <name><surname>Ye</surname><given-names>J</given-names></name>, “<article-title>On similarity preserving feature selection</article-title>,” <source>IEEE Trans. Knowl. Data Eng</source>, vol. <volume>25</volume>, no. <issue>3</issue>, pp. <fpage>619</fpage>–<lpage>632</lpage>, <month>Mar</month>. <year>2013</year>.</mixed-citation>
      </ref>
      <ref id="R12">
        <label>[12]</label>
        <mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>H</given-names></name>, <name><surname>Long</surname><given-names>F</given-names></name>, and <name><surname>Ding</surname><given-names>C</given-names></name>, “<article-title>Feature selection based on mutual information criteria of max-dependency, max-relevance, and min-redundancy</article-title>,” <source>IEEE Trans. Pattern Anal. Mach. Intell</source>, vol. <volume>27</volume>, no. <issue>8</issue>, pp. <fpage>1226</fpage>–<lpage>1238</lpage>, <month>Aug</month>. <year>2005</year>.<pub-id pub-id-type="pmid">16119262</pub-id></mixed-citation>
      </ref>
      <ref id="R13">
        <label>[13]</label>
        <mixed-citation publication-type="journal"><name><surname>Bron</surname><given-names>EE</given-names></name>, <name><surname>Smits</surname><given-names>M</given-names></name>, <name><surname>Niessen</surname><given-names>WJ</given-names></name>, and <name><surname>Klein</surname><given-names>S</given-names></name>, “<article-title>Feature selection based on the SVM weight vector for classification of dementia</article-title>,” <source>IEEE J. Biomed. Health. Inform</source>, vol. <volume>19</volume>, no. <issue>5</issue>, pp. <fpage>1617</fpage>–<lpage>1626</lpage>, <month>Sep</month>. <year>2015</year>.<pub-id pub-id-type="pmid">25974958</pub-id></mixed-citation>
      </ref>
      <ref id="R14">
        <label>[14]</label>
        <mixed-citation publication-type="journal"><name><surname>Du</surname><given-names>Y</given-names></name>, <name><surname>Hao</surname><given-names>H</given-names></name>, <name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Pearlson</surname><given-names>GD</given-names></name>, and <name><surname>Calhoun</surname><given-names>VD</given-names></name>, “<article-title>Identifying commonality and specificity across psychosis sub-groups via classification based on features from dynamic connectivity analysis</article-title>,”<source>NeuroImage: Clin</source>, vol. <volume>27</volume>, <year>2020</year>, <comment>Art. no. 102284.</comment></mixed-citation>
      </ref>
      <ref id="R15">
        <label>[15]</label>
        <mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>Q</given-names></name>, <name><surname>Pedrycz</surname><given-names>W</given-names></name>, <name><surname>Yu</surname><given-names>D</given-names></name>, and <name><surname>Lang</surname><given-names>J</given-names></name>, “<article-title>Selecting discrete and continuous features based on neighborhood decision error minimization</article-title>,” <source>Trans. Syst. Man Cybern. Part B-Cybern</source>, vol. <volume>40</volume>, no. <issue>1</issue>, pp. <fpage>137</fpage>–<lpage>150</lpage>, <year>2010</year>.</mixed-citation>
      </ref>
      <ref id="R16">
        <label>[16]</label>
        <mixed-citation publication-type="journal"><name><surname>Yong</surname><given-names>L</given-names></name>, <name><surname>Wenliang</surname><given-names>H</given-names></name>, <name><surname>Yunliang</surname><given-names>J</given-names></name>, and <name><surname>Zhiyong</surname><given-names>Z</given-names></name>, “<article-title>Quick attribute reduct algorithm for neighborhood rough set model</article-title>,” <source>Inf. Sci</source>, vol. <volume>271</volume>, pp. <fpage>65</fpage>–<lpage>81</lpage>, <year>2014</year>.</mixed-citation>
      </ref>
      <ref id="R17">
        <label>[17]</label>
        <mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>Q</given-names></name>, <name><surname>Yu</surname><given-names>D</given-names></name>, <name><surname>Liu</surname><given-names>J</given-names></name>, and <name><surname>Wu</surname><given-names>C</given-names></name>, “<article-title>Neighborhood rough set based heterogeneous feature subset selection</article-title>,” <source>Inf. Sci</source>, vol. <volume>178</volume>, no. <issue>18</issue>, pp. <fpage>3577</fpage>–<lpage>3594</lpage>, <year>2008</year>.</mixed-citation>
      </ref>
      <ref id="R18">
        <label>[18]</label>
        <mixed-citation publication-type="journal"><name><surname>Sun</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, and <name><surname>Zhang</surname><given-names>S</given-names></name>, “<article-title>An attribute reduction method using neighborhood entropy measures in neighborhood rough sets</article-title>,” <source>Entropy</source>, vol. <volume>21</volume>, no. <issue>2</issue>, <year>2019</year>, <comment>Art. no. 155.</comment></mixed-citation>
      </ref>
      <ref id="R19">
        <label>[19]</label>
        <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <name><surname>Zheng</surname><given-names>J</given-names></name>, <name><surname>Ma</surname><given-names>Y</given-names></name>, and <name><surname>Xue</surname><given-names>Y</given-names></name>, “<article-title>Gene selection for tumor classification using neighborhood rough sets and entropy measures</article-title>,” <source>J. Biomed. Inform</source>, vol. <volume>67</volume>, pp. <fpage>59</fpage>–<lpage>68</lpage>, <year>2017</year>.<pub-id pub-id-type="pmid">28215562</pub-id></mixed-citation>
      </ref>
      <ref id="R20">
        <label>[20]</label>
        <mixed-citation publication-type="journal"><name><surname>Sun</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Qian</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, and <name><surname>Zhang</surname><given-names>S</given-names></name>, “<article-title>Feature selection using neighborhood entropy-based uncertainty measures for gene expression data classification</article-title>,” <source>Inf. Sci</source>, vol. <volume>502</volume>, pp. <fpage>18</fpage>–<lpage>41</lpage>, <year>2019</year>.</mixed-citation>
      </ref>
      <ref id="R21">
        <label>[21]</label>
        <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Cai</surname><given-names>M</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>, and <name><surname>Li</surname><given-names>Q</given-names></name>, “<article-title>Accelerated multi-granularity reduction based on neighborhood rough sets</article-title>,” <source>Appl. Intell</source>, pp. <fpage>1</fpage>–<lpage>16</lpage>, <year>2022</year>.</mixed-citation>
      </ref>
      <ref id="R22">
        <label>[22]</label>
        <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Y</given-names></name>, <name><surname>Li</surname><given-names>J</given-names></name>, <name><surname>Lin</surname><given-names>P</given-names></name>, <name><surname>Lin</surname><given-names>G</given-names></name>, and <name><surname>Chen</surname><given-names>J</given-names></name>, “<article-title>Feature selection via neighborhood multi-granulation fusion</article-title>,” <source>Knowl.-Based Syst</source>, vol. <volume>67</volume>, pp. <fpage>162</fpage>–<lpage>168</lpage>, <year>2014</year>.</mixed-citation>
      </ref>
      <ref id="R23">
        <label>[23]</label>
        <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>K</given-names></name>, <name><surname>Yang</surname><given-names>X</given-names></name>, <name><surname>Fujita</surname><given-names>H</given-names></name>, <name><surname>Liu</surname><given-names>D</given-names></name>, <name><surname>Yang</surname><given-names>X</given-names></name>, and <name><surname>Qian</surname><given-names>Y</given-names></name>, “<article-title>An efficient selector for multi-granularity attribute reduction</article-title>,” <source>Inf. Sci</source>, vol. <volume>505</volume>, pp. <fpage>457</fpage>–<lpage>472</lpage>, <year>2019</year>.</mixed-citation>
      </ref>
      <ref id="R24">
        <label>[24]</label>
        <mixed-citation publication-type="journal"><name><surname>Wilson</surname><given-names>DR</given-names></name> and <name><surname>Martinez</surname><given-names>TR</given-names></name>, “<article-title>Improved heterogeneous distance functions</article-title>,” <source>J. Artif. Intell. Res</source>, vol. <volume>6</volume>, pp. <fpage>1</fpage>–<lpage>34</lpage>, <year>1997</year>.</mixed-citation>
      </ref>
      <ref id="R25">
        <label>[25]</label>
        <mixed-citation publication-type="journal"><name><surname>Dai</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>W</given-names></name>, <name><surname>Tian</surname><given-names>H</given-names></name>, and <name><surname>Liu</surname><given-names>L</given-names></name>, “<article-title>Attribute selection based on a new conditional entropy for incomplete decision systems</article-title>,” <source>Knowl.-Based Syst</source>, vol. <volume>39</volume>, pp. <fpage>207</fpage>–<lpage>213</lpage>, <year>2013</year>.</mixed-citation>
      </ref>
      <ref id="R26">
        <label>[26]</label>
        <mixed-citation publication-type="journal"><name><surname>Shannon</surname><given-names>CE</given-names></name>, “<article-title>A mathematical theory of communication</article-title>,” <source>Bell system Tech. J</source>, vol. <volume>27</volume>, no. <issue>3</issue>, pp. <fpage>379</fpage>–<lpage>423</lpage>, <year>1948</year>.</mixed-citation>
      </ref>
      <ref id="R27">
        <label>[27]</label>
        <mixed-citation publication-type="journal"><name><surname>Freund</surname><given-names>Y</given-names></name> and <name><surname>Schapire</surname><given-names>RE</given-names></name>, “<article-title>A decision-theoretic generalization of on-line learning and an application to boosting</article-title>,” <source>J. Comput. System Sci</source>, vol. <volume>55</volume>, no. <issue>1</issue>, pp. <fpage>119</fpage>–<lpage>139</lpage>, <year>1997</year>.</mixed-citation>
      </ref>
      <ref id="R28">
        <label>[28]</label>
        <mixed-citation publication-type="journal"><name><surname>Goldman</surname><given-names>M</given-names></name>
<etal/>, “<article-title>The UCSC cancer genomics browser: Update 2015</article-title>,” <source>Nucleic Acids Res</source>, vol. <volume>43</volume>, no. <issue>D1</issue>, pp. <fpage>D812</fpage>–<lpage>D817</lpage>, <year>2015</year>.<pub-id pub-id-type="pmid">25392408</pub-id></mixed-citation>
      </ref>
      <ref id="R29">
        <label>[29]</label>
        <mixed-citation publication-type="journal"><name><surname>Ferri</surname><given-names>J</given-names></name>
<etal/>, “<article-title>Resting-state thalamic dysconnectivity in schizophrenia and relationships with symptoms</article-title>,” <source>Psychol. Med</source>, vol. <volume>48</volume>, no. <issue>15</issue>, pp. <fpage>2492</fpage>–<lpage>2499</lpage>, <year>2018</year>.<pub-id pub-id-type="pmid">29444726</pub-id></mixed-citation>
      </ref>
      <ref id="R30">
        <label>[30]</label>
        <mixed-citation publication-type="journal"><name><surname>Tamminga</surname><given-names>CA</given-names></name>, <name><surname>Pearlson</surname><given-names>G</given-names></name>, <name><surname>Keshavan</surname><given-names>M</given-names></name>, <name><surname>Sweeney</surname><given-names>J</given-names></name>, <name><surname>Clementz</surname><given-names>B</given-names></name>, and <name><surname>Thaker</surname><given-names>G</given-names></name>, “<article-title>Bipolar and schizophrenia network for intermediate phenotypes: Outcomes across the psychosis continuum</article-title>,” <source>Schizophrenia Bull</source>, vol. <volume>40</volume>, no. <issue>Suppl</issue>_2, pp. <fpage>S131</fpage>–<lpage>S137</lpage>, <year>2014</year>.</mixed-citation>
      </ref>
      <ref id="R31">
        <label>[31]</label>
        <mixed-citation publication-type="journal"><name><surname>Duand</surname><given-names>Y</given-names></name><name><surname>Fan</surname><given-names>Y</given-names></name>, “<article-title>Group information guided ICA for fMRI data analysis</article-title>,” <source>Neuroimage</source>, vol. <volume>69</volume>, pp. <fpage>157</fpage>–<lpage>197</lpage>, <year>2013</year>..<pub-id pub-id-type="pmid">23194820</pub-id></mixed-citation>
      </ref>
      <ref id="R32">
        <label>[32]</label>
        <mixed-citation publication-type="journal"><name><surname>Du</surname><given-names>Y</given-names></name>
<etal/>, “<article-title>NeuroMark: An automated and adaptive ICA based pipeline to identify reproducible fMRI markers of brain disorders</article-title>,” <source>NeuroImage: Clin</source>, vol. <volume>28</volume>, <year>2020</year>, <comment>Art. no. 102375.</comment></mixed-citation>
      </ref>
      <ref id="R33">
        <label>[33]</label>
        <mixed-citation publication-type="journal"><name><surname>Jafri</surname><given-names>MJ</given-names></name>, <name><surname>Pearlson</surname><given-names>GD</given-names></name>, <name><surname>Stevens</surname><given-names>M</given-names></name>, and <name><surname>Calhoun</surname><given-names>VD</given-names></name>, “<article-title>A method for functional network connectivity among spatially independent resting-state components in schizophrenia</article-title>,”<source>Neuroimage</source>, vol. <volume>39</volume>, no. <issue>4</issue>, pp. <fpage>1666</fpage>–<lpage>1681</lpage>, <year>2008</year>.<pub-id pub-id-type="pmid">18082428</pub-id></mixed-citation>
      </ref>
      <ref id="R34">
        <label>[34]</label>
        <mixed-citation publication-type="journal"><name><surname>El-Manzalawy</surname><given-names>Y</given-names></name>, <name><surname>Hsieh</surname><given-names>T-Y</given-names></name>, <name><surname>Shivakumar</surname><given-names>M</given-names></name>, <name><surname>Kim</surname><given-names>D</given-names></name>, and <name><surname>Honavar</surname><given-names>V</given-names></name>, “<article-title>Min-redundancy and max-relevance multi-view feature selection for predicting ovarian cancer survival using multi-omics data</article-title>,” <source>BMC Med. Genomic</source>, vol. <volume>11</volume>, no. <issue>3</issue>, pp. <fpage>19</fpage>–<lpage>31</lpage>, <year>2018</year>.</mixed-citation>
      </ref>
      <ref id="R35">
        <label>[35]</label>
        <mixed-citation publication-type="journal"><name><surname>Steardo</surname><given-names>L</given-names><suffix>Jr.</suffix></name>
<etal/>, “<article-title>Application of support vector machine on fMRI data as biomarkers in schizophrenia diagnosis: A systematic review</article-title>,” <source>Front. Psychiatry</source>, vol. <volume>11</volume>, <year>2020</year>, <comment>Art. no. 588.</comment></mixed-citation>
      </ref>
      <ref id="R36">
        <label>[36]</label>
        <mixed-citation publication-type="journal"><name><surname>Rashid</surname><given-names>B</given-names></name> and <name><surname>Calhoun</surname><given-names>V</given-names></name>, “<article-title>Towards a brain-based predictome of mental illness</article-title>,” <source>Hum. Brain Mapping</source>, vol. <volume>41</volume>, no. <issue>12</issue>, pp. <fpage>3468</fpage>–<lpage>3535</lpage>, <year>2020</year>.</mixed-citation>
      </ref>
      <ref id="R37">
        <label>[37]</label>
        <mixed-citation publication-type="journal"><name><surname>Cai</surname><given-names>XL</given-names></name>
<etal/>, “<article-title>Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data</article-title>,” <source>Hum. Brain Mapping</source>, vol. <volume>41</volume>, no. <issue>1</issue>, pp. <fpage>172</fpage>–<lpage>184</lpage>, <year>2020</year>.</mixed-citation>
      </ref>
      <ref id="R38">
        <label>[38]</label>
        <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>H</given-names></name>
<etal/>, “<article-title>Aberrant resting-state functional connectivity of salience network in first-episode schizophrenia</article-title>,” <source>Brain Imag. Behav</source>, vol. <volume>14</volume>, no. <issue>5</issue>, pp. <fpage>1350</fpage>–<lpage>1360</lpage>, <year>2020</year>.</mixed-citation>
      </ref>
      <ref id="R39">
        <label>[39]</label>
        <mixed-citation publication-type="journal"><name><surname>Henseler</surname><given-names>I</given-names></name>, <name><surname>Falkai</surname><given-names>P</given-names></name>, and <name><surname>Gruber</surname><given-names>O</given-names></name>, “<article-title>Disturbed functional connectivity within brain networks subserving domain-specific subcomponents of working memory in schizophrenia: Relation to performance and clinical symptoms</article-title>,” <source>J. Psychiatr. Res</source>, vol. <volume>44</volume>, no. <issue>6</issue>, pp. <fpage>364</fpage>–<lpage>372</lpage>, <year>2010</year>.<pub-id pub-id-type="pmid">19837416</pub-id></mixed-citation>
      </ref>
      <ref id="R40">
        <label>[40]</label>
        <mixed-citation publication-type="journal"><name><surname>Ploner</surname><given-names>M</given-names></name>, <name><surname>Schmitz</surname><given-names>F</given-names></name>, <name><surname>Freund</surname><given-names>H-J</given-names></name>, and <name><surname>Schnitzler</surname><given-names>A</given-names></name>, “<article-title>Differential organization of touch and pain in human primary somatosensory cortex</article-title>,” <source>J. Neurophysiol</source>, vol. <volume>83</volume>, no. <issue>3</issue>, pp. <fpage>1770</fpage>–<lpage>1776</lpage>, <year>2000</year>.<pub-id pub-id-type="pmid">10712498</pub-id></mixed-citation>
      </ref>
      <ref id="R41">
        <label>[41]</label>
        <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>RR</given-names></name>
<etal/>, “<article-title>Altered functional connectivity strength and its correlations with cognitive function in subjects with ultra-high risk for psychosis at rest</article-title>,” <source>CNS Neurosci. Therapeutics</source>, vol. <volume>24</volume>, no. <issue>12</issue>, pp. <fpage>1140</fpage>–<lpage>1148</lpage>, <year>2018</year>.</mixed-citation>
      </ref>
      <ref id="R42">
        <label>[42]</label>
        <mixed-citation publication-type="journal"><name><surname>Ramsay</surname><given-names>IS</given-names></name>, <name><surname>Schallmo</surname><given-names>M-P</given-names></name>, <name><surname>Biagianti</surname><given-names>B</given-names></name>, <name><surname>Fisher</surname><given-names>M</given-names></name>, <name><surname>Vinogradov</surname><given-names>S</given-names></name>, and <name><surname>Sponheim</surname><given-names>SR</given-names></name>, “<article-title>Deficits in auditory and visual sensory discrimination reflect a genetic liability for psychosis and predict disruptions in global cognitive functioning</article-title>,” <source>Front. Psychiatry</source>, vol. <volume>11</volume>, <year>2020</year>, <comment>Art. no. 638.</comment></mixed-citation>
      </ref>
      <ref id="R43">
        <label>[43]</label>
        <mixed-citation publication-type="journal"><name><surname>Bush</surname><given-names>G</given-names></name>, <name><surname>Luu</surname><given-names>P</given-names></name>, and <name><surname>Posner</surname><given-names>MI</given-names></name>, “<article-title>Cognitive and emotional influences in anterior cingulate cortex</article-title>,” <source>Trends Cogn. Sci</source>, vol. <volume>4</volume>, no. <issue>6</issue>, pp. <fpage>215</fpage>–<lpage>222</lpage>, <year>2000</year>.<pub-id pub-id-type="pmid">10827444</pub-id></mixed-citation>
      </ref>
      <ref id="R44">
        <label>[44]</label>
        <mixed-citation publication-type="journal"><name><surname>Onitsuka</surname><given-names>T</given-names></name>
<etal/>, “<article-title>Middle and inferior temporal gyrus gray matter volume abnormalities in chronic schizophrenia: An MRI study</article-title>,” <source>Amer. J. Psychiatry</source>, vol. <volume>161</volume>, no. <issue>9</issue>, pp. <fpage>1603</fpage>–<lpage>1611</lpage>, <year>2004</year>.<pub-id pub-id-type="pmid">15337650</pub-id></mixed-citation>
      </ref>
      <ref id="R45">
        <label>[45]</label>
        <mixed-citation publication-type="journal"><name><surname>Wylie</surname><given-names>KP</given-names></name> and <name><surname>Tregellas</surname><given-names>JR</given-names></name>, “<article-title>The role of the insula in schizophrenia</article-title>,” <source>Schizophrenia Res</source>, vol. <volume>123</volume>, no. <issue>2–3</issue>, pp. <fpage>93</fpage>–<lpage>104</lpage>, <year>2010</year>.</mixed-citation>
      </ref>
      <ref id="R46">
        <label>[46]</label>
        <mixed-citation publication-type="journal"><name><surname>Klumpp</surname><given-names>H</given-names></name>, <name><surname>Keller</surname><given-names>J</given-names></name>, <name><surname>Miller</surname><given-names>GA</given-names></name>, <name><surname>Casas</surname><given-names>BR</given-names></name>, <name><surname>Best</surname><given-names>JL</given-names></name>, and <name><surname>Deldin</surname><given-names>PJ</given-names></name>, “<article-title>Semantic processing of emotional words in depression and schizophrenia</article-title>,” <source>Int. J. Psychophysiol</source>, vol. <volume>75</volume>, no. <issue>2</issue>, pp. <fpage>211</fpage>–<lpage>215</lpage>, <year>2010</year>.<pub-id pub-id-type="pmid">20006969</pub-id></mixed-citation>
      </ref>
      <ref id="R47">
        <label>[47]</label>
        <mixed-citation publication-type="journal"><name><surname>Anand</surname><given-names>KS</given-names></name> and <name><surname>Dhikav</surname><given-names>V</given-names></name>, “<article-title>Hippocampus in health and disease: An overview</article-title>,” <source>Ann. Indian Acad. Neurol</source>, vol. <volume>15</volume>, no. <issue>4</issue>, <year>2012</year>, <comment>Art. no. 239.</comment></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig position="float" id="F1">
      <label>Fig. 1.</label>
      <caption>
        <p id="P56">The experimental pipelines for the proposed methods (i.e., WNRE and MGWNRE) and the competing methods (i.e., NDDM, EGGS, FSDNE, UCFS, ReliefF, and SVM-RFE). (a) Denotes the outer 10-fold cross-validation with embedded inner 5-fold cross-validation experimental pipeline of each method on main datasets (i.e., the SRBCT, Colon, BRCA, and FBIRN datasets). (b) Denotes a 10-fold cross-validation experimental pipeline on independent datasets (i.e., the BSNIP and MPRC datasets) using the top-10 high-frequency features selected from the FBIRN dataset by each method. FiSc is the abbreviation for Fisher score-based feature selection method, which is used to preselect candidate features to improve computing efficiency. Classification performance includes accuracy, sensitivity, and specificity.</p>
      </caption>
      <graphic xlink:href="nihms-1862735-f0001" position="float"/>
    </fig>
    <fig position="float" id="F2">
      <label>Fig. 2.</label>
      <caption>
        <p id="P57">Classification performance of various methods on omics datasets. (a–c) Show the classification performance on SRBCT dataset based on SVM, 3NN, and AdaBoost classifiers, respectively. (d–f) Show the classification performance on Colon dataset based on SVM, 3NN, and AdaBoost classifiers, respectively. (g–i) Show the classification performance on BRCA dataset based on SVM, 3NN, and AdaBoost classifiers, respectively. “♦” means the average value of 10-fold cross-validation results.</p>
      </caption>
      <graphic xlink:href="nihms-1862735-f0002" position="float"/>
    </fig>
    <fig position="float" id="F3">
      <label>Fig. 3.</label>
      <caption>
        <p id="P58">Classification performance of various methods on fMRI datasets. (a–c) Show the classification performance on the main dataset (i.e., FBIRN) based on SVM, 3NN, and AdaBoost classifiers, respectively. (d–f) Show the classification performance on the independent dataset (i.e., BSNIP) based on SVM, 3NN, and AdaBoost classifiers, respectively. (g–i) Show the classification performance on the other independent dataset (i.e., MPRC) based on SVM, 3NN, and AdaBoost classifiers, respectively. “♦” means the average value of 10-fold cross-validation results.</p>
      </caption>
      <graphic xlink:href="nihms-1862735-f0003" position="float"/>
    </fig>
    <fig position="float" id="F4">
      <label>Fig. 4.</label>
      <caption>
        <p id="P59">Average FNC strength of HC and SZ groups on the features selected by MGWNRE for (a) FBIRN dataset, (b) BSNIP dataset, and (c) MPRC dataset. The brain is divided into seven brain functional domains, including sub-cortical (SC), auditory (AU), sensorimotor (SM), visual (VI), cognitive-control (CC), default-mode (DM), and cerebellar (CB) domains. “Corr” represents the connectivity strength between different ICs. IC denotes the independent component representing one brain functional network.</p>
      </caption>
      <graphic xlink:href="nihms-1862735-f0004" position="float"/>
    </fig>
    <fig position="float" id="F5">
      <label>Fig. 5.</label>
      <caption>
        <p id="P60">Algorithm ranking chart of the comprehensive classification performance based on (a) SVM classifier, (b) 3NN classifier, and (c) AdaBoost classifier for different feature selection methods on all datasets, including SRBCT, Colon, BRCA, FBIRN, BSNIP, and MPRC datasets. For each method, the red diamond symbol indicates the ranking, and the length of the blue horizontal line represents the standard deviation of the comprehensive classification performances on multiple datasets.</p>
      </caption>
      <graphic xlink:href="nihms-1862735-f0005" position="float"/>
    </fig>
    <table-wrap position="float" id="T1" orientation="landscape">
      <label>Table I</label>
      <caption>
        <p id="P61">Classification Performance and the Number of Selected Features of Various Methods on Omics Datasets, Including SRBCT, Colon, and BRCA. THE Used Classifiers Include SVM, 3NN, and AdaBoost</p>
      </caption>
      <table frame="hsides" rules="none">
        <colgroup span="1">
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="3" align="left" valign="middle" colspan="1">Datasets</th>
            <th rowspan="3" align="left" valign="middle" colspan="1">Methods</th>
            <th colspan="3" align="center" valign="top" rowspan="1">SVM</th>
            <th colspan="3" align="left" valign="top" rowspan="1">3NN</th>
            <th colspan="3" align="left" valign="top" rowspan="1">AdaBoost</th>
            <th rowspan="3" align="left" valign="middle" colspan="1">Num</th>
          </tr>
          <tr>
            <th colspan="9" align="left" valign="top" rowspan="1">
<hr/>
</th>
          </tr>
          <tr>
            <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="12" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td rowspan="8" align="left" valign="middle" colspan="1">
<bold>SRBCT</bold>
</td>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>NDDM</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.6±4.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.0±6.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">94.3±6.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>97.5±7.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">93.5±8.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">54</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>EGGS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.1±17.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.7±27.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">78.3±17.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.4±22.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.0±34.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57.7±24.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.7±22.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">84.2±27.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.0±26.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">25</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>FSDNE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">62.9±15.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.3±30.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.3±20.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.4±22.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.3±30.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">51.0±27.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">52.5±21.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.3±36.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">52.2±23.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">9</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>UCFS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">93.5±9.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">96.7±10.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">92.0±14.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.3±12.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±16.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.9±16.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.8±12.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">96.7±10.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.1±20.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">30</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>ReliefF</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.8±4.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">97.5±7.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.8±4.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">97.5±7.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.4±10.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.0±21.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">91.7±11.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">53</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>SVM-RFE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.6±4.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">96.7±10.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">97.5±5.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">96.7±10.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.3±5.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">94.3±8.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">92.5±16.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>96.6±7.4</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">20</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>WNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.9±3.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98.3±5.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">95.2±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">93.3±14.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">96.7±7.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">92.9±8.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">92.5±16.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">94.6±8.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">114</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>MGWNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>100.0±0.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>95.4±6.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>97.5±7.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">94.6±8.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">53</td>
          </tr>
          <tr>
            <td colspan="12" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td rowspan="8" align="center" valign="middle" colspan="1">
<bold>Colon</bold>
</td>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>NDDM</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">74.3±15.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">55.0±37.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±12.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.5±10.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.7±39.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.0±12.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.9±12.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.5±35.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.8±12.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">36</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>EGGS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.1±22.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56.7±37.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.0±25.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.9±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">41.7±28.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.0±12.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.7±8.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.0±30.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">84.3±14.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">23</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>FSDNE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.3±22.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">55.0±29.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.5±24.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.8±17.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">33.3±33.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.0±20.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.5±22.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">64.2±39.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.7±29.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>UCFS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.4±19.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.0±38.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.5±19.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.9±16.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.7±45.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">93.0±11.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">78.8±11.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56.7±43.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.0±12.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>ReliefF</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">74.8±17.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">50.8±48.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.8±30.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.8±13.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.8±39.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">91.3±11.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.1±16.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>75.0±36.2</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.3±14.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">98</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>SVM-RFE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.7±10.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.7±34.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.5±12.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.8±11.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.3±33.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.0±12.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">78.6±13.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.3±35.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.5±12.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">20</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>WNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.1±11.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.3±40.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.5±13.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.5±17.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.7±40.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.5±13.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>85.2±14.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.0±41.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>95.5±9.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>MGWNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>88.3±13.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>80.0±35.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>92.5±12.1</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>88.6±13.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>76.7±34.4</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>95.0±10.5</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.6±13.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.7±40.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">93.0±11.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70</td>
          </tr>
          <tr>
            <td colspan="12" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td rowspan="8" align="left" valign="middle" colspan="1">
<bold>BRCA</bold>
</td>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>NDDM</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.3±7.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.3±11.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">67.4±8.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.6±5.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>88.3±13.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.4±6.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.4±4.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">91.7±11.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">53.1±5.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>EGGS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.2±8.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.3±13.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.7±10.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.6±5.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>88.3±13.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.3±5.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.7±3.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>93.3±8.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">50.6±4.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">142</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>FSDNE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.3±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.3±13.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.2±12.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.6±7.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.7±21.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.5±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57.7±4.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.7±15.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">52.6±5.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>UCFS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.8±4.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±14.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">67.7±7.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.6±5.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">84.7±14.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.1±5.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.0±6.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.0±16.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>56.3±5.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">339</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>ReliefF</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.5±7.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.7±13.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.0±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.6±4.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.7±13.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.9±5.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57.1±5.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±16.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">50.6±5.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">198</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>SVM-RFE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">64.6±7.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.7±13.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.6±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.0±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.7±15.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57.5±8.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57.1±3.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±16.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">50.6±3.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">126</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>WNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.6±7.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>90.0±8.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">64.9±8.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>69.5±7.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>88.3±13.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>65.2±7.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">58.4±4.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.7±15.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">51.8±3.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">144</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>MGWNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>72.2±5.5</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>90.0±11.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>68.4±6.5</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.2±5.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>88.3±13.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.1±6.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>62.6±6.4</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.7±13.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">53.5±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="TFN1">
          <p id="P62">Bold numbers represent the best classification results among the eight feature selection methods. Num indicates the average number of selected features by each method.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="T2" orientation="landscape">
      <label>Table II</label>
      <caption>
        <p id="P63">Classification Performance and the Number of Selected Features of Various Methods on fMRI Datasets, Including FBIRN, BSNIP, and MPRC. THE Used Classifiers Include SVM, 3NN, and AdaBoost</p>
      </caption>
      <table frame="hsides" rules="none">
        <colgroup span="1">
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="3" align="left" valign="middle" colspan="1">Datasets</th>
            <th rowspan="3" align="left" valign="middle" colspan="1">Methods</th>
            <th colspan="3" align="center" valign="top" rowspan="1">SVM</th>
            <th colspan="3" align="left" valign="top" rowspan="1">3NN</th>
            <th colspan="3" align="left" valign="top" rowspan="1">AdaBoost</th>
            <th rowspan="3" align="left" valign="middle" colspan="1">Num</th>
          </tr>
          <tr>
            <th colspan="9" align="left" valign="top" rowspan="1">
<hr/>
</th>
          </tr>
          <tr>
            <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Accuracy (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Sensitivity (%)</th>
            <th align="center" valign="top" rowspan="1" colspan="1">Specificity (%)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="12" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td rowspan="8" align="center" valign="middle" colspan="1">
<bold>FBIRN</bold>
</td>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>NDDM</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.6±5.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">91.4±6.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±8.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.1±4.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.0±6.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.0±9.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.9±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.8±12.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>83.0±14.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">24</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>EGGS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.3±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.3±8.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.0±13.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.6±5.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.7±7.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.0±8.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.7±4.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.8±7.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.0±7.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>FSDNE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.6±5.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">92.1±7.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.0±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.9±8.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.7±7.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.0±11.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.3±9.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.6±9.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.0±12.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>UCFS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.2±9.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">86.5±6.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.0±19.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.3±6.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.3±10.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">78.0±16.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.2±8.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.5±9.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.0±12.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">139</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>ReliefF</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.1±4.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.6±6.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.0±8.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.5±6.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.1±8.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.0±8.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.2±5.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.3±8.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>83.0±11.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>SVM-RFE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.9±8.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">88.3±10.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.0±11.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">85.5±10.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.5±10.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.0±14.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.3±6.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">84.8±10.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.0±14.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">33</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>WIN RE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.3±5.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>92.9±5.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">87.0±6.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.9±9.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">90.6±7.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">89.0±13.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.84±6.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">84.9±7.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.0±14.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">55</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>MGWNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>91.2±5.4</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">91.3±5.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>91.0±8.8</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>93.9±5.1</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>93.8±4.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>94.0±7.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>84.6±6.3</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>87.2±9.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>83.0±13.4</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">21</td>
          </tr>
          <tr>
            <td colspan="12" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td rowspan="8" align="left" valign="middle" colspan="1">
<bold>BSNIP</bold>
</td>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>NDDM</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">74.7±2.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">62.4±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>86.0±73</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.4±4.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">67.9±10.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>76.7±113</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.4±7.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.1±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.6±8.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>EGGS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.5±6.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">64.4±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">78.1±12.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.6±3.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">64.4±7.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.5±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.9±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">53.8±16.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.6±8.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>FSDNE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.7±6.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.9±11.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.7±10.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.0±5.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">52.3±11.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.0±11.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.7±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.6±16.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.4±11.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>UCFS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.8±7.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.8±14.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.6±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.2±10.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">57.2±14.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.7±10.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.2±11.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56.4±15.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">61.9±14.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>ReliefF</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">74.8±9.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.9±14.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.0±10.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.5±7.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">62.2±14.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.1±12.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.3±7.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.8±11.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.6±13.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>SVM-RFE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>76.6±6.2</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.0±8.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.7±7.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.5±5.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.2±11.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.0±10.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.9±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.8±11.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>73.5±133</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>WNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.0±3.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>74.5±5.3</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.4±6.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.6±7.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.9±13.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">71.2±9.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.3±5.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.8±9.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.9±10.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>MGWNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.3±7.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.4±12.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.0±12.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>74.0±5.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>73.2±10.3</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">74.8±9.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>69.2±4.6</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>67.8±6.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.4±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td colspan="12" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td rowspan="8" align="left" valign="middle" colspan="1">
<bold>MPRC</bold>
</td>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>NDDM</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.7±9.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.9±12.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">81.5±12.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.7±5.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.4±7.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.3±9.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.0±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">82.3±6.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.5±16.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>EGGS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.8±8.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.8±11.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56.2±12.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.5±8.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.4±10.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56.9±11.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.7±5.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">62.1±9.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">56.9±6.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>FSDNE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.3±12.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.5±14.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.4±20.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.4±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.6±11.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.2±15.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.6±7.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">70.8±10.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.2±13.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>UCFS</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">65.1±8.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.4±10.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.0±12.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">64.7±6.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.0±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">60.8±11.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">59.4±8.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">66.8±10.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">50.8±13.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>ReliefF</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.2±7.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.6±13.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.7±9.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.3±8.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.9±11.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.9±17.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.2±9.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.1±9.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.1±17.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>SVM-RFE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.7±8.4</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.0±13.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">75.4±9.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.1±6.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">74.8±11.8</td>
            <td align="center" valign="top" rowspan="1" colspan="1">69.2±13.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">68.2±11.3</td>
            <td align="center" valign="top" rowspan="1" colspan="1">72.7±14.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">63.1±13.5</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>WNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>84.2±10.1</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>85.2±10.3</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>83.1±14.9</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.7±6.0</td>
            <td align="center" valign="top" rowspan="1" colspan="1">79.1±10.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">76.2±9.2</td>
            <td align="center" valign="top" rowspan="1" colspan="1">77.4±9.7</td>
            <td align="center" valign="top" rowspan="1" colspan="1">80.4±7.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">73.8±14.6</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">
<bold>MGWNRE</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">83.8±6.1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">84.3±8.9</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>83.1±11.4</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>80.6±6.3</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>80.6±10.0</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>80.8±13.2</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>78.1±8.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>83.0±8.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">
<bold>76.2±11.7</bold>
</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="TFN2">
          <p id="P64">Bold numbers represent the best classification results among the eight feature selection methods. Num indicates the average number of selected features by each method.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <table-wrap position="float" id="T3" orientation="landscape">
      <label>TABLE III</label>
      <caption>
        <p id="P65">Group Differences of the top-10 Important FNC Features Selected By MGWNRE on Different Datasets, Including FBIRN, BSNIP, and MPRC Datasets. For Each Dataset, Two-Sample T-Tests Were Used to Examine the Group Differences for Each Selected FNC Feature, and the P-Values and T-Values of HC VS. SZ are Shown</p>
      </caption>
      <table frame="hsides" rules="none">
        <colgroup span="1">
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
          <col align="left" valign="middle" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="3" align="left" valign="middle" colspan="1">Brain functional network<break/>(IC ID, brain functional domain)</th>
            <th rowspan="3" align="left" valign="middle" colspan="1">Brain functional network<break/>(IC ID, brain functional domain)</th>
            <th colspan="2" align="center" valign="top" rowspan="1">FBIRN<break/>HC vs. SZ)</th>
            <th colspan="2" align="center" valign="top" rowspan="1">BSNIP<break/>(HC vs. SZ)</th>
            <th colspan="2" align="center" valign="top" rowspan="1">MPRC<break/>(HC vs. SZ)</th>
          </tr>
          <tr>
            <th colspan="6" align="left" valign="top" rowspan="1">
<hr/>
</th>
          </tr>
          <tr>
            <th align="center" valign="top" rowspan="1" colspan="1">P-value</th>
            <th align="center" valign="top" rowspan="1" colspan="1">T-value</th>
            <th align="center" valign="top" rowspan="1" colspan="1">P-value</th>
            <th align="center" valign="top" rowspan="1" colspan="1">T-value</th>
            <th align="center" valign="top" rowspan="1" colspan="1">P-value</th>
            <th align="center" valign="top" rowspan="1" colspan="1">T-value</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td colspan="8" align="left" valign="top" rowspan="1">
<hr/>
</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Caudate (69, SC)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Thalamus (45, SC)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.03e-20</td>
            <td align="center" valign="top" rowspan="1" colspan="1">10.33</td>
            <td align="center" valign="top" rowspan="1" colspan="1">8.27e-06</td>
            <td align="center" valign="top" rowspan="1" colspan="1">4.53</td>
            <td align="center" valign="top" rowspan="1" colspan="1">7.14e-05</td>
            <td align="center" valign="top" rowspan="1" colspan="1">4.03</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Thalamus (45, SC)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Superior temporal gyms (21, AU)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.33e-29</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−13.13</td>
            <td align="center" valign="top" rowspan="1" colspan="1">4.28e-17</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−8.92</td>
            <td align="center" valign="top" rowspan="1" colspan="1">2.49e-23</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−10.91</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Thalamus (45, SC)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Cerebellum (13, CB)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.30e-24</td>
            <td align="center" valign="top" rowspan="1" colspan="1">11.57</td>
            <td align="center" valign="top" rowspan="1" colspan="1">3.39e-14</td>
            <td align="center" valign="top" rowspan="1" colspan="1">7.95</td>
            <td align="center" valign="top" rowspan="1" colspan="1">9.48e-18</td>
            <td align="center" valign="top" rowspan="1" colspan="1">9.18</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Thalamus (45, SC)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Cerebellum (18, CB)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">8.67e-26</td>
            <td align="center" valign="top" rowspan="1" colspan="1">11.94</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.40e-18</td>
            <td align="center" valign="top" rowspan="1" colspan="1">9.38</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.67e-24</td>
            <td align="center" valign="top" rowspan="1" colspan="1">11.25</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Left postcentral gyrus (9, SM)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Calcarine gyrus (16, VI)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">6.13e-26</td>
            <td align="center" valign="top" rowspan="1" colspan="1">11.99</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.33e-14</td>
            <td align="center" valign="top" rowspan="1" colspan="1">8.09</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.52e-ll</td>
            <td align="center" valign="top" rowspan="1" colspan="1">7.04</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Right postcentral gyrus (11, SM)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Calcarine gyrus (16, VI)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.24e-25</td>
            <td align="center" valign="top" rowspan="1" colspan="1">11.89</td>
            <td align="center" valign="top" rowspan="1" colspan="1">5.56e-15</td>
            <td align="center" valign="top" rowspan="1" colspan="1">8.22</td>
            <td align="center" valign="top" rowspan="1" colspan="1">8.21e-12</td>
            <td align="center" valign="top" rowspan="1" colspan="1">7.14</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Superior parietal lobule (80, SM)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Inferior occipital gyrus (20, VI)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">9.15e-08</td>
            <td align="center" valign="top" rowspan="1" colspan="1">5.52</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.79e-08</td>
            <td align="center" valign="top" rowspan="1" colspan="1">5.78</td>
            <td align="center" valign="top" rowspan="1" colspan="1">9.23e-07</td>
            <td align="center" valign="top" rowspan="1" colspan="1">5.02</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Middle temporal gyrus (62, VI)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Insula (33, CC)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">2.36e-l 1</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−7.04</td>
            <td align="center" valign="top" rowspan="1" colspan="1">4.67e-03</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−2.85</td>
            <td align="center" valign="top" rowspan="1" colspan="1">6.34e-03</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−2.75</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Middle temporal gyrus (62, VI)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Anterior cingulate cortex (17, DM)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">7.49e-15</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−8.34</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.40e-07</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−5.39</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.48e-02</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−2.45</td>
          </tr>
          <tr>
            <td align="left" valign="top" rowspan="1" colspan="1">Right middle occipital gyrus (12, VI)</td>
            <td align="left" valign="top" rowspan="1" colspan="1">Hippocampus (83, CC)</td>
            <td align="center" valign="top" rowspan="1" colspan="1">2.97e-11</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−7.00</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.20e-07</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−5.42</td>
            <td align="center" valign="top" rowspan="1" colspan="1">1.51e-01</td>
            <td align="center" valign="top" rowspan="1" colspan="1">−1.44</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="TFN3">
          <p id="P66">Here, IC denotes the independent component. The brain is divided into seven brain functional domains, including sub-cortical (SC), auditory (AU), sensorimotor (SM), visual (VI), cognitive-control (CC), default-mode (DM), and cerebellar (CB) domains.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </floats-group>
</article>
