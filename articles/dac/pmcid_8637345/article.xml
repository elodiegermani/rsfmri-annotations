<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" article-type="research-article">
  <?properties open_access?>
  <?properties manuscript?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-journal-id">9215515</journal-id>
      <journal-id journal-id-type="pubmed-jr-id">20498</journal-id>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>NeuroImage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">34607021</article-id>
      <article-id pub-id-type="pmc">8637345</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2021.118588</article-id>
      <article-id pub-id-type="manuscript">NIHMS1755363</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Spatiotemporal trajectories in resting-state FMRI revealed by convolutional variational autoencoder</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Xiaodi</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Maltbie</surname>
            <given-names>Eric A.</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Keilholz</surname>
            <given-names>Shella D.</given-names>
          </name>
          <xref ref-type="corresp" rid="CR1">*</xref>
        </contrib>
        <aff id="A1">The Wallace H. Coulter Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Health Sciences Research Building, 1760 Haygood Drive, SuiteW200, Atlanta, GA, 30322, USA</aff>
      </contrib-group>
      <author-notes>
        <fn fn-type="con" id="FN1">
          <p id="P1">Author credit role</p>
          <p id="P2">X.Z., E.M., and S.K. contributed to experimental design, interpretation, and manuscript preparation. X.Z. developed and implemented the VAE network. X.Z. and E.M. prepared the data for the VAE.</p>
        </fn>
        <corresp id="CR1"><label>*</label>Corresponding author. <email>shella.keilholz@bme.gatech.edu</email> (S.D. Keilholz).</corresp>
      </author-notes>
      <pub-date pub-type="nihms-submitted">
        <day>25</day>
        <month>11</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>01</day>
        <month>10</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>12</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>02</day>
        <month>12</month>
        <year>2021</year>
      </pub-date>
      <volume>244</volume>
      <fpage>118588</fpage>
      <lpage>118588</lpage>
      <!--elocation-id from pubmed: 10.1016/j.neuroimage.2021.118588-->
      <permissions>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
          <license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>)</license-p>
        </license>
      </permissions>
      <abstract id="ABS1">
        <p id="P3">Recent resting-state fMRI studies have shown that brain activity exhibits temporal variations in functional connectivity by using various approaches including sliding window correlation, co-activation patterns, independent component analysis, quasi-periodic patterns, and hidden Markov models. These methods often model the brain activity as a discretized hopping among several brain states that are defined by the spatial configurations of network activity. However, the discretized states are merely a simplification of what is likely to be a continuous process, where each network evolves over time following its unique path. To model these characteristic spatiotemporal trajectories, we trained a variational autoencoder using rs-fMRI data and evaluated the spatiotemporal features of the latent variables obtained from the trained networks. Our results suggest that there are a relatively small number of approximately orthogonal whole-brain spatiotemporal patterns that capture the most prominent features of rs-fMRI data, which can serve as the building blocks to construct all possible spatiotemporal dynamics in resting state fMRI. These spatiotemporal patterns provide insight into how activity flows across the brain in concordance with known network structures and functional connectivity gradients.</p>
      </abstract>
      <kwd-group>
        <kwd>Resting state fMRI</kwd>
        <kwd>Spatiotemporal dynamics</kwd>
        <kwd>Deep learning</kwd>
        <kwd>Variational autoencoder</kwd>
        <kwd>Resting state networks</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <label>1.</label>
      <title>Introduction</title>
      <p id="P4">In resting state fMRI (rs-fMRI), the blood oxygenation level-dependent (BOLD) signal is acquired in the absence of an explicit task or stimulation (<xref rid="R8" ref-type="bibr">Biswal et al., 1995</xref>; <xref rid="R51" ref-type="bibr">Ogawa et al., 1992</xref>). Networks of spatially distributed brain regions whose time courses are correlated, referred to as “resting state networks” (RSN) (<xref rid="R11" ref-type="bibr">Cordes et al., 2000</xref>; <xref rid="R13" ref-type="bibr">Damoiseaux et al., 2006</xref>; <xref rid="R17" ref-type="bibr">Fox et al., 2006</xref>; <xref rid="R18" ref-type="bibr">Fox and Raichle, 2007</xref>; <xref rid="R21" ref-type="bibr">Ghahremani et al., 2016</xref>; <xref rid="R23" ref-type="bibr">Greicius et al., 2003</xref>; <xref rid="R26" ref-type="bibr">Hampson et al., 2002</xref>; <xref rid="R54" ref-type="bibr">Power et al., 2011</xref>; <xref rid="R58" ref-type="bibr">Smith et al., 2009</xref>), can be reliably observed under numerous conditions and serve as the foundation of our knowledge of the brain’s functional architecture. Recent studies have revealed that these large-scale patterns of brain activity exhibit temporal variations at relatively fast time-scales (seconds-minutes) (<xref rid="R3" ref-type="bibr">Allen et al., 2014</xref>; <xref rid="R10" ref-type="bibr">Chang and Glover, 2010</xref>; <xref rid="R27" ref-type="bibr">Handwerker et al., 2012</xref>; <xref rid="R32" ref-type="bibr">Jones et al., 2012a</xref>; <xref rid="R35" ref-type="bibr">Keilholz et al., 2013</xref>; <xref rid="R40" ref-type="bibr">Kiviniemi et al., 2011</xref>; <xref rid="R47" ref-type="bibr">Majeed et al., 2011</xref>; <xref rid="R55" ref-type="bibr">Sakoğlu et al., 2010</xref>), and that these dynamics are sensitive to changes related to behavior, cognition (<xref rid="R2" ref-type="bibr">Albert et al., 2009</xref>; <xref rid="R5" ref-type="bibr">Bassett et al., 2011</xref>; <xref rid="R14" ref-type="bibr">Esposito et al., 2006</xref>; <xref rid="R16" ref-type="bibr">Fornito et al., 2012</xref>; <xref rid="R64" ref-type="bibr">Thompson et al., 2013</xref>), and pathology (<xref rid="R12" ref-type="bibr">Damaraju et al., 2014</xref>; <xref rid="R25" ref-type="bibr">Hamilton et al., 2011</xref>; <xref rid="R32" ref-type="bibr">Jones et al., 2012a</xref>). A number of techniques have been used to characterize the time-varying patterns of activity, including sliding window correlation (SWC) (<xref rid="R3" ref-type="bibr">Allen et al., 2014</xref>; <xref rid="R10" ref-type="bibr">Chang and Glover, 2010</xref>; <xref rid="R27" ref-type="bibr">Handwerker et al., 2012</xref>; <xref rid="R32" ref-type="bibr">Jones et al., 2012a</xref>; <xref rid="R35" ref-type="bibr">Keilholz et al., 2013</xref>; <xref rid="R40" ref-type="bibr">Kiviniemi et al., 2011</xref>), co-activation patterns (CAPs) (<xref rid="R46" ref-type="bibr">Liu and Duyn, 2013</xref>; <xref rid="R62" ref-type="bibr">Tagliazucchi et al., 2012</xref>), Independent component analysis (ICA) (<xref rid="R3" ref-type="bibr">Allen et al., 2014</xref>; <xref rid="R12" ref-type="bibr">Damaraju et al., 2014</xref>; <xref rid="R40" ref-type="bibr">Kiviniemi et al., 2011</xref>) and hidden Markov models (HMM) (<xref rid="R65" ref-type="bibr">Vidaurre et al., 2017</xref>). However, most of these methods consider spatial and temporal information separately, when in reality the temporal and spatial aspects of brain activity are intricately related. Brain activity has often been modeled as a discretized hopping among several brain states that are defined by the spatial configurations of network activity. However, the discretized states are merely a simplification of what is likely to be a continuous process, where each network evolves over time following its unique path. In this case, the presence of stereotyped pathways of evolution between states that manifest as characteristic spatiotemporal trajectories in the rs-fMRI data would provide new insight into the systems-level coordination of brain function.</p>
      <p id="P5">At least one characteristic spatiotemporal trajectory has already been observed using a recursive algorithm. The resulting quasi-periodic patterns (QPPs) revealed highly reproducible spatiotemporal trajectories showing sinusoidal patterns of activation and deactivation in the default mode network (DMN) and task positive network (TPN) with opposite phases (<xref rid="R1" ref-type="bibr">Abbas et al., 2019</xref>; <xref rid="R68" ref-type="bibr">Yousefi et al., 2018</xref>), along with propagation along the cortex. Despite these successes, the primary QPP only explains 25–50% of the variance in the BOLD signal (<xref rid="R31" ref-type="bibr">Hutchison et al., 2013</xref>), suggesting that there is still a large portion of the signal not accounted for, and there are potentially other spatiotemporal trajectories not yet identified. An effort has been made to identify these secondary components by performing QPP analysis again after regressing out the primary QPP component (<xref rid="R67" ref-type="bibr">Yousefi and Keilholz, 2021</xref>). The primary QPP (QPP1) is calculated, and convolved with the QPP1’s correlation time course to form the regressor. With the contribution of QPP1 regressed out using GLM (general linear model) method, subsequent QPP2 can be obtained from the residual time course by applying the same QPP algorithm again. This process can be performed repeatedly, yielding multiple QPPs. These secondary QPPs (QPP2, QPP3 and so on) have demonstrated distinct spatiotemporal patterns that are different from the primary ones, and typically explain progressively less variance (it was reported in (<xref rid="R67" ref-type="bibr">Yousefi and Keilholz, 2021</xref>) that QPP1 explains ~37% of the original functional connectivity, QPPs 1–2 explain ~53%, and QPPs 1–3 explain ~63%). However, the number of additional components identified was typically limited to three. To date there has not been an exhaustive search for all possible characteristic spatiotemporal trajectories, potentially due to difficulties from the computational complexities, as well as the reduced robustness and interpretability after the repeated calculation of regression and convolution.</p>
      <p id="P6">Deep learning methods could potentially solve this problem because they are inherently designed to extract key information or characteristic patterns from very complicated systems in a data-driven way. Convolutional neural networks (CNN), in particular, have proven very successful at extracting spatial features from images, e.g. AlexNet (<xref rid="R41" ref-type="bibr">Krizhevsky et al., 2017</xref>) and GoogLeNet (<xref rid="R61" ref-type="bibr">Szegedy et al., 2015</xref>), and there are also studies using convolutional neural networks to extract temporal features from time series, e.g. applications in natural language processing (<xref rid="R20" ref-type="bibr">Gehring et al., 2017</xref>; <xref rid="R34" ref-type="bibr">Kalchbrenner et al., 2014</xref>; <xref rid="R36" ref-type="bibr">Kim, 2014</xref>) where the convolutional kernel was shown to be capable of extracting the features from the ordering of words in a sentence. In a more generic setting, (<xref rid="R4" ref-type="bibr">Bai et al., 2018</xref>) has shown that the CNN is capable of learning the temporal structures of time series in various tasks. Therefore, supposing there is a specific spatiotemporal property attributable to intrinsic brain dynamics, presumably it would be captured by a CNN as well.</p>
      <p id="P7">As of today there are relative few studies in resting state fMRI that use deep learning methods, most of which focus on classification problems, e.g., classification of Alzheimer’s disease (<xref rid="R56" ref-type="bibr">Sarraf and Tofighi, 2017</xref>), mild cognitive impairment (MCI) (<xref rid="R50" ref-type="bibr">Meszlényi et al., 2017</xref>; <xref rid="R60" ref-type="bibr">Suk et al., 2016</xref>), bipolar disorder (<xref rid="R59" ref-type="bibr">Smucny et al., 2021</xref>) and ADHD (<xref rid="R48" ref-type="bibr">Mao et al., 2019</xref>). A few studies attempt to extract features in the fMRI data. For example, <xref rid="R45" ref-type="bibr">Li and Fan (2018)</xref> used a RNN to detect anomaly, which is used to identify state changes between different task/fixation blocks in the HCP data. <xref rid="R69" ref-type="bibr">Zhang et al. (2019)</xref> used a Deep Belief Network to obtain brain networks by combining functional data from fMRI and structural data from DTI. <xref rid="R30" ref-type="bibr">Huang et al. (2018)</xref> used a convolutional autoencoder to extract temporal features from task-fMRI data, which describes variations in the hemodynamic response function (HRF). <xref rid="R29" ref-type="bibr">Hu et al. (2018)</xref> trained a restricted Boltzmann machine using task-fMRI data, which was claimed to outperform ICA in terms of higher temporal correlation with task paradigms, and greater spatial overlap with the general linear model. Despite deep learning’s great potential, none of the existing studies is designed to detect characteristic spatiotemporal brain trajectories.</p>
      <p id="P8">Every model provides unique insight into the systems-level neural activity detected with rs-fMRI. Spatial ICA identifies spatially distributed networks of coherent activity over the course of the scan. In contrast, coactivation patterns identify repeated instantaneous occurrences of common spatial patterns over the course of the scan, which may involve multiple networks. Thus, ICA encourages us to think of the brain as a set of discrete networks whose activities change over time, while coactivation patterns motivate us to find time points of strong signal fluctuation driven by internal or external stimuli that account for the activity across the brain. QPPs and the spatiotemporal latent variables we found in this study imply that we should think of the entire brain as a single complex system, with persistent features and stereotyped patterns of evolution, much like the climate of the earth.</p>
      <p id="P9">Given our goal of finding spatiotemporal patterns that can serve as “building blocks” for rs-fMRI, we proposed a deep learning method to extract characteristic spatiotemporal trajectories from rs-fMRI time courses. Specifically, a variational autoencoder (VAE) was trained to identify a relatively small number of approximately orthogonal whole-brain spatiotemporal patterns that capture the most prominent features of rs-fMRI data. Among all available deep learning / machine learning models, we chose VAE for the following reasons: 1) the goal is to learn the characteristic spatiotemporal patterns from the unlabeled rs-fMRI data in an unsupervised manner (specifically learning latent representations) 2) Among all the machine learning / deep learning methods for creating latent representations, VAE has an advantageous combination of nonlinear mapping that enables learning of more complicated features and its orthogonality in the latent space that improves the interpretability compared to a plain autoencoder (<xref rid="R38" ref-type="bibr">Kingma and Welling, 2019</xref>, <xref rid="R39" ref-type="bibr">2014</xref>). The resulting latent variables show that characteristic brain trajectories (beyond the QPP) exist and provide insight into how activity flows across the brain in concordance with known network structures and functional connectivity gradients.</p>
    </sec>
    <sec id="S2">
      <label>2.</label>
      <title>Methods</title>
      <sec id="S3">
        <label>2.1.</label>
        <title>fMRI data preprocessing</title>
        <p id="P10">The minimally processed rs-fMRI data from the 412 subjects with “study completion: full 3T imaging protocol completed” label was downloaded from the Human Connectome Project (HCP) S500 release (<xref rid="R22" ref-type="bibr">Glasser et al., 2013</xref>). The resting-state fMRI data were acquired using Gradient-echo EPI with the following parameters: TR/TE = 720 ms/33.1 ms, resolution = 2.0 mm isotropic, matrix size = 104 × 90, number of slice = 72, number of TR = 1200. Further preprocessing included the following procedures: The first 5 frames were removed to minimize the transient effects before reaching equilibrium. Gray matter (GM), white matter (WM) and cerebrospinal fluid (CSF) signal were averaged within their masks provided by HCP. Then GM, WM, and CSF signals, along with 12 motion parameters (provided by HCP), linear and quadratic trends were regressed out altogether at the voxel level. The regressed BOLD signals were then bandpass filtered using a 0.01–0.1 Hz 6-order Butterworth filter. Finally the BOLD signals were parcellated using the Brainnetome atlas (<xref rid="R15" ref-type="bibr">Fan et al., 2016</xref>) and each parcel was z-scored. The final parcellated BOLD signal has 412 subjects by 1195 time points by 246 parcels. For better visualization, the 246 parcels were then sorted into 7 functional networks using Yeo’s 7-network model (<xref rid="R63" ref-type="bibr">Thomas Yeo et al., 2011</xref>) provided by the Brainnetome website, namely default mode (DMN), visual (VIS), somatomotor (SM), dorsal attention (DA), ventral attention (VA), frontalparietal (FP) and limbic (LIM) networks, with the remaining parcels all classified as subcortical regions (SC).</p>
      </sec>
      <sec id="S4">
        <label>2.2.</label>
        <title>Variational autoencoder</title>
        <p id="P11">An autoencoder is a type of neural network used to learn efficient data representation in an unsupervised manner. It typically consists of an encoder network that gradually reduces dimensions, and a symmetric decoder network that recovers the dimensions. In this case, the output of the encoder has the lowest dimensionality in the entire network, and thus is a bottleneck of the information, which forces the network to extract features that most represent the data structure, since any reconstruction error is penalized.</p>
        <p id="P12">To improve generalizability, a variant of the autoencoder architecture called a variational autoencoder (VAE) includes a random sampling process (<xref rid="R39" ref-type="bibr">Kingma and Welling, 2014</xref>). The model learns the distributions of the latent variables (by learning means and variances), instead of learning a deterministic mapping. A random sample is drawn from the distributions for every data point passing through the latent layer. The calculation of the loss function involved in this process and how it is back propagated to update the parameters in the networks was described in the original VAE paper (<xref rid="R39" ref-type="bibr">Kingma and Welling, 2014</xref>). To summarize, the loss function that corresponds to the randomization process is the Kullback-Leibler (KL) divergence, which has a closed form when the prior distribution is assumed to be Gaussian. Thus, by minimizing the sum of the reconstruction loss and the KL divergence, the latent variable not only learns the most representative features in the dataset, but also becomes as close to a multidimensional standard Gaussian distribution (all components are independent, zero-mean, unit-variance) as possible. This tendency to approach Gaussian distribution serves as a regularization effect, which leads to a smoother latent distribution compared to the plain autoencoder, and thus improves the generalizability of the model. The VAE model essentially assumes that if the network is deep enough (having enough expressive power), then any complicated system can be mapped to a series of disentangled Gaussian-distributed variables.</p>
      </sec>
      <sec id="S5">
        <label>2.3.</label>
        <title>Convolutional variational autoencoder design</title>
        <p id="P13">With the goal of extracting common spatiotemporal trajectories in brain activities, we chose to feed the neural network with short rs-fMRI segments instead of single frames. Each rs-fMRI scan (1195 TR) was divided into 36 segments that are 33-TR long (23.76 s), with 50% overlap. The 33-TR segment length was chosen based on prior work identifying a strong spatiotemporal pattern with a duration of ~20 s (<xref rid="R47" ref-type="bibr">Majeed et al., 2011</xref>). Based on the assumption that the rules governing the network dynamics are shift-invariant across time, convolutional layers were used in the first few layers instead of fully connected layers. As suggested by (<xref rid="R43" ref-type="bibr">Lecun et al., 1998</xref>), the parameter sharing in the convolutional layer greatly reduces the number of parameters in the model when compared with a fully-connected layer, thus improves the generalizability of the trained neural networks. Instead of using the common 2D convolutional kernel, here we used a 1D convolutional kernel that applies only to the temporal dimension, because the fMRI signal in the parcellated space is not shift-invariant across different parcels in the spatial domain.</p>
        <p id="P14">This neural network architecture is shown in <xref ref-type="fig" rid="F1">Fig. 1</xref>. The network consists of a symmetric encoder and decoder pair, either of which has 3 convolutional layers and 2 fully-connected layers. Each convolutional/fully-connected layer consists of a weight layer and a Rectified Linear Unit (ReLU) activation layer. Please note that the convolutional layers are multi-channel convolutional layers, where each feature map (channel) encodes a unique temporal feature that combines all channels from its input. The multiple channels encode the spatial information of the brain activity. For the first layer, the 246 spatial parcels directly form the 246 channels, which were encoded into 128 channels. For the subsequent layers, the channels encode higher-level spatiotemporal features whose receptive field still covers the whole brain (246 parcels). Details regarding the network architectures including number of trainable parameters can be found in the <xref ref-type="supplementary-material" rid="SD1">supplemental materials</xref>, <xref ref-type="supplementary-material" rid="SD1">Table S.1</xref>. The performance of four other alternative network designs with different numbers of layers or different numbers of hidden units was evaluated using holdout validation (the network architectures and results are shown in <xref ref-type="supplementary-material" rid="SD1">supplemental materials section S.1</xref>) and the architecture shown in <xref ref-type="fig" rid="F1">Fig. 1</xref> showed the best performance. The encoder encodes the input rs-fMRI segments of size 246 parcels by 33 time points into a 32×1 latent representation that roughly follows a multidimensional Gaussian distribution. The distributions of the latent variables were represented in means and variances that are estimated by the networks. Then during training, a sample was randomly drawn from this distribution whenever a data point arrives at the latent layer. This random process is a key feature in variational autoencoder, which improves its robustness and generalizability. Then the decoder performs a series of reverse operations (dilated convolution being the reverse operation of convolution) to reconstruct rs-fMRI segments from the 32×1 latent representation.</p>
      </sec>
      <sec id="S6">
        <label>2.4.</label>
        <title>Training and testing of the model</title>
        <p id="P15">The 412 subjects were randomly split into a training set (<italic>n</italic> = 248), a validation set (<italic>n</italic> = 82) and a testing set (<italic>n</italic> = 82). Then the segments were shuffled, resulting a training set with size of [248×36,246,33], a validation set and a testing set both with size of [82×36,246,33]. To make the model more regularized, we used a variant of VAE called beta-VAE (<xref rid="R28" ref-type="bibr">Higgins et al., 2017</xref>), whose loss function is the sum of reconstruction loss (root mean square error between input and output) and the K-L divergence loss weighted by a factor beta (beta=4). Large beta values increase the penalty for KL-divergence and therefore the model is more regularized (variables become closer to orthogonal). As proposed in the original beta-VAE paper, as well as confirmed in our experiments (shown in <xref ref-type="supplementary-material" rid="SD1">supplemental materials section S.2</xref>), beta = 4 gives a reasonable result that appear to be more robust and regularized than a regular VAE (a special case where beta = 1). The networks were implemented using Pytorch (<xref rid="R52" ref-type="bibr">Paszke et al., 2017</xref>) and were trained on a Nvidia GTX2080Ti GPU using Adam optimizer (<xref rid="R37" ref-type="bibr">Kingma and Ba, 2015</xref>) with a learning rate of 0.001 for 90 epochs. To verify the model, we used the rs-fMRI segments from the testing set as the input and compared the rs-fMRI segments reconstructed by the networks with the input. The reconstruction provides a qualitative assessment of how much information is preserved by the latent representation.</p>
      </sec>
      <sec id="S7">
        <label>2.5.</label>
        <title>Feature visualization of the latent variables</title>
        <p id="P16">Neural networks are often described as “black boxes” and it is not uncommon to see difficulties in interpreting why they perform well over a particular task. There are a few methods for visualizing features learned by the networks that can help interpret the results, including saliency maps and class visualization (<xref rid="R57" ref-type="bibr">Simonyan et al., 2014</xref>), although these methods are typically used for classifiers. Thanks to its Gaussian-distributed latent variables and its symmetric encoder-decoder design, there is one visualization method exclusive to variational autoencoder. The latent variables are disentangled, because penalizing the KL divergence leads to a multidimensional Gaussian distribution where all components are independent from each other. This means that the effect of each latent variable is isolated, thus can be visualized by propagating a perturbation of such latent variable though the decoder. In addition, because of the symmetric design and the fact that reconstruction loss encourages identity mapping, given a certain perturbation in a latent variable, the manifested spatiotemporal pattern in the reconstruction when passing such perturbation through the decoder, should ideally be the same spatiotemporal pattern that would result in such perturbation in the latent variable when passing through the encoder. In other words, the VAE learns a two-way mapping between the perturbation in the latent variable and the spatiotemporal pattern in the fMRI segments. By isolating the effect of each latent variable through perturbation in such a controlled manner, we can visualize the spatiotemporal pattern to which each latent variable corresponds. Using this method, we vary each of the 32 latent variables from −3 to +3 (since 99.7% of the data lies in the ±3 sigma range of a Gaussian distribution) with 500 increment steps, and observe how the rs-fMRI segments reconstructed by the decoder vary. This process returns a 4D vector (500 increments, 246 parcels, 33 time points, 32 latent variables), which can be visualized if one dimension is fixed. By fixing the perturbation at its maximum amplitude, we obtained a set of 32 spatiotemporal patterns or trajectories of brain activities that can activate their corresponding latent variables, which is shown in <xref ref-type="fig" rid="F2">Fig. 2</xref>. All of the additional processing and visualization steps after the training the VAE were implemented in MATLAB R2020a (MathWorks, Natick, MA). The code for training VAE and analysis results is available in our lab’s Github page <ext-link ext-link-type="uri" xlink:href="https://github.com/GT-EmoryMINDlab/Variational_Autoencoder_for_Resting-state_FMRI">https://github.com/GT-EmoryMINDlab/Variational_Autoencoder_for_Resting-state_FMRI</ext-link>.</p>
      </sec>
      <sec id="S8">
        <label>2.6.</label>
        <title>Grouping of the latent variables based on their spatial similarity</title>
        <p id="P17">These 32 spatiotemporal patterns exhibit a few common spatial configurations which show synchronized fluctuations. Thus the 32 latent dimensions can be further organized into several groups based on their similarity in the spatial domain. To do that, first the time points when the fMRI time course reaches maximum variance across spatial dimensions were extracted (shown with black cursors in <xref ref-type="fig" rid="F2">Fig. 2</xref>). The reason why the time points with maximum variance were chosen is that the signal power (variance) reaches its highest value at these points, which maximizes the signal-to-noise ratio. This makes the estimation of spatial profile more robust to noise. The spatial profiles (as a function of latent variable) at the max-variance time points of the 32 latent variables were compared with each other and reorganized into several groups using K-means clustering (with spatial similarity calculated with Pearson correlation being the clustering criteria, and k empirically chosen as 6). To ensure the robustness of K-means clustering, we repeated the clustering algorithm with 200 random initializations, and chose the one that has the best separation of clusters.</p>
        <p id="P18">Then clusters were sorted in descending order by the variance explained by each latent variable (calculated as the variance across time domain, which was then summed over 246 parcels). The variance of individual latent variables within a cluster is also in descending order for better visualization. Aside from the spatial profiles, the functional connectivity of each latent variable’s spatiotemporal pattern was calculated. The weighted average (weighted by the variance of the latent variable) functional connectivity within each cluster was shown to provide an alternative representation of the spatial configurations among major functional networks of the 6 clusters.</p>
      </sec>
      <sec id="S9">
        <label>2.7.</label>
        <title>Comparison with the primary QPP</title>
        <p id="P19">The latent variables of the trained networks capture spatiotemporal trajectories of the brain, in a manner similar to the QPPs. Thus the features of latent variable 1, whose variance is the highest, was compared with the primary QPP. The primary QPP was calculated from the same testing set (<italic>n</italic> = 82) with the Brainnetome parcellation, using the existing Matlab code for calculating QPPs published in (<xref rid="R68" ref-type="bibr">Yousefi et al., 2018</xref>).</p>
      </sec>
    </sec>
    <sec id="S10">
      <label>3.</label>
      <title>Results</title>
      <sec id="S11">
        <label>3.1.</label>
        <title>The convolutional VAE decomposes rs-fMRI segments into a weighted combination of spatiotemporal patterns</title>
        <p id="P20">The trained convolutional VAE learns to represent any rs-fMRI segments using the 32 latent variables. To visualize the latent variables, we used the method described in <xref rid="S7" ref-type="sec">Section 2.5</xref>. <xref ref-type="fig" rid="F2">Fig. 2</xref> shows a set of 32 spatiotemporal trajectories of brain activity that can activate their corresponding latent variables. This set of spatiotemporal patterns were learnt to be the most representative features existing in short rs-fMRI segments, and any given rs-fMRI segment can be expressed by a weighted sum of these orthogonal spatiotemporal patterns, with the weights being the values of latent variables for that particular rs-fMRI segment. Note that each cluster of the spatiotemporal trajectories shares a common spatial network configuration (which can also be seen in the clusters in <xref ref-type="fig" rid="F3">Fig. 3</xref>), while each individual latent variable within a given cluster describes a unique evolution of activity for that particular network configuration. These latent variables are organized into 6 groups based on their spatial configurations using the method described in <xref rid="S8" ref-type="sec">Section 2.6</xref>. It can be seen that each cluster shares a common spatial organization of connectivity. For example, all 6 of the latent variables in the first cluster exhibit the anticorrelated DMN-TPN network configuration. All 32 spatiotemporal patterns share the same display scale, thus higher contrast suggests higher variance explained and presumably greater importance of the latent variable.</p>
      </sec>
      <sec id="S12">
        <label>3.2.</label>
        <title>The 32 latent dimensions can be further clustered based on their spatial similarity</title>
        <p id="P21">To better illustrate the common spatial configurations shared by the latent variables, here we leave out the temporal dimension by focusing on the time point when the fMRI time course reaches maximum variance across spatial dimensions, as described in <xref rid="S8" ref-type="sec">Section 2.6</xref>. The spatial configurations at this timepoint are shown for each variable in each cluster in <xref ref-type="fig" rid="F2">Fig. 2</xref>, accompanied by a matrix of the spatial similarity (Pearson correlation) between the spatial configurations that clearly shows the division into six distinct groups. The weighted averaged functional connectivity for each group is also shown to provide an alternative representation of the spatial configurations, and the variance explained for each latent variable is given.</p>
        <p id="P22">It can be seen in <xref ref-type="fig" rid="F3">Fig. 3</xref> panel A that, with in the primary cluster, whose mean variance is the highest, the spatial profile of every latent dimension at the max-variance time has the DM, FP and LIM network on one end, and VIS, SM, DA and VA networks on the opposite end. Although this max-variance time only gives a snapshot of this opposing relationship, such contrast can be seen throughout the course of the trajectories (both shown in the time courses in <xref ref-type="fig" rid="F2">Fig. 2</xref>, and the functional connectivity in <xref ref-type="fig" rid="F3">Fig. 3</xref> panel C). This finding is in agreement with many previous studies, including the DMN/TPN anticorrelation found in (<xref rid="R19" ref-type="bibr">Fox et al., 2005</xref>), quasiperiodic patterns (<xref rid="R47" ref-type="bibr">Majeed et al., 2011</xref>) and principal functional connectivity gradients (<xref rid="R49" ref-type="bibr">Margulies et al., 2016</xref>). The latent variables in the primary cluster all show that the DMN and TPN have a few components (with very high variance) with opposite phase at almost every instantaneous moment, suggesting this is the most prominent feature existing in resting state fMRI, which is likely the reason why we can see a consistent anti-correlation between the two networks.</p>
        <p id="P23">The secondary cluster, which has the second highest variance, also has an interesting feature that further separates different networks within the task positive network. At the max-variance time, it can be seen from <xref ref-type="fig" rid="F3">Fig. 3</xref> panel A that, every latent variable in cluster 2 has the negative end corresponding to the activation of VIS and DA networks, and the positive end corresponding to the activation of SM and VA networks. These together with the primary cluster, exhibit a remarkable resemblance to the principal gradients. The principal gradients are obtained using a method called diffusion embedding, which maps brain regions into an embedded space, where strongly connected points are closely spaced while loosely connected points are far apart. It was reported that in principle gradient 1, the transmodal DMN regions are anchored at one end and the unimodal visual, somatosensory/motor regions are at the other end, whereas in principle gradient 2, the visual networks are at one end and the somatosensory/motor regions are on the opposite end. This close resemblance between latent variables and principal gradients provides evidence that the network configurations based on the connectivity geometry revealed by the principal gradients closely reflects the instantaneous network activity demonstrated by the VAE.</p>
      </sec>
      <sec id="S13">
        <label>3.3.</label>
        <title>The primary latent dimension shows a spatial-temporal pattern very similar to the QPP</title>
        <p id="P24">It can be seen from <xref ref-type="fig" rid="F2">Fig. 2</xref> that the first latent dimension (which has the highest variance) encodes a spatiotemporal pattern that shows one cycle of anti-correlated activities between DMN and TPN over a 24 s time window. This spatiotemporal feature is very similar to the primary QPP except having opposite phase (the phase in <xref ref-type="fig" rid="F4">Fig. 4</xref> is already reversed for better comparison with QPP). The network is trained with randomly initialized weights, which leads to random polarity of latent variables for every training trial. Thus, the polarity can be ignored and the latent variable 1 and the primary QPP essentially extracted very similar information. This similarity makes sense because QPP averages the time points that have the most prominent correlation with the template, thus reinforcing itself over multiple iterations, and extracting the most prominent, reoccurring spatial temporal features. It is not surprising that such spatial temporal features have the most variance and thus were picked up by the variational autoencoder as the first latent dimension.</p>
        <p id="P25">Aside from the first latent dimension, there are also 5 other latent dimensions in the primary cluster that share very similar spatial distributions, but differ in frequency and phase. To better visualize these differences among the timings of the latent variables, the latent features from a region of interest (ROI) in the SM was shown as a function of both the value of latent variable and time in <xref ref-type="fig" rid="F5">Fig. 5</xref>. Specifically, these latent variables with smaller variance tend to have higher frequencies. These spatiotemporal trajectories have not been previously reported, probably because their variance is relatively small compared to the primary component. On top of this, the VAE also identifies 5 other clusters of latent variables that have different spatial configurations. In the traditional QPP calculations, these features may have been canceled out with each other during the averaging process.</p>
      </sec>
      <sec id="S14">
        <label>3.4.</label>
        <title>Reconstruction of rs-fMRI segments in the testing set</title>
        <p id="P26"><xref ref-type="fig" rid="F6">Fig. 6</xref> shows the reconstruction of the rs-fMRI segments and the corresponding weights of latent variables. This reconstruction provides a qualitative assessment of how much information is lost during the encoding-decoding process. Although it is not a perfect match, most of the timing and the amplitude information is captured, especially for fluctuations with high amplitudes. It is worth mentioning that each rs-fMRI segment has 246 parcels and 33 time points, while the encoded representation only has 32 variables, which is around 1/250 of the original size. This fairly good quality of reconstruction despite such a high compression rate suggests that the original parcellated rs-fMRI data is actually quite redundant, which is potentially due to the fact that many parcels coactivate with each other, while others may show anticorrelations. This interlinked relationship among different brain regions greatly reduces the degree of freedom in the system. Thus, the proposed VAE extracts a set of orthogonal bases that accounts for most of the degree of freedom (that have the highest variances), which creates a parsimonious representation of brain activity that reveals such relationships among brain regions.</p>
      </sec>
    </sec>
    <sec id="S15">
      <label>4.</label>
      <title>Discussions</title>
      <sec id="S16">
        <label>4.1.</label>
        <title>Innovativeness of the method</title>
        <p id="P27">We demonstrated a new method to study the intrinsic features in resting-state fMRI using a convolutional variational autoencoder. This particular architecture has never been used to characterize rs-fMRI, although there have been a few applications in other fields that have similar convolutional VAE architectures. For example, (<xref rid="R42" ref-type="bibr">Kulkarni et al., 2015</xref>) used a 2-D convolutional variational autoencoder to learn intrinsic spatial patterns from images. The features of the network architecture that we developed (namely the autoencoder design, the variational approach and the 1-D convolutional layers) have many advantages for studying rs-fMRI temporal dynamics.</p>
        <p id="P28">Firstly, the proposed method provides a parsimonious representation of brain activity by condensing it into a few highly representative components, without losing too much information. Each “brain state”, which is the collection of activity across the entire brain at any given time, can be represented as a point in a hyperplane. This brain state representation tends to be very high-dimensional. For example, the 2 mm volumetric HCP data has 91 × 109 × 91 = 902,629 voxels, and even the greatly downsampled data examined here after parcellation with the BN atlas has 246 parcels. Extremely high-dimensional data is very sparse and hard to generalize, which is also known as the “curse of dimensionality” <xref rid="R6" ref-type="bibr">Bellman (1952)</xref>. Thus, this high-dimensional definition of brain states, is overly complicated and redundant, because the many resting state networks are spatially organized, and the temporal dynamics involved may also be governed by certain rules. The “true” brain state vector may live in a much lower dimension space, which is what the VAE is designed to capture. The parsimonious representation of brain activity (using a 32-component vector to represent the brain state dynamics contained in a 246 parcels by 33 time points matrix) captures the most distinctive and prominent common trajectories that can serve as the building blocks to construct all possible spatiotemporal dynamics in resting state fMRI. This provides insight into both the spatial organization of the networks, and the characteristic dynamics for those networks. The variational approach (which includes random sampling and penalizing KL divergence) has forced the latent components to be nearly orthogonal to each other, which have helped to create a robust and unique decomposition of the brain activity and make the latent variables easier to interpret since they are disentangled.</p>
        <p id="P29">Secondly, the use of 1-D convolutional layers has taken the structure along temporal dimension into consideration, which enables the method to simultaneously extract not only spatial patterns, but also their temporal dynamics. As discussed later, most analysis methods consider spatial information and temporal information independently. The learned latent representations were grouped into a few clusters that show similar spatial configurations that are in agreement with the anticorrelated DMN-TPN and principal gradients. Moreover, the temporal dynamics within these spatial configurations were also provided in the form of a few orthogonal components, where the one with the highest variance closely resembles the primary QPP, while the others show temporal structures that were previously extensively reported in the past.</p>
        <p id="P30">Thirdly, as a deep learning method, this method makes minimal assumptions about rs-fMRI. The use of 1-D convolutional kernel implies that the rule governing the temporal dynamics is shift-invariant along time and is applicable to all subjects, which is a reasonable assumption to make if the goal is to find common spatiotemporal features that exist across subjects. Other than that, the neural network itself does not make any other assumptions about rs-fMRI. However it is worthwhile to point out that although the neural networks themselves make minimal assumptions about the brain dynamics in rs-fMRI, the standard rs-fMRI data preprocessing steps do make assumptions regarding frequency bands, window length, parcellations and global signal regressions.</p>
      </sec>
      <sec id="S17">
        <label>4.2.</label>
        <title>Comparison with existing methods</title>
        <p id="P31">While there is no existing method that strictly focuses on the same goal as the proposed method, many other methods are conceptually related, and the spatial configurations obtained by the proposed method can be compared with existing methods. In this section we compare the results from our VAE approach to other existing methods for rs-fMRI analysis, including principal component analysis (PCA), principal gradients, QPP, SWC, ICA, CAP and HMM.</p>
        <sec id="S18">
          <label>4.2.1.</label>
          <title>Relation to principal component analysis (PCA)</title>
          <p id="P32">PCA and the VAE used for this study share some similarities. Both methods identify orthogonal bases for the original data and can achieve dimensionality reduction by selecting a few components that explain the most variance. In fact, a two-layer VAE with a linear activation function produces almost identical results to PCA, because both methods aim to create a linear projection of the data to an orthogonal space <xref rid="R53" ref-type="bibr">Plaut (2018)</xref>. In our VAE, there are 10 layers in total, making the VAE capable of creating a much more nonlinear mapping that might capture features that would not be found in a linear mapping. On top of that, the proposed VAE has three 1-D convolutional layers to extract characteristic temporal dynamics, which are not captured by PCA. Thus the latent variables in our model captures spatiotemporal dynamics, whereas the traditional PCA often gives eigenvectors in the spatial domain, e.g. (<xref rid="R44" ref-type="bibr">Leonardi et al., 2013</xref>).</p>
        </sec>
        <sec id="S19">
          <label>4.2.2.</label>
          <title>Relation to diffusion embedding (principal functional connectivity gradients)</title>
          <p id="P33">Principal functional connectivity gradients were described using a method called diffusion embedding, which nonlinearly maps brain region into an embedded hyperplane, where strongly connected points are close whereas loosely connected points are far apart (<xref rid="R49" ref-type="bibr">Margulies et al., 2016</xref>). The “gradients” that define the hyperplane reveal connectivity patterns over space. Like PCA, diffusion embedding provides information about connectivity geometry, but loses temporal information, whereas the proposed VAE provides a set of spatiotemporal patterns that demonstrate clusters of spatial organization while also providing information about characteristic temporal dynamics.</p>
          <p id="P34">Because diffusion embedding and the VAE method emphasize different features of the rs-fMRI data, they are complementary to each other. The principal gradient is able to differentiate several networks along the gradient (e.g. DMN-FP-DA-VIS) whereas the variational autoencoder can only provide coarse locations (DMN and FP on one end, and DA, VA, VIS, SM on the other end). The VAE however, is also capable of showing temporal features and considers both the dynamics involved in brain activity and the interactions among brain regions, which the principle gradient lacks. Thus, they bring insights into different aspects of the same complicated brain system. The fact that the first two clusters of latent variables in VAE and the first two principal gradients show a consistent DMN versus TPN along the primary axis, and VIS versus SM, as well as DA versus VA along the secondary axis, is a reassuring indication of the consistency of the two approaches.</p>
        </sec>
        <sec id="S20">
          <label>4.2.3.</label>
          <title>Relation to QPP regression</title>
          <p id="P35">The spatiotemporal feature that would activate latent variable 1 is very similar to the spatiotemporal patterns found in the primary QPP, specifically a sinusoidal wave-like fluctuation showing anti-correlation between the DMN and TPN, as shown in <xref ref-type="fig" rid="F4">Fig. 4</xref>. The QPP picks up the most prominent feature in rs-fMRI because it iteratively averages the time points that have the highest correlation with the template to update the template, so it makes sense for such a feature to capture the largest portion of the variance. Aside from the primary QPP, a set of secondary QPPs have been obtained from mouse (<xref rid="R7" ref-type="bibr">Belloy et al., 2018</xref>) and human (<xref rid="R67" ref-type="bibr">Yousefi and Keilholz, 2021</xref>) resting-state fMRI data, by recursively regressing out QPP components. QPP regression is similar to the VAE method in that they both extract components that are independent to each other, and they both capture reoccurring spatiotemporal patterns. However, QPP regression was often done only for the first few components, without an exhaustive search for all possible components, perhaps because of the decreased robustness involved in the recursive convolution and regression, as well as the increased computational cost. The VAE method, however, gives an overview of all spatiotemporal patterns at the same time.</p>
        </sec>
        <sec id="S21">
          <label>4.2.4.</label>
          <title>Relation to sliding window correlation (SWC)</title>
          <p id="P36">The proposed VAE was trained with short rs-fMRI segments of approximately 24 s in length. Although during training the rs-fMRI segments were shuffled, during testing (shown in <xref ref-type="fig" rid="F6">Fig. 6</xref>) there was no shuffling, and the rs-fMRI time course was essentially transformed into latent representations using a 24-second, 50%-overlapping sliding windows, in a manner similar to the sliding window correlation method. However, for the VAE approach, the windows are used to train 32 latent variables which capture the spatiotemporal dynamics, while for sliding window correlation, dynamics are represented by the time varying correlation values. K-means clustering is applied for both approaches. For the VAE, clustering is used to group latent variables by their spatial similarity. For SWC, however, clustering the time-varying correlation is the basis for “brain states” that can be defined for each time window in the scan. Since the VAE requires components to be nearly independent of each other, the resulting clusters are more unique and clearly defined, whereas in SWC, the clusters seem to have more ambiguities because different components can mix and the long window (typically around 1–2 min) used for correlation can obscure short-term dynamics. For example, in (<xref rid="R3" ref-type="bibr">Allen et al., 2014</xref>) it was shown that the brain exhibits 7 states with connectivity patterns using a SWC method, among which states 2–7 all show notable anticorrelation between default-mode regions and sensory systems, with some variations (e.g.,. state 5 and 6 separates posterior DM nodes (precuneus and PCC) from anterior and lateral parietal regions; state 6 and 7 shows positive correlation between DM and SM area, and negative correlation between SM and VIS regions). These effects manifest as a slight deviation from the average functional connectivity, whereas in our VAE method, such separations are much more clearly defined, e.g. SM versus VIS in cluster 2, and posterior DM regions versus anterior and lateral parietal DM regions in cluster 2 and cluster 4.</p>
        </sec>
        <sec id="S22">
          <label>4.2.5.</label>
          <title>Relation to independent component analysis (ICA)</title>
          <p id="P37">The proposed method also has some similarities to ICA, another popular method for dimensionality reduction. Though both methods try to decompose the rs-fMRI signal into independent components, the approaches they take are different. ICA can be used to discover either spatially or temporally independent components. Most rs-fMRI studies use a spatial ICA (sICA) approach to find spatial components that are maximally independent in space (<xref rid="R9" ref-type="bibr">Calhoun et al., 2009</xref>). It is typically applied as one step in the preprocessing to create a “functional parcellation”, which is also known as intrinsic connectivity networks (ICNs), and is often applied in conjunction with further analysis methods like SWC, e.g. (<xref rid="R3" ref-type="bibr">Allen et al., 2014</xref>). ICA seeks to create a matrix decomposition of the entire rs-fMRI dataset, where one matrix represents spatially independent networks and the other represent the time courses of the signals from different sources. Although the time course of each spatial component can be obtained, these time courses remain in the same length as the original unprocessed time course, with no characterization of the temporal building blocks. The proposed VAE, on the other hand, is trying to extract characteristic, repeatable features that are independent from each other, on a much shorter time scale. It identifies instantaneous brain trajectories within a short time window (~20 s) that are very characteristic, so that all the dynamics in rs-fMRI can be explained by the same set of common trajectories. The counter-part of ICA’s role of creating parcellation in this study was achieved by using the Brainnetome atlas 246-region parcellation (an anatomical parcellation), which was then organized using Yeo’s 7network7-network model.</p>
        </sec>
        <sec id="S23">
          <label>4.2.6.</label>
          <title>Relation to HMM and CAP</title>
          <p id="P38">HMM and CAP methods are explicitly designed to characterize changes in the rs-fMRI signal over time and emphasize individual time frames in the rs-fMRI time series. The VAE, on the other hand, focuses on the dynamic patterns within rs-fMRI segments, linking spatial patterns with temporal variation. Nevertheless, the spatial patterns obtained with the three methods can be compared. For the HMM method it was reported that every fMRI frame can be classified into one of the 12 brain states, which are organized into 2 metastates (<xref rid="R65" ref-type="bibr">Vidaurre et al., 2017</xref>). The first metastate (state 1–4), is composed of sensory (somatic, visual, and auditory) and motor regions, and the second metastate (state 6–12) covers higher order cognitive regions that include the DMN, language, and prefrontal areas. Individual states may show specific network patterns, e.g. state 4 (visual), state 6 (DMN), state 9 (Language). In the CAP method, the few frames with posterior cingulate cortex (PCC) activation (whose correlation map resembles DMN) can be decomposed into 8 different spatial patterns (<xref rid="R46" ref-type="bibr">Liu and Duyn, 2013</xref>). In the first 4 components, CAP1 and CAP2 more closely resemble DMN than CAP3 and CAP4, with CAP1 extending more dorsally and CAP2 more ventrally. CAP3 highlights the middle frontal gyrus (MFG, lies in FP network in Yeo’s parcellation), whereas CAP4 highlights the superior frontal gyrus (SFG, DM network) and the parahippocampus gyrus (PHG, LIM network). There are also another 4 CAPs with less resemblance to DMN that have lower within-group similarity. These variations of spatial patterns observed in the individual time frames, could emerge from the superposition of the orthogonal components found in the proposed VAE model. For example, positive components in latent cluster 1 (DMN activation) superimposed with positive components in latent cluster 2 (DM and LIM activation) could give rise to a spatial pattern similar to CAP4, whereas positive components in latent cluster 1 superimposed with negative components in latent cluster 2 (FP activation) could result in something more similar to CAP3.</p>
        </sec>
      </sec>
      <sec id="S24">
        <label>4.3.</label>
        <title>New findings from the VAE</title>
        <p id="P39">Although fundamentally different from existing methods, the trained VAE returns results in line with many previous studies. In particular, the DMN-TPN contrast seen here was also reported in DMN-TPN anticorrelation, QPPs, metastates (<xref rid="R65" ref-type="bibr">Vidaurre et al., 2017</xref>) and principal gradients. In addition to recapitulating previous findings, the VAE method also reveals some spatiotemporal trajectories that were not previously discovered or extensively discussed. For example, there are spatiotemporal trajectories that generally follow the DMN-TPN spatial configuration, but have much faster frequencies when compared to the QPP (e.g. latent variable 2, 4, 5 in the primary latent variable cluster). A second example is given by the spatiotemporal trajectories in the secondary cluster, which show temporal dynamics along a spatial distribution similar to principal gradient 2 (VIS, DA on one side and SM, VA on the other). These additional spatiotemporal dynamics are worth investigating in the future, including but not limited to their reproducibility and whether they would change under different cognitive states.</p>
        <p id="P40">Another interesting feature to notice is that there seem to be two modes of activity revealed by the spatiotemporal trajectories. One mode has distinct on and off blocks showing two networks having exactly opposite phase (e.g. latent variable 1). Another mode shows a gradual change of phase/peak time along the spatial dimension, which behaves more like a wave propagating through different networks, which could also be related the findings in (<xref rid="R24" ref-type="bibr">Gu et al., 2020</xref>) and (<xref rid="R67" ref-type="bibr">Yousefi and Keilholz, 2021</xref>). This propagation/time lag, and how it interacts with the first mode (the well-known DMN-TPN anticorrelation) is worth investigating in the future.</p>
      </sec>
      <sec id="S25">
        <label>4.4.</label>
        <title>Potential applications</title>
        <p id="P41">The proposed VAE has found a set of characteristic spatiotemporal brain trajectories that can explain most of the dynamics involved in rs-fMRI. This new perspective provides insights into the brain’s spatiotemporal dynamics that cannot be accessed from traditional methods such as functional connectivity. Future work should explore how these characteristic trajectories change when the cognitive state is changed (e.g. task performance, sleeping vs resting state) or with the presence of a neurological or psychiatric disorder (e.g. Alzheimer’s disease, major depression disorder or ADHD) as these alterations may change the fMRI characteristics and instantaneous dynamics. For example, in (<xref rid="R33" ref-type="bibr">Jones et al., 2012b</xref>) it was reported that the differences in static connectivity observed in Alzheimer’s disease can be explained by differences in dwell time in DMN sub-network configurations, which suggests the dynamics of brain activity, and presumably the characteristic spatiotemporal brain trajectories are also altered by Alzheimer’s disease. Potential additional approaches include training multiple VAEs on patient and control groups to see if the characteristic trajectories identified are different, using the characteristic trajectories from healthy resting-state data as a benchmark to identify statistical differences among groups, or training a classifier to utilize trajectories to identify the cognitive state or neurological disorder. It is also interesting to see if the family structure in HCP dataset and the variations in ages would cause any noticeable changes in the spatiotemporal patterns.</p>
      </sec>
      <sec id="S26">
        <label>4.5.</label>
        <title>Technical limitations</title>
        <p id="P42">Although the proposed method has opened up a new perspective for viewing rs-fMRI dynamics, it does have some technical limitations. First many of the hyperparameters are empirically chosen, which is almost always not the most “optimal” solution of the problem. While it is possible to perform an exhaustive grid search for optimal parameters in some circumstances, the computational cost quickly become infeasible when the number and the range of parameters being tuned is large (<xref rid="R66" ref-type="bibr">Wu et al., 2019</xref>). That said, we did consider many factors when designing the neural network so that the parameters involved are within a reasonable range. For example, the number of layers cannot be too small, or the model will lack expressive power and cannot capture complicated features; on the other hand, the number of layers cannot be too large or the gradient will not backpropagate easily, resulting in diffculties in training. We also performed a holdout validation to examine the effect of the hyperparameters like the number of latent variables and number of layers (the results were shown in <xref ref-type="supplementary-material" rid="SD1">supplementary materials section S.1</xref>). While the choices we made are not necessarily the best, they certainly are not the worst.</p>
        <p id="P43">Secondly the network was trained with a built-in “sliding window”. We chose to divide the dataset into 50% overlapping, 33-TR (24 s) long time window. This is likely to limit the lowest frequency component the model can identify, which is around 1/24 = 0.042 Hz. Fluctuations that occur at lower frequencies are likely to be ignored by the model. Using a longer window may help capture components with lower frequencies, but doing such also requires an increase number of latent variables to encode the additional information in the elongated window, thus making the model more complex and harder to train. Eventually there will be a soft limit of how long the window can be feasibly implemented, which puts a lower bound to the frequencies that can be properly identified.</p>
        <p id="P44">Thirdly the proposed method is tailored for parcellated rs-fMRI data. For nonparcellated rs-fMRI data, it would make more sense to use multidimensional convolutional layers instead of the 1-D convolutional layers we used in our work, since volumetric rs-fMRI data may preserve the property of shift-invariance not only in the time domain, but also in the spatial domain as well. However, volumetric rs-fMRI data are orders of magnitude larger than parcellated rs-fMRI data in size, whose modeling demands a neural network with more complex structure and greater expressive power. This increased model size makes the network harder to train. Whether it is possible to train such a model for nonparcellated rs-fMRI data, and if so how the latent variable would differ from those obtained from a model trained with parcellated rs-fMRI data, still remains unknown at the moment.</p>
      </sec>
    </sec>
    <sec id="S27">
      <label>5.</label>
      <title>Conclusion</title>
      <p id="P45">In this article we proposed a novel convolutional variational autoencoder to extract intrinsic spatiotemporal patterns from short segments of resting-state fMRI data. The extracted latent dimensions show clear clusters in the spatial domain that are in agreement with previous findings, but also provide temporal information about the evolution of brain activity as well. Some spatiotemporal features were similar to previously-described QPPs, but there are others with smaller variances that were not previously discovered, which is worth investigating in the future.</p>
    </sec>
    <sec sec-type="supplementary-material" id="SM1">
      <title>Supplementary Material</title>
      <supplementary-material content-type="local-data" id="SD1">
        <label>1</label>
        <media xlink:href="NIHMS1755363-supplement-1.docx" orientation="portrait" id="d40e645" position="anchor"/>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack id="S28">
      <title>Acknowledgements</title>
      <p id="P46">Funding: This work was supported by the National Institutes of Health (NIH) [grant numbers R01NS078095–01]; the Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative [grant number R01 MH 111416]; and the National Science Foundation (NSF) INSPIRE [grant number 1533260].</p>
      <p id="P47">The authors would like to thank the Washington University– University of Minnesota Consortium of the Human Connectome Project (WU-Minn HCP) for generating and making publicly available the HCP data. The authors would like to thank Chinese Scholarship Council (CSC) for financial support.</p>
    </ack>
    <fn-group>
      <fn id="FN2">
        <p id="P48">Data and code availability statement</p>
        <p id="P49">The data was downloaded from the publicly available Human Connectome Project (HCP) dataset (<xref rid="R22" ref-type="bibr">Glasser et al., 2013</xref>).</p>
        <p id="P50">The code used for training the VAE was implemented using Pytorch (<xref rid="R52" ref-type="bibr">Paszke et al., 2017</xref>). All of the additional processing and visualization steps after the training the VAE were implemented in MATLAB R2020a (MathWorks, Natick, MA). The code will be available in our lab’s Github page <ext-link ext-link-type="uri" xlink:href="https://github.com/GT-EmoryMINDlab">https://github.com/GT-EmoryMINDlab</ext-link>.</p>
        <p id="P51">Glasser, M.F., Sotiropoulos, S.N., Wilson, J.A., Coalson, T.S., Fischl, B., Andersson, J.L., Xu, J., Jbabdi, S., Webster, M., Polimeni, J.R., Van Essen, D.C., Jenkinson, M., 2013. The minimal preprocessing pipelines for the Human Connectome Project. Neuroimage 80, 105–124. <ext-link ext-link-type="doi" xlink:href="10.1016/j.neuroimage.2013.04.127">https://doi.org/10.1016/j.neuroimage.2013.04.127</ext-link></p>
        <p id="P52">Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., Facebook, Z.D., Research, A.I., Lin, Z., Desmaison, A., Antiga, L., Srl, O., Lerer, A., 2017. Automatic differentiation in PyTorch.</p>
      </fn>
      <fn id="FN3">
        <p id="P53">Supplementary materials</p>
        <p id="P54"><xref ref-type="supplementary-material" rid="SD1">Supplementary material</xref> associated with this article can be found, in the online version, at doi:<ext-link ext-link-type="doi" xlink:href="10.1016/j.neuroimage.2021.118588">10.1016/j.neuroimage.2021.118588</ext-link>.</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="R1">
        <mixed-citation publication-type="journal"><name><surname>Abbas</surname><given-names>A</given-names></name>, <name><surname>Belloy</surname><given-names>M</given-names></name>, <name><surname>Kashyap</surname><given-names>A</given-names></name>, <name><surname>Billings</surname><given-names>J</given-names></name>, <name><surname>Nezafati</surname><given-names>M</given-names></name>, <name><surname>Schumacher</surname><given-names>EH</given-names></name>, <name><surname>Keilholz</surname><given-names>S</given-names></name>, <year>2019</year>. <article-title>Quasi-periodic patterns contribute to functional connectivity in the brain</article-title>. <source>Neuroimage</source>
<volume>191</volume>, <fpage>193</fpage>–<lpage>204</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.01.076</pub-id>.<pub-id pub-id-type="pmid">30753928</pub-id></mixed-citation>
      </ref>
      <ref id="R2">
        <mixed-citation publication-type="journal"><name><surname>Albert</surname><given-names>NB</given-names></name>, <name><surname>Robertson</surname><given-names>EM</given-names></name>, <name><surname>Miall</surname><given-names>RC</given-names></name>, <year>2009</year>. <article-title>The resting human brain and motor learning</article-title>. <source>Curr. Biol</source>. <volume>19</volume>, <fpage>1023</fpage>–<lpage>1027</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2009.04.028</pub-id>.<pub-id pub-id-type="pmid">19427210</pub-id></mixed-citation>
      </ref>
      <ref id="R3">
        <mixed-citation publication-type="journal"><name><surname>Allen</surname><given-names>EA</given-names></name>, <name><surname>Damaraju</surname><given-names>E</given-names></name>, <name><surname>Plis</surname><given-names>SM</given-names></name>, <name><surname>Erhardt</surname><given-names>EB</given-names></name>, <name><surname>Eichele</surname><given-names>T</given-names></name>, <name><surname>Calhoun</surname><given-names>VD</given-names></name>, <year>2014</year>. <article-title>Tracking whole-brain connectivity dynamics in the resting state</article-title>. <source>Cereb. Cortex</source>
<volume>24</volume>, <fpage>663</fpage>–<lpage>676</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhs352</pub-id>.<pub-id pub-id-type="pmid">23146964</pub-id></mixed-citation>
      </ref>
      <ref id="R4">
        <mixed-citation publication-type="journal"><name><surname>Bai</surname><given-names>S</given-names></name>, <name><surname>Kolter</surname><given-names>JZ</given-names></name>, <name><surname>Koltun</surname><given-names>V</given-names></name>, <year>2018</year>. <article-title>An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</article-title>. <source>arXiv</source>.</mixed-citation>
      </ref>
      <ref id="R5">
        <mixed-citation publication-type="journal"><name><surname>Bassett</surname><given-names>DS</given-names></name>, <name><surname>Wymbs</surname><given-names>NF</given-names></name>, <name><surname>Porter</surname><given-names>MA</given-names></name>, <name><surname>Mucha</surname><given-names>PJ</given-names></name>, <name><surname>Carlson</surname><given-names>JM</given-names></name>, <name><surname>Grafton</surname><given-names>ST</given-names></name>, <year>2011</year>. <article-title>Dynamic reconfiguration of human brain networks during learning</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>108</volume>, <fpage>7641</fpage>–<lpage>7646</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1018985108</pub-id>.<pub-id pub-id-type="pmid">21502525</pub-id></mixed-citation>
      </ref>
      <ref id="R6">
        <mixed-citation publication-type="journal"><name><surname>Bellman</surname><given-names>R</given-names></name>, <year>1952</year>. <article-title>On the theory of dynamic programming</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>38</volume>, <fpage>716</fpage>–<lpage>719</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.38.8.716</pub-id>.<pub-id pub-id-type="pmid">16589166</pub-id></mixed-citation>
      </ref>
      <ref id="R7">
        <mixed-citation publication-type="journal"><name><surname>Belloy</surname><given-names>ME</given-names></name>, <name><surname>Naeyaert</surname><given-names>M</given-names></name>, <name><surname>Abbas</surname><given-names>A</given-names></name>, <name><surname>Shah</surname><given-names>D</given-names></name>, <name><surname>Vanreusel</surname><given-names>V</given-names></name>, <name><surname>van Audekerke</surname><given-names>J</given-names></name>, <name><surname>Keilholz</surname><given-names>SD</given-names></name>, <name><surname>Keliris</surname><given-names>GA</given-names></name>, <name><surname>Van der Linden</surname><given-names>A</given-names></name>, <name><surname>Verhoye</surname><given-names>M</given-names></name>, <year>2018</year>. <article-title>Dynamic resting state fMRI analysis in mice reveals a set of Quasi-periodic patterns and illustrates their relationship with the global signal</article-title>. <source>Neuroimage</source> doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.01.075</pub-id>.</mixed-citation>
      </ref>
      <ref id="R8">
        <mixed-citation publication-type="journal"><name><surname>Biswal</surname><given-names>B</given-names></name>, <name><surname>Zerrin Yetkin</surname><given-names>F</given-names></name>, <name><surname>Haughton</surname><given-names>VM</given-names></name>, <name><surname>Hyde</surname><given-names>JS</given-names></name>, <year>1995</year>. <article-title>Functional connectivity in the motor cortex of resting human brain using echo-planar mri</article-title>. <source>Magn. Reson. Med</source>. <volume>34</volume>, <fpage>537</fpage>–<lpage>541</lpage>. doi:<pub-id pub-id-type="doi">10.1002/mrm.1910340409</pub-id>.<pub-id pub-id-type="pmid">8524021</pub-id></mixed-citation>
      </ref>
      <ref id="R9">
        <mixed-citation publication-type="journal"><name><surname>Calhoun</surname><given-names>VD</given-names></name>, <name><surname>Liu</surname><given-names>J</given-names></name>, <name><surname>Adali</surname><given-names>T</given-names></name>, <year>2009</year>. <article-title>A review of group ICA for fMRI data and ICA for joint inference of imaging, genetic, and ERP data</article-title>. <source>Neuroimage</source>
<volume>45</volume>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.10.057</pub-id>.</mixed-citation>
      </ref>
      <ref id="R10">
        <mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>C</given-names></name>, <name><surname>Glover</surname><given-names>GH</given-names></name>, <year>2010</year>. <article-title>Time-frequency dynamics of resting-state brain connectivity measured with fMRI</article-title>. <source>Neuroimage</source>
<volume>50</volume>, <fpage>81</fpage>–<lpage>98</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.011</pub-id>.<pub-id pub-id-type="pmid">20006716</pub-id></mixed-citation>
      </ref>
      <ref id="R11">
        <mixed-citation publication-type="journal"><name><surname>Cordes</surname><given-names>D</given-names></name>, <name><surname>Haughton</surname><given-names>VM</given-names></name>, <name><surname>Arfanakis</surname><given-names>K</given-names></name>, <name><surname>Wendt</surname><given-names>GJ</given-names></name>, <name><surname>Turski</surname><given-names>PA</given-names></name>, <name><surname>Moritz</surname><given-names>CH</given-names></name>, <name><surname>Quigley</surname><given-names>MA</given-names></name>, <name><surname>Meyerand</surname><given-names>ME</given-names></name>, <year>2000</year>. <article-title>Mapping functionally related regions of brain with functional connectivity MR imaging</article-title>. <source>Am. J. Neuroradiol</source>. <volume>21</volume>.</mixed-citation>
      </ref>
      <ref id="R12">
        <mixed-citation publication-type="journal"><name><surname>Damaraju</surname><given-names>E</given-names></name>, <name><surname>Allen</surname><given-names>EA</given-names></name>, <name><surname>Belger</surname><given-names>A</given-names></name>, <name><surname>Ford</surname><given-names>JM</given-names></name>, <name><surname>McEwen</surname><given-names>S</given-names></name>, <name><surname>Mathalon</surname><given-names>DH</given-names></name>, <name><surname>Mueller</surname><given-names>BA</given-names></name>, <name><surname>Pearlson</surname><given-names>GD</given-names></name>, <name><surname>Potkin</surname><given-names>SG</given-names></name>, <name><surname>Preda</surname><given-names>A</given-names></name>, <name><surname>Turner</surname><given-names>JA</given-names></name>, <name><surname>Vaidya</surname><given-names>JG</given-names></name>, <name><surname>Van Erp</surname><given-names>TG</given-names></name>, <name><surname>Calhoun</surname><given-names>VD</given-names></name>, <year>2014</year>. <article-title>Dynamic functional connectivity analysis reveals transient states of dysconnectivity in schizophrenia</article-title>. <source>NeuroImage Clin</source>. <volume>5</volume>, <fpage>298</fpage>–<lpage>308</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.nicl.2014.07.003</pub-id>.<pub-id pub-id-type="pmid">25161896</pub-id></mixed-citation>
      </ref>
      <ref id="R13">
        <mixed-citation publication-type="journal"><name><surname>Damoiseaux</surname><given-names>JS</given-names></name>, <name><surname>Rombouts</surname><given-names>SARB</given-names></name>, <name><surname>Barkhof</surname><given-names>F</given-names></name>, <name><surname>Scheltens</surname><given-names>P</given-names></name>, <name><surname>Stam</surname><given-names>CJ</given-names></name>, <name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <year>2006</year>. <article-title>Consistent resting-state networks across healthy subjects</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>103</volume>, <fpage>13848</fpage>–<lpage>13853</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0601417103</pub-id>.<pub-id pub-id-type="pmid">16945915</pub-id></mixed-citation>
      </ref>
      <ref id="R14">
        <mixed-citation publication-type="journal"><name><surname>Esposito</surname><given-names>F</given-names></name>, <name><surname>Bertolino</surname><given-names>A</given-names></name>, <name><surname>Scarabino</surname><given-names>T</given-names></name>, <name><surname>Latorre</surname><given-names>V</given-names></name>, <name><surname>Blasi</surname><given-names>G</given-names></name>, <name><surname>Popolizio</surname><given-names>T</given-names></name>, <name><surname>Tedeschi</surname><given-names>G</given-names></name>, <name><surname>Cirillo</surname><given-names>S</given-names></name>, <name><surname>Goebel</surname><given-names>R</given-names></name>, <name><surname>Di Salle</surname><given-names>F</given-names></name>, <year>2006</year>. <article-title>Independent component model of the default-mode brain function: assessing the impact of active thinking</article-title>. <source>Brain Res. Bull</source>.<volume>70</volume>, <fpage>263</fpage>–<lpage>269</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.brainresbull.2006.06.012</pub-id>.<pub-id pub-id-type="pmid">17027761</pub-id></mixed-citation>
      </ref>
      <ref id="R15">
        <mixed-citation publication-type="journal"><name><surname>Fan</surname><given-names>L</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Zhuo</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Chen</surname><given-names>L</given-names></name>, <name><surname>Yang</surname><given-names>Z</given-names></name>, <name><surname>Chu</surname><given-names>C</given-names></name>, <name><surname>Xie</surname><given-names>S</given-names></name>, <name><surname>Laird</surname><given-names>AR</given-names></name>, <name><surname>Fox</surname><given-names>PT</given-names></name>, <name><surname>Eickhoff</surname><given-names>SB</given-names></name>, <name><surname>Yu</surname><given-names>C</given-names></name>, <name><surname>Jiang</surname><given-names>T</given-names></name>, <year>2016</year>. <article-title>The human brainnetome atlas: a new brain atlas based on connectional architecture</article-title>. <source>Cereb. Cortex</source>
<volume>26</volume>, <fpage>3508</fpage>–<lpage>3526</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhw157</pub-id>.<pub-id pub-id-type="pmid">27230218</pub-id></mixed-citation>
      </ref>
      <ref id="R16">
        <mixed-citation publication-type="journal"><name><surname>Fornito</surname><given-names>A</given-names></name>, <name><surname>Harrison</surname><given-names>BJ</given-names></name>, <name><surname>Zalesky</surname><given-names>A</given-names></name>, <name><surname>Simons</surname><given-names>JS</given-names></name>, <year>2012</year>. <article-title>Competitive and cooperative dynamics of large-scale brain functional networks supporting recollection</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>109</volume>, <fpage>12788</fpage>–<lpage>12793</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1204185109</pub-id>.<pub-id pub-id-type="pmid">22807481</pub-id></mixed-citation>
      </ref>
      <ref id="R17">
        <mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>MD</given-names></name>, <name><surname>Corbetta</surname><given-names>M</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Vincent</surname><given-names>JL</given-names></name>, <name><surname>Raichle</surname><given-names>ME</given-names></name>, <year>2006</year>. <article-title>Spontaneous neuronal activity distinguishes human dorsal and ventral attention systems</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>103</volume>, <fpage>10046</fpage>–<lpage>10051</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0604187103</pub-id>.<pub-id pub-id-type="pmid">16788060</pub-id></mixed-citation>
      </ref>
      <ref id="R18">
        <mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>MD</given-names></name>, <name><surname>Raichle</surname><given-names>ME</given-names></name>, <year>2007</year>. <article-title>Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging</article-title>. <source>Nat. Rev. Neurosci</source>. doi:<pub-id pub-id-type="doi">10.1038/nrn2201</pub-id>.</mixed-citation>
      </ref>
      <ref id="R19">
        <mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>MD</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Vincent</surname><given-names>JL</given-names></name>, <name><surname>Corbetta</surname><given-names>M</given-names></name>, <name><surname>Van Essen</surname><given-names>DC</given-names></name>, <name><surname>Raichle</surname><given-names>ME</given-names></name>, <year>2005</year>. <article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>102</volume>, <fpage>9673</fpage>–<lpage>9678</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0504136102</pub-id>.<pub-id pub-id-type="pmid">15976020</pub-id></mixed-citation>
      </ref>
      <ref id="R20">
        <mixed-citation publication-type="journal"><name><surname>Gehring</surname><given-names>J</given-names></name>, <name><surname>Auli</surname><given-names>M</given-names></name>, <name><surname>Grangier</surname><given-names>D</given-names></name>, <name><surname>Yarats</surname><given-names>D</given-names></name>, <name><surname>Dauphin</surname><given-names>YN</given-names></name>, <year>2017</year>. <part-title>Convolutional sequence to sequence learning</part-title>. In: <source>34th Int. Conf. Mach. Learn. ICML 2017</source>, <volume>3</volume>, pp. <fpage>2029</fpage>–<lpage>2042</lpage>.</mixed-citation>
      </ref>
      <ref id="R21">
        <mixed-citation publication-type="journal"><name><surname>Ghahremani</surname><given-names>M</given-names></name>, <name><surname>Hutchison</surname><given-names>RM</given-names></name>, <name><surname>Menon</surname><given-names>RS</given-names></name>, <name><surname>Everling</surname><given-names>S</given-names></name>, <year>2016</year>. <article-title>Frontoparietal functional connectivity in the common marmoset</article-title>. <source>Cereb. Cortex</source>. doi:<pub-id pub-id-type="doi">10.1093/cer-cor/bhw198</pub-id>.</mixed-citation>
      </ref>
      <ref id="R22">
        <mixed-citation publication-type="journal"><name><surname>Glasser</surname><given-names>MF</given-names></name>, <name><surname>Sotiropoulos</surname><given-names>SN</given-names></name>, <name><surname>Wilson</surname><given-names>JA</given-names></name>, <name><surname>Coalson</surname><given-names>TS</given-names></name>, <name><surname>Fischl</surname><given-names>B</given-names></name>, <name><surname>Andersson</surname><given-names>JL</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Jbabdi</surname><given-names>S</given-names></name>, <name><surname>Webster</surname><given-names>M</given-names></name>, <name><surname>Polimeni</surname><given-names>JR</given-names></name>, <name><surname>Van Essen</surname><given-names>DC</given-names></name>, <name><surname>Jenkinson</surname><given-names>M</given-names></name>, <year>2013</year>. <article-title>The minimal preprocessing pipelines for the human connectome project</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>105</fpage>–<lpage>124</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id>.<pub-id pub-id-type="pmid">23668970</pub-id></mixed-citation>
      </ref>
      <ref id="R23">
        <mixed-citation publication-type="journal"><name><surname>Greicius</surname><given-names>MD</given-names></name>, <name><surname>Krasnow</surname><given-names>B</given-names></name>, <name><surname>Reiss</surname><given-names>AL</given-names></name>, <name><surname>Menon</surname><given-names>V</given-names></name>, <year>2003</year>. <article-title>Functional connectivity in the resting brain: a network analysis of the default mode hypothesis</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>100</volume>, <fpage>253</fpage>–<lpage>258</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0135058100</pub-id>.<pub-id pub-id-type="pmid">12506194</pub-id></mixed-citation>
      </ref>
      <ref id="R24">
        <mixed-citation publication-type="journal"><name><surname>Gu</surname><given-names>Y</given-names></name>, <name><surname>Sainburg</surname><given-names>LE</given-names></name>, <name><surname>Kuang</surname><given-names>S</given-names></name>, <name><surname>Han</surname><given-names>F</given-names></name>, <name><surname>Williams</surname><given-names>JW</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>N</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>, <name><surname>Leopold</surname><given-names>DA</given-names></name>, <name><surname>Liu</surname><given-names>X</given-names></name>, <year>2020</year>. <article-title>Brain activity fluctuations propagate as waves traversing the cortical hierarchy</article-title>. <source>bioRxiv 2020.08.18.256610</source>.</mixed-citation>
      </ref>
      <ref id="R25">
        <mixed-citation publication-type="journal"><name><surname>Hamilton</surname><given-names>JP</given-names></name>, <name><surname>Chen</surname><given-names>G</given-names></name>, <name><surname>Thomason</surname><given-names>ME</given-names></name>, <name><surname>Schwartz</surname><given-names>ME</given-names></name>, <name><surname>Gotlib</surname><given-names>IH</given-names></name>, <year>2011</year>. <article-title>Investigating neural primacy in major depressive disorder: multivariate Granger causality analysis of resting-state fMRI time-series data</article-title>. <source>Mol. Psychiatry</source>
<volume>16</volume>, <fpage>763</fpage>–<lpage>772</lpage>. doi:<pub-id pub-id-type="doi">10.1038/mp.2010.46</pub-id>.<pub-id pub-id-type="pmid">20479758</pub-id></mixed-citation>
      </ref>
      <ref id="R26">
        <mixed-citation publication-type="journal"><name><surname>Hampson</surname><given-names>M</given-names></name>, <name><surname>Peterson</surname><given-names>BS</given-names></name>, <name><surname>Skudlarski</surname><given-names>P</given-names></name>, <name><surname>Gatenby</surname><given-names>JC</given-names></name>, <name><surname>Gore</surname><given-names>JC</given-names></name>, <year>2002</year>. <article-title>Detection of functional connectivity using temporal correlations in MR images</article-title>. <source>Hum. Brain Mapp</source>. <volume>15</volume>,<fpage>247</fpage>–<lpage>262</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.10022</pub-id>.<pub-id pub-id-type="pmid">11835612</pub-id></mixed-citation>
      </ref>
      <ref id="R27">
        <mixed-citation publication-type="journal"><name><surname>Handwerker</surname><given-names>DA</given-names></name>, <name><surname>Roopchansingh</surname><given-names>V</given-names></name>, <name><surname>Gonzalez-Castillo</surname><given-names>J</given-names></name>, <name><surname>Bandettini</surname><given-names>PA</given-names></name>, <year>2012</year>. <article-title>Periodic changes in fMRI connectivity</article-title>. <source>Neuroimage</source>
<volume>63</volume>, <fpage>1712</fpage>–<lpage>1719</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.06.078</pub-id>.<pub-id pub-id-type="pmid">22796990</pub-id></mixed-citation>
      </ref>
      <ref id="R28">
        <mixed-citation publication-type="journal"><name><surname>Higgins</surname><given-names>I</given-names></name>, <name><surname>Matthey</surname><given-names>L</given-names></name>, <name><surname>Pal</surname><given-names>A</given-names></name>, <name><surname>Burgess</surname><given-names>C</given-names></name>, <name><surname>Glorot</surname><given-names>X</given-names></name>, <name><surname>Botvinick</surname><given-names>M</given-names></name>, <name><surname>Mohamed</surname><given-names>S</given-names></name>, <name><surname>Lerchner</surname><given-names>A</given-names></name>, <year>2017</year>. <article-title>Beta-vae: Learning basic visual concepts with a constrained variational framework</article-title>. <source>ICLR</source>.</mixed-citation>
      </ref>
      <ref id="R29">
        <mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>X</given-names></name>, <name><surname>Huang</surname><given-names>H</given-names></name>, <name><surname>Peng</surname><given-names>B</given-names></name>, <name><surname>Han</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>N</given-names></name>, <name><surname>Lv</surname><given-names>J</given-names></name>, <name><surname>Guo</surname><given-names>L</given-names></name>, <name><surname>Guo</surname><given-names>C</given-names></name>, <name><surname>Liu</surname><given-names>T</given-names></name>, <year>2018</year>. <article-title>Latent source mining in FMRI via restricted Boltzmann machine</article-title>. <source>Hum. Brain Mapp</source>. <volume>39</volume>, <fpage>2368</fpage>–<lpage>2380</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.24005</pub-id>.<pub-id pub-id-type="pmid">29457314</pub-id></mixed-citation>
      </ref>
      <ref id="R30">
        <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>H</given-names></name>, <name><surname>Hu</surname><given-names>X</given-names></name>, <name><surname>Zhao</surname><given-names>Y</given-names></name>, <name><surname>Makkie</surname><given-names>M</given-names></name>, <name><surname>Dong</surname><given-names>Q</given-names></name>, <name><surname>Zhao</surname><given-names>S</given-names></name>, <name><surname>Guo</surname><given-names>L</given-names></name>, <name><surname>Liu</surname><given-names>T</given-names></name>, <year>2018</year>. <article-title>Modeling task fMRI data via deep convolutional autoencoder</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>37</volume>, <fpage>1551</fpage>–<lpage>1561</lpage>. doi:<pub-id pub-id-type="doi">10.1109/TMI.2017.2715285</pub-id>.<pub-id pub-id-type="pmid">28641247</pub-id></mixed-citation>
      </ref>
      <ref id="R31">
        <mixed-citation publication-type="journal"><name><surname>Hutchison</surname><given-names>RM</given-names></name>, <name><surname>Womelsdorf</surname><given-names>T</given-names></name>, <name><surname>Allen</surname><given-names>EA</given-names></name>, <name><surname>Bandettini</surname><given-names>PA</given-names></name>, <name><surname>Calhoun</surname><given-names>VD</given-names></name>, <name><surname>Corbetta</surname><given-names>M</given-names></name>, <name><surname>Della Penna</surname><given-names>S</given-names></name>, <name><surname>Duyn</surname><given-names>JH</given-names></name>, <name><surname>Glover</surname><given-names>GH</given-names></name>, <name><surname>Gonzalez-Castillo</surname><given-names>J</given-names></name>, <name><surname>Handwerker</surname><given-names>DA</given-names></name>, <name><surname>Keilholz</surname><given-names>S</given-names></name>, <name><surname>Kiviniemi</surname><given-names>V</given-names></name>, <name><surname>Leopold</surname><given-names>DA</given-names></name>, <name><surname>de Pasquale</surname><given-names>F</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <name><surname>Walter</surname><given-names>M</given-names></name>, <name><surname>Chang</surname><given-names>C</given-names></name>, <year>2013</year>. <article-title>Dynamic functional connectivity: promise, issues, and interpretations</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>360</fpage>–<lpage>378</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.079</pub-id>.<pub-id pub-id-type="pmid">23707587</pub-id></mixed-citation>
      </ref>
      <ref id="R32">
        <mixed-citation publication-type="journal"><name><surname>Jones</surname><given-names>DT</given-names></name>, <name><surname>Vemuri</surname><given-names>P</given-names></name>, <name><surname>Murphy</surname><given-names>MC</given-names></name>, <name><surname>Gunter</surname><given-names>JL</given-names></name>, <name><surname>Senjem</surname><given-names>ML</given-names></name>, <name><surname>Machulda</surname><given-names>MM</given-names></name>, <name><surname>Przybelski</surname><given-names>SA</given-names></name>, <name><surname>Gregg</surname><given-names>BE</given-names></name>, <name><surname>Kantarci</surname><given-names>K</given-names></name>, <name><surname>Knopman</surname><given-names>DS</given-names></name>, <name><surname>Boeve</surname><given-names>BF</given-names></name>, <name><surname>Petersen</surname><given-names>RC</given-names></name>, <name><surname>Jack</surname><given-names>CR</given-names></name>, <year>2012a</year>. <article-title>Non-stationarity in the “Resting Brain’s” modular architecture</article-title>. <source>PLoS ONE</source>
<volume>7</volume>, <fpage>e39731</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0039731</pub-id>.<pub-id pub-id-type="pmid">22761880</pub-id></mixed-citation>
      </ref>
      <ref id="R33">
        <mixed-citation publication-type="journal"><name><surname>Jones</surname><given-names>DT</given-names></name>, <name><surname>Vemuri</surname><given-names>P</given-names></name>, <name><surname>Murphy</surname><given-names>MC</given-names></name>, <name><surname>Gunter</surname><given-names>JL</given-names></name>, <name><surname>Senjem</surname><given-names>ML</given-names></name>, <name><surname>Machulda</surname><given-names>MM</given-names></name>, <name><surname>Przybelski</surname><given-names>SA</given-names></name>, <name><surname>Gregg</surname><given-names>BE</given-names></name>, <name><surname>Kantarci</surname><given-names>K</given-names></name>, <name><surname>Knopman</surname><given-names>DS</given-names></name>, <name><surname>Boeve</surname><given-names>BF</given-names></name>, <name><surname>Petersen</surname><given-names>RC</given-names></name>, <name><surname>Jack</surname><given-names>CR</given-names></name>, <year>2012b</year>. <article-title>Non-stationarity in the “Resting Brain’s” modular architecture</article-title>. <source>PLoS ONE 7</source>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0039731</pub-id>.</mixed-citation>
      </ref>
      <ref id="R34">
        <mixed-citation publication-type="book"><name><surname>Kalchbrenner</surname><given-names>N</given-names></name>, <name><surname>Grefenstette</surname><given-names>E</given-names></name>, <name><surname>Blunsom</surname><given-names>P</given-names></name>, <year>2014</year>. <part-title>A convolutional neural network for modelling sentences</part-title>. In: <source>52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014 - Proceedings of the Conference. Association for Computational Linguistics (ACL)</source>, pp. <fpage>655</fpage>–<lpage>665</lpage>. doi:<pub-id pub-id-type="doi">10.3115/v1/p14-1062</pub-id>.</mixed-citation>
      </ref>
      <ref id="R35">
        <mixed-citation publication-type="journal"><name><surname>Keilholz</surname><given-names>SD</given-names></name>, <name><surname>Magnuson</surname><given-names>ME</given-names></name>, <name><surname>Pan</surname><given-names>WJ</given-names></name>, <name><surname>Willis</surname><given-names>M</given-names></name>, <name><surname>Thompson</surname><given-names>GJ</given-names></name>, <year>2013</year>. <article-title>Dynamic properties of functional connectivity in the rodent</article-title>. <source>Brain Connect</source>
<volume>3</volume>, <fpage>31</fpage>–<lpage>40</lpage>. doi:<pub-id pub-id-type="doi">10.1089/brain.2012.0115</pub-id>.<pub-id pub-id-type="pmid">23106103</pub-id></mixed-citation>
      </ref>
      <ref id="R36">
        <mixed-citation publication-type="book"><name><surname>Kim</surname><given-names>Y</given-names></name>, <year>2014</year>. <part-title>Convolutional neural networks for sentence classification</part-title>. In: <source>EMNLP 2014 – 2014 Conf. Empir. Methods Nat. Lang. Process. Proc. Conf</source>, pp. <fpage>1746</fpage>–<lpage>1751</lpage>.</mixed-citation>
      </ref>
      <ref id="R37">
        <mixed-citation publication-type="book"><name><surname>Kingma</surname><given-names>DP</given-names></name>, <name><surname>Ba</surname><given-names>JL</given-names></name>, <year>2015</year>. <part-title>Adam: a method for stochastic optimization</part-title>. In: <source>3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings. International Conference on Learning Representations, ICLR</source></mixed-citation>
      </ref>
      <ref id="R38">
        <mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>DP</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>, <year>2019</year>. <article-title>An introduction to variational autoencoders</article-title>. <source>Found. Trends Mach. Learn</source>. <volume>12</volume>, <fpage>307</fpage>–<lpage>392</lpage>. doi:<pub-id pub-id-type="doi">10.1561/2200000056</pub-id>.</mixed-citation>
      </ref>
      <ref id="R39">
        <mixed-citation publication-type="book"><name><surname>Kingma</surname><given-names>DP</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>, <year>2014</year>. <part-title>Auto-encoding variational bayes</part-title>. In: <source>2nd International Conference on Learning Representations, ICLR 2014 - Conference Track Proceedings. International Conference on Learning Representations, ICLR</source>.</mixed-citation>
      </ref>
      <ref id="R40">
        <mixed-citation publication-type="journal"><name><surname>Kiviniemi</surname><given-names>V</given-names></name>, <name><surname>Vire</surname><given-names>T</given-names></name>, <name><surname>Remes</surname><given-names>J</given-names></name>, <name><surname>Elseoud</surname><given-names>AA</given-names></name>, <name><surname>Starck</surname><given-names>T</given-names></name>, <name><surname>Tervonen</surname><given-names>O</given-names></name>, <name><surname>Nikkinen</surname><given-names>J</given-names></name>, <year>2011</year>. <article-title>A sliding time-window ICA reveals spatial variability of the default mode network in time</article-title>. <source>Brain Connect</source>
<volume>1</volume>, <fpage>339</fpage>–<lpage>347</lpage>. doi:<pub-id pub-id-type="doi">10.1089/brain.2011.0036</pub-id>.<pub-id pub-id-type="pmid">22432423</pub-id></mixed-citation>
      </ref>
      <ref id="R41">
        <mixed-citation publication-type="journal"><name><surname>Krizhevsky</surname><given-names>A</given-names></name>, <name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Hinton</surname><given-names>GE</given-names></name>, <year>2017</year>. <article-title>ImageNet classification with deep convolutional neural networks</article-title>. <source>Commun. ACM</source>
<volume>60</volume>, <fpage>84</fpage>–<lpage>90</lpage>. doi:<pub-id pub-id-type="doi">10.1145/3065386</pub-id>.</mixed-citation>
      </ref>
      <ref id="R42">
        <mixed-citation publication-type="journal"><name><surname>Kulkarni</surname><given-names>TD</given-names></name>, <name><surname>Whitney</surname><given-names>WF</given-names></name>, <name><surname>Kohli</surname><given-names>P</given-names></name>, <name><surname>Tenenbaum</surname><given-names>JB</given-names></name>, <year>2015</year>. <article-title>Deep convolutional inverse graphics network</article-title>. <source>Adv. Neural Inf. Process. Syst</source>
<fpage>2539</fpage>–<lpage>2547</lpage> 2015-Janua.</mixed-citation>
      </ref>
      <ref id="R43">
        <mixed-citation publication-type="journal"><name><surname>Lecun</surname><given-names>Y</given-names></name>, <name><surname>Bottou</surname><given-names>L</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>, <name><surname>Haffner</surname><given-names>P</given-names></name>, <year>1998</year>. <article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proceedings of the IEEE</source>. <volume>86</volume> (<issue>11</issue>), <fpage>2278</fpage>–<lpage>2324</lpage>.</mixed-citation>
      </ref>
      <ref id="R44">
        <mixed-citation publication-type="journal"><name><surname>Leonardi</surname><given-names>N</given-names></name>, <name><surname>Richiardi</surname><given-names>J</given-names></name>, <name><surname>Gschwind</surname><given-names>M</given-names></name>, <name><surname>Simioni</surname><given-names>S</given-names></name>, <name><surname>Annoni</surname><given-names>JM</given-names></name>, <name><surname>Schluep</surname><given-names>M</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P</given-names></name>, <name><surname>Van De Ville</surname><given-names>D</given-names></name>, <year>2013</year>. <article-title>Principal components of functional connectivity: a new approach to study dynamic brain connectivity during rest</article-title>. <source>Neuroimage</source>
<volume>83</volume>, <fpage>937</fpage>–<lpage>950</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.07.019</pub-id>.<pub-id pub-id-type="pmid">23872496</pub-id></mixed-citation>
      </ref>
      <ref id="R45">
        <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Fan</surname><given-names>Y</given-names></name>, <year>2018</year>. <article-title>Identification of temporal transition of functional states using recurrent neural networks from functional MRI</article-title>. <source>Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)</source>
<fpage>232</fpage>–<lpage>239</lpage> 11072 LNCS.</mixed-citation>
      </ref>
      <ref id="R46">
        <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Duyn</surname><given-names>JH</given-names></name>, <year>2013</year>. <article-title>Time-varying functional network information extracted from brief instances of spontaneous brain activity</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>110</volume>, <fpage>4392</fpage>–<lpage>4397</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1216856110</pub-id>.<pub-id pub-id-type="pmid">23440216</pub-id></mixed-citation>
      </ref>
      <ref id="R47">
        <mixed-citation publication-type="journal"><name><surname>Majeed</surname><given-names>W</given-names></name>, <name><surname>Magnuson</surname><given-names>M</given-names></name>, <name><surname>Hasenkamp</surname><given-names>W</given-names></name>, <name><surname>Schwarb</surname><given-names>H</given-names></name>, <name><surname>Schumacher</surname><given-names>EH</given-names></name>, <name><surname>Barsalou</surname><given-names>L</given-names></name>, <name><surname>Keilholz</surname><given-names>SD</given-names></name>, <year>2011</year>. <article-title>Spatiotemporal dynamics of low frequency BOLD fluctuations in rats and humans</article-title>. <source>Neuroimage</source>
<volume>54</volume>, <fpage>1140</fpage>–<lpage>1150</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.08.030</pub-id>.<pub-id pub-id-type="pmid">20728554</pub-id></mixed-citation>
      </ref>
      <ref id="R48">
        <mixed-citation publication-type="journal"><name><surname>Mao</surname><given-names>Z</given-names></name>, <name><surname>Su</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>G</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Huang</surname><given-names>Y</given-names></name>, <name><surname>Yue</surname><given-names>W</given-names></name>, <name><surname>Sun</surname><given-names>L</given-names></name>, <name><surname>Xiong</surname><given-names>N</given-names></name>, <year>2019</year>. <article-title>Spatiotemporal deep learning method for ADHD fMRI classification</article-title>. <source>Inf. Sci. (Ny)</source>
<volume>499</volume>, <fpage>1</fpage>–<lpage>11</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.ins.2019.05.043</pub-id>.</mixed-citation>
      </ref>
      <ref id="R49">
        <mixed-citation publication-type="journal"><name><surname>Margulies</surname><given-names>DS</given-names></name>, <name><surname>Ghosh</surname><given-names>SS</given-names></name>, <name><surname>Goulas</surname><given-names>A</given-names></name>, <name><surname>Falkiewicz</surname><given-names>M</given-names></name>, <name><surname>Huntenburg</surname><given-names>JM</given-names></name>, <name><surname>Langs</surname><given-names>G</given-names></name>, <name><surname>Bezgin</surname><given-names>G</given-names></name>, <name><surname>Eickhoff</surname><given-names>SB</given-names></name>, <name><surname>Castellanos</surname><given-names>FX</given-names></name>, <name><surname>Petrides</surname><given-names>M</given-names></name>, <name><surname>Jefferies</surname><given-names>E</given-names></name>, <name><surname>Smallwood</surname><given-names>J</given-names></name>, <year>2016</year>. <article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>. <volume>113</volume>, <fpage>12574</fpage>–<lpage>12579</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id>.<pub-id pub-id-type="pmid">27791099</pub-id></mixed-citation>
      </ref>
      <ref id="R50">
        <mixed-citation publication-type="journal"><name><surname>Meszlényi</surname><given-names>RJ</given-names></name>, <name><surname>Buza</surname><given-names>K</given-names></name>, <name><surname>Vidnyánszky</surname><given-names>Z</given-names></name>, <year>2017</year>. <article-title>Resting state fMRI functional connectivity-based classification using a convolutional neural network architecture</article-title>. <source>Front. Neuroinform</source>. <volume>11</volume>, <fpage>61</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fninf.2017.00061</pub-id>.<pub-id pub-id-type="pmid">29089883</pub-id></mixed-citation>
      </ref>
      <ref id="R51">
        <mixed-citation publication-type="journal"><name><surname>Ogawa</surname><given-names>S</given-names></name>, <name><surname>Tank</surname><given-names>DW</given-names></name>, <name><surname>Menon</surname><given-names>R</given-names></name>, <name><surname>Ellermann</surname><given-names>JM</given-names></name>, <name><surname>Kim</surname><given-names>SG</given-names></name>, <name><surname>Merkle</surname><given-names>H</given-names></name>, <name><surname>Ugurbil</surname><given-names>K</given-names></name>, <year>1992</year>. <article-title>Intrinsic signal changes accompanying sensory stimulation: functional brain mapping with magnetic resonance imaging</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>89</volume>. doi:<pub-id pub-id-type="doi">10.1073/pnas.89.13.5951</pub-id>.</mixed-citation>
      </ref>
      <ref id="R52">
        <mixed-citation publication-type="journal"><name><surname>Paszke</surname><given-names>A</given-names></name>, <name><surname>Gross</surname><given-names>S</given-names></name>, <name><surname>Chintala</surname><given-names>S</given-names></name>, <name><surname>Chanan</surname><given-names>G</given-names></name>, <name><surname>Yang</surname><given-names>E</given-names></name>, <name><surname>Facebook</surname><given-names>ZD</given-names></name>, <name><surname>Research</surname><given-names>AI</given-names></name>, <name><surname>Lin</surname><given-names>Z</given-names></name>, <name><surname>Desmaison</surname><given-names>A</given-names></name>, <name><surname>Antiga</surname><given-names>L</given-names></name>, <name><surname>Srl</surname><given-names>O</given-names></name>, <name><surname>Lerer</surname><given-names>A</given-names></name>, <year>2017</year>. <source>Automatic differentiation in PyTorch</source>.</mixed-citation>
      </ref>
      <ref id="R53">
        <mixed-citation publication-type="journal"><name><surname>Plaut</surname><given-names>E</given-names></name>, <year>2018</year>. <article-title>From Principal Subspaces to Principal Components with Linear Autoencoders</article-title>. <source>arXiv</source>.</mixed-citation>
      </ref>
      <ref id="R54">
        <mixed-citation publication-type="journal"><name><surname>Power</surname><given-names>JD</given-names></name>, <name><surname>Cohen</surname><given-names>AL</given-names></name>, <name><surname>Nelson</surname><given-names>SM</given-names></name>, <name><surname>Wig</surname><given-names>GS</given-names></name>, <name><surname>Barnes</surname><given-names>KA</given-names></name>, <name><surname>Church</surname><given-names>JA</given-names></name>, <name><surname>Vogel</surname><given-names>AC</given-names></name>, <name><surname>Laumann</surname><given-names>TO</given-names></name>, <name><surname>Miezin</surname><given-names>FM</given-names></name>, <name><surname>Schlaggar</surname><given-names>BL</given-names></name>, <name><surname>Petersen</surname><given-names>SE</given-names></name>, <year>2011</year>. <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source>
<volume>72</volume>, <fpage>665</fpage>–<lpage>678</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.006</pub-id>.<pub-id pub-id-type="pmid">22099467</pub-id></mixed-citation>
      </ref>
      <ref id="R55">
        <mixed-citation publication-type="journal"><name><surname>Sakoğlu</surname><given-names>Ü</given-names></name>, <name><surname>Pearlson</surname><given-names>GD</given-names></name>, <name><surname>Kiehl</surname><given-names>KA</given-names></name>, <name><surname>Wang</surname><given-names>YM</given-names></name>, <name><surname>Michael</surname><given-names>AM</given-names></name>, <name><surname>Calhoun</surname><given-names>VD</given-names></name>, <year>2010</year>. <article-title>A method for evaluating dynamic functional network connectivity and task-modulation: application to schizophrenia</article-title>. <source>Magn. Reson. Mater. Physics, Biol. Med</source>
<volume>23</volume>, <fpage>351</fpage>–<lpage>366</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10334-010-0197-8</pub-id>.</mixed-citation>
      </ref>
      <ref id="R56">
        <mixed-citation publication-type="book"><name><surname>Sarraf</surname><given-names>S</given-names></name>, <name><surname>Tofighi</surname><given-names>G</given-names></name>, <year>2017</year>. <part-title>Deep learning-based pipeline to recognize Alzheimer’s disease using fMRI data</part-title>. In: <source>FTC 2016 - Proceedings of Future Technologies Conference</source>. <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>, pp. <fpage>816</fpage>–<lpage>820</lpage>. doi:<pub-id pub-id-type="doi">10.1109/FTC.2016.7821697</pub-id>.</mixed-citation>
      </ref>
      <ref id="R57">
        <mixed-citation publication-type="book"><name><surname>Simonyan</surname><given-names>K</given-names></name>, <name><surname>Vedaldi</surname><given-names>A</given-names></name>, <name><surname>Zisserman</surname><given-names>A</given-names></name>, <year>2014</year>. <part-title>Deep inside convolutional networks: visualising image classification models and saliency maps</part-title>. In: <source>2nd Int. Conf. Learn. Represent. ICLR 2014 - Work. Track Proc</source>, pp. <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
      </ref>
      <ref id="R58">
        <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Fox</surname><given-names>PT</given-names></name>, <name><surname>Miller</surname><given-names>KL</given-names></name>, <name><surname>Glahn</surname><given-names>DC</given-names></name>, <name><surname>Fox</surname><given-names>PM</given-names></name>, <name><surname>Mackay</surname><given-names>CE</given-names></name>, <name><surname>Filippini</surname><given-names>N</given-names></name>, <name><surname>Watkins</surname><given-names>KE</given-names></name>, <name><surname>Toro</surname><given-names>R</given-names></name>, <name><surname>Laird</surname><given-names>AR</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <year>2009</year>. <article-title>Correspondence of the brain’s functional architecture during activation and rest</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>106</volume>, <fpage>13040</fpage>–<lpage>13045</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.0905267106</pub-id>.<pub-id pub-id-type="pmid">19620724</pub-id></mixed-citation>
      </ref>
      <ref id="R59">
        <mixed-citation publication-type="journal"><name><surname>Smucny</surname><given-names>J</given-names></name>, <name><surname>Davidson</surname><given-names>I</given-names></name>, <name><surname>Carter</surname><given-names>CS</given-names></name>, <year>2021</year>. <article-title>Comparing machine and deep learning-based algorithms for prediction of clinical improvement in psychosis with functional magnetic resonance imaging</article-title>. <source>Hum. Brain Mapp</source>. <volume>42</volume>, <fpage>1197</fpage>–<lpage>1205</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.25286</pub-id>.<pub-id pub-id-type="pmid">33185307</pub-id></mixed-citation>
      </ref>
      <ref id="R60">
        <mixed-citation publication-type="journal"><name><surname>Suk</surname><given-names>H.Il</given-names></name>, <name><surname>Wee</surname><given-names>CY</given-names></name>, <name><surname>Lee</surname><given-names>SW</given-names></name>, <name><surname>Shen</surname><given-names>D</given-names></name>, <year>2016</year>. <article-title>State-space model with deep learning for functional dynamics estimation in resting-state fMRI</article-title>. <source>Neuroimage</source>
<volume>129</volume>, <fpage>292</fpage>–<lpage>307</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.01.005</pub-id>.<pub-id pub-id-type="pmid">26774612</pub-id></mixed-citation>
      </ref>
      <ref id="R61">
        <mixed-citation publication-type="journal"><name><surname>Szegedy</surname><given-names>C</given-names></name>, <name><surname>Liu</surname><given-names>W</given-names></name>, <name><surname>Jia</surname><given-names>Y</given-names></name>, <name><surname>Sermanet</surname><given-names>P</given-names></name>, <name><surname>Reed</surname><given-names>S</given-names></name>, <name><surname>Anguelov</surname><given-names>D</given-names></name>, <name><surname>Erhan</surname><given-names>D</given-names></name>, <name><surname>Vanhoucke</surname><given-names>V</given-names></name>, <name><surname>Rabinovich</surname><given-names>A</given-names></name>, <year>2015</year>. <source>Going deeper with convolutions</source>.</mixed-citation>
      </ref>
      <ref id="R62">
        <mixed-citation publication-type="journal"><name><surname>Tagliazucchi</surname><given-names>E</given-names></name>, <name><surname>von Wegner</surname><given-names>F</given-names></name>, <name><surname>Morzelewski</surname><given-names>A</given-names></name>, <name><surname>Brodbeck</surname><given-names>V</given-names></name>, <name><surname>Laufs</surname><given-names>H</given-names></name>, <year>2012</year>. <article-title>Dynamic BOLD functional connectivity in humans and its electrophysiological correlates</article-title>. <source>Front. Hum. Neurosci</source>
<volume>6</volume>. doi:<pub-id pub-id-type="doi">10.3389/fnhum.2012.00339</pub-id>.</mixed-citation>
      </ref>
      <ref id="R63">
        <mixed-citation publication-type="journal"><name><surname>Thomas Yeo</surname><given-names>BT</given-names></name>, <name><surname>Krienen</surname><given-names>FM</given-names></name>, <name><surname>Sepulcre</surname><given-names>J</given-names></name>, <name><surname>Sabuncu</surname><given-names>MR</given-names></name>, <name><surname>Lashkari</surname><given-names>D</given-names></name>, <name><surname>Hollinshead</surname><given-names>M</given-names></name>, <name><surname>Roffman</surname><given-names>JL</given-names></name>, <name><surname>Smoller</surname><given-names>JW</given-names></name>, <name><surname>Zöllei</surname><given-names>L</given-names></name>, <name><surname>Polimeni</surname><given-names>JR</given-names></name>, <name><surname>Fisch</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>H</given-names></name>, <name><surname>Buckner</surname><given-names>RL</given-names></name>, <year>2011</year>. <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>J. Neurophysiol</source>. <volume>106</volume>, <fpage>1125</fpage>–<lpage>1165</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id>.<pub-id pub-id-type="pmid">21653723</pub-id></mixed-citation>
      </ref>
      <ref id="R64">
        <mixed-citation publication-type="journal"><name><surname>Thompson</surname><given-names>GJ</given-names></name>, <name><surname>Magnuson</surname><given-names>ME</given-names></name>, <name><surname>Merritt</surname><given-names>MD</given-names></name>, <name><surname>Schwarb</surname><given-names>H</given-names></name>, <name><surname>Pan</surname><given-names>WJ</given-names></name>, <name><surname>Mckinley</surname><given-names>A</given-names></name>, <name><surname>Tripp</surname><given-names>LD</given-names></name>, <name><surname>Schumacher</surname><given-names>EH</given-names></name>, <name><surname>Keilholz</surname><given-names>SD</given-names></name>, <year>2013</year>. <article-title>Short-time windows of correlation between large-scale functional brain networks predict vigilance intraindividually and interindividually</article-title>. <source>Hum. Brain Mapp</source>. <volume>34</volume>, <fpage>3280</fpage>–<lpage>3298</lpage>. doi:<pub-id pub-id-type="doi">10.1002/hbm.22140</pub-id>.<pub-id pub-id-type="pmid">22736565</pub-id></mixed-citation>
      </ref>
      <ref id="R65">
        <mixed-citation publication-type="journal"><name><surname>Vidaurre</surname><given-names>D</given-names></name>, <name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Woolrich</surname><given-names>MW</given-names></name>, <year>2017</year>. <article-title>Brain network dynamics are hierarchically organized in time</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>
<volume>114</volume>, <fpage>12827</fpage>–<lpage>12832</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1705120114</pub-id>.<pub-id pub-id-type="pmid">29087305</pub-id></mixed-citation>
      </ref>
      <ref id="R66">
        <mixed-citation publication-type="journal"><name><surname>Wu</surname><given-names>J</given-names></name>, <name><surname>Chen</surname><given-names>XY</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Xiong</surname><given-names>LD</given-names></name>, <name><surname>Lei</surname><given-names>H</given-names></name>, <name><surname>Deng</surname><given-names>SH</given-names></name>, <year>2019</year>. <article-title>Hyperparameter optimization for machine learning models based on Bayesian optimization</article-title>. <source>J. Electron. Sci. Technol</source>. <volume>17</volume>, <fpage>26</fpage>–<lpage>40</lpage>. doi:<pub-id pub-id-type="doi">10.11989/JEST.1674-862X.80904120</pub-id>.</mixed-citation>
      </ref>
      <ref id="R67">
        <mixed-citation publication-type="journal"><name><surname>Yousefi</surname><given-names>B</given-names></name>, <name><surname>Keilholz</surname><given-names>S</given-names></name>, <year>2021</year>. <article-title>Propagating patterns of intrinsic activity along macroscale gradients coordinate functional connections across the whole brain</article-title>. <source>Neuroimage</source>
<volume>231</volume>, <fpage>117827</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117827</pub-id>.<pub-id pub-id-type="pmid">33549755</pub-id></mixed-citation>
      </ref>
      <ref id="R68">
        <mixed-citation publication-type="journal"><name><surname>Yousefi</surname><given-names>B</given-names></name>, <name><surname>Shin</surname><given-names>J</given-names></name>, <name><surname>Schumacher</surname><given-names>EH</given-names></name>, <name><surname>Keilholz</surname><given-names>SD</given-names></name>, <year>2018</year>. <article-title>Quasi-periodic patterns of intrinsic brain activity in individuals and their relationship to global signal</article-title>. <source>Neuroimage</source>
<volume>167</volume>, <fpage>297</fpage>–<lpage>308</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.11.043</pub-id>.<pub-id pub-id-type="pmid">29175200</pub-id></mixed-citation>
      </ref>
      <ref id="R69">
        <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>S</given-names></name>, <name><surname>Dong</surname><given-names>Q</given-names></name>, <name><surname>Zhang</surname><given-names>W</given-names></name>, <name><surname>Huang</surname><given-names>H</given-names></name>, <name><surname>Zhu</surname><given-names>D</given-names></name>, <name><surname>Liu</surname><given-names>T</given-names></name>, <year>2019</year>. <article-title>Discovering hierarchical common brain networks via multimodal deep belief network</article-title>. <source>Med. Image Anal</source>. <volume>54</volume>, <fpage>238</fpage>–<lpage>252</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.media.2019.03.011</pub-id>.<pub-id pub-id-type="pmid">30954851</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig id="F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <title>The architecture of the networks.</title>
        <p id="P55">The networks consist of a symmetric encoder and decoder, both having 3 convolutional or dilated convolutional layers, and 2 fully connected layers. The size is shown on the top of each layer. For CONV layers, the size is expressed as number of channels x number of time points. For FC layers, the size is expressed as number of features. Please note that the CONV layers are multi-channel convolutional layers, where each feature map (channel) encodes a unique temporal feature that combines all channels from its input. The encoder encodes rs-fMRI segments of size 246 × 33 into 32 × 1 latent variables that follow Gaussian distributions, whose mean and variance were estimated by the network. Then a sample is randomly drawn from the distribution, which is then propagated through the decoder to reconstruct back to rs-fMRI segments. CONV, convolutional layer; DECONV, dilated convolutional layer;FC, fully-connected layer.</p>
      </caption>
      <graphic xlink:href="nihms-1755363-f0001"/>
    </fig>
    <fig id="F2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <title>Spatiotemporal patterns extracted by latent variables.</title>
        <p id="P56">Using methods described in <xref rid="S7" ref-type="sec">Section 2.5</xref>, the effect of each latent variable can be isolated and visualized through controlled perturbation in the latent space. Each subplot is obtained by perturbing only one latent variable at a time while fixing the rest of the latent variables at zero. The amount of perturbation was set to +3 (corresponding to +3<italic>σ</italic> for a standard Gaussian distribution, which is roughly 99.7 percentile) The x-axis is time in seconds. The y-axis is the 246 parcels. The patterns have arbitrary units, but all subplots share the same display scale so that higher variance results in higher contrast. The 32 latent variables are already organized in 6 clusters (see their spatial configurations in <xref ref-type="fig" rid="F3">Fig. 3</xref>). The black cursor indicates the time of maximum spatial variance across parcels, which was used to extract spatial profiles and perform clustering.</p>
      </caption>
      <graphic xlink:href="nihms-1755363-f0002"/>
    </fig>
    <fig id="F3" orientation="portrait" position="float">
      <label>Fig. 3.</label>
      <caption>
        <title>The latent dimensions can be organized into 6 clusters (shown in rows) based on their spatial similarities.</title>
        <p id="P57">Panel A shows the spatial profile represented by each latent variable, obtained through the controlled perturbation that was previously described. The spatial profiles were acquired at the max-variance time (in <xref ref-type="fig" rid="F2">Fig. 2</xref>), which was shown as a function of the perturbation of the corresponding latent variable. The x-axis is the latent variable sliding from −3 to 3, which roughly covers the entire range of the standard Gaussian distribution. The y-axis is the 246 parcels. Panel B shows the spatial similarities among latent variables at the max-variance time, measured by Pearson correlation between the spatial profiles. The latent variables were then clustered using K-means clustering using the spatial similarity as the clustering criteria (<italic>K</italic> = 6). The cluster label index and the variance explained are also shown. Panel C shows the weighted mean functional connectivity of each cluster of latent variables. The functional connectivity for each latent variable was calculated over the 33-TR window shown in the spatiotemporal patterns in <xref ref-type="fig" rid="F2">Fig. 2</xref>. Then a weighted average was calculated, with the weight of each FC matrix being their corresponding variance in panel B. They offer an alternative representation of the spatial configuration of brain activities, and the information they represent is more or less the same as the spatial profiles shown in panel A.</p>
      </caption>
      <graphic xlink:href="nihms-1755363-f0003"/>
    </fig>
    <fig id="F4" orientation="portrait" position="float">
      <label>Fig. 4.</label>
      <caption>
        <title>Spatial temporal features represented by latent variable 1 (panel A), the primary QPP (panel B) and their difference.</title>
        <p id="P58">Both the latent feature and the QPP were divided by their 98th percentile to normalize. It can be seen that the spatial temporal features represented by latent variable 1 are very similar to the primary QPP (Pearson correlation coefficient = 0.759), but there are also some differences, most notably in the strength of frontoparietal involvement and near transitions between positive and negative activation in the somatomotor network.</p>
      </caption>
      <graphic xlink:href="nihms-1755363-f0004"/>
    </fig>
    <fig id="F5" orientation="portrait" position="float">
      <label>Fig. 5.</label>
      <caption>
        <title>Temporal patterns extracted by latent dimensions.</title>
        <p id="P59">The temporal pattern as a function of the value of the corresponding latent variable can be visualized by selecting a specific region of interest to fix the spatial axis. In this particular figure we choose 5 parcels in the somatomotor (SM) network (96th parcel to 100th parcel, all in the Postcentral Gyrus). The x-axis is time in seconds. The y-axis is the value of the latent variable, sliding from −3 to +3.</p>
      </caption>
      <graphic xlink:href="nihms-1755363-f0005"/>
    </fig>
    <fig id="F6" orientation="portrait" position="float">
      <label>Fig. 6.</label>
      <caption>
        <title>A fMRI segment can be encoded as a 32-dimensional code.</title>
        <p id="P60">Panel A shows 20 concatenated original rs-fMRI segments. Panel B shows the reconstructed rs-fMRI segments. It can be seen that the reconstruction matches fairly well with the original signal although there are some abrupt changes at the edge of each segment (that were concatenated together). Panel C and D show the values of latent variables in cluster1 and cluster 2, respectively. The remaining 4 clusters were not shown for display purposes.</p>
      </caption>
      <graphic xlink:href="nihms-1755363-f0006"/>
    </fig>
  </floats-group>
</article>
