<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">AIMS Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">AIMS Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">neurosci</journal-id>
      <journal-title-group>
        <journal-title>AIMS Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">2373-8006</issn>
      <issn pub-type="epub">2373-7972</issn>
      <publisher>
        <publisher-name>AIMS Press</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">33709030</article-id>
      <article-id pub-id-type="pmc">7940114</article-id>
      <article-id pub-id-type="publisher-id">neurosci-08-02-016</article-id>
      <article-id pub-id-type="doi">10.3934/Neuroscience.2021016</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>ISOMAP and machine learning algorithms for the construction of embedded functional connectivity networks of anatomically separated brain regions from resting state fMRI data of patients with Schizophrenia</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Gallos</surname>
            <given-names>Ioannis K</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Gkiatis</surname>
            <given-names>Kostakis</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Matsopoulos</surname>
            <given-names>George K</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Siettos</surname>
            <given-names>Constantinos</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">3</xref>
          <xref ref-type="corresp" rid="cor1">*</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>School of Applied Mathematical and Physical Sciences, National Technical University of Athens, Greece</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>School of Electrical and Computer Engineering, National Technical University of Athens, Greece</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Dipartimento di Matematica e Applicazioni “Renato Caccioppoli”, Università degli Studi di Napoli Federico II, Italy</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1"><bold>* Correspondence:</bold> Email: <email>constantinos.siettos@unina.it</email>; Tel: <phone>39081675615</phone>.</corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>19</day>
        <month>2</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2021</year>
      </pub-date>
      <volume>8</volume>
      <issue>2</issue>
      <fpage>295</fpage>
      <lpage>321</lpage>
      <history>
        <date date-type="received">
          <day>1</day>
          <month>2</month>
          <year>2021</year>
        </date>
        <date date-type="accepted">
          <day>18</day>
          <month>2</month>
          <year>2021</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© 2021 the Author(s), licensee AIMS Press</copyright-statement>
        <copyright-year>2021</copyright-year>
        <copyright-holder>the Author(s)</copyright-holder>
        <license>
          <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0">http://creativecommons.org/licenses/by/4.0</ext-link>)</license-p>
        </license>
      </permissions>
      <abstract>
        <p>We construct Functional Connectivity Networks (FCN) from resting state fMRI (rsfMRI) recordings towards the classification of brain activity between healthy and schizophrenic subjects using a publicly available dataset (the COBRE dataset) of 145 subjects (74 healthy controls and 71 schizophrenic subjects). First, we match the anatomy of the brain of each individual to the Desikan-Killiany brain atlas. Then, we use the conventional approach of correlating the parcellated time series to construct FCN and ISOMAP, a nonlinear manifold learning algorithm to produce low-dimensional embeddings of the correlation matrices. For the classification analysis, we computed five key local graph-theoretic measures of the FCN and used the LASSO and Random Forest (RF) algorithms for feature selection. For the classification we used standard linear Support Vector Machines. The classification performance is tested by a double cross-validation scheme (consisting of an outer and an inner loop of “Leave one out” cross-validation (LOOCV)). The standard cross-correlation methodology produced a classification rate of 73.1%, while ISOMAP resulted in 79.3%, thus providing a simpler model with a smaller number of features as chosen from LASSO and RF, namely the participation coefficient of the right thalamus and the strength of the right lingual gyrus.</p>
      </abstract>
      <kwd-group>
        <kwd>resting state fMRI</kwd>
        <kwd>Schizophrenia</kwd>
        <kwd>functional connectivity networks</kwd>
        <kwd>numerical analysis</kwd>
        <kwd>manifold learning</kwd>
        <kwd>ISOMAP</kwd>
        <kwd>feature selection</kwd>
        <kwd>LASSO</kwd>
        <kwd>random forests</kwd>
        <kwd>machine learning</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <label>1</label>
      <title>Introduction</title>
      <p>Schizophrenia is a functional chronic mental disorder which affects how a person thinks, feels and acts. Symptoms may vary across patients and they include hallucinations, delusions, thought and movement disorders, disruptions in emotions and cognitive deficits. Prevalence of schizophrenia has reported to be around the 1% of the worldwide population without any significant difference between males and females <xref rid="b1" ref-type="bibr">[1]</xref>. In terms of brain connectivity, the “dysconnection hypothesis” has been the dominant theory on the cause of underlying brain malfunction in schizophrenia, suggesting both anatomical and functional brain dysfunction at different levels ranging from neurochemical to emerging functional connectivity impairments, thus demonstrating that schizophrenia could be perceived as a disorder of the human connectome <xref rid="b2" ref-type="bibr">[2]</xref>–<xref rid="b5" ref-type="bibr">[5]</xref>.</p>
      <p>Regarding the investigation of the functional brain connectome and neurological disorders, resting state magnetic resonance imaging (rsfMRI) has been proven a powerful tool <xref rid="b6" ref-type="bibr">[6]</xref>–<xref rid="b8" ref-type="bibr">[8]</xref>. This technique also holds the advantage of being non-invasive and at the same time capable of capturing deep structures of the brain (e.g. sub-cortical regions of the brain, such as the thalamus). Over the years, meta analysis of rsfMRI made possible the identification of the so-called resting state networks (RSN). These networks are reproducible across individual subjects and connect regions of the brain with certain functional properties <xref rid="b9" ref-type="bibr">[9]</xref>–<xref rid="b11" ref-type="bibr">[11]</xref>. Moreover, rsfMRI has also aided in both the detection of functional connectivity differences and the diagnosis of several neurological disorders, including schizophrenia <xref rid="b4" ref-type="bibr">[4]</xref>, <xref rid="b12" ref-type="bibr">[12]</xref>–<xref rid="b14" ref-type="bibr">[14]</xref>.</p>
      <p>Until today, many studies have proposed several classification/diagnostic biomarkers of schizophrenia <xref rid="b15" ref-type="bibr">[15]</xref>–<xref rid="b19" ref-type="bibr">[19]</xref>. A typical pipeline for the construction of FCN includes a standard preprocessing routine (e.g. motion correction, removal of non-brain tissue etc.), the use of a parcellation scheme for signal extraction using e.g. Independent Component Analysis (ICA), or the extraction of time series directly in accordance to a predetermined anatomical or functional atlas, and finally the construction of FCN by cross-correlating the corresponding time series. Based on the constructed FCN, specific features are calculated and classifiers are implemented to classify between patients with schizophrenia and healthy controls. Typically, studies suggest the most informative features as biomarkers associated with the disease.</p>
      <p>For example, for the construction of FCN and their classification, Cheng et al. <xref rid="b18" ref-type="bibr">[18]</xref> used correlation of rsfMRI time series from 278 anatomical atlas-derived nodes from a data set of 29 healthy and 19 schizophrenic subjects. Four different feature sets have been tested, namely, the betweenness centrality scores of all nodes, their ranks, the top ten highest scores and the top ten ranks. The best results were obtained using the rank of betweenness centrality of the top ten hubs of the network. They reported an accuracy of 79% using a single leave one-out cross-validation (LOOCV) and linear standard SVM (LSVM). Xiang et al. <xref rid="b15" ref-type="bibr">[15]</xref> also used correlation of time series extracted in accordance with a 246 node anatomical atlas from the COBRE dataset. They computed similar local graph measures to the ones computed here, namely, the degree of node, the participation coefficient, the local clustering coefficient, the betweenness centrality and the local efficiency. The authors utilized different feature selection algorithms such as the Least Absolute Shrinkage Operator (LASSO), Group LASSO (GLASSO) and Sparse Group LASSO (SGLASSO). Using LASSO and 123 features, they obtained a 83.4% classification, a 86.2% with GLASSO and 225 features, and a 93.1% with SGLASSO and 55 features. The evaluation method was one single LOOCV while the parameter tuning for each feature selection algorithm was done via grid search inside a single LOOCV. The classification algorithm that produced the best results in their study was the LSVM. Apparently, the authors, with SGLASSO, which is a two parameter feature selection method, optimized two parameters and trained the LSVM all within a single LOOCV scheme.</p>
      <p>Eventually, as stated in <xref rid="b19" ref-type="bibr">[19]</xref>, the validation method ( cross-validation) affects both the estimation of accuracy and the identification of the dominant features that could be represented as biomarkers. Indeed, Moghimi et al. <xref rid="b19" ref-type="bibr">[19]</xref> compared the results of single and double cross-validation schemes to a large dataset comprised of 170 subjects finding that a double cross-validation may lead to even a 20% decrease in the classification performance. The authors assessed more than 19000 global and local network measures and used the Sequential Feature Selection (SFS) algorithm in order to find the most predominant features, that could potentially serve as biomarkers. While using a single cross-validation, their best reported accuracy was 87% with 14 features, following a double cross-validation scheme their best reported accuracy was 73%, resulting from only a single feature. The addition of any other feature decreased the accuracy rate. They finally suggested that the cross-validation procedure may end up with inflated classification rates as a result of over-fitting to a specific dataset. The classification performance using single cross-validation analysis may be also apparently increased by utilizing more features that are less likely to generalize to independent datasets <xref rid="b19" ref-type="bibr">[19]</xref>, <xref rid="b20" ref-type="bibr">[20]</xref>.</p>
      <p>In a recent study of Cai et al. <xref rid="b21" ref-type="bibr">[21]</xref>, the authors applied a promising classification framework proposed in <xref rid="b22" ref-type="bibr">[22]</xref> to two independent datasets evaluating the within and between site generalizability of the model. The scope of the study was to test the generalizability of the current models for diagnosis and classification of schizophrenia. While with the proposed methodology, Du et al. <xref rid="b22" ref-type="bibr">[22]</xref> reported a 93% accuracy rate, the authors in <xref rid="b21" ref-type="bibr">[21]</xref> found a within-site accuracy rate of 73% and between-site accuracy of 70%. Finally, Cai et al. <xref rid="b21" ref-type="bibr">[21]</xref> attributed the findings to overfitting, a possible heterogeneity of their validating datasets and possible presence of noise, even if a comprehensive preprocessing routine had been applied. Interestingly, the approximately 20% difference in the expected accuracy was found also in the study of Moghimi et al. <xref rid="b19" ref-type="bibr">[19]</xref> between single and double cross-validation schemes.</p>
      <p>Therefore, despite the fact that in some studies the reported classification performance is relatively high <xref rid="b15" ref-type="bibr">[15]</xref>, <xref rid="b22" ref-type="bibr">[22]</xref>, in general the obtained proposed accuracy rates and suggested biomarkers are diverse <xref rid="b19" ref-type="bibr">[19]</xref>–<xref rid="b21" ref-type="bibr">[21]</xref>, <xref rid="b23" ref-type="bibr">[23]</xref>. There are several reasons why this happens. First of all, a single cross-validation procedure may end up with an over-optimistic estimate of model's performance <xref rid="b20" ref-type="bibr">[20]</xref>, <xref rid="b24" ref-type="bibr">[24]</xref> especially when feature selection takes place <xref rid="b19" ref-type="bibr">[19]</xref>. Another reason is the small sample size <xref rid="b25" ref-type="bibr">[25]</xref>, <xref rid="b26" ref-type="bibr">[26]</xref>. Also the pre-processing procedure may play an important role to the performance of the final classification model <xref rid="b19" ref-type="bibr">[19]</xref>. Thus, finding reliable/reproducible biomarkers (e.g. that generalize among different individuals) for schizophrenia remains a challenging problem <xref rid="b19" ref-type="bibr">[19]</xref>, <xref rid="b21" ref-type="bibr">[21]</xref>, <xref rid="b23" ref-type="bibr">[23]</xref>, <xref rid="b25" ref-type="bibr">[25]</xref>.</p>
      <p>Besides the use of linear correlation for the construction of FCN, nonlinear manifold learning algorithms such as Isometric Mapping (ISOMAP) and Diffusion Maps, have been also applied for the construction of FCN <xref rid="b16" ref-type="bibr">[16]</xref>, <xref rid="b27" ref-type="bibr">[27]</xref>. Other approaches such as cross-recurrence analysis and multilayer modelling <xref rid="b28" ref-type="bibr">[28]</xref> have been also proposed. Anderson and Cohen <xref rid="b16" ref-type="bibr">[16]</xref> used ISOMAP for the construction of embedded low-dimensional FCN for the classification between controls and schizophrenia patients using the COBRE dataset. ROIs were acquired using single subject ICA (for a review on ICA see in <xref rid="b29" ref-type="bibr">[29]</xref>). The analysis revealed differences in small-world properties among groups and 13 global-graph theoretic features led to a reported 65% accuracy rate (evaluating the model using a 10-fold cross validation scheme). Gallos et al. <xref rid="b27" ref-type="bibr">[27]</xref> used both linear (multidimensional scaling) and nonlinear manifold approaches (ISOMAP, Locally Linear Embedding, kernel PCA and Diffusion Maps) to construct embedded FCN based on the COBRE dataset. The classification performance of the global network properties was tested using key global graph-theoretic properties and several machine learning techniques including radial SVM and neural networks. The performance of two widely used metrics for the construction of FCN metrics, namely the Euclidean distance and the cross correlation metric was also assessed. As in <xref rid="b16" ref-type="bibr">[16]</xref> the analysis was performed based on the global graph theoretical measures.</p>
      <p>Thus, here, building on recent methodological advances <xref rid="b16" ref-type="bibr">[16]</xref>, <xref rid="b27" ref-type="bibr">[27]</xref>, <xref rid="b30" ref-type="bibr">[30]</xref>, we used ISOMAP to construct embedded FCN towards the classification of 71 schizophrenia patients and 74 healthy controls from the COBRE dataset, targeting at the local graph theoretical properties of the embedded FCN. Thus, we matched the different anatomical regions of each individual in accordance with the Desikan-Killiany Atlas <xref rid="b31" ref-type="bibr">[31]</xref>. This atlas has been recently used in a network-based analysis for exploring the dynamic functional core of human brain at a resting state <xref rid="b32" ref-type="bibr">[32]</xref>. We constructed FCN by (a) the standard approach, i.e. by-cross-correlating the rsfMRI time series <xref rid="b15" ref-type="bibr">[15]</xref>, <xref rid="b18" ref-type="bibr">[18]</xref>, <xref rid="b19" ref-type="bibr">[19]</xref> and, (b) using ISOMAP <xref rid="b16" ref-type="bibr">[16]</xref>, <xref rid="b27" ref-type="bibr">[27]</xref>, <xref rid="b33" ref-type="bibr">[33]</xref> to produce low dimensional embeddings of the correlation matrices. Based on the constructed FCN, we calculated five local graph theoretic measures, namely the participation coefficient, the strength of node, the betweenness centrality, the nodal efficiency and the local clustering coefficient. These measures have been well tried and tested in recent classification studies associated with schizophrenia <xref rid="b15" ref-type="bibr">[15]</xref>, <xref rid="b18" ref-type="bibr">[18]</xref>, <xref rid="b19" ref-type="bibr">[19]</xref>, <xref rid="b34" ref-type="bibr">[34]</xref>. LASSO and Random Forest (RF) algorithms were used for feature selection. In order to select the most informative features and to evaluate the final model's performance we used a linear SVM with a double cross validation scheme.</p>
    </sec>
    <sec sec-type="materials|methods" id="s2">
      <label>2</label>
      <title>Materials and methods</title>
      <sec id="s2.1">
        <label>2.1</label>
        <title>Data description</title>
        <p>The analysis is based on the Schizophrenia Centers of Biomedical Research Excellence (COBRE) dataset (publicly available at: <ext-link ext-link-type="uri" xlink:href="http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html">http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html</ext-link>). The COBRE dataset comprises of high resolution T1 images as well as rsfMRI data from 146 subjects. For the subject 0040075 there were missing rsfMRI data and subsequently it was excluded from further analysis, leaving a total of 71 Schizophrenic patients (Male/Female: 57/14; handedness R/L/B: 59/10/2; age: 38.1 ± 13.9) and 74 healthy controls (Male/Female: 51/23; handedness R/L/B: 71/1/2; age: 35.8 ± 11.5). All subjects were screened prior to any acquisition and exclusion criteria included: history of neurological disorder other than schizophrenia, mental retardation, severe head traumas with more than five minutes loss of consciousness, substance abuse or dependence within the last 12 months. Acquisition protocols were the same for both groups and included a T1-multi-echo-MPRAGE of high resolution (TR/TE/TI = 2530/[1.64, 3.5, 5.36, 7.22, 9.08]/900 ms, flip angle = 7°, matrix = 256×256×176, voxel-size = 1×1×1 mm<sup>3</sup>) and rs-fMRI with the single-shot echo planar imaging technique (TR: 2 s, TE: 29 ms, matrix size: 64×64, 32 slices, voxel-size: 3×3×4 mm<sup>3</sup>).</p>
      </sec>
      <sec id="s2.2">
        <label>2.2</label>
        <title>Preprocessing and signal extraction</title>
        <p>The fMRI data preprocessing was carried out using FEAT (FMRI Expert Analysis Tool) Version 6.00, part of FSL (FMRIB's Software Library). The pipeline included motion correction using Fsl's linear registration tools (MCFLIRT) <xref rid="b35" ref-type="bibr">[35]</xref>, slice-timing correction using Fourier-space time-series phase-shifting, non-brain tissue removal using Fsl's brain extraction tool (BET) <xref rid="b36" ref-type="bibr">[36]</xref>, spatial smoothing using a Gaussian kernel of 5mm Full Width at Half Maximum (FWHM), grand-mean intensity normalization of the entire 4D dataset by a single multiplicative factor. In order to further refine our data from noise due to motion artifacts, we also employed denoising via ICA AROMA methodology <xref rid="b37" ref-type="bibr">[37]</xref> which detects and regresses out noise-related independent components. High-pass filtering at 100Hz was applied after ICA AROMA procedure as it is recommended, in order to better identify motion-related components while at the same time avoiding ringing artifacts <xref rid="b37" ref-type="bibr">[37]</xref>. Additionally, a high-pass filter was favoured against a band-pass, as temporal band-pass filtering discards meaningful signal existing in higher frequencies <xref rid="b38" ref-type="bibr">[38]</xref>.</p>
        <p>Finally, FreeSurfer software package version 6.0.1 <xref rid="b39" ref-type="bibr">[39]</xref> was utilized to parcellate each individual T1-MPRAGE image into anatomical regions according to Desikan-Killiany (DK) Atlas <xref rid="b31" ref-type="bibr">[31]</xref>. Briefly, the FreeSurfer process pipeline included brain extraction, intensity normalization for the reconstruction of gray and white matter boundaries and pial surface extraction to approximately 150.000 vertices per hemisphere. For pairing each hemispheric surface with a spherical template of DK, atlas non-rigid transformations were performed and corrected iteratively until individual cortical folding patterns were matched with cortical geometry across subjects. Finally, parcellation of each individual subject was registered to the rsfMRI space and time series were extracted from 84 cortical and sub-cortical regions in a subject-specific manner. These time series were used for any further analysis.</p>
      </sec>
      <sec id="s2.3">
        <label>2.3</label>
        <title>Construction of FCN using Cross-Correlation</title>
        <p>For each pair of time series, here from <italic>M</italic> = 84 anatomical regions of the brain, say <bold>A</bold><sub><italic>i</italic></sub> and <bold>A</bold><sub><italic>j</italic></sub>, the cross-correlation function (CCF) (see also in <xref rid="b16" ref-type="bibr">[16]</xref>) reads:</p>
        <p>
          <disp-formula id="eq001">
            <mml:math id="eq001a">
              <mml:mrow>
                <mml:mi>C</mml:mi>
                <mml:mi>C</mml:mi>
                <mml:mi>F</mml:mi>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:msub>
                  <mml:mstyle mathvariant="bold" mathsize="normal">
                    <mml:mi>A</mml:mi>
                  </mml:mstyle>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mn>,</mml:mn>
                <mml:msub>
                  <mml:mstyle mathvariant="bold" mathsize="normal">
                    <mml:mi>A</mml:mi>
                  </mml:mstyle>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mn>,</mml:mn>
                <mml:mi>l</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mi>E</mml:mi>
                    <mml:mo stretchy="false">[</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>A</mml:mi>
                      </mml:mstyle>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mn>,</mml:mn>
                        <mml:mi>t</mml:mi>
                        <mml:mo>+</mml:mo>
                        <mml:mi>l</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mover accent="true">
                          <mml:mstyle mathvariant="bold" mathsize="normal">
                            <mml:mi>A</mml:mi>
                          </mml:mstyle>
                          <mml:mo stretchy="true"> ¯</mml:mo>
                        </mml:mover>
                      </mml:mrow>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>A</mml:mi>
                      </mml:mstyle>
                      <mml:mrow>
                        <mml:mi>j</mml:mi>
                        <mml:mn>,</mml:mn>
                        <mml:mi>t</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mover accent="true">
                          <mml:mstyle mathvariant="bold" mathsize="normal">
                            <mml:mi>A</mml:mi>
                          </mml:mstyle>
                          <mml:mo stretchy="true"> ¯</mml:mo>
                        </mml:mover>
                      </mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msqrt>
                      <mml:mrow>
                        <mml:mi>E</mml:mi>
                        <mml:mo stretchy="false">[</mml:mo>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mstyle mathvariant="bold" mathsize="normal">
                            <mml:mi>A</mml:mi>
                          </mml:mstyle>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mn>,</mml:mn>
                            <mml:mi>t</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>−</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mover accent="true">
                              <mml:mstyle mathvariant="bold" mathsize="normal">
                                <mml:mi>A</mml:mi>
                              </mml:mstyle>
                              <mml:mo stretchy="true"> ¯</mml:mo>
                            </mml:mover>
                          </mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                        <mml:msup>
                          <mml:mo stretchy="false">)</mml:mo>
                          <mml:mn>2</mml:mn>
                        </mml:msup>
                        <mml:mo stretchy="false">]</mml:mo>
                        <mml:mi>E</mml:mi>
                        <mml:mo stretchy="false">[</mml:mo>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mstyle mathvariant="bold" mathsize="normal">
                            <mml:mi>A</mml:mi>
                          </mml:mstyle>
                          <mml:mrow>
                            <mml:mi>j</mml:mi>
                            <mml:mn>,</mml:mn>
                            <mml:mi>t</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                        <mml:mo>−</mml:mo>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mover accent="true">
                              <mml:mstyle mathvariant="bold" mathsize="normal">
                                <mml:mi>A</mml:mi>
                              </mml:mstyle>
                              <mml:mo stretchy="true"> ¯</mml:mo>
                            </mml:mover>
                          </mml:mrow>
                          <mml:mi>j</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msqrt>
                    <mml:msup>
                      <mml:mo stretchy="false">)</mml:mo>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                    <mml:mo stretchy="false">]</mml:mo>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mn>,</mml:mn>
              </mml:mrow>
            </mml:math>
            <label>(2.1)</label>
          </disp-formula>
        </p>
        <p>where <italic>l</italic> represent the time lag (i.e. shifting in time, both backwards and forwards), and <inline-formula><mml:math id="in001"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mo stretchy="true"> ¯</mml:mo></mml:mover></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> denotes the average value of the entire time series. Here, we considered a maximum of three time lags (the same number of lags considered also in <xref rid="b16" ref-type="bibr">[16]</xref>). Hence, for each pair of time series we calculated 7 correlation scores, three of them shifted back in time (e.g. one, two and three time lags), three of them shifted forward in time and one of them (zero lag) being the simple standard linear correlation. The intuition behind this metric is to detect the correlation between brain regions that might have a high correlation value but with a small phase shift. Cross-correlation has long been applied as an fMRI signal processing strategy <xref rid="b40" ref-type="bibr">[40]</xref>.</p>
        <p>For the construction of the FCN connectivity/distance matrices, we used a pseudo-distance metric <italic>d<sub>c</sub></italic> defined as (see also in <xref rid="b16" ref-type="bibr">[16]</xref>):</p>
        <p>
          <disp-formula id="eq002">
            <mml:math id="eq002a">
              <mml:mrow>
                <mml:msub>
                  <mml:mi>d</mml:mi>
                  <mml:mi>c</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:msub>
                  <mml:mstyle mathvariant="bold" mathsize="normal">
                    <mml:mi>A</mml:mi>
                  </mml:mstyle>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mn>,</mml:mn>
                <mml:msub>
                  <mml:mstyle mathvariant="bold" mathsize="normal">
                    <mml:mi>A</mml:mi>
                  </mml:mstyle>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>−</mml:mo>
                <mml:munder>
                  <mml:mstyle mathsize="140%" displaystyle="true">
                    <mml:mrow>
                      <mml:mi>m</mml:mi>
                      <mml:mi>a</mml:mi>
                      <mml:mi>x</mml:mi>
                    </mml:mrow>
                  </mml:mstyle>
                  <mml:mrow>
                    <mml:mi>l</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>0,1,2,3</mml:mn>
                  </mml:mrow>
                </mml:munder>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mo>|</mml:mo>
                <mml:mi>C</mml:mi>
                <mml:mi>C</mml:mi>
                <mml:mi>F</mml:mi>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:msub>
                  <mml:mstyle mathvariant="bold" mathsize="normal">
                    <mml:mi>A</mml:mi>
                  </mml:mstyle>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mn>,</mml:mn>
                <mml:msub>
                  <mml:mstyle mathvariant="bold" mathsize="normal">
                    <mml:mi>A</mml:mi>
                  </mml:mstyle>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mn>,</mml:mn>
                <mml:mi>l</mml:mi>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>|</mml:mo>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mn>.</mml:mn>
              </mml:mrow>
            </mml:math>
            <label>(2.2)</label>
          </disp-formula>
        </p>
        <p>However, the connectivity/distance matrices are hardly comparable across subjects, as they are fully connected <xref rid="b16" ref-type="bibr">[16]</xref>. Therefore, as a common practice, we set up a thresholding procedure to the (dis)similarity matrices in order to keep the strongest connections of the derived FCN. In order to remove the effect of the variable network density on the calculation of the graph measures across groups, we followed the approach of proportional thresholding (PT) <xref rid="b41" ref-type="bibr">[41]</xref>. We examined different levels of PT ranging from 20% to 50% (similar ranges have been also used in recent studies <xref rid="b4" ref-type="bibr">[4]</xref>, <xref rid="b15" ref-type="bibr">[15]</xref>, <xref rid="b18" ref-type="bibr">[18]</xref>) with a step of 5%. Other approaches of thresholding that have been proposed include data-driven topological filtering based on Orthogonal Minimum Spanning Trees (OMST) with applications in different neuroimaging modalities <xref rid="b42" ref-type="bibr">[42]</xref>, <xref rid="b43" ref-type="bibr">[43]</xref>.</p>
      </sec>
      <sec id="s2.4">
        <label>2.4</label>
        <title>Construction of FCN using ISOMAP</title>
        <p>ISOMAP is a non-linear dimensionality reduction/manifold learning algorithm that considering a set of <italic>M</italic> objects/observables <inline-formula><mml:math id="in002"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mn>1</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mn>2</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:mo>…</mml:mo><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> produces a low-dimensional data representation <inline-formula><mml:math id="in003"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mn>1</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mn>2</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:mo>…</mml:mo><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="in004"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> minimizing the objective function:</p>
        <p>
          <disp-formula id="eq003">
            <mml:math id="eq003a">
              <mml:mrow>
                <mml:mstyle displaystyle="true">
                  <mml:munder>
                    <mml:mo>∑</mml:mo>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mn>,</mml:mn>
                      <mml:mi>j</mml:mi>
                      <mml:mn>,</mml:mn>
                      <mml:mtext> </mml:mtext>
                      <mml:mi>i</mml:mi>
                      <mml:mo>≠</mml:mo>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:munder>
                </mml:mstyle>
                <mml:msup>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mtext> </mml:mtext>
                    <mml:msub>
                      <mml:mi>d</mml:mi>
                      <mml:mi>G</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>x</mml:mi>
                      </mml:mstyle>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mn>,</mml:mn>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>x</mml:mi>
                      </mml:mstyle>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>−</mml:mo>
                    <mml:mi>d</mml:mi>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>x</mml:mi>
                      </mml:mstyle>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mn>,</mml:mn>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>x</mml:mi>
                      </mml:mstyle>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mn>2</mml:mn>
                </mml:msup>
                <mml:mn>,</mml:mn>
              </mml:mrow>
            </mml:math>
            <label>(2.3)</label>
          </disp-formula>
        </p>
        <p>where <inline-formula><mml:math id="in005"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the shortest path (e.g. the geodesic distance) and <inline-formula><mml:math id="in006"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the (dis) similarity obtained (here, the cross-correlation-based pseudo-distance, described in 2.3) between all pairs of points <inline-formula><mml:math id="in007"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mn>1</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mn>2</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:mo>…</mml:mo><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
        <p>Here, the observables <bold>x</bold><sub><italic>i</italic></sub> are the amplitudes of time series matched to anatomical regions of the brain <inline-formula><mml:math id="in008"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mn>,</mml:mn><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,..</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
        <p>The steps of the algorithm that solves the above minimization problem can be described briefly as follows <xref rid="b33" ref-type="bibr">[33]</xref>:</p>
        <list list-type="bullet">
          <list-item>
            <p>Create a graph <inline-formula><mml:math id="in009"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mn>,</mml:mn><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where the vertices <italic>V</italic> are the time series matched to anatomical regions of the brain <bold>A</bold><sub><italic>i</italic></sub>; its connections <italic>E</italic> are created by applying either the <italic>k</italic>-nearest neighbors algorithm or alternatively, a fixed distance among vertices, the so-called <italic>ε</italic>-distance. For example, a connection/link between time series of different brain regions is established if <inline-formula><mml:math id="in010"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>,</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>ε</mml:mi><mml:mtext> </mml:mtext><mml:mn>,</mml:mn><mml:mtext> </mml:mtext><mml:mo>∀</mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>. If a link exists between <bold>A</bold><sub><italic>i</italic></sub>, <bold>A</bold><sub><italic>j</italic></sub>, set the weight <italic>w<sub>i</sub></italic><sub>,<italic>j</italic></sub> of the edge as <inline-formula><mml:math id="in011"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>,</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. Otherwise, if no link exists between <bold>A</bold><sub><italic>i</italic></sub> and <bold>A</bold><sub><italic>j</italic></sub>, set <italic>w<sub>i</sub></italic><sub>,<italic>j</italic></sub> = 0. Here, we used the <italic>k</italic> nearest neighbours algorithm <xref rid="b33" ref-type="bibr">[33]</xref> exploring a wide range of values of <italic>k</italic> ∈ [6, 20]. Below <italic>k</italic> = 6 some graphs became fragmented while above <italic>k</italic> = 20 each node would have more than 25% of the total nodes as neighbours. This would end up with a very dense graph that geodesic distance is less meaningful (approximately every node would have a very similar and shortest path to any other). Thus, we decided not to explore values of <italic>k</italic> greater than twenty.</p>
          </list-item>
          <list-item>
            <p>Calculate the shortest paths (geodesic distances) <inline-formula><mml:math id="in012"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> between all pairs of nodes based on the distances <italic>d<sub>i</sub></italic><sub>,<italic>j</italic></sub>; the calculation of the shortest paths can be done for example, by applying the Dijkstra algorithm <xref rid="b44" ref-type="bibr">[44]</xref>. This procedure results to a matrix <bold>D<sub>G</sub></bold> containing the geodesic distance between all pairs of nodes:</p>
            <p>
              <disp-formula id="eq004">
                <mml:math id="eq004a">
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>D</mml:mi>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>G</mml:mi>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mi>j</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>≡</mml:mo>
                    <mml:msub>
                      <mml:mi>d</mml:mi>
                      <mml:mi>G</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>A</mml:mi>
                      </mml:mstyle>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mn>,</mml:mn>
                    <mml:msub>
                      <mml:mstyle mathvariant="bold" mathsize="normal">
                        <mml:mi>A</mml:mi>
                      </mml:mstyle>
                      <mml:mi>j</mml:mi>
                    </mml:msub>
                    <mml:mo stretchy="false">)</mml:mo>
                    <mml:mo>=</mml:mo>
                    <mml:mi>m</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>n</mml:mi>
                    <mml:mo>{</mml:mo>
                    <mml:msub>
                      <mml:mi>d</mml:mi>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mn>,</mml:mn>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mn>,</mml:mn>
                    <mml:msub>
                      <mml:mi>d</mml:mi>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                        <mml:mn>,</mml:mn>
                        <mml:mi>k</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>+</mml:mo>
                    <mml:msub>
                      <mml:mi>d</mml:mi>
                      <mml:mrow>
                        <mml:mi>k</mml:mi>
                        <mml:mn>,</mml:mn>
                        <mml:mi>j</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>}</mml:mo>
                    <mml:mn>,</mml:mn>
                    <mml:mtext> </mml:mtext>
                    <mml:mi>k</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1,2,</mml:mn>
                    <mml:mo>…</mml:mo>
                    <mml:mn>,</mml:mn>
                    <mml:mi>M</mml:mi>
                    <mml:mtext> </mml:mtext>
                    <mml:mi>k</mml:mi>
                    <mml:mo>≠</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mn>,</mml:mn>
                    <mml:mi>j</mml:mi>
                    <mml:mn>.</mml:mn>
                  </mml:mrow>
                </mml:math>
                <label>(2.4)</label>
              </disp-formula>
            </p>
          </list-item>
          <list-item>
            <p>Estimate the new coordinates of the low-dimensional embedded manifold <inline-formula><mml:math id="in013"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mn>1</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mn>2</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:mo>…</mml:mo><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> by making use of the multi-dimensional scaling (MDS) algorithm <xref rid="b45" ref-type="bibr">[45]</xref> on the geodesic matrix <bold>D<sub>G</sub></bold> which was calculated in the previous step.</p>
          </list-item>
        </list>
        <p>For the new embedded coordinates <inline-formula><mml:math id="in014"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mn>1</mml:mn></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mn>2</mml:mn></mml:msub><mml:mn>,...,</mml:mn><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the low dimensional space, we set up a thresholding procedure (see <xref ref-type="sec" rid="s2.3">subsection 2.3</xref>) to construct graphs for further analysis.</p>
        <p>The selection of the embedding dimension <italic>p</italic> was based on the spectrum of the eigenvalues resulting from the last step of the algorithm (the MDS decomposition on the geodesic distance matrix <bold>D<sub>G</sub></bold>) (see also in <xref rid="b27" ref-type="bibr">[27]</xref>). A gap between some of the first larger eigenvalues and the rest of the spectrum suggests that these few larger eigenmodes extract most of the information related to the distance differences among data points. Thus, it is known that these few eigendimensions are capable of representing information in the low-dimensional space where non-trivial intrinsic properties are revealed <xref rid="b46" ref-type="bibr">[46]</xref>. In particular, to justify possible embedding dimensions, we followed the steps below: The eigenvalues were sorted in decreasing order so that <inline-formula><mml:math id="in015"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> ... <inline-formula><mml:math id="in016"><mml:mrow><mml:mo>≥</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. For every subject, the pairwise differences <inline-formula><mml:math id="in017"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="in018"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, ... , <inline-formula><mml:math id="in019"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> were computed. A gap among the average pairwise differences indicates from which point and further, the consideration of another eigendimension has a small contribution to the construction of the embedded FCN. In other words, a gap in the eigenpectrum of the final decomposition denotes the intrinsic dimensionality of the manifold from which the data points were sampled <xref rid="b46" ref-type="bibr">[46]</xref>. Another alternative metric that we computed for the selection of the embedding dimension is that of the residual variance <inline-formula><mml:math id="in020"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>R</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mi>D</mml:mi><mml:mi>Y</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>
<xref rid="b33" ref-type="bibr">[33]</xref>, where <italic>D<sub>Y</sub></italic> is the matrix of euclidean distances in the low dimensional embedding, <italic>D<sub>G</sub></italic> the matrix with the geodesic distances (the algorithm's best estimate of the intrinsic distances) and <italic>R</italic> the Pearson correlation coefficient. Again, a gap after the first few embedding dimensions in the residual variance is indicative of the intrinsic dimension of the dataset <xref rid="b33" ref-type="bibr">[33]</xref>. For the implementation of the ISOMAP algorithm, we utilized the package “vegan” <xref rid="b47" ref-type="bibr">[47]</xref> in the R free software environment <xref rid="b48" ref-type="bibr">[48]</xref>.</p>
      </sec>
      <sec id="s2.5">
        <label>2.5</label>
        <title>Local graph-theoretical measures</title>
        <p>We assessed five key local graph measures as described in <xref rid="b49" ref-type="bibr">[49]</xref>. In particular, we analyzed the local topological properties of the obtained FCN as resulted through thresholding on the basis of the strength of node, the betweenness centrality, the local efficiency, the local clustering coefficient and the participation coefficient <xref rid="b49" ref-type="bibr">[49]</xref>. The final feature vector size for each subject was 420-dimensional (5 local properties for each one of the 84 nodes of an individual's graph). Given a graph <inline-formula><mml:math id="in021"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mn>,</mml:mn><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>N</italic> is the total number of nodes, <italic>a<sub>ij</sub></italic> represents the binary link (0, unconnected or 1, connected), <inline-formula><mml:math id="in022"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the degree of node and <italic>d<sub>ij</sub></italic> the distance that separates node <italic>i</italic> from node <italic>j</italic>, the above graph measures are defined as follows <xref rid="b49" ref-type="bibr">[49]</xref>:</p>
        <list list-type="bullet">
          <list-item>
            <p>Strength of node: <inline-formula><mml:math id="in023"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic>w<sub>ij</sub></italic> is the weight of an edge coincide with node i and j (here, links between nodes represent distances, so <inline-formula><mml:math id="in024"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>).</p>
          </list-item>
          <list-item>
            <p>Local efficiency: <inline-formula><mml:math id="in025"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="in026"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the number of the nodes of the subgraph <bold>G</bold><sub><italic>i</italic></sub> that is consisted of the node's neighbors. <italic>E<sub>g</sub></italic> is the global efficiency of a graph given by <inline-formula><mml:math id="in027"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle></mml:mrow></mml:munder></mml:mstyle><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mn>,</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, where M is the number of nodes and <inline-formula><mml:math id="in028"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>G</mml:mi></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mn>,</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the shortest paths between nodes i and j.</p>
          </list-item>
          <list-item>
            <p>Local clustering coefficient: <inline-formula><mml:math id="in029"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:mfrac><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
          </list-item>
          <list-item>
            <p>Betweenness centrality: <inline-formula><mml:math id="in030"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:mfrac><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="in031"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the number of shortest paths between nodes <italic>n<sub>mj</sub></italic> that pass through node i and <italic>n<sub>mj</sub></italic> is the total number of shortest paths.</p>
          </list-item>
          <list-item>
            <p>Participation coefficient: <inline-formula><mml:math id="in032"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>M</mml:mi></mml:mstyle></mml:mrow></mml:munder></mml:mstyle><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> where <bold>M</bold> is the set of modules, <italic>k<sub>i</sub></italic>(<italic>m</italic>) is the degree of node <italic>i</italic> inside the module m. The so-called “Louvain algorithm” <xref rid="b50" ref-type="bibr">[50]</xref> was employed for finding the community structure of the graph.</p>
          </list-item>
        </list>
        <p>The strength of a node is a fundamental measure of prominent importance that can characterize the centrality of a node. Nodes with high strength are often considered as main hubs of the network <xref rid="b49" ref-type="bibr">[49]</xref>. An alternative to the strength is the betweenness centrality score, that can also reflect the degree of centrality from another perspective. A high betweenness centrality score for a node indicates that most of the information that flows within a network passes through that node. The local clustering coefficient is another key measure of functional segregation of a node <xref rid="b51" ref-type="bibr">[51]</xref>. It quantifies the interconnection of node's neighbours or the possibility that nearby neighbours of a node have also links to each other. The local efficiency reflects the ability of a sub-network constructed by a node and its immediate neighbours to transfer information in terms of the shortest path lengths. For example, a high local efficiency score indicates that the information transmission is more efficient/faster since the shortest paths between them are small. The participation coefficient measures a node's distribution of links/edges among different modules/communities of the graph. When a node doesn't share any link outside its module, then the participation coefficient is zero. On the other hand, if the edges of a node distribute evenly between all modules of a graph, then the coefficient reaches its maximal value. Finally, one can characterize a node based on its participation coefficient as a “provincial” hub, if the score is low, or as a “connector” hub if the score is high <xref rid="b52" ref-type="bibr">[52]</xref>.</p>
        <p>The graph measures were computed utilizing the “igraph” <xref rid="b53" ref-type="bibr">[53]</xref> and “brainGraph” packages in the R free software environment <xref rid="b48" ref-type="bibr">[48]</xref>.</p>
      </sec>
      <sec id="s2.6">
        <label>2.6</label>
        <title>Feature selection</title>
        <p>Here, we used two different methodologies/strategies, namely the Least Absolute Shrinkage and Selection Operator (LASSO) and Random Forests (RF) for feature selection. Our final feature matrices were of high dimensionality (the final feature vector size was 420-dimensional: 5 measures for each of the 84 nodes matched to the different anatomical regions of the brain) containing a lot of redundant information. Thus, the choice of the most predominant features is crucial for the classification process and the detection of potential biomarkers of the disease.</p>
        <sec id="s2.6.1">
          <label>2.6.1</label>
          <title>Least Absolute Shrinkage and Selection Operator (LASSO)</title>
          <p>The LASSO algorithm has been utilized in recent studies on schizophrenia for both accurate classification and detection of biomarkers of the disease <xref rid="b15" ref-type="bibr">[15]</xref>, <xref rid="b54" ref-type="bibr">[54]</xref>.</p>
          <p>The procedure of the LASSO algorithm stems by finding a solution to the following optimization problem:</p>
          <p>
            <disp-formula id="eq005">
              <mml:math id="eq005a">
                <mml:mrow>
                  <mml:munder>
                    <mml:mrow>
                      <mml:mi>a</mml:mi>
                      <mml:mi>r</mml:mi>
                      <mml:mi>g</mml:mi>
                      <mml:mi>m</mml:mi>
                      <mml:mi>i</mml:mi>
                      <mml:mi>n</mml:mi>
                    </mml:mrow>
                    <mml:mi>a</mml:mi>
                  </mml:munder>
                  <mml:mrow>
                    <mml:mo>∥</mml:mo>
                    <mml:mrow>
                      <mml:mi>y</mml:mi>
                      <mml:mo>−</mml:mo>
                      <mml:mi>X</mml:mi>
                      <mml:mi>a</mml:mi>
                    </mml:mrow>
                    <mml:mo>∥</mml:mo>
                  </mml:mrow>
                  <mml:mo>+</mml:mo>
                  <mml:msub>
                    <mml:mi>λ</mml:mi>
                    <mml:mn>1</mml:mn>
                  </mml:msub>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mrow>
                        <mml:mo>∥</mml:mo>
                        <mml:mi>a</mml:mi>
                        <mml:mo>∥</mml:mo>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:msub>
                  <mml:mo>,</mml:mo>
                </mml:mrow>
              </mml:math>
              <label>(2.5)</label>
            </disp-formula>
          </p>
          <p>where <bold>X</bold> represents the feature matrix of size <italic>n</italic>×<italic>p</italic> with <italic>n</italic> being the number of subjects and <italic>p</italic> the dimensionality of the feature vector, <bold>y</bold> is a vector containing the class labels for the subjects (0 for healthy controls, 1 for schizophrenia patients), <bold>a</bold> is the vector of coefficients and <italic>λ</italic><sub>1</sub> the penalizing factor. The penalty factor <italic>λ</italic><sub>1</sub> determines how regularized the model is, and thus, how many features are retained. As the value of the penalizing factor drops, coefficients are getting smaller and smaller. Typically, most of them decline to zero. The absolute value of a non zero coefficient can be then used as a measure of the feature's relative importance. It is highly recommended to use LASSO in conjunction with cross-validation <xref rid="b26" ref-type="bibr">[26]</xref>, <xref rid="b55" ref-type="bibr">[55]</xref>, <xref rid="b56" ref-type="bibr">[56]</xref> (here we used the LOOCV scheme). Thus, one can choose the penalizing factor based on the misclassification error estimated by a CV procedure, so that it is more probable that the final model generalizes well to unknown data samples. Here, we estimated the CV classification error and chose the penalizing factor according to the “one standard deviation rule”. According to this rule <xref rid="b24" ref-type="bibr">[24]</xref>, we selected the most parsimonious model with its error being no more than one standard deviation above the error of the best model. This practice has been suggested by Hastie <italic>et al</italic>. <xref rid="b57" ref-type="bibr">[57]</xref> for general cross-validation use. For the implementation of LASSO, in conjunction with cross validation, we utilized the “glmnet” package <xref rid="b56" ref-type="bibr">[56]</xref> of the R free software environment <xref rid="b48" ref-type="bibr">[48]</xref>.</p>
        </sec>
        <sec id="s2.6.2">
          <label>2.6.2</label>
          <title>Random forest (RF)</title>
          <p>RF is an ensemble machine learning algorithm used for both classification and regression purposes <xref rid="b58" ref-type="bibr">[58]</xref>. It comprises of a large number of classification and regression trees <xref rid="b59" ref-type="bibr">[59]</xref>, where each one operates independently. Every individual tree is constructed using a bootstrap (i.e. random sampling with replacement) version of the training data. Once the tree is constructed, the “out of bag” sample (the instances not used in the construction step) of the original data is used as a test set. The error rate in the “out of bag” samples of all trees in the forest is the estimate of the generalization error of the final model. Prediction of new samples are made through a majority voting system between trees where the class with the most votes becomes the final prediction of the model. While the algorithm is inherently stochastic is considered to be robust to noise and resistant to both overfitting and the presence of outliers <xref rid="b60" ref-type="bibr">[60]</xref>. The algorithm has been applied to fMRI data for both feature selection and classification purposes <xref rid="b61" ref-type="bibr">[61]</xref>, <xref rid="b62" ref-type="bibr">[62]</xref>. RF, can be also utilized for feature selection using random subspace methodology for measuring feature importance by calculating the so-called Gini impurity index <xref rid="b63" ref-type="bibr">[63]</xref>. This index/criterion is computed based on the impurity reduction principle <xref rid="b64" ref-type="bibr">[64]</xref> and make no hypothesis of data belonging to specific distributions and therefore,is non parametric. For a binary split, the Gini index of a node <italic>t</italic> can be calculated as follows:</p>
          <p>
            <disp-formula id="eq006">
              <mml:math id="eq006a">
                <mml:mrow>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                  <mml:mo>−</mml:mo>
                  <mml:mstyle displaystyle="true">
                    <mml:munderover>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>j</mml:mi>
                        <mml:mo>=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mn>2</mml:mn>
                    </mml:munderover>
                  </mml:mstyle>
                  <mml:mi>p</mml:mi>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mi>j</mml:mi>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                    <mml:mn>2</mml:mn>
                  </mml:msup>
                  <mml:mn>,</mml:mn>
                </mml:mrow>
              </mml:math>
              <label>(2.6)</label>
            </disp-formula>
          </p>
          <p>where <italic>p</italic> is the frequency of each class <italic>j</italic> that passes through that node. A low Gini index implies that the specific feature is important in partitioning data into the two distinct classes (here, schizophrenia patient/healthy control). Specifically, a tree structure 𝒯 trained on a learning sample of size <italic>N</italic> tries to identify at each node <italic>t</italic>, a split <italic>s<sub>t</sub></italic> for which the sample <italic>N<sub>t</sub></italic> that pass through the node is split into two child nodes <italic>t<sub>R</sub></italic> and <italic>t<sub>L</sub></italic> by maximizing the decrease below <xref rid="b65" ref-type="bibr">[65]</xref>:</p>
          <p>
            <disp-formula id="eq007">
              <mml:math id="eq007a">
                <mml:mrow>
                  <mml:mi>Δ</mml:mi>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mi>s</mml:mi>
                  <mml:mn>,</mml:mn>
                  <mml:mi>t</mml:mi>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:msub>
                    <mml:mi>p</mml:mi>
                    <mml:mi>R</mml:mi>
                  </mml:msub>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>t</mml:mi>
                    <mml:mi>L</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>−</mml:mo>
                  <mml:msub>
                    <mml:mi>p</mml:mi>
                    <mml:mi>L</mml:mi>
                  </mml:msub>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>t</mml:mi>
                    <mml:mi>R</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mn>,</mml:mn>
                </mml:mrow>
              </mml:math>
              <label>(2.7)</label>
            </disp-formula>
          </p>
          <p>where <inline-formula><mml:math id="in034"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math id="in035"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Adding all the weighted decreases of all nodes <italic>t</italic> using a specific feature, say <italic>X<sub>m</sub></italic> averaged over all trees, one can obtain the mean decrease in Gini index (MDG) <xref rid="b65" ref-type="bibr">[65]</xref>:</p>
          <p>
            <disp-formula id="eq008">
              <mml:math id="eq008a">
                <mml:mrow>
                  <mml:mi>M</mml:mi>
                  <mml:mi>D</mml:mi>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>X</mml:mi>
                    <mml:mi>m</mml:mi>
                  </mml:msub>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mn>1</mml:mn>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mi>N</mml:mi>
                        <mml:mi>T</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                  </mml:mfrac>
                  <mml:mstyle displaystyle="true">
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mi>T</mml:mi>
                    </mml:munder>
                  </mml:mstyle>
                  <mml:mstyle displaystyle="true">
                    <mml:munder>
                      <mml:mo>∑</mml:mo>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mo>∈</mml:mo>
                        <mml:mi>T</mml:mi>
                        <mml:mo>:</mml:mo>
                        <mml:mi>u</mml:mi>
                        <mml:mo stretchy="false">(</mml:mo>
                        <mml:msub>
                          <mml:mi>s</mml:mi>
                          <mml:mi>t</mml:mi>
                        </mml:msub>
                        <mml:mo stretchy="false">)</mml:mo>
                        <mml:mo>=</mml:mo>
                        <mml:msub>
                          <mml:mi>X</mml:mi>
                          <mml:mi>m</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:munder>
                  </mml:mstyle>
                  <mml:mi>p</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mi>t</mml:mi>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mi>Δ</mml:mi>
                  <mml:mi>G</mml:mi>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:msub>
                    <mml:mi>s</mml:mi>
                    <mml:mi>t</mml:mi>
                  </mml:msub>
                  <mml:mn>,</mml:mn>
                  <mml:mi>t</mml:mi>
                  <mml:mo stretchy="false">)</mml:mo>
                  <mml:mn>,</mml:mn>
                </mml:mrow>
              </mml:math>
              <label>(2.8)</label>
            </disp-formula>
          </p>
          <p>where <italic>N<sub>T</sub></italic> is the number of trees in the forest, <inline-formula><mml:math id="in036"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> and <italic>u</italic>(<italic>s<sub>t</sub></italic>) is the feature used in the split of node <italic>t</italic>.</p>
          <p>MDG reflects the average of a variable's total decrease in node impurity, weighted by the proportion of samples reaching that node across all trees of the ensemble. In order to have a robust evaluation of feature importance it is generally recommended that the RF should be run multiple times <xref rid="b66" ref-type="bibr">[66]</xref>. After measuring and ranking features by importance, elimination of bottom less useful features may lead to an increase in the accuracy of the final model <xref rid="b61" ref-type="bibr">[61]</xref>. In this study, we perform feature selection via RF in two steps:</p>
          <list list-type="bullet">
            <list-item>
              <p>We estimated MDG for all features across 30 independent runs (more runs did not change the outcome of the analysis) of the model. We averaged the results to eliminate the stochastic nature of the algorithm in order to obtain a stable ranking. We eliminated 95% of the features and kept only the most important ones (the ones with the highest MDG indices).</p>
            </list-item>
            <list-item>
              <p>For the remaining ranked features, we trained models with different subsets of predictors starting from the single most important feature to all features remained after elimination, by a step of two (the first model uses only one feature, the second the first three, the third the first five etc.). In the case that two or more models were tied in terms of performance, we chosen the simplest model (the one with the fewer features).</p>
            </list-item>
          </list>
          <p>For our computations, we used the R package “randomForest” <xref rid="b67" ref-type="bibr">[67]</xref>. The number of trees in the “forest” was set to 500 (similar number of trees also used in <xref rid="b61" ref-type="bibr">[61]</xref>, <xref rid="b62" ref-type="bibr">[62]</xref>) and the parameter concerning the number of features analyzed at each node to find the best split was set equal to the square root of the number of features. The latter is the recommended value of the package and the same strategy have been also used by other studies <xref rid="b61" ref-type="bibr">[61]</xref>, <xref rid="b62" ref-type="bibr">[62]</xref>, <xref rid="b66" ref-type="bibr">[66]</xref>.</p>
        </sec>
      </sec>
      <sec id="s2.7">
        <label>2.7</label>
        <title>Overview of the methodology and classification procedure</title>
        <p>The overall pipeline proposed in this study (1A) along with the classification scheme (1B) used is presented in <xref ref-type="fig" rid="neurosci-08-02-016-g001">Figure 1</xref>. At first, we pre-processed the raw fMRI data (see 2.2) and extracted the time series using an anatomical parcellation scheme (the Desikan-Killiany atlas) for each subject (see 2.2). As a next step, we constructed the cross correlation matrices of the derived time series (see 2.3). We then embedded the dimension of the matrices using ISOMAP and constructed the graph objects of the low dimensional embeddings (this step is skipped in the case of the correlation method). We then applied proportional thresholding (PT) on the graph structures and computed the 5 key local graph-theoretic measures (see 2.5) as described in the methodology. To ensure that the selected features can be generalized across subjects <xref rid="b20" ref-type="bibr">[20]</xref>, and that the evaluation of the model's performance will be unbiased <xref rid="b24" ref-type="bibr">[24]</xref>, we performed a double cross validation procedure <xref rid="b19" ref-type="bibr">[19]</xref>. Our double cross validation consisted of an outer and an inner loop of “leave one out” cross validation (LOOCV) scheme. The outer loop evaluates the model's performance, while the inner loop optimizes the feature selection procedure (here with LASSO and RF). Initially, out of the total number of subjects considered in this study (<italic>N</italic> = 145), we first left one subject out (as test subject) and continued with the other 144 (for training and validation). On these remaining subjects (<italic>N</italic> = 144) we employed the feature selection with another (inner) loop of LOOCV. We then trained a linear standard SVM with the features determined by the inner loop of LOOCV and tried to predict the class label of the initially left/unseen test subjects. This procedure is repeated 145 times. Thus, the estimation of the final model's performance remains unbiased and the selected features are more likely to be generalizable for unseen samples <xref rid="b19" ref-type="bibr">[19]</xref>, <xref rid="b20" ref-type="bibr">[20]</xref>. A schematic representation of the procedure discussed above can be inspected in 1B.</p>
        <p>The confusion matrix was also computed for the classification model. In the case of binary classification, the confusion matrix is a 2 × 2 square matrix reporting the number of true positives <italic>TP</italic>, false positives <italic>FP</italic>, true negatives <italic>TN</italic> and false negatives <italic>FN</italic>. In particular, we considered cases of schizophrenia patients as positives <italic>P</italic> and healthy controls as negatives <italic>N</italic>. Sensitivity (known also as the True Positive Rate) and specificity (True Negative Rate) are statistical measures for the evaluation of a binary classification model. The sensitivity <italic>TPR</italic> is defined as <inline-formula><mml:math id="in037"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, while specificity <italic>TNR</italic> as <inline-formula><mml:math id="in038"><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. Here, Specificity quantifies the ability of a model to correctly identify a healthy control subject, while sensitivity measures the proportion of schizophrenic subjects correctly identified by the model.</p>
        <fig id="neurosci-08-02-016-g001" position="float">
          <label>Figure 1.</label>
          <caption>
            <title>A) Overview of the proposed methodology. B) The double cross validation scheme.</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g001"/>
        </fig>
      </sec>
      <sec id="s2.8">
        <label>2.8</label>
        <title>Support vector machines (SVM)</title>
        <p>The classification performance was assessed in the outer loop of LOOCV using standard Linear Support Vector Machines (LSVM). The features given to the classifier were those features determined by the optimization of feature selection procedure inside the inner loop of LOOCV. The final “best” LSVM model was trained 145 times on 144 out of 145 subjects and each time we tried to predict the class label of the unseen test subject. Briefly, the LSVM finds the best plane or hyperplane that separates the two groups in the feature space. Specifically, given a set of data points <inline-formula><mml:math id="in039"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mn>,</mml:mn><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2..</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, where <italic>N</italic> reflect the total number of subjects, <inline-formula><mml:math id="in040"><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>R</mml:mi></mml:mstyle><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> represents <italic>d</italic> attributes/features for subject <italic>i</italic> and <inline-formula><mml:math id="in041"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1,1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> the subject's class label (here, a schizophrenia patient or a healthy control), SVM aims at finding the best separating hyperplane by maximizing the margin of separation. In general, a hyperplane can be defined as <inline-formula><mml:math id="in042"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mo>·</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> where <bold>w</bold> are the weights of features <bold>x</bold><sub><italic>i</italic></sub>. Any hyperplanes lying in parallel can then be described as <inline-formula><mml:math id="in043"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mo>·</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> if <italic>y<sub>i</sub></italic> = 1 and <inline-formula><mml:math id="in044"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mo>·</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>≤</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> if <italic>y<sub>i</sub></italic> = –1. Thus, the optimization problem refers to the maximization of the margin between hyperplanes <inline-formula><mml:math id="in045"><mml:mrow><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>w</mml:mi><mml:mo>∥</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula> so that for every <inline-formula><mml:math id="in046"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2..</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mn>,</mml:mn><mml:mtext> </mml:mtext><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mo>·</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. A regularization parameter <italic>C</italic> is also included. This parameter controls the penalty of the error <italic>z<sub>i</sub></italic> and allows for a trade-off between misclassifications and size of the separating margin. For example, a large value of <italic>C</italic>, will end up with a smaller-margin between separating hyperplanes. On the other hand, a small value will lead the solution of the final optimization problem to a larger-margin, even if that hyperplane misclassifies some points (in order for the model to generalize well in future data samples). Therefore, the final optimization problem, becomes the one which minimizes <inline-formula><mml:math id="in047"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∥</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:msup><mml:mo>∥</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>·</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub></mml:mstyle><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> subject to <inline-formula><mml:math id="in048"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi></mml:mstyle><mml:mo>·</mml:mo><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>x</mml:mi></mml:mstyle><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="in049"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1,2..</mml:mn><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>. Here, The regularization parameter <italic>C</italic> was set to 1 (similar value of parameter <italic>C</italic> used also in <xref rid="b19" ref-type="bibr">[19]</xref>). For the implementation of SVM algorithms, we utilized those offered by the “caret” <xref rid="b68" ref-type="bibr">[68]</xref> package of the R free software environment <xref rid="b48" ref-type="bibr">[48]</xref>.</p>
      </sec>
    </sec>
    <sec id="s3">
      <label>3</label>
      <title>Results</title>
      <p>Following the methodology described in <xref ref-type="sec" rid="s2.3">section 2.3</xref>, we first constructed the FCN by correlating the time-courses (matched to the 84 anatomical brain regions) and then we proceeded with the construction of FCN based on the ISOMAP.</p>
      <sec>
        <label>3.1</label>
        <title>Construction of low dimensional embeddings of FCN using ISOMAP and visualization</title>
        <p>As described in the methodology, the embedding dimension was selected via the inspection of the eigenspectrum of the decomposition and complementary by inspecting the residual variance for each one of the low dimensional embeddings. In <xref ref-type="fig" rid="neurosci-08-02-016-g002">Figure 2A</xref>, we show the average differences between the fifteen largest eigenvalues of the final decomposition, while in 2B the average residual variance across subjects. As it is shown in <xref ref-type="fig" rid="neurosci-08-02-016-g002">Figure 2A</xref>, there is a large gap between the first and second pair of eigenvalues, while a second gap appears between the second and the third eigenvalues. Finally, a smaller third gap appears between the third and fourth pair of eigenvalues. Finally, after the fifth and sixth eigenvalues, most of the pairwise differences have an almost equal value that is close to zero. Similarly, the average residual variance (<xref ref-type="fig" rid="neurosci-08-02-016-g002">Figure 2B</xref>) falls rapidly until the first 3 dimensions and continues decreasing smoother and smoother up to five dimensions. In fact, this indicates that there is no substantial difference in the magnitude of eigenvalues (and the decrease in the residual variance) further from this point. Thus, we decided not to explore low-dimensional embeddings larger than five dimensions. Instead, we focused our analysis on four low-dimensional embeddings where 2,3,4 and 5 dimensions are retained. In <xref rid="neurosci-08-02-016-t01" ref-type="table">Table 1</xref>, we report the residual variance per embedding dimension for each group. In <xref ref-type="fig" rid="neurosci-08-02-016-g003">Figure 3</xref>, we present a 2D low dimensional embedding of the average correlation matrix for each one of the two groups (healthy controls and schizophrenia patients) as derived by ISOMAP. For visualization purposes, we included only 46 out of the 84 brain regions which belong to four major Resting state networks namely the Default Mode Network (DMN), the Sub-cortical Limbic Network (SLN), the Sensory Motor Network (SRMN) and the Visual Network (VSN). We label as DMN the lateral parts of the isthmus of cingulate gyrus (ic), lateral orbito-frontal cortex (lof), medial orbito-frontal cortex (mof), parahippocampal gyrus (ph), posterior cingulate cortex (pcc), Precuneus cortex (prec), rostral anterior cingulate cortex (rac). SLN includes the lateral parts of the accubens (acc), amygdala (amg), caudate nucleus (caud), pallidum (pal), putamen (put) and thalamus (thal). SMRN comprises of lateral parts of paracentral gyrus (pac), postcentral gyrus (pc), precentral gyrus (prc) and superior parietal (sp). Finally VSN includes lateral parts of the Cuneus (cun), fusiform gyrus (fs), lateral Occipital cortex (loc), lingual gyrus (lg) and pericalcarine cortex (prcn). As it can be seen from <xref ref-type="fig" rid="neurosci-08-02-016-g003">Figure 3</xref>, ISOMAP achieves a satisfactory grouping of the four major RSNs in the case of controls 3A. On the other hand nodes are more disorganized in the case of patients with schizophrenia 3B.</p>
        <fig id="neurosci-08-02-016-g002" position="float">
          <label>Figure 2.</label>
          <caption>
            <title>A) Average pairwise differences of the 15 largest eigenvalues (see 2.4). B) Mean residual variance for low dimensional embeddings of different dimensionality (1 to 15 dimensions) as derived by ISOMAP based on the optimal parameters. The red dashed vertical line marks the maximum number of dimensions.</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g002"/>
        </fig>
        <table-wrap id="neurosci-08-02-016-t01" position="float">
          <label>Table 1.</label>
          <caption>
            <title>Residual variance per Embedding dimension for each group (eg. healthy controls and schizophrenia patients).</title>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead valign="top">
              <tr>
                <td rowspan="1" colspan="1">Group</td>
                <td rowspan="1" colspan="1">Emb. dimension</td>
                <td rowspan="1" colspan="1">Residual variance (Mean ± SD)</td>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td rowspan="5" valign="middle" colspan="1">Healthy controls</td>
                <td rowspan="1" colspan="1"><italic>p</italic> = 1</td>
                <td rowspan="1" colspan="1">0.61 ± 0.11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 2</td>
                <td rowspan="1" colspan="1">0.39 ± 0.12</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 3</td>
                <td rowspan="1" colspan="1">0.25 ± 0.1</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 4</td>
                <td rowspan="1" colspan="1">0.18 ± 0.08</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 5</td>
                <td rowspan="1" colspan="1">0.13 ± 0.06</td>
              </tr>
              <tr>
                <td colspan="3" valign="middle" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="5" valign="middle" colspan="1">Schizophrenia patients</td>
                <td rowspan="1" colspan="1"><italic>p</italic> = 1</td>
                <td rowspan="1" colspan="1">0.63 ± 0.12</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 2</td>
                <td rowspan="1" colspan="1">0.41 ± 0.12</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 3</td>
                <td rowspan="1" colspan="1">0.29 ± 0.11</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 4</td>
                <td rowspan="1" colspan="1">0.21 ± 0.08</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 5</td>
                <td rowspan="1" colspan="1">0.15 ± 0.07</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <fig id="neurosci-08-02-016-g003" position="float">
          <label>Figure 3.</label>
          <caption>
            <title>Visualization of a 2D embedding given by ISOMAP on the average correlation matrix for each group. Here, only brain regions that are considered part of four major RSNs, the default mode (DMN), the sensory motor (SMRN), the visual (VSN) and the sub-cortical limbic network (SLN) are included. A) Healthy controls B) Schizophrenia patients. The capital letter R and L at the end of each label reflects the lateral part of the brain region (eg. L for left and R for right). The list of the abbreviations used to label the anatomical regions of the brain is the following. For the DMN: isthmus of cingulate gyrus (ic), lateral orbito-frontal cortex (lof), medial orbito-frontal cortex (mof), parahippocampal gyrus (ph), posterior cingulate cortex (pcc), Precuneus cortex (prec), rostral anterior cingulate cortex (rac). For the SLN: accubens (acc), amygdala (amg), caudate nucleus (caud), pallidum (pal), putamen (put) and thalamus (thal). For the SRMN: paracentral gyrus (pac), postcentral gyrus (pc), precentral gyrus (prc) and superior parietal (sp). For the VSN: Cuneus (cun), fusiform gyrus (fs), lateral Occipital cortex (loc), lingual gyrus (lg) and pericalcarine cortex (prcn).</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g003"/>
        </fig>
      </sec>
      <sec id="s3.2">
        <label>3.2</label>
        <title>Classification performance</title>
        <p>Using LASSO, the best, with respect to the embedding dimension, number of <italic>k</italic> nearest neighbors in the ISOMAP algorithm and the level of proportional thresholding (PT), classification rates along with the sensitivity and specificity rates for each method are shown in <xref rid="neurosci-08-02-016-t02" ref-type="table">Table 2</xref>. Similarly, results using the RF method for feature selection are also shown in <xref rid="neurosci-08-02-016-t03" ref-type="table">Table 3</xref>.</p>
        <table-wrap id="neurosci-08-02-016-t02" position="float">
          <label>Table 2.</label>
          <caption>
            <title>Best classification rates obtained with the two methods employed in this study; proportional thresholding PT, embedding dimension <italic>p</italic>, parameter (<italic>k</italic>-nearest neighbours for ISOMAP), accuracy (Acc), sensitivity (Sens), specificity (Spec) rates. Features were chosen by LASSO.</title>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead valign="top">
              <tr>
                <td rowspan="1" colspan="1">Method</td>
                <td rowspan="1" colspan="1">Emb.dim</td>
                <td rowspan="1" colspan="1">Parameter</td>
                <td rowspan="1" colspan="1">PT (%)</td>
                <td rowspan="1" colspan="1">Accuracy (%)</td>
                <td rowspan="1" colspan="1">Sensitivity (%)</td>
                <td rowspan="1" colspan="1">Specificity (%)</td>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td rowspan="1" colspan="1">Correlation</td>
                <td rowspan="1" colspan="1">-</td>
                <td rowspan="1" colspan="1">-</td>
                <td rowspan="1" colspan="1">30</td>
                <td rowspan="1" colspan="1">
                  <bold>73.1</bold>
                </td>
                <td rowspan="1" colspan="1">77.4</td>
                <td rowspan="1" colspan="1">68.9</td>
              </tr>
              <tr>
                <td colspan="7" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="4" valign="middle" colspan="1">ISOMAP</td>
                <td rowspan="1" colspan="1"><italic>p</italic> = 2</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 14</td>
                <td rowspan="1" colspan="1">40</td>
                <td rowspan="1" colspan="1">75.9</td>
                <td rowspan="1" colspan="1">83.1</td>
                <td rowspan="1" colspan="1">68.9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 3</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 15</td>
                <td rowspan="1" colspan="1">35</td>
                <td rowspan="1" colspan="1">
                  <bold>79.3</bold>
                </td>
                <td rowspan="1" colspan="1">85.9</td>
                <td rowspan="1" colspan="1">72.9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 4</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 12</td>
                <td rowspan="1" colspan="1">40</td>
                <td rowspan="1" colspan="1">76.6</td>
                <td rowspan="1" colspan="1">85.9</td>
                <td rowspan="1" colspan="1">67.6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 5</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 18</td>
                <td rowspan="1" colspan="1">45</td>
                <td rowspan="1" colspan="1">75.9</td>
                <td rowspan="1" colspan="1">80.3</td>
                <td rowspan="1" colspan="1">71.6</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap id="neurosci-08-02-016-t03" position="float">
          <label>Table 3.</label>
          <caption>
            <title>Best classification rates obtained with the two methods employed in this study; proportional thresholding PT, embedding dimension <italic>p</italic>, parameter (<italic>k</italic>-nearest neighbours for ISOMAP), accuracy (Acc), sensitivity (Sens), specificity (Spec) rates. Features were chosen by RF.</title>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead valign="top">
              <tr>
                <td rowspan="1" colspan="1">Method</td>
                <td rowspan="1" colspan="1">Emb.dim</td>
                <td rowspan="1" colspan="1">Parameter</td>
                <td rowspan="1" colspan="1">PT (%)</td>
                <td rowspan="1" colspan="1">Accuracy (%)</td>
                <td rowspan="1" colspan="1">Sensitivity (%)</td>
                <td rowspan="1" colspan="1">Specificity (%)</td>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td rowspan="1" colspan="1">Correlation</td>
                <td rowspan="1" colspan="1">-</td>
                <td rowspan="1" colspan="1">-</td>
                <td rowspan="1" colspan="1">40</td>
                <td rowspan="1" colspan="1">
                  <bold>71</bold>
                </td>
                <td rowspan="1" colspan="1">77.4</td>
                <td rowspan="1" colspan="1">64.8</td>
              </tr>
              <tr>
                <td colspan="7" rowspan="1">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td rowspan="4" valign="middle" colspan="1">ISOMAP</td>
                <td rowspan="1" colspan="1"><italic>p</italic> = 2</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 15</td>
                <td rowspan="1" colspan="1">45</td>
                <td rowspan="1" colspan="1">76.6</td>
                <td rowspan="1" colspan="1">80.3</td>
                <td rowspan="1" colspan="1">72.9</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 3</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 15</td>
                <td rowspan="1" colspan="1">35</td>
                <td rowspan="1" colspan="1">
                  <bold>78.6</bold>
                </td>
                <td rowspan="1" colspan="1">87.3</td>
                <td rowspan="1" colspan="1">70.3</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 4</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 12</td>
                <td rowspan="1" colspan="1">40</td>
                <td rowspan="1" colspan="1">74.5</td>
                <td rowspan="1" colspan="1">81.7</td>
                <td rowspan="1" colspan="1">67.6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><italic>p</italic> = 5</td>
                <td rowspan="1" colspan="1"><italic>k</italic> = 17</td>
                <td rowspan="1" colspan="1">45</td>
                <td rowspan="1" colspan="1">76.6</td>
                <td rowspan="1" colspan="1">81.7</td>
                <td rowspan="1" colspan="1">71.6</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>Using LASSO for feature selection, the best classification rate for ISOMAP was 79.3%, obtained retaining 3 dimensions, <italic>k</italic> = 15 nearest neighbours and 35% PT. The conventional correlation peaked at 73.1% (at 30% PT). Interestingly, the 6.2% difference in the classification performance translates mainly to an increase in the sensitivity (reflecting the ability of the model to correctly identify a schizophrenic subject). Using RF for feature selection the results were similar to those obtained with LASSO. Specifically, the correlation method peaked at 73% (at 40% PT) while ISOMAP at 78.6% and 35% PT. The whole pattern of classification rates, using both strategies of feature selection, through all PT points used in this study is shown in <xref ref-type="fig" rid="neurosci-08-02-016-g004">Figure 4A,B</xref>. Using both feature selection methodologies, ISOMAP did not only produced the best classification rates but was also more robust with respect to the level of thresholding when compared to the standard methodology. When using LASSO 4A, ISOMAP was more robust than the correlation method for a wide range of levels of PT (eg. 30%–50%) with the accuracy rates being above 75%. When using RF for feature selection, ISOMAP provided again superior results with accuracy rates being higher than 70% in the PT range of 30% to 50%. <xref ref-type="fig" rid="neurosci-08-02-016-g005">Figure 5</xref> depicts the maximum classification obtained for each low dimensional embedding (2, 3, 4 and 5 dimensions retained) with respect to the value of <italic>k</italic> nearest neighbors for both of the feature selection strategies employed in this study (eg LASSO and RF). All four ISOMAP-based low-dimensional embeddings produced better classification rates than the standard cross-correlation, while the overall optimal was obtained when using three embedding dimensions for both feature selection methods.</p>
        <fig id="neurosci-08-02-016-g004" position="float">
          <label>Figure 4.</label>
          <caption>
            <title>Classification performance across all thresholding (PT) points for the two methods employed (cross-correlation and ISOMAP). A) When LASSO used for feature selection. B) when RF algorithm was used for feature selection. The PT points with the best classification rates are marked with an asterisk “*”. Using LASSO for feature selection, ISOMAP peaked at 79.3% with a 35% PT while cross-correlation peaked at 73.1% with 30% PT. Using the RF methodology would decrease the highest classification rates for both ISOMAP and correlation by almost 1% and 2% respectively.</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g004"/>
        </fig>
        <fig id="neurosci-08-02-016-g005" position="float">
          <label>Figure 5.</label>
          <caption>
            <title>Classification performance for different values of the <italic>k</italic>-nearest neighbours of ISOMAP when A) features selected by LASSO, B) features selected by RF. Accuracy rates are shown for all 4 different low-dimensional embeddings (<italic>p</italic> = 2,3,4,5)</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g005"/>
        </fig>
      </sec>
      <sec id="s3.3">
        <label>3.3</label>
        <title>Features selected using LASSO</title>
        <p>Despite the fact that the final feature vector for each subject was 420-dimensional (five local measures for each one of the 84 brain regions) with the total number of subjects being 145, the LASSO selected mainly, two features. The selected features which were chosen almost equally for both ISOMAP and correlation were the participation coefficient of the right thalamus and the strength of the right lingual gyrus. In <xref ref-type="fig" rid="neurosci-08-02-016-g006">Figure 6</xref>, are shown barplots of all the features chosen (at least once) for each method considering the optimal parameters (proportional thresolding (PT) point, embedding dimension and <italic>k</italic>-nearest neighbours) that produced the highest classification rates. Thus, the maximum number of selections for a feature would be 145 (total number of the independent experiments LOOCV with a sample of 145 subjects). When using correlation (6A), LASSO selected mainly two features (the participation of the right thalamus and the strength of the right lingual gyrus), but in some cases would end up with a more complex model, adding more features. The absolute coefficients of the LASSO model over 145 computational experiments were <inline-formula><mml:math id="in050"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.08</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> for the participation coefficient of right thalamus and <inline-formula><mml:math id="in051"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.18</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> for the strength of right lingual gyrus. When using ISOMAP (6A), LASSO selected almost exactly these 2 features (the participation coefficient of the right thalamus with average coefficient <inline-formula><mml:math id="in052"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.28</mml:mn><mml:mo>±</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:math></inline-formula> and the strength of the right lingual gyrus, <inline-formula><mml:math id="in053"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.11</mml:mn><mml:mo>±</mml:mo><mml:mn>0.04</mml:mn></mml:mrow></mml:math></inline-formula>) in every computational experiment. Therefore, using ISOMAP the participation coefficient of the right thalamus considered more important for LASSO than the strength of the right lingual gyrus. The exact opposite was observed when using the correlation method.</p>
        <fig id="neurosci-08-02-016-g006" position="float">
          <label>Figure 6.</label>
          <caption>
            <title>Features selected when utilizing LASSO methodology for A) The correlation method, B) ISOMAP. The total number of computational experiments were 145 in total. Thus, at maximum a feature can be selected n = 145 times. The x-axis shows the features that each method selected at least once. The letters Pc, Lc, Bc and St (before the colon “:”) denote the participation coefficient, local clustering, betweenness centrality and strength, respectively (neither of the methods chose any node's local efficiency). The capital letter after the colon refer to the lateral part of the anatomical region (Left and Right lateral parts) of the node and finally the remaining letters denote the region itself. The list of the abbreviations concerning the anatomical regions of the brain is the following: acc: accubens nucleus; cun: cuneus; lg: lingual gyrus; lof: lateral orbito-frontal cortex; pal: pallidum; pc: post central gyrus; pcc: posterior cingulate cortex; prc: pericalcarine; rmf: rostral middle frontal gyrus; tp: temporal pole; thal: thalamus.</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g006"/>
        </fig>
      </sec>
      <sec id="s3.4">
        <label>3.4</label>
        <title>Features selected using Random Forests</title>
        <p>In general, when using the Random Forest (RF) algorithm for feature selection, more features were selected comparing to LASSO. Barplots of selected features when using the RF algorithm are presented in <xref ref-type="fig" rid="neurosci-08-02-016-g007">Figure 7</xref>. Specifically, the features selected were 24 when using the cross-correlation method (7A) and 7 when using ISOMAP (7B). Most selected features (selected more than 100 times) for the correlation method were the strength of the right and left lingual gyrus (145 times <inline-formula><mml:math id="in054"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.6</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></inline-formula> and 144 times <inline-formula><mml:math id="in055"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>L</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.28</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></inline-formula> respectively), the right cuneus (144, <inline-formula><mml:math id="in056"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.14</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>), the right lateral occipital cortex (122, <inline-formula><mml:math id="in057"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.96</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) and local clustering of the left lingual gyrus (112, <inline-formula><mml:math id="in058"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>c</mml:mi><mml:mo>:</mml:mo><mml:mi>L</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.84</mml:mn><mml:mo>±</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>). When using ISOMAP, the most frequently selected features were the participation coefficient of the right thalamus (145 times, <inline-formula><mml:math id="in059"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.91</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></inline-formula>) and strength of the right and left lingual gyrus (145 times, <inline-formula><mml:math id="in060"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>R</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.59</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></inline-formula> and 144 times, <inline-formula><mml:math id="in061"><mml:mrow><mml:mi>M</mml:mi><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>L</mml:mi><mml:mi>l</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></inline-formula> respectively). ISOMAP provided more simple models for classification achieving better accuracy. It is remarkable that almost the same features were chosen when using ISOMAP regardless of the method used for feature selection. Thus, when using ISOMAP, the highest classification rates obtained were almost identical for both feature selection strategies (79.3% for LASSO and 78.6% for RF). Interestingly, when using the cross-correlation method 7B, the participation coefficient of right thalamus was chosen only few times (four times). The Random Forest algorithm could not identify the importance of these features; it added other features in the model, ultimately leading to lower classification rates. A characteristic ranking of features over 30 RF model runs can be seen in <xref ref-type="fig" rid="neurosci-08-02-016-g007">Figure 7C</xref>. The ranking was based on the Mean Decrease Gini (MDG) index 2.6 and shows a great amount of redundancy inherent to the dataset. Thus, only a small set of features were identified as important for the classification between healthy controls and patients with schizophrenia.</p>
      </sec>
      <sec id="s3.5">
        <label>3.5</label>
        <title>Most important features detected</title>
        <p>Finally, for the two most important features (the ones derived by ISOMAP and led to the highest accuracy rate ), we present the distributions between groups as boxplots (<xref ref-type="fig" rid="neurosci-08-02-016-g008">Figure 8A,B</xref>). Specifically, it is shown that controls exhibited a larger strength in the right lingual gyrus (Welch's t-test: p &lt; 0.05 Bonferroni corrected for multiple comparisons over 420 features) while patients exhibited larger participation coefficients of the right thalamus (Welch's t-test: p &lt; 0.05 Bonferroni corrected for multiple comparisons over 420 features). We also show a projection of each subject on a 2D feature space as derived by these 2 features (<xref ref-type="fig" rid="neurosci-08-02-016-g008">Figure 8C</xref>). Despite the fact that it is clear that these two features provide a good classification between groups, the cluster of patients is more tight than the cluster of healthy controls. This observation indicates that our model tends to provide a relatively high sensitivity rate and a more modest specificity rate.</p>
        <fig id="neurosci-08-02-016-g007" position="float">
          <label>Figure 7.</label>
          <caption>
            <title>Features selected when using Random Forests (RF) (see 2.6) using A) the standard correlation method, and B) ISOMAP. The total number of computational experiments were 145 in total. Thus, at maximum a feature can be selected n = 145 times. The x-axis shows the features that each method selected at least once. The letters Pc, Lef, Lc, Bc and St (before the colon “:”) denote the participation coefficient, local efficiency, local clustering, betweenness centrality and strength, respectively (neither of the methods chose any node's betweenness centrality). The capital letter after the colon refers to the lateral part of the anatomical region (Left and Right lateral parts) of the node and finally the remaining letters denote the region itself. The list of the abbreviations of the anatomical regions of the brain is the following: bst: banks of the superior temporal sulcus; cun: cuneus; fs: fusiform gyrus; lg: lingual gyrus; loc: lateral occipital cortex; pac: paracentral gyrus; prc: pericalcarine; ph: parahippocampal gyrus; rmf: rostral middle frontal gyrus; sm: supramarginal gyrus; sp: superior parietal; thal: thalamus. C) Characteristic ranking of feature importance over 30 RF model runs inside the inner loop of LOOCV (see 2.6). The ranking is based on the Mean Decrease Gini (MDG) for each feature. The red horizontal line marks the cut off value used for collecting the most important features.</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g007"/>
        </fig>
        <fig id="neurosci-08-02-016-g008" position="float">
          <label>Figure 8.</label>
          <caption>
            <title>Boxplots of A) the strength of the right lingual gyrus (St:Rlg), B) the participation coefficient of the right thalamus (Pc: Rthal). C) 2D Projection of subjects on the two most important features reported in this study (eg. the ones yielded the best classification accuracy rates).</title>
          </caption>
          <graphic xlink:href="neurosci-08-02-016-g008"/>
        </fig>
      </sec>
    </sec>
    <sec id="s4">
      <label>4</label>
      <title>Discussion</title>
      <p>Our analysis targeted at revealing classification biomarkers for schizophrenia patients at the ROI level based on resting state fMRI recordings using ISOMAP for the construction of embedding FCN. For our analysis, we used the publicly available dataset (COBRE) matching the brain anatomies to the Desikan-Killiany brain atlas. To assess the classification performance of the FCN constructed with ISOMAP, we compared it against the standard cross-correlation technique on a double cross-validation basis. When using the standard cross-correlation approach, we got similar results with the ones reported in previous studies <xref rid="b18" ref-type="bibr">[18]</xref>, <xref rid="b19" ref-type="bibr">[19]</xref>, <xref rid="b69" ref-type="bibr">[69]</xref>, <xref rid="b70" ref-type="bibr">[70]</xref>. For example, Moghimi et al. <xref rid="b19" ref-type="bibr">[19]</xref> used correlation to analyse a similarly large independent rsfMRI dataset of 170 subjects (88 healthy controls and 82 schizophrenia patients) using double cross-validation for both feature selection and model validation, getting classification rates as high as 73%. In the study of <xref rid="b19" ref-type="bibr">[19]</xref> that employed the correlation method for constructing FCN from rsfMRI matching to anatomical regions of the brain (as in our work), the highest classification rate obtained using a single feature. In particular, this feature was the matching index between the left thalamus and the left post central gyrus; the thalamus is part of the reward system while the post central gyrus is located in the primary somatosensory cortex, which is part of the somatosensory system. The best accuracy rate was 73% and in the same threshold point as the one we found here (preserving 30% of the strongest edges). Moreover, the sensitivity and specificity rates reported in <xref rid="b19" ref-type="bibr">[19]</xref> were close enough with the ones reported here when using the cross-correlation method and LASSO for feature selection. In particular, they reported a sensitivity rate of 77% (here, 77.4%) and specificity rate of 68% (here 68.9%) using SVM. This is remarkable, as we worked with an independent dataset and tested different set of features utilizing different feature selection methods. In a recent study <xref rid="b21" ref-type="bibr">[21]</xref>, the authors applied a classification framework proposed in <xref rid="b22" ref-type="bibr">[22]</xref> to two independent datasets evaluating the within and between site generalizability of the model. While the proposed methodology in <xref rid="b22" ref-type="bibr">[22]</xref> reported a satisfying 93% accuracy rate, Cai et al. <xref rid="b21" ref-type="bibr">[21]</xref> found a within-site accuracy rate of 73% and between-site accuracy of 70%. The approximately 20 % difference was also found in the study of <xref rid="b19" ref-type="bibr">[19]</xref> that is attributed to the differences of the results taken when using single and double cross validation. Single cross validation tended to over-optimistically evaluate the model's performance <xref rid="b19" ref-type="bibr">[19]</xref>, <xref rid="b20" ref-type="bibr">[20]</xref>. Using the standard cross-correlation and double cross validation we report practically the same classification accuracy with the one reported in <xref rid="b19" ref-type="bibr">[19]</xref> working on an independent dataset. In another study of Nieuwenhuis et al. <xref rid="b69" ref-type="bibr">[69]</xref>, two large independent datasets were analysed. Using T1 structural MR images and double cross-validation, they reported a 70.4% classification accuracy. Another more recent study <xref rid="b71" ref-type="bibr">[71]</xref> involving also two large independent fMRI datasets tested different strategies of Group Independent component analysis for the derivation of subject specific networks from group networks. They used these networks as features and the best reported average classification accuracy was 76.5% (evaluating the model with 100 repeats of cross validation). These classification rates are more likely to reflect the true classification power that contemporary models have <xref rid="b20" ref-type="bibr">[20]</xref>, <xref rid="b21" ref-type="bibr">[21]</xref>. <xref rid="b23" ref-type="bibr">[23]</xref>–<xref rid="b25" ref-type="bibr">[25]</xref>.</p>
      <p>Our feature selection analysis based on both the LASSO and Random Forest algorithms revealed that out of a 420-dimensional feature vector for each subject, only a handful of features were important. Thus, there was a great amount of redundancy inherent to the dataset, a fact that was also reported in <xref rid="b19" ref-type="bibr">[19]</xref> (where just one single feature produced the best accuracy rates), in <xref rid="b70" ref-type="bibr">[70]</xref> (where only seven discriminative independent components used as features) and in <xref rid="b18" ref-type="bibr">[18]</xref> (where ten features were found as important, namely the betweenness centrality scores of ten prominent hubs of the network).</p>
      <p>On the other hand, ISOMAP has been recently applied for the construction of FCN <xref rid="b16" ref-type="bibr">[16]</xref>, <xref rid="b27" ref-type="bibr">[27]</xref> with the nodes of the network matching the outcomes of a single-subject ICA analysis. <xref rid="b16" ref-type="bibr">[16]</xref>, working on the same dataset as here, reported a 65% classification accuracy using SVM, considering 13 global graph theoretic measures (no feature selection was performed, thus all these measures were given as features to the classifier). The model's performance was evaluated using a 10-fold cross validation scheme. Here, building on this work and on a recently published work (see <xref rid="b27" ref-type="bibr">[27]</xref>) which targeted at the global properties of the FCN using ICA, we made a more thorough assessment of ISOMAP, focusing on the analysis of the local properties of the embedded FCN, thus being able to identify classification biomarkers linked with the activity in specific brain regions. First, we used an anatomical atlas to associate the rsfMRI time series with specific brain regions in order to address the well known problem of the variability in the ICA decomposition when used for the construction of FCN <xref rid="b27" ref-type="bibr">[27]</xref>, <xref rid="b72" ref-type="bibr">[72]</xref>. The experiment comprised of only a single session per subject with a relatively small duration (6 minutes), so we wouldn't expect a robust decomposition for all subjects (see also the discussion in <xref rid="b73" ref-type="bibr">[73]</xref>). Second, for our analysis we used key local graph theoretic-measures (strength of node, local clustering, local efficiency, participation coefficient and betweenness centrality) and performed feature selection using LASSO and Random Forests. Third, we considered a wide range of values for tuning the parameter the number <italic>k</italic> of nearest neighbours in ISOMAP and justified the choice of the low-dimensional embedding dimension based on the gap in the eigenspectrum and the residual variance. Fourth, we took an “extra” advanced pre-processing step by using ICA AROMA <xref rid="b37" ref-type="bibr">[37]</xref> to detect and factor out noise-related (motion artifacts and other structured noise components like cardiac pulsation confounds) independent components as it is highly recommended (see the discussion in <xref rid="b16" ref-type="bibr">[16]</xref>). Fifth, we compared ISOMAP to the current standard cross-correlation (by correlating the time series and performed thresholding to construct FCN), based at the local theoretical graph measures of the derived FCN.</p>
      <p>Our analysis showed that ISOMAP outperformed the standard cross-correlation approach, thus increasing the classification performance by 6.2%. This difference was translated mainly to an increase in the sensitivity rate (the ability of a classification model to correctly identify a schizophrenic subject). The sensitivity rate for ISOMAP was 85.9% compared to a 77.4% for the conventional method. Furthermore, the performance of ISOMAP was more robust producing higher classification rates than the conventional methodology across different threshold points. As ISOMAP needs to be tuned (<italic>k</italic>-nearest neighbours, embedding dimension <italic>p</italic>), we showed that for a considerable range of the values of <italic>k</italic>, ISOMAP scored higher classification rates (above 75%). All low-dimensional embeddings produced higher classification rates than the competent standard approach. Finally, when using ISOMAP, both of the feature selection methods had a tendency to choose a more simple model (with mainly two or three features, appearing in almost all 145 computational experiments). This indicates that ISOMAP captured most of the useful information in the dataset (by reducing it to its intrinsic dimension), while discarded information that could be attributed to various sources of noise and confounds (see also the discussion in <xref rid="b46" ref-type="bibr">[46]</xref>). At this point, we should note that we decided to use a simple “baseline” classifier (such as the LSVM) as the aim of this study was the investigation of the performance of ISOMAP compared to the standard cross-correlation and not the influence of various machine learning approaches. Consequently, our analysis was focused on how the ISOMAP-based derived embedded FCN affect the feature selection procedure as implemented here by Lasso and Random Forests. Finally, we used a double cross-validation scheme to get an unbiased estimate of the expected accuracy of the model (i.e. not to get a specific classification model <xref rid="b23" ref-type="bibr">[23]</xref>) optimizing the feature selection procedure. A comparative analysis of different machine learning algorithms is out of the scope of the current study (such a comparative analysis between various manifold and machine learning approaches, yet based on global-graph theoretical properties of ICA-based constructed FCN can be found in <xref rid="b27" ref-type="bibr">[27]</xref>).</p>
    </sec>
    <sec id="s5">
      <label>5</label>
      <title>Conclusions</title>
      <p>Using ISOMAP for the construction of brain atlas-based embedded FCN and utilizing different feature selection methods, we found that the most informative features that led to the highest classification rates were the participation coefficient of the right thalamus and the strength of the right lingual gyrus. On the one hand, the thalamus is thought to play a prominent role in the coordination of information as it flows from functional and structural pathways which have been consistently linked to the schizophrenia <xref rid="b74" ref-type="bibr">[74]</xref>, <xref rid="b75" ref-type="bibr">[75]</xref>. Abnormalities in the function of the thalamus have been associated with cognitive deficits and anomalies in sensory experience (e.g. auditory/visual hallucinations) <xref rid="b76" ref-type="bibr">[76]</xref>. On the other hand, The lingual gyrus is a main component of the visual cortex that contributes in visual processing/memory <xref rid="b77" ref-type="bibr">[77]</xref> and the identification and recognition of words <xref rid="b78" ref-type="bibr">[78]</xref>. Many studies have reported abnormalities in the lingual gyrus associated with schizophrenia <xref rid="b79" ref-type="bibr">[79]</xref>, <xref rid="b80" ref-type="bibr">[80]</xref>. Interestingly, recent classification studies involving two independent datasets refer to both of these brain regions as key regions in both characterization of the disease and discrimination between healthy controls and patients with schizophrenia <xref rid="b21" ref-type="bibr">[21]</xref>, <xref rid="b81" ref-type="bibr">[81]</xref>. Other studies have listed these regions as discriminatory in schizophrenia as well <xref rid="b15" ref-type="bibr">[15]</xref>, <xref rid="b19" ref-type="bibr">[19]</xref>. Other important regions found here, include the cuneus and latteral occipital cortex, both parts of the occipital lobe which has been known to be affected as a consequence of the disease <xref rid="b82" ref-type="bibr">[82]</xref>. Moreover, our study provides evidence that the use of ISOMAP for the construction of embedded FCN contributes to a more accurate and robust classification plus a finer detection of biomarkers at the ROI level that are more likely to be generalized on other datasets.</p>
    </sec>
  </body>
  <back>
    <fn-group>
      <fn fn-type="COI-statement">
        <p><bold>Conflict of interest:</bold> The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="b1">
        <label>1</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Bhugra</surname><given-names>D</given-names></name></person-group>
<article-title>The global prevalence of schizophrenia</article-title>
<source>PLoS Med</source>
<year>2005</year>
<volume>2</volume>
<fpage>e151</fpage>
<pub-id pub-id-type="pmid">15916460</pub-id></element-citation>
      </ref>
      <ref id="b2">
        <label>2</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group>
<article-title>The disconnection hypothesis</article-title>
<source>Schizophr Res</source>
<year>1998</year>
<volume>30</volume>
<fpage>115</fpage>
<lpage>125</lpage>
<pub-id pub-id-type="pmid">9549774</pub-id></element-citation>
      </ref>
      <ref id="b3">
        <label>3</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Liang</surname><given-names>M</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><etal/></person-group>
<article-title>Disrupted small-world networks in schizophrenia</article-title>
<source>Brain</source>
<year>2008</year>
<volume>131</volume>
<fpage>945</fpage>
<lpage>961</lpage>
<pub-id pub-id-type="pmid">18299296</pub-id></element-citation>
      </ref>
      <ref id="b4">
        <label>4</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Lynall</surname><given-names>ME</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Kerwin</surname><given-names>R</given-names></name><etal/></person-group>
<article-title>Functional connectivity and brain networks in schizophrenia</article-title>
<source>J Neurosci</source>
<year>2010</year>
<volume>30</volume>
<fpage>9477</fpage>
<lpage>9487</lpage>
<pub-id pub-id-type="pmid">20631176</pub-id></element-citation>
      </ref>
      <ref id="b5">
        <label>5</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Griffa</surname><given-names>A</given-names></name><name><surname>Baumann</surname><given-names>PS</given-names></name><name><surname>Ferrari</surname><given-names>C</given-names></name><etal/></person-group>
<article-title>Characterizing the connectome in schizophrenia with diffusion spectrum imaging</article-title>
<source>Hum Brain Mapp</source>
<year>2015</year>
<volume>36</volume>
<fpage>354</fpage>
<lpage>366</lpage>
<pub-id pub-id-type="pmid">25213204</pub-id></element-citation>
      </ref>
      <ref id="b6">
        <label>6</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Biswal</surname><given-names>BB</given-names></name></person-group>
<article-title>Resting state fMRI: a personal history</article-title>
<source>Neuroimage</source>
<year>2012</year>
<volume>62</volume>
<fpage>938</fpage>
<lpage>944</lpage>
<pub-id pub-id-type="pmid">22326802</pub-id></element-citation>
      </ref>
      <ref id="b7">
        <label>7</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Dong</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Chang</surname><given-names>X</given-names></name><etal/></person-group>
<article-title>Dysfunction of large-scale brain networks in schizophrenia: a meta-analysis of resting-state functional connectivity</article-title>
<source>Schizophr Bull</source>
<year>2018</year>
<volume>44</volume>
<fpage>168</fpage>
<lpage>181</lpage>
<pub-id pub-id-type="pmid">28338943</pub-id></element-citation>
      </ref>
      <ref id="b8">
        <label>8</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name><name><surname>Andersson</surname><given-names>J</given-names></name><etal/></person-group>
<article-title>Resting-state fMRI in the human connectome project</article-title>
<source>Neuroimage</source>
<year>2013</year>
<volume>80</volume>
<fpage>144</fpage>
<lpage>168</lpage>
<pub-id pub-id-type="pmid">23702415</pub-id></element-citation>
      </ref>
      <ref id="b9">
        <label>9</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Moussa</surname><given-names>MN</given-names></name><name><surname>Steen</surname><given-names>MR</given-names></name><name><surname>Laurienti</surname><given-names>PJ</given-names></name><etal/></person-group>
<article-title>Consistency of Network Modules in Resting-State fMRI Connectome Data</article-title>
<source>PloS One</source>
<year>2012</year>
<volume>7</volume>
<fpage>e44428</fpage>
<pub-id pub-id-type="pmid">22952978</pub-id></element-citation>
      </ref>
      <ref id="b10">
        <label>10</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Fox</surname><given-names>PT</given-names></name><name><surname>Miller</surname><given-names>KL</given-names></name><etal/></person-group>
<article-title>Correspondence of the brain's functional architecture during activation and rest</article-title>
<source>Proce Natl Acad Sci</source>
<year>2009</year>
<volume>106</volume>
<fpage>13040</fpage>
<lpage>13045</lpage>
</element-citation>
      </ref>
      <ref id="b11">
        <label>11</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Damoiseaux</surname><given-names>JS</given-names></name><name><surname>Rombouts</surname><given-names>SARB</given-names></name><name><surname>Barkhof</surname><given-names>F</given-names></name><etal/></person-group>
<article-title>Consistent resting-state networks across healthy subjects</article-title>
<source>Proce Natl Acad Sci</source>
<year>2006</year>
<volume>103</volume>
<fpage>13848</fpage>
<lpage>13853</lpage>
</element-citation>
      </ref>
      <ref id="b12">
        <label>12</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Argyelan</surname><given-names>M</given-names></name><name><surname>Ikuta</surname><given-names>T</given-names></name><name><surname>DeRosse</surname><given-names>P</given-names></name><etal/></person-group>
<article-title>Resting-state fMRI connectivity impairment in schizophrenia and bipolar disorder</article-title>
<source>Schizophr Bull</source>
<year>2014</year>
<volume>40</volume>
<fpage>100</fpage>
<lpage>110</lpage>
<pub-id pub-id-type="pmid">23851068</pub-id></element-citation>
      </ref>
      <ref id="b13">
        <label>13</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Arribas</surname><given-names>JI</given-names></name><name><surname>Calhoun</surname><given-names>VD</given-names></name><name><surname>Adali</surname><given-names>T</given-names></name></person-group>
<article-title>Automatic Bayesian classification of healthy controls, bipolar disorder, and schizophrenia using intrinsic connectivity maps from FMRI data</article-title>
<source>IEEE Transa Biomed Eng</source>
<year>2010</year>
<volume>57</volume>
<fpage>2850</fpage>
<lpage>2860</lpage>
</element-citation>
      </ref>
      <ref id="b14">
        <label>14</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Matsubara</surname><given-names>T</given-names></name><name><surname>Tashiro</surname><given-names>T</given-names></name><name><surname>Uehara</surname><given-names>K</given-names></name></person-group>
<article-title>Deep neural generative model of functional MRI images for psychiatric disorder diagnosis</article-title>
<source>IEEE Transa Biomed Eng</source>
<year>2019</year>
<volume>66</volume>
<fpage>2768</fpage>
<lpage>2779</lpage>
</element-citation>
      </ref>
      <ref id="b15">
        <label>15</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Xiang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Tan</surname><given-names>G</given-names></name><etal/></person-group>
<article-title>Schizophrenia identification using multi-view graph measures of functional brain networks</article-title>
<source>Front Bioeng Biotechnol</source>
<year>2020</year>
<volume>7</volume>
<fpage>479</fpage>
<pub-id pub-id-type="pmid">32010682</pub-id></element-citation>
      </ref>
      <ref id="b16">
        <label>16</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Anderson</surname><given-names>A</given-names></name><name><surname>Cohen</surname><given-names>MS</given-names></name></person-group>
<article-title>Decreased small-world functional network connectivity and clustering across resting state networks in schizophrenia: an fMRI classification tutorial</article-title>
<source>Front Hum Neurosci</source>
<year>2013</year>
<volume>7</volume>
<fpage>520</fpage>
<pub-id pub-id-type="pmid">24032010</pub-id></element-citation>
      </ref>
      <ref id="b17">
        <label>17</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Arbabshirani</surname><given-names>MR</given-names></name><name><surname>Kiehl</surname><given-names>KA</given-names></name><name><surname>Pearlson</surname><given-names>DG</given-names></name></person-group>
<article-title>Classification of schizophrenia patients based on resting-state functional network connectivity</article-title>
<source>Front Neurosci</source>
<year>2013</year>
<volume>7</volume>
<fpage>133</fpage>
<pub-id pub-id-type="pmid">23966903</pub-id></element-citation>
      </ref>
      <ref id="b18">
        <label>18</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Cheng</surname><given-names>H</given-names></name><name><surname>Newman</surname><given-names>S</given-names></name><name><surname>Goñi</surname><given-names>J</given-names></name><etal/></person-group>
<article-title>Classification of schizophrenia patients based on restingstate functional network connectivity</article-title>
<source>Schizophr Res</source>
<year>2015</year>
<volume>168</volume>
<fpage>345</fpage>
<lpage>352</lpage>
<pub-id pub-id-type="pmid">26299706</pub-id></element-citation>
      </ref>
      <ref id="b19">
        <label>19</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Moghimi</surname><given-names>P</given-names></name><name><surname>Lim</surname><given-names>KO</given-names></name><name><surname>Netoff</surname><given-names>TI</given-names></name></person-group>
<article-title>Data Driven Classification Using fMRI Network Measures: Application to Schizophrenia</article-title>
<source>Front Neuroinform</source>
<year>2018</year>
<volume>12</volume>
<fpage>71</fpage>
<pub-id pub-id-type="pmid">30425631</pub-id></element-citation>
      </ref>
      <ref id="b20">
        <label>20</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Sundermann</surname><given-names>B</given-names></name><name><surname>Herr</surname><given-names>D</given-names></name><name><surname>Schwindt</surname><given-names>W</given-names></name><etal/></person-group>
<article-title>Multivariate classification of blood oxygen level–dependent fMRI data with diagnostic intention: a clinical perspective</article-title>
<source>Am J Neuroradiol</source>
<year>2014</year>
<volume>35</volume>
<fpage>848</fpage>
<lpage>855</lpage>
<pub-id pub-id-type="pmid">24029388</pub-id></element-citation>
      </ref>
      <ref id="b21">
        <label>21</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Cai</surname><given-names>XL</given-names></name><name><surname>Xie</surname><given-names>DJ</given-names></name><name><surname>Madsen</surname><given-names>KH</given-names></name><etal/></person-group>
<article-title>Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data</article-title>
<source>Hum Brain Mapp</source>
<year>2020</year>
<volume>41</volume>
<fpage>172</fpage>
<lpage>184</lpage>
<pub-id pub-id-type="pmid">31571320</pub-id></element-citation>
      </ref>
      <ref id="b22">
        <label>22</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Du</surname><given-names>W</given-names></name><name><surname>Calhoun</surname><given-names>VD</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><etal/></person-group>
<article-title>High classification accuracy for schizophrenia with rest and task fMRI data</article-title>
<source>Front Hum Neurosci</source>
<year>2012</year>
<volume>6</volume>
<fpage>145</fpage>
<pub-id pub-id-type="pmid">22675292</pub-id></element-citation>
      </ref>
      <ref id="b23">
        <label>23</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pereira</surname><given-names>F</given-names></name><name><surname>Mitchell</surname><given-names>T</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group>
<article-title>Machine learning classifiers and fMRI: a tutorial overview</article-title>
<source>Neuroimage</source>
<year>2009</year>
<volume>45</volume>
<fpage>S199</fpage>
<lpage>S209</lpage>
<pub-id pub-id-type="pmid">19070668</pub-id></element-citation>
      </ref>
      <ref id="b24">
        <label>24</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Krstajic</surname><given-names>D</given-names></name><name><surname>Buturovic</surname><given-names>LJ</given-names></name><name><surname>Leahy</surname><given-names>DE</given-names></name><etal/></person-group>
<article-title>Cross-validation pitfalls when selecting and assessing regression and classification models</article-title>
<source>J Cheminform</source>
<year>2014</year>
<volume>6</volume>
<fpage>1</fpage>
<lpage>15</lpage>
<pub-id pub-id-type="pmid">24397863</pub-id></element-citation>
      </ref>
      <ref id="b25">
        <label>25</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pettersson-Yeo</surname><given-names>W</given-names></name><name><surname>Allen</surname><given-names>P</given-names></name><name><surname>Benetti</surname><given-names>S</given-names></name><etal/></person-group>
<article-title>Dysconnectivity in schizophrenia: where are we now?</article-title>
<source>Neurosci Biobehav Rev</source>
<year>2011</year>
<volume>35</volume>
<fpage>1110</fpage>
<lpage>1124</lpage>
<pub-id pub-id-type="pmid">21115039</pub-id></element-citation>
      </ref>
      <ref id="b26">
        <label>26</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Fekete</surname><given-names>T</given-names></name><name><surname>Wilf</surname><given-names>M</given-names></name><name><surname>Rubin</surname><given-names>D</given-names></name><etal/></person-group>
<article-title>Combining classification with fMRI-derived complex network measures for potential neurodiagnostics</article-title>
<source>PloS One</source>
<year>2013</year>
<volume>8</volume>
<fpage>e62867</fpage>
<pub-id pub-id-type="pmid">23671641</pub-id></element-citation>
      </ref>
      <ref id="b27">
        <label>27</label>
        <element-citation publication-type="other">
<person-group person-group-type="author"><name><surname>Gallos</surname><given-names>IK</given-names></name><name><surname>Galaris</surname><given-names>E</given-names></name><name><surname>Siettos</surname><given-names>CI</given-names></name></person-group>
<article-title>Construction of embedded fMRI resting-state functional connectivity networks using manifold learning</article-title>
<source>Cogn Neurodyn</source>
<year>2020</year>
</element-citation>
      </ref>
      <ref id="b28">
        <label>28</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Lombardi</surname><given-names>A</given-names></name><name><surname>Guaragnella</surname><given-names>C</given-names></name><name><surname>Amoroso</surname><given-names>N</given-names></name><etal/></person-group>
<article-title>Modelling cognitive loads in schizophrenia by means of new functional dynamic indexes</article-title>
<article-title/>
<source>NeuroImage</source>
<year>2019</year>
<volume>195</volume>
<fpage>150</fpage>
<lpage>164</lpage>
</element-citation>
      </ref>
      <ref id="b29">
        <label>29</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hyv¨arinen</surname><given-names>A</given-names></name><name><surname>Oja</surname><given-names>E</given-names></name></person-group>
<article-title>Independent component analysis: algorithms and applications</article-title>
<source>Neural Netw</source>
<year>2000</year>
<volume>13</volume>
<fpage>411</fpage>
<lpage>430</lpage>
<pub-id pub-id-type="pmid">10946390</pub-id></element-citation>
      </ref>
      <ref id="b30">
        <label>30</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Haak</surname><given-names>KV</given-names></name><name><surname>Marquand</surname><given-names>AF</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name></person-group>
<article-title>Connectopic mapping with resting-state fMRI</article-title>
<source>Neuroimage</source>
<year>2018</year>
<volume>170</volume>
<fpage>83</fpage>
<lpage>94</lpage>
<pub-id pub-id-type="pmid">28666880</pub-id></element-citation>
      </ref>
      <ref id="b31">
        <label>31</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Desikan</surname><given-names>RS</given-names></name><name><surname>Ségonne</surname><given-names>F</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><etal/></person-group>
<article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>
<source>Neuroimage</source>
<year>2006</year>
<volume>31</volume>
<fpage>968</fpage>
<lpage>980</lpage>
<pub-id pub-id-type="pmid">16530430</pub-id></element-citation>
      </ref>
      <ref id="b32">
        <label>32</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kabbara</surname><given-names>A</given-names></name><name><surname>Falou</surname><given-names>WEL</given-names></name><name><surname>Khalil</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>The dynamic functional core network of the human brain at rest</article-title>
<source>Sci Rep</source>
<year>2017</year>
<volume>7</volume>
<fpage>1</fpage>
<lpage>16</lpage>
<pub-id pub-id-type="pmid">28127051</pub-id></element-citation>
      </ref>
      <ref id="b33">
        <label>33</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>De Silva</surname><given-names>V</given-names></name><name><surname>Langford</surname><given-names>JC</given-names></name></person-group>
<article-title>A global geometric framework for nonlinear dimensionality reduction</article-title>
<source>Science</source>
<year>2000</year>
<volume>290</volume>
<fpage>2319</fpage>
<lpage>2323</lpage>
<pub-id pub-id-type="pmid">11125149</pub-id></element-citation>
      </ref>
      <ref id="b34">
        <label>34</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Pan</surname><given-names>Y</given-names></name><etal/></person-group>
<article-title>Complex brain network analysis and its applications to brain disorders: a survey</article-title>
<source>Complexity</source>
<year>2017</year>
<volume>2017</volume>
<fpage>1</fpage>
<lpage>27</lpage>
</element-citation>
      </ref>
      <ref id="b35">
        <label>35</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>
<source>Neuroimage</source>
<year>2002</year>
<volume>17</volume>
<fpage>825</fpage>
<lpage>841</lpage>
<pub-id pub-id-type="pmid">12377157</pub-id></element-citation>
      </ref>
      <ref id="b36">
        <label>36</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Smith</surname><given-names>SM</given-names></name></person-group>
<article-title>Fast robust automated brain extraction</article-title>
<source>Hum Brain Mapp</source>
<year>2002</year>
<volume>17</volume>
<fpage>143</fpage>
<lpage>155</lpage>
<pub-id pub-id-type="pmid">12391568</pub-id></element-citation>
      </ref>
      <ref id="b37">
        <label>37</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pruim</surname><given-names>RHR</given-names></name><name><surname>Mennes</surname><given-names>M</given-names></name><name><surname>van Rooij</surname><given-names>D</given-names></name><etal/></person-group>
<article-title>ICA-AROMA: A robust ICA-based strategy for removing motion artifacts from fMRI data</article-title>
<source>Neuroimage</source>
<year>2015</year>
<volume>112</volume>
<fpage>267</fpage>
<lpage>277</lpage>
<pub-id pub-id-type="pmid">25770991</pub-id></element-citation>
      </ref>
      <ref id="b38">
        <label>38</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kalcher</surname><given-names>K</given-names></name><name><surname>Boubela</surname><given-names>RN</given-names></name><name><surname>Huf</surname><given-names>W</given-names></name><etal/></person-group>
<article-title>The spectral diversity of resting-state fluctuations in the human brain</article-title>
<source>PloS One</source>
<year>2014</year>
<volume>9</volume>
<fpage>e93375</fpage>
<pub-id pub-id-type="pmid">24728207</pub-id></element-citation>
      </ref>
      <ref id="b39">
        <label>39</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name></person-group>
<article-title>FreeSurfer</article-title>
<source>Neuroimage</source>
<year>2012</year>
<volume>62</volume>
<fpage>774</fpage>
<lpage>781</lpage>
<pub-id pub-id-type="pmid">22248573</pub-id></element-citation>
      </ref>
      <ref id="b40">
        <label>40</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hyde</surname><given-names>JS</given-names></name><name><surname>Jesmanowicz</surname><given-names>A</given-names></name></person-group>
<article-title>Cross-correlation: an fMRI signal-processing strategy</article-title>
<source>Neuroimage</source>
<year>2012</year>
<volume>62</volume>
<fpage>848</fpage>
<lpage>851</lpage>
<pub-id pub-id-type="pmid">22051223</pub-id></element-citation>
      </ref>
      <ref id="b41">
        <label>41</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>MP</given-names></name><name><surname>de Lange</surname><given-names>SC</given-names></name><name><surname>Zalesky</surname><given-names>A</given-names></name><etal/></person-group>
<article-title>Proportional thresholding in restingstate fMRI functional connectivity networks and consequences for patient-control connectome studies: Issues and recommendations</article-title>
<source>Neuroimage</source>
<year>2017</year>
<volume>152</volume>
<fpage>437</fpage>
<lpage>449</lpage>
<pub-id pub-id-type="pmid">28167349</pub-id></element-citation>
      </ref>
      <ref id="b42">
        <label>42</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Dimitriadis</surname><given-names>SI</given-names></name><name><surname>Antonakakis</surname><given-names>M</given-names></name><name><surname>Simos</surname><given-names>P</given-names></name><etal/></person-group>
<article-title>Data-driven topological filtering based on orthogonal minimal spanning trees: application to multigroup magnetoencephalography restingstate connectivity</article-title>
<source>Brain Connect</source>
<year>2017</year>
<volume>7</volume>
<fpage>661</fpage>
<lpage>670</lpage>
<pub-id pub-id-type="pmid">28891322</pub-id></element-citation>
      </ref>
      <ref id="b43">
        <label>43</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Dimitriadis</surname><given-names>SI</given-names></name><name><surname>Salis</surname><given-names>C</given-names></name><name><surname>Tarnanas</surname><given-names>I</given-names></name><etal/></person-group>
<article-title>Topological filtering of dynamic functional brain networks unfolds informative chronnectomics: a novel data-driven thresholding scheme based on orthogonal minimal spanning trees (OMSTs)</article-title>
<source>Front Neuroinform</source>
<year>2017</year>
<volume>11</volume>
<fpage>28</fpage>
<pub-id pub-id-type="pmid">28491032</pub-id></element-citation>
      </ref>
      <ref id="b44">
        <label>44</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Dijkstra</surname><given-names>EW</given-names></name></person-group>
<article-title>A note on two problems in connexion with graphs</article-title>
<source>Front Neuroinform</source>
<year>1959</year>
<volume>1</volume>
<fpage>269</fpage>
<lpage>271</lpage>
</element-citation>
      </ref>
      <ref id="b45">
        <label>45</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kruskal</surname><given-names>JB</given-names></name></person-group>
<article-title>Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</article-title>
<source>Psychometrika</source>
<year>1964</year>
<volume>29</volume>
<fpage>1</fpage>
<lpage>27</lpage>
</element-citation>
      </ref>
      <ref id="b46">
        <label>46</label>
        <element-citation publication-type="book">
<person-group person-group-type="author"><name><surname>Saul</surname><given-names>LK</given-names></name><name><surname>Weinberger</surname><given-names>KQ</given-names></name><name><surname>Ham</surname><given-names>JH</given-names></name><etal/></person-group>
<article-title>Spectral methods for dimensionality reduction</article-title>
<source>Semisupervised Learning</source>
<publisher-loc>Cambridge, MA, USA</publisher-loc>
<publisher-name>The MIT Press</publisher-name>
<year>2006</year>
<fpage>292</fpage>
<lpage>308</lpage>
</element-citation>
      </ref>
      <ref id="b47">
        <label>47</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Oksanen</surname><given-names>J</given-names></name><name><surname>Kindt</surname><given-names>R</given-names></name><name><surname>Legendre</surname><given-names>P</given-names></name><etal/></person-group>
<article-title>The vegan package</article-title>
<source>Community Ecol Package</source>
<year>2007</year>
<volume>10</volume>
<fpage>631</fpage>
<lpage>637</lpage>
</element-citation>
      </ref>
      <ref id="b48">
        <label>48</label>
        <element-citation publication-type="other">
<collab>Team, R Core</collab>
<source>R: A language and environment for statistical computing</source>
<year>2013</year>
</element-citation>
      </ref>
      <ref id="b49">
        <label>49</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group>
<article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>
<source>Neuroimage</source>
<year>2010</year>
<volume>52</volume>
<fpage>1059</fpage>
<lpage>1069</lpage>
<pub-id pub-id-type="pmid">19819337</pub-id></element-citation>
      </ref>
      <ref id="b50">
        <label>50</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Blondel</surname><given-names>VD</given-names></name><name><surname>Guillaume</surname><given-names>JL</given-names></name><name><surname>Lambiotte</surname><given-names>R</given-names></name><etal/></person-group>
<article-title>Fast unfolding of communities in large networks</article-title>
<source>J Stat Mech Theory Exp</source>
<year>2008</year>
<volume>2008</volume>
<fpage>P10008</fpage>
</element-citation>
      </ref>
      <ref id="b51">
        <label>51</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Barrat</surname><given-names>A</given-names></name><name><surname>Barthélemy</surname><given-names>M</given-names></name><name><surname>Pastor-Satorras</surname><given-names>R</given-names></name><etal/></person-group>
<article-title>The architecture of complex weighted networks</article-title>
<source>Proc Natl Acad Sci USA</source>
<year>2004</year>
<volume>101</volume>
<fpage>3747</fpage>
<lpage>3752</lpage>
<pub-id pub-id-type="pmid">15007165</pub-id></element-citation>
      </ref>
      <ref id="b52">
        <label>52</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Lessov-Schlaggar</surname><given-names>CN</given-names></name><etal/></person-group>
<article-title>Evidence for hubs in human functional brain networks</article-title>
<source>Neuron</source>
<year>2013</year>
<volume>79</volume>
<fpage>798</fpage>
<lpage>813</lpage>
<pub-id pub-id-type="pmid">23972601</pub-id></element-citation>
      </ref>
      <ref id="b53">
        <label>53</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Csardi</surname><given-names>G</given-names></name><name><surname>Nepusz</surname><given-names>T</given-names></name></person-group>
<article-title>The igraph software package for complex network research</article-title>
<source>InterJournal Complex Syst</source>
<year>2006</year>
<volume>1695</volume>
<fpage>1</fpage>
<lpage>9</lpage>
</element-citation>
      </ref>
      <ref id="b54">
        <label>54</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Chan</surname><given-names>MK</given-names></name><name><surname>Krebs</surname><given-names>MO</given-names></name><name><surname>Cox</surname><given-names>D</given-names></name><etal/></person-group>
<article-title>Development of a blood-based molecular biomarker test for identification of schizophrenia before disease onset</article-title>
<source>Transl Psychiatry</source>
<year>2015</year>
<volume>5</volume>
<fpage>e601</fpage>
<pub-id pub-id-type="pmid">26171982</pub-id></element-citation>
      </ref>
      <ref id="b55">
        <label>55</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Usai</surname><given-names>MG</given-names></name><name><surname>Goddard</surname><given-names>ME</given-names></name><name><surname>Hayes</surname><given-names>BJ</given-names></name></person-group>
<article-title>LASSO with cross-validation for genomic selection</article-title>
<source>Genet Res</source>
<year>2009</year>
<volume>91</volume>
<fpage>427</fpage>
<lpage>436</lpage>
</element-citation>
      </ref>
      <ref id="b56">
        <label>56</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group>
<article-title>Regularization paths for generalized linear models via coordinate descent</article-title>
<source>J Stat Softw</source>
<year>2010</year>
<volume>33</volume>
<fpage>1</fpage>
<lpage>22</lpage>
<pub-id pub-id-type="pmid">20808728</pub-id></element-citation>
      </ref>
      <ref id="b57">
        <label>57</label>
        <element-citation publication-type="book">
<person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name></person-group>
<source>The elements of statistical learning: data mining, inference, and prediction</source>
<edition>2nd Eds</edition>
<publisher-loc>New York City, USA</publisher-loc>
<publisher-name>Springer</publisher-name>
<year>2009</year>
</element-citation>
      </ref>
      <ref id="b58">
        <label>58</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L</given-names></name></person-group>
<article-title>Random forests</article-title>
<source>Mach Learn</source>
<year>2001</year>
<volume>45</volume>
<fpage>5</fpage>
<lpage>32</lpage>
</element-citation>
      </ref>
      <ref id="b59">
        <label>59</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Loh</surname><given-names>WY</given-names></name></person-group>
<article-title>Classification and regression trees</article-title>
<source>WIRES Data Min Knowl</source>
<year>2011</year>
<volume>1</volume>
<fpage>14</fpage>
<lpage>23</lpage>
</element-citation>
      </ref>
      <ref id="b60">
        <label>60</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Menze</surname><given-names>BH</given-names></name><name><surname>Kelm</surname><given-names>BM</given-names></name><name><surname>Masuch</surname><given-names>R</given-names></name><etal/></person-group>
<article-title>A comparison of random forest and its Gini importance with standard chemometric methods for the feature selection and classification of spectral data</article-title>
<source>BMC Bioinformatics</source>
<year>2009</year>
<volume>10</volume>
<fpage>213</fpage>
<pub-id pub-id-type="pmid">19591666</pub-id></element-citation>
      </ref>
      <ref id="b61">
        <label>61</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Zhu</surname><given-names>X</given-names></name><name><surname>Du</surname><given-names>X</given-names></name><name><surname>Kerich</surname><given-names>M</given-names></name><etal/></person-group>
<article-title>Random forest based classification of alcohol dependence patients and healthy controls using resting state MRI</article-title>
<source>Neurosci Lett</source>
<year>2018</year>
<volume>676</volume>
<fpage>27</fpage>
<lpage>33</lpage>
<pub-id pub-id-type="pmid">29626649</pub-id></element-citation>
      </ref>
      <ref id="b62">
        <label>62</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kesler</surname><given-names>SR</given-names></name><name><surname>Rao</surname><given-names>A</given-names></name><name><surname>Blayney</surname><given-names>DW</given-names></name><etal/></person-group>
<article-title>Predicting long-term cognitive outcome following breast cancer with pre-treatment resting state fMRI and random forest machine learning</article-title>
<source>Front Hum Neurosci</source>
<year>2017</year>
<volume>11</volume>
<fpage>555</fpage>
<pub-id pub-id-type="pmid">29187817</pub-id></element-citation>
      </ref>
      <ref id="b63">
        <label>63</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Ceriani</surname><given-names>L</given-names></name><name><surname>Verme</surname><given-names>P</given-names></name></person-group>
<article-title>The origins of the Gini index: extracts from Variabilità e Mutabilità (1912) by Corrado Gini</article-title>
<source>J Econ Inequal</source>
<year>2012</year>
<volume>10</volume>
<fpage>421</fpage>
<lpage>443</lpage>
</element-citation>
      </ref>
      <ref id="b64">
        <label>64</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Strobl</surname><given-names>C</given-names></name><name><surname>Boulesteix</surname><given-names>AL</given-names></name><name><surname>Augustin</surname><given-names>T</given-names></name></person-group>
<article-title>Unbiased split selection for classification trees based on the Gini index</article-title>
<source>Comput Stat Data Anal</source>
<year>2007</year>
<volume>52</volume>
<fpage>483</fpage>
<lpage>501</lpage>
</element-citation>
      </ref>
      <ref id="b65">
        <label>65</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Louppe</surname><given-names>G</given-names></name><name><surname>Wehenkel</surname><given-names>L</given-names></name><name><surname>Sutera</surname><given-names>A</given-names></name><etal/></person-group>
<article-title>Understanding variable importances in forests of randomized trees</article-title>
<source>Adv Neural Inf Process Syst</source>
<year>2013</year>
<volume>26</volume>
<fpage>431</fpage>
<lpage>439</lpage>
</element-citation>
      </ref>
      <ref id="b66">
        <label>66</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Behnamian</surname><given-names>A</given-names></name><name><surname>Millard</surname><given-names>K</given-names></name><name><surname>Banks</surname><given-names>SN</given-names></name><etal/></person-group>
<article-title>A systematic approach for variable selection with random forests: achieving stable variable importance values</article-title>
<source>IEEE Geosci Remote S</source>
<year>2017</year>
<volume>14</volume>
<fpage>1988</fpage>
<lpage>1992</lpage>
</element-citation>
      </ref>
      <ref id="b67">
        <label>67</label>
        <element-citation publication-type="other">
<person-group person-group-type="author"><name><surname>RColorBrewer</surname><given-names>S</given-names></name><name><surname>Liaw</surname><given-names>A</given-names></name><name><surname>Wiener</surname><given-names>M</given-names></name><etal/></person-group>
<source>Package ‘randomForest’</source>
<year>2018</year>
</element-citation>
      </ref>
      <ref id="b68">
        <label>68</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kuhn</surname><given-names>M</given-names></name></person-group>
<article-title>Building predictive models in R using the caret package</article-title>
<source>J Stat Softw</source>
<year>2008</year>
<volume>28</volume>
<fpage>1</fpage>
<lpage>26</lpage>
<pub-id pub-id-type="pmid">27774042</pub-id></element-citation>
      </ref>
      <ref id="b69">
        <label>69</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Nieuwenhuis</surname><given-names>M</given-names></name><name><surname>van Haren</surname><given-names>NE</given-names></name><name><surname>Pol</surname><given-names>HEH</given-names></name><etal/></person-group>
<article-title>Classification of schizophrenia patients and healthy controls from structural MRI scans in two large independent samples</article-title>
<source>Neuroimage</source>
<year>2012</year>
<volume>61</volume>
<fpage>606</fpage>
<lpage>612</lpage>
<pub-id pub-id-type="pmid">22507227</pub-id></element-citation>
      </ref>
      <ref id="b70">
        <label>70</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Fan</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>H</given-names></name><etal/></person-group>
<article-title>Discriminant analysis of functional connectivity patterns on Grassmann manifold</article-title>
<source>Neuroimage</source>
<year>2011</year>
<volume>56</volume>
<fpage>2058</fpage>
<lpage>2067</lpage>
<pub-id pub-id-type="pmid">21440643</pub-id></element-citation>
      </ref>
      <ref id="b71">
        <label>71</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Salman</surname><given-names>MS</given-names></name><name><surname>Du</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>D</given-names></name><etal/></person-group>
<article-title>Group ICA for identifying biomarkers in schizophrenia: ‘Adaptive’ networks via spatially constrained ICA show more sensitivity to group differences than spatio-temporal regression</article-title>
<source>NeuroImage Clin</source>
<year>2019</year>
<volume>22</volume>
<fpage>101747</fpage>
<pub-id pub-id-type="pmid">30921608</pub-id></element-citation>
      </ref>
      <ref id="b72">
        <label>72</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Himberg</surname><given-names>J</given-names></name><name><surname>Hyvärinen</surname><given-names>A</given-names></name><name><surname>Esposito</surname><given-names>F</given-names></name></person-group>
<article-title>Validating the independent components of neuroimaging time series via clustering and visualization</article-title>
<source>Neuroimage</source>
<year>2004</year>
<volume>22</volume>
<fpage>1214</fpage>
<lpage>1222</lpage>
<pub-id pub-id-type="pmid">15219593</pub-id></element-citation>
      </ref>
      <ref id="b73">
        <label>73</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Cole</surname><given-names>DM</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Beckmann</surname><given-names>CF</given-names></name></person-group>
<article-title>Advances and pitfalls in the analysis and interpretation of resting-state FMRI data</article-title>
<source>Front Syst Neurosci</source>
<year>2010</year>
<volume>4</volume>
<fpage>8</fpage>
<pub-id pub-id-type="pmid">20407579</pub-id></element-citation>
      </ref>
      <ref id="b74">
        <label>74</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Andreasen</surname><given-names>NC</given-names></name></person-group>
<article-title>The role of the thalamus in schizophrenia</article-title>
<source>Can J Psychiatry</source>
<year>1997</year>
<volume>42</volume>
<fpage>27</fpage>
<lpage>33</lpage>
<pub-id pub-id-type="pmid">9040920</pub-id></element-citation>
      </ref>
      <ref id="b75">
        <label>75</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Byne</surname><given-names>W</given-names></name><name><surname>Hazlett</surname><given-names>EA</given-names></name><name><surname>Buchsbaum</surname><given-names>MS</given-names></name><etal/></person-group>
<article-title>The thalamus and schizophrenia: current status of research</article-title>
<source>Acta Neuropathol</source>
<year>2009</year>
<volume>117</volume>
<fpage>347</fpage>
<lpage>368</lpage>
<pub-id pub-id-type="pmid">18604544</pub-id></element-citation>
      </ref>
      <ref id="b76">
        <label>76</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pergola</surname><given-names>G</given-names></name><name><surname>Selvaggi</surname><given-names>P</given-names></name><name><surname>Trizio</surname><given-names>S</given-names></name><etal/></person-group>
<article-title>The role of the thalamus in schizophrenia from a neuroimaging perspective</article-title>
<source>Neurosci Biobehav Rev</source>
<year>2015</year>
<volume>54</volume>
<fpage>57</fpage>
<lpage>75</lpage>
<pub-id pub-id-type="pmid">25616183</pub-id></element-citation>
      </ref>
      <ref id="b77">
        <label>77</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Bogousslavsky</surname><given-names>J</given-names></name><name><surname>Miklossy</surname><given-names>J</given-names></name><name><surname>Deruaz</surname><given-names>JP</given-names></name><etal/></person-group>
<article-title>Lingual and fusiform gyri in visual processing: a clinico-pathologic study of superior altitudinal hemianopia</article-title>
<source>J Neurol Neurosurg Psychiatry</source>
<year>1987</year>
<volume>50</volume>
<fpage>607</fpage>
<lpage>614</lpage>
<pub-id pub-id-type="pmid">3585386</pub-id></element-citation>
      </ref>
      <ref id="b78">
        <label>78</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Mechelli</surname><given-names>A</given-names></name><name><surname>Humphreys</surname><given-names>GW</given-names></name><name><surname>Mayall</surname><given-names>K</given-names></name><etal/></person-group>
<article-title>Differential effects of word length and visual contrast in the fusiform and lingual gyri during reading</article-title>
<source>Proc Biol Sci</source>
<year>2000</year>
<volume>267</volume>
<fpage>1909</fpage>
<lpage>1913</lpage>
<pub-id pub-id-type="pmid">11052544</pub-id></element-citation>
      </ref>
      <ref id="b79">
        <label>79</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Yu</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Fan</surname><given-names>F</given-names></name><etal/></person-group>
<article-title>Decreased gray matter volume of cuneus and lingual gyrus in schizophrenia patients with tardive dyskinesia is associated with abnormal involuntary movement</article-title>
<source>Sci Rep</source>
<year>2018</year>
<volume>8</volume>
<fpage>1</fpage>
<lpage>7</lpage>
<pub-id pub-id-type="pmid">29311619</pub-id></element-citation>
      </ref>
      <ref id="b80">
        <label>80</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kogata</surname><given-names>T</given-names></name><name><surname>lidaka</surname><given-names>T</given-names></name></person-group>
<article-title>A review of impaired visual processing and the daily visual world in patients with schizophrenia</article-title>
<source>Nagoya J Med Sci</source>
<year>2018</year>
<volume>80</volume>
<fpage>317</fpage>
<lpage>328</lpage>
<pub-id pub-id-type="pmid">30214081</pub-id></element-citation>
      </ref>
      <ref id="b81">
        <label>81</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Yamamoto</surname><given-names>M</given-names></name><name><surname>Bagarinao</surname><given-names>E</given-names></name><name><surname>Kushima</surname><given-names>I</given-names></name><etal/></person-group>
<article-title>Support vector machine-based classification of schizophrenia patients and healthy controls using structural magnetic resonance imaging from two independent sites</article-title>
<source>PloS One</source>
<year>2020</year>
<volume>15</volume>
<fpage>e0239615</fpage>
<pub-id pub-id-type="pmid">33232334</pub-id></element-citation>
      </ref>
      <ref id="b82">
        <label>82</label>
        <element-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Tohid</surname><given-names>H</given-names></name><name><surname>Faizan</surname><given-names>M</given-names></name><name><surname>Faizan</surname><given-names>U</given-names></name></person-group>
<article-title>Alterations of the occipital lobe in schizophrenia</article-title>
<source>Neurosciences</source>
<year>2015</year>
<volume>20</volume>
<fpage>213</fpage>
<lpage>224</lpage>
<pub-id pub-id-type="pmid">26166588</pub-id></element-citation>
      </ref>
    </ref-list>
  </back>
</article>
