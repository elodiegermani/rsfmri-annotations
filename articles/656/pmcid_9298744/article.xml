<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1662-4548</issn>
      <issn pub-type="epub">1662-453X</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">35873806</article-id>
      <article-id pub-id-type="pmc">9298744</article-id>
      <article-id pub-id-type="doi">10.3389/fnins.2022.933660</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Convolutional Recurrent Neural Network for Dynamic Functional MRI Analysis and Brain Disease Identification</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>Kai</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/1786403/overview"/>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Jie</surname>
            <given-names>Biao</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/734328/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Dong</surname>
            <given-names>Peng</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>Xintao</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Bian</surname>
            <given-names>Weixin</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Liu</surname>
            <given-names>Mingxia</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref>
          <xref rid="c002" ref-type="corresp">
<sup>*</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/696936/overview"/>
        </contrib>
      </contrib-group>
      <aff id="aff1"><sup>1</sup><institution>School of Computer and Information, Anhui Normal University</institution>, <addr-line>Wuhu</addr-line>, <country>China</country></aff>
      <aff id="aff2"><sup>2</sup><institution>Department of Radiology and Biomedical Research Imaging Center (BRIC), University of North Carolina at Chapel Hill</institution>, <addr-line>Chapel Hill, NC</addr-line>, <country>United States</country></aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: Xi Jiang, University of Electronic Science and Technology of China, China</p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: Jiashuang Huang, Nanjing University of Aeronautics and Astronautics, China; Qi Zhu, Nanjing University of Aeronautics and Astronautics, China</p>
        </fn>
        <corresp id="c001">*Correspondence: Biao Jie <email>jbiao@nuaa.edu.cn</email></corresp>
        <corresp id="c002">Mingxia Liu <email>mxliu@med.unc.edu</email></corresp>
        <fn fn-type="other" id="fn001">
          <p>This article was submitted to Brain Imaging Methods, a section of the journal Frontiers in Neuroscience</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>06</day>
        <month>7</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2022</year>
      </pub-date>
      <volume>16</volume>
      <elocation-id>933660</elocation-id>
      <history>
        <date date-type="received">
          <day>01</day>
          <month>5</month>
          <year>2022</year>
        </date>
        <date date-type="accepted">
          <day>13</day>
          <month>6</month>
          <year>2022</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright Â© 2022 Lin, Jie, Dong, Ding, Bian and Liu.</copyright-statement>
        <copyright-year>2022</copyright-year>
        <copyright-holder>Lin, Jie, Dong, Ding, Bian and Liu</copyright-holder>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Dynamic functional connectivity (dFC) networks derived from resting-state functional magnetic resonance imaging (rs-fMRI) help us understand fundamental dynamic characteristics of human brains, thereby providing an efficient solution for automated identification of brain diseases, such as Alzheimer's disease (AD) and its prodromal stage. Existing studies have applied deep learning methods to dFC network analysis and achieved good performance compared with traditional machine learning methods. However, they seldom take advantage of sequential information conveyed in dFC networks that could be informative to improve the diagnosis performance. In this paper, we propose a convolutional recurrent neural network (CRNN) for automated brain disease classification with rs-fMRI data. Specifically, we first construct dFC networks from rs-fMRI data using a sliding window strategy. Then, we employ three convolutional layers and long short-term memory (LSTM) layer to extract high-level features of dFC networks and also preserve the sequential information of extracted features, followed by three fully connected layers for brain disease classification. Experimental results on 174 subjects with 563 rs-fMRI scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) demonstrate the effectiveness of our proposed method in binary and multi-category classification tasks.</p>
      </abstract>
      <kwd-group>
        <kwd>dynamic functional connectivity</kwd>
        <kwd>sequential information</kwd>
        <kwd>Alzheimer's disease</kwd>
        <kwd>classification</kwd>
        <kwd>fMRI</kwd>
      </kwd-group>
      <counts>
        <fig-count count="10"/>
        <table-count count="4"/>
        <equation-count count="1"/>
        <ref-count count="62"/>
        <page-count count="14"/>
        <word-count count="9124"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro" id="s1">
      <title>1. Introduction</title>
      <p>Alzheimer's disease (AD) is the most common neurodegenerative disease in the elderly, accounting for about two-thirds of all dementia cases, which can cause irreversible loss of brain neurons (Nussbaum and Ellis, <xref rid="B33" ref-type="bibr">2003</xref>). The clinical manifestations are progressive impairment of memory, insight, and judgment, as well as obstacles to the orientation of the surrounding environment and language obstacles (Tarawneh and Holtzman, <xref rid="B46" ref-type="bibr">2012</xref>). The cost of long-term care for patients with AD may bring a heavy economic burden to the family and society (Association, <xref rid="B3" ref-type="bibr">2016</xref>). Mild cognitive impairment (MCI), the prodromal stage of AD, may develop into clinical AD at a fairly rapid rate (Petersen et al., <xref rid="B35" ref-type="bibr">2001</xref>). Therefore, accurate diagnosis of MCI and AD is of great significance for early treatment and prevention of disease progression.</p>
      <p>Resting-state functional magnetic resonance imaging (rs-fMRI), which measures low-frequency fluctuations in blood oxygen level dependent (BOLD) signals, provides a non-invasive solution for studying the functional structure of the brain (Lee et al., <xref rid="B29" ref-type="bibr">2013</xref>). Functional connectivity (FC) networks derived from rs-fMRI data help describe the temporal dependency of neuronal activation patterns between brain regions (van den Heuvel and Hulshoff Pol, <xref rid="B50" ref-type="bibr">2010</xref>), and have been applied to the automated diagnosis of brain diseases, such as AD and MCI (Chen et al., <xref rid="B11" ref-type="bibr">2011</xref>; Wee et al., <xref rid="B55" ref-type="bibr">2012</xref>), schizophrenia (Shen et al., <xref rid="B41" ref-type="bibr">2010</xref>), and autism spectrum disorder (Wang et al., <xref rid="B53" ref-type="bibr">2019c</xref>). The existing studies usually implicitly assume that the FC of the human brain is <italic>stationary</italic> during fMRI recording (Sporns, <xref rid="B43" ref-type="bibr">2011</xref>), thus ignoring the temporal dynamics of the brain network. Many studies have shown that, even in the resting state, FC also exhibits significant temporal dynamic changes (Hutchison et al., <xref rid="B18" ref-type="bibr">2013</xref>; Zhang et al., <xref rid="B61" ref-type="bibr">2016</xref>). Increasing evidence suggests that the dynamics of FC networks may be related to cognitive states (Chang et al., <xref rid="B10" ref-type="bibr">2013</xref>; Thompson et al., <xref rid="B48" ref-type="bibr">2013</xref>), and assessing the dynamics of FC networks is critical for better understanding the pathology of brain diseases (Zhang et al., <xref rid="B61" ref-type="bibr">2016</xref>). Several recent studies have resorted to dynamic FC (dFC) network to characterize the temporal changes of FC between brain regions (Hutchison et al., <xref rid="B18" ref-type="bibr">2013</xref>) and investigated the association of changes in dFC networks with brain diseases (Jones et al., <xref rid="B24" ref-type="bibr">2012</xref>). Also, studies have applied <italic>dynamic</italic> FC networks to brain disease classification (Sakoglu et al., <xref rid="B39" ref-type="bibr">2009</xref>; Wee et al., <xref rid="B54" ref-type="bibr">2016</xref>), and achieved better performance compared with those that use traditional stationary FC networks.</p>
      <p>Existing studies on dFC network analysis can be roughly categorized into two categories: (1) traditional machine learning methods, and (2) deep learning methods. The first category typically extracts low-level network measures (i.e., clustering coefficients) as rs-fMRI features and trains a learning model (i.e., support vector machine, SVM) for classification (Wee et al., <xref rid="B54" ref-type="bibr">2016</xref>). For example, Jie et al. (<xref rid="B20" ref-type="bibr">2018</xref>) extract and integrate temporal and spatial variability of dFC networks for MCI classification. These methods usually rely on handcrafted feature representations for classification/prediction models, thereby producing sub-optimal classification performance. In contrast, deep learning methods usually learn features of dFC networks in a data-driven manner for brain network analysis (Kawahara et al., <xref rid="B27" ref-type="bibr">2016</xref>). For example, several studies have applied convolutional neural network (CNN) to the automated diagnosis of brain diseases (Wang et al., <xref rid="B52" ref-type="bibr">2019b</xref>; Jie et al., <xref rid="B19" ref-type="bibr">2020</xref>). Compared with the traditional machine learning methods, deep learning methods could automatically learn data-driven features from dFC networks and provide a unified framework for feature learning and classification/prediction, thus achieving good classification performance. However, these methods usually ignore the sequential information of dFC networks that could be used to further improve the performance.</p>
      <p>In this article, we propose a convolutional recurrent neural network (CRNN) for brain disease classification with rs-fMRI data, which can explicitly model the sequential information conveyed in dynamic FC networks for end-to-end brain disease identification. To the best of our knowledge, this is among the first attempt to construct a convolutional recurrent neural network for dFC network analysis using rs-fMRI data. <xref rid="F1" ref-type="fig">Figure 1</xref> illustrates the architecture of our proposed CRNN method. Specifically, we first construct dFC networks from the rs-fMRI time series at successive, overlapping time windows, where Pearson correlation coefficients (PCC) of the region-based BOLD signals are used as measures of FC between brain regions. Then, we employ three convolutional layers to extract features from the constructed dFC networks and construct a long short-term memory (LSTM) (Sainath et al., <xref rid="B38" ref-type="bibr">2015</xref>) layer to capture sequential information of extracted features. The extracted features are finally fed into three fully connected layers to identify patients with brain diseases from normal controls. We evaluated the proposed CRNN method on 174 subjects with 563 rs-fMRI scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database<xref rid="fn0001" ref-type="fn"><sup>1</sup></xref>. The experimental results demonstrate the effectiveness of our proposed method.</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p>Illustration of the proposed convolutional recurrent neural network (CRNN) for brain disease classification with rs-fMRI data, consisting of <bold>(A)</bold> image preprocessing and dynamic functional connectivity network construction, <bold>(B)</bold> temporal and sequential features extraction <italic>via</italic> three convolutional layers and a long short-term memory (LSTM) layer, and <bold>(C)</bold> classification <italic>via</italic> three fully connected layers.</p>
        </caption>
        <graphic xlink:href="fnins-16-933660-g0001" position="float"/>
      </fig>
      <p>The remainder of this article is organized as follows. In section 2, we first review related study on the FC network and deep learning for brain disease diagnosis. We then introduce the materials used in the experiments and the details of our proposed framework in section 3. In section 4, we first introduce the experimental setup and methods for comparison and then present the corresponding experimental results. In section 5, we study the influence of key parameters and point out several limitations of this study as well as future research directions. Finally, we conclude this article in section 6.</p>
    </sec>
    <sec id="s2">
      <title>2. Related Study</title>
      <sec>
        <title>2.1. Brain Network Analysis</title>
        <p>Network analysis provides an important way of exploring the association between brain functional organization and brain diseases (Kaiser, <xref rid="B26" ref-type="bibr">2011</xref>). Learning properties of brain networks shows great promise for identifying biomarkers from neuroimaging data. Functional connectivity (FC) networks estimated from rs-fMRI have been extensively used for brain disease analysis. Many FC network analysis models have been developed, from simple stationary FC (sFC) networks (Zanin et al., <xref rid="B59" ref-type="bibr">2012</xref>; Qiao et al., <xref rid="B36" ref-type="bibr">2018</xref>) to complex time-frequency analysis based dynamic FC (dFC) networks (Jones et al., <xref rid="B24" ref-type="bibr">2012</xref>; Jie et al., <xref rid="B20" ref-type="bibr">2018</xref>). Previous studies have found disrupted FC associated with specific brain regions in patients with AD/MCI such as the hippocampus (Liu et al., <xref rid="B30" ref-type="bibr">2008</xref>), posterior cingulate cortex (Bai et al., <xref rid="B4" ref-type="bibr">2009</xref>), and amygdala (Yao et al., <xref rid="B58" ref-type="bibr">2013</xref>), and have reported abnormal network properties such as changed small world characteristics in AD/MCI patients (Supekar et al., <xref rid="B45" ref-type="bibr">2008</xref>). However, these studies mainly focus on topological differences of FC networks between patients and normal controls (NCs) using graph theory (Stam et al., <xref rid="B44" ref-type="bibr">2009</xref>; Brier et al., <xref rid="B8" ref-type="bibr">2014</xref>).</p>
        <p>On the other hand, several studies have successfully applied FC networks to the classification of brain diseases using machine learning methods. For example, Jie et al. (<xref rid="B23" ref-type="bibr">2014</xref>) used a graph-kernel-based method to identify patients with MCI from normal controls. Wee et al. (<xref rid="B55" ref-type="bibr">2012</xref>) designed a multimodality classification framework based on a multi-kernel support vector machine (SVM). Gan et al. (<xref rid="B15" ref-type="bibr">2021</xref>) developed a multi-graph fusion method to fuse FC networks, and employed sparse-SVM to jointly conduct brain region selection and disease diagnosis. Several studies have integrated multiple properties of FC networks for the diagnosis of MCI (Zanin et al., <xref rid="B59" ref-type="bibr">2012</xref>; Jie et al., <xref rid="B20" ref-type="bibr">2018</xref>), autism (Anderson et al., <xref rid="B2" ref-type="bibr">2011</xref>), and early tourette syndrome in children (Wen et al., <xref rid="B56" ref-type="bibr">2017</xref>). In general, existing studies on FC network classification mainly rely on two kinds of methods: traditional machine learning methods and deep learning methods, with details introduced as follows.</p>
      </sec>
      <sec>
        <title>2.2. Machine Learning for Brain Network Classification</title>
        <p>In traditional machine learning based methods, many handcrafted measures are usually extracted from FC networks as features for training a classification model (e.g., support vector machine, SVM). For example, several studies extracted connectivity strength (Chen et al., <xref rid="B11" ref-type="bibr">2011</xref>) and local clustering coefficient (Wee et al., <xref rid="B55" ref-type="bibr">2012</xref>; Jie et al., <xref rid="B21" ref-type="bibr">2016</xref>) from sFC network as features to train an SVM for MCI identification. Additionally, some studies extracted and integrated multiple properties of sFC networks for the diagnosis of brain diseases (Zanin et al., <xref rid="B59" ref-type="bibr">2012</xref>; Jie et al., <xref rid="B22" ref-type="bibr">2013</xref>), and achieved better performance in comparison with single network measures.</p>
        <p>On the other hand, temporal dynamics of dFC networks are extracted for brain disease analysis (Chang and Glover, <xref rid="B9" ref-type="bibr">2010</xref>). For example, several studies have extracted clustering coefficients (Wee et al., <xref rid="B54" ref-type="bibr">2016</xref>), temporal variabilities (SakoÄlu et al., <xref rid="B40" ref-type="bibr">2010</xref>; Jie et al., <xref rid="B20" ref-type="bibr">2018</xref>), and/or root-mean-square (Chen et al., <xref rid="B12" ref-type="bibr">2017</xref>) features from dFC networks to train a classifier for brain disease classification, and achieve better classification performance compared with sFC network based methods. However, these studies generally treat feature learning and classification separately, which could degrade the classification performance. Also, these studies typically extract handcrafted network measures as features, which highly rely on expert knowledge.</p>
      </sec>
      <sec>
        <title>2.3. Deep Learning for Brain Network Classification</title>
        <p>Deep learning methods (e.g., convolutional neural networks, CNNs) that can learn representations of data have been successfully applied to various fields (LeCun et al., <xref rid="B28" ref-type="bibr">2015</xref>). There is significant interest in the development and application of deep learning methods to medical image analysis, including image segmentation (Milletari et al., <xref rid="B32" ref-type="bibr">2016</xref>; Akkus et al., <xref rid="B1" ref-type="bibr">2017</xref>), registration (Boveiri et al., <xref rid="B7" ref-type="bibr">2020</xref>), and brain disease diagnosis (Shen et al., <xref rid="B42" ref-type="bibr">2015</xref>; Deepak and Ameer, <xref rid="B14" ref-type="bibr">2019</xref>; Wen et al., <xref rid="B57" ref-type="bibr">2020</xref>). In recent years, many studies have successfully applied deep learning methods to brain FC network analysis (Ju et al., <xref rid="B25" ref-type="bibr">2017</xref>; Zeng et al., <xref rid="B60" ref-type="bibr">2018</xref>; Zhang et al., <xref rid="B62" ref-type="bibr">2020</xref>). For example, Kawahara et al. (<xref rid="B27" ref-type="bibr">2016</xref>) developed a CNN-based FC network analysis method to predict cognitive and motor developmental outcome scores of preterm infants. Zeng et al. (<xref rid="B60" ref-type="bibr">2018</xref>) built a deep discriminant autoencoder network for cross-site classification of schizophrenia. MeszlÃ©nyi et al. (<xref rid="B31" ref-type="bibr">2017</xref>) developed a CNN-based method for FC network analysis and MCI classification. He et al. (<xref rid="B16" ref-type="bibr">2020</xref>) developed a deep neural network (DNN) for FC prediction of behavior and demographics Unfortunately, these methods mainly focus on stationary FC networks and, thus, cannot be applied to dynamic FC network analysis.</p>
        <p>Several recent studies employ deep learning methods for dFC network based disease analysis and yield better performance compared with sFC network based methods. For example, Wang et al. (<xref rid="B51" ref-type="bibr">2019a</xref>) presented a dFC network-based CNN framework for electroencephalogram (EEG) based person identification in diverse human states. Jie et al. (<xref rid="B19" ref-type="bibr">2020</xref>) built a weighted correlation kernel based CNN framework for automated diagnosis of MCI. However, the valuable sequential information conveyed in dynamic FC networks is generally neglected in these studies. To this end, we propose a convolutional recurrent neural network to explicitly capture the sequential information conveyed in dynamic FC networks for brain disease classification with rs-fMRI data.</p>
      </sec>
    </sec>
    <sec sec-type="materials and methods" id="s3">
      <title>3. Materials and Methods</title>
      <p><xref rid="F1" ref-type="fig">Figure 1</xref> illustrates the proposed convolutional recurrent neural network (CRNN) for rs-fMRI based brain disease classification, consisting of three parts: (a) image preprocessing and dynamic functional connectivity (dFC) network construction, (b) feature learning, and (c) classification. In this section, we first present the subjects used in this study and then introduce the details of the proposed method.</p>
      <sec>
        <title>3.1. Subjects</title>
        <p>The rs-fMRI data obtained from the ADNI database were studied in this paper. In this study, we used 563 scans of 174 subjects, including 31 AD, 45 late MCI (lMCI), 50 early MCI (eMCI), and 48 normal controls (NCs). It is worth noting that the subjects participating in the study may have one or more scans at different time points. The 563 scans can be divided into 99 cases of AD, 145 cases of lMCI, 165 cases of eMCI, and 154 cases of NC. The specifications of the data acquired in each scan are: the in-plane image resolution is 2.29â3.31<italic>mm</italic>, the slice thickness is 3.31<italic>mm</italic>, TE (echo time) is 30<italic>ms</italic>, and TR (repetition time) is 2.2â3.1<italic>s</italic>. There are 140 volumes (time points) for each subject. The demographic and clinical information of rs-fMRI scans of all subjects is summarized in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
        <table-wrap position="float" id="T1">
          <label>Table 1</label>
          <caption>
            <p>Demographic information of all rs-fMRI scans of the subjects used in this study (Mean Â± SD).</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="1" colspan="1">
<bold>Group</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>AD</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>lMCI</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>eMCI</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>NC</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender (M/F)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">55/44</td>
                <td valign="top" align="center" rowspan="1" colspan="1">95/50</td>
                <td valign="top" align="center" rowspan="1" colspan="1">73/92</td>
                <td valign="top" align="center" rowspan="1" colspan="1">67/87</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Age (Years)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.7 Â± 7.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">72.3 Â± 8.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">72.4 Â± 7.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">76.0 Â± 6.8</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">MMSE</td>
                <td valign="top" align="center" rowspan="1" colspan="1">21.8 Â± 3.3</td>
                <td valign="top" align="center" rowspan="1" colspan="1">27.1 Â± 2.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">28.1 Â± 1.6</td>
                <td valign="top" align="center" rowspan="1" colspan="1">28.8 Â± 1.4</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>M/F, Male/Female</italic>.</p>
            <p><italic>MMSE, Mini-Mental State Examination</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.2. Proposed Method</title>
        <sec>
          <title>3.2.1. Image Preprocessing and Network Construction</title>
          <p>All rs-fMRI data are preprocessed by standard procedures using FSL FEAT software. Specifically, we discard the first 3 volumes before preprocessing, and then process the remaining 137 volumes according to the standard pipeline, including (1) slice timing correction, (2) head motion estimation, (3) bandpass filtering, and (4) the regression of white matter, cerebrospinal fluid and motion parameters. To reduce the influence of head motion, we remove the fMRI data of the head moving more than 2.0<italic>mm</italic> in any direction or 2Â° in any rotation. Then, we perform structural skull stripping and map the fMRI data of the skull stripping to the Montreal Neurological Institute space. A 6<italic>mm</italic> Gaussian kernel is used to spatially smooth the rs-fMRI data. Subjects whose frame displacement exceeds 2.5 min (FD &gt;0.5) are not included in our analysis. Finally, using the automated anatomical labeling (AAL) template, the brain space of each subject's fMRI scan was partitioned into 116 regions of interest (ROIs). For each subject, the average rs-fMRI time series from the BOLD signals in all ROIs were calculated, which are used for the construction of dFC networks.</p>
          <p>We constructed the dFC network using an overlapping sliding window strategy. As shown in <xref rid="F1" ref-type="fig">Figure 1A</xref>, for each subject with <italic>N</italic> ROIs, we first partition the time series into <italic>T</italic> overlapped windows/segments, and build an FC network/matrix G<sup><italic>t</italic></sup>ââ<sup><italic>N</italic>Ã<italic>N</italic></sup> within the <italic>t</italic>-th (<italic>t</italic> = 1, â¯â, <italic>T</italic>) time window. In G<sup><italic>t</italic></sup>, each node denotes a specific ROI, and the edge weight between a pair of ROIs is the Pearson's correlation coefficient (PCC). In this way, we can obtain a set of <italic>T</italic> FC networks ð¢ with the window length of <italic>L</italic> and the sliding step size of <italic>S</italic> to characterize the dynamics of brain networks for each subject, i.e., ð¢ = [G<sup>1</sup>, G<sup>2</sup>, â¯â, G<sup><italic>T</italic></sup>]ââ<sup><italic>T</italic>Ã<italic>N</italic>Ã<italic>N</italic></sup>.</p>
        </sec>
        <sec>
          <title>3.2.2. Temporal and Sequential Feature Extraction</title>
          <p>As shown in <xref rid="F1" ref-type="fig">Figure 1B</xref>, we define four layers in the proposed CRNN framework to model both temporal and sequential features of the constructed dynamic functional connectivity networks. Specifically, following (Jie et al., <xref rid="B19" ref-type="bibr">2020</xref>), we first define three convolutional layers to extract hierarchical (i.e., region, whole-network, and temporal) features from the constructed dFC networks, respectively. Then, we use a recurrent neural network layer to learn the important sequential features of brain networks. More details can be found in the following.</p>
          <p><italic>(i) Region feature extraction</italic>. To learn region features from the whole dFC networks, in the first convolutional layer, we set the size of the kernel of <italic>S</italic><sub>1</sub> Ã <italic>N</italic> Ã 1 and set the stride along three dimensions (i.e., one temporal and two spatial dimensions) to (1, 1, 1). The convolution along two spatial dimensions is a feature mapping for each ROI, while the convolution along the temporal dimension denotes different feature mappings of the same ROI. This helps characterize the temporal properties of the corresponding ROI. Features extracted from this layer characterize temporal dynamics of brain regions, and these features are high-order since these features are calculated based on functional connectivities of specific ROI across <italic>S</italic>1 FC networks.</p>
          <p><italic>(ii) Whole-network feature extraction</italic>. To extract whole-network features from our learned region features, in the second convolutional layer, we set the kernel of <italic>S</italic><sub>2</sub> Ã 1 Ã <italic>N</italic>, and set the stride in three dimensions to (1, 1, 1). For this layer, the convolution along two spatial dimensions is a feature mapping for the whole FC network. The convolution along the temporal dimension represents different mappings of the whole FC network, reflecting temporal changes in dFC networks.</p>
          <p><italic>(iii) Temporal feature extraction</italic>. We further define the third convolutional layer to model the temporal features of the whole dFC network. Specifically, we set the kernel size of <italic>S</italic><sub>3</sub> Ã 1 Ã 1 and set the stride size in three dimensions to (2, 1, 1). Therefore, the features obtained in this layer with a kernel can be considered representations of the temporal dynamics of the brain network. It is worth noting that these three convolution layers are used for learning high-level and high-order temporal features from dFC networks derived from the rs-fMRI time series.</p>
          <p><italic>(iv) Sequential feature extraction</italic>. As a type of RNN that incorporates a memory cell, long short-term memory (LSTM) (Sainath et al., <xref rid="B38" ref-type="bibr">2015</xref>) has been successfully applied to temporal modeling in various domains, such as video and speech analysis. To capture the temporal dynamics of brain networks, we propose to use an LSTM layer to model the sequential information of dFC networks. Specifically, to fit the input shape required by the LSTM, we first flatten the temporal features learned in the previous convolutional layer. The flattened features are then fed into an LSTM layer defined as follows:</p>
          <disp-formula id="E1">
<label>(1)</label>
<mml:math id="M1" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>Ï</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mtext>Â Â </mml:mtext></mml:mtd><mml:mtd><mml:mtext>Â Â </mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <disp-formula id="E2">
<label>(2)</label>
<mml:math id="M2" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo class="qopname">tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <disp-formula id="E3">
<label>(3)</label>
<mml:math id="M3" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>Ï</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <disp-formula id="E4">
<label>(4)</label>
<mml:math id="M4" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>Ï</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <disp-formula id="E5">
<label>(5)</label>
<mml:math id="M5" overflow="scroll"><mml:mtable class="eqnarray" columnalign="left"><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo class="qopname">tanh</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math>
</disp-formula>
          <p>where <italic>f</italic><sup><italic>t</italic></sup>, <italic>g</italic><sup><italic>t</italic></sup>, and <italic>o</italic><sup><italic>t</italic></sup> denote the forget gate unit, the external input gate unit, and the output gate unit at time <italic>t</italic>, respectively. Here, <italic>x</italic><sup><italic>t</italic></sup>, <italic>h</italic><sup><italic>t</italic></sup>, and <italic>s</italic><sup><italic>t</italic></sup> are the input vector, hidden vector, and state vector, respectively. <italic>U</italic><sup><italic>k</italic></sup>, <italic>W</italic><sup><italic>k</italic></sup>, and <italic>b</italic><sup><italic>k</italic></sup> with <italic>k</italic>â<italic>f, g, o, i</italic> denote weights and biases, respectively. Additionally, Ï and tanh denote sigmoid and hyperbolic tangent activation functions. The output sequential features of the LSTM layer are subsequently reshaped back to feed the next layer for classification.</p>
        </sec>
        <sec>
          <title>3.2.3. Classification</title>
          <p>In the classification module, we use three fully connected layers (containing 32, 16, and 4 neurons, respectively) to learn a mapping between sequential features and category labels (e.g., patient with AD or NC) for classification. The output (<italic>via</italic> softmax) of the proposed method is the probability of the subject belonging to a specific category. In the proposed CRNN, a rectified linear unit (ReLU) is employed as the activation function of each layer, and dropout with a rate of 0.25 is used in each fully connected layer.</p>
        </sec>
        <sec>
          <title>3.2.4. Implementation</title>
          <p>The proposed CRNN is implemented in Python based on the Keras package, and the model is trained on a single GPU (NVIDIA GeForce GTX 1080Ti) with 11 GB of memory. When constructing dynamic FC networks, we empirically set the fixed length of the time window as <italic>L</italic> = 70 and the sliding step size as <italic>S</italic> = 2. Therefore, the number of time windows per subject is <italic>T</italic> = 34. In the three convolutional layers, we, respectively, set the convolution kernel size along the time dimension as follows: <italic>S</italic><sub>1</sub> = 2, <italic>S</italic><sub>2</sub> = 2, and <italic>S</italic><sub>3</sub> = 8. The corresponding channel numbers of the three convolutional layers are set as follows: <italic>K</italic><sub>1</sub> = 8, <italic>K</italic><sub>2</sub> = 16, and <italic>K</italic><sub>3</sub> = 32. According to the above parameters, we can calculate <italic>T</italic><sub>1</sub> = 13. When predicting the progression of brain diseases, softmax is used as the activation function of the last fully connected layer for binary classifications and four-category classifications. Here, we use the Adam optimizer with recommended parameters for training, by empirically setting the number of epochs to 200 and the batch size to 16.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s4">
      <title>4. Experiment</title>
      <sec>
        <title>4.1. Experimental Settings</title>
        <p>We employ a <italic>subject-level</italic> 5<italic>-fold cross-validation</italic> strategy in this study, ensuring that scans from the same subject do not appear in both train and test sets. Specifically, all subjects with baseline were first divided into 5 subsets of roughly the same size. Each subset is then selected in turn as the test set, and the remaining 4 subsets (including their other scans) and subjects without baseline scans are combined to form the training set. In addition, in each fold of cross-validation, we further select 20% of the training data as the validation data to determine the optimal parameters of a specific classification model. It is worth noting that we only use a baseline scan of each subject in the test set as testing subject to evaluate the performance of our proposed method. Also, each scan of each subject is considered an independent sample, but all scans of the same subject have the same category label. Finally, the classification results generated by a method with 5-fold cross-validation are averaged and recorded.</p>
        <p>In order to evaluate the effectiveness of the proposed model, we conducted both binary and multi-class classification experiments, including (1) eMCI vs. NC classification, (2) AD vs. NC classification, and (3) AD vs. lMCI vs. eMCI vs. NC classification. Three evaluation metrics are used to measure the performance of binary classifications, namely classification accuracy (ACC), sensitivity (SEN), and specificity (SPE). For multi-class disease classification, we evaluate the performance by calculating both the overall accuracy of all categories and the classification accuracy of each category.</p>
      </sec>
      <sec>
        <title>4.2. Methods for Comparison</title>
        <p>In the experiments, we first compared our method with three baseline methods and state-of-the-art methods.</p>
        <p>(1) <bold>baseline</bold>: In this method, we first construct an sFC network for each subject by calculating the Pearson correlation coefficient between the entire time series of any pair of ROIs. Then, the connectivity strength of the stationary FC network is used as a network feature. The <italic>t</italic>-test method with a threshold (i.e., <italic>p</italic>-value &lt; 0.05) is used for feature selection of binary class tasks. Finally, a linear support vector machine (SVM) with default parameters is used for classification.</p>
        <p>(2) <bold>CC</bold>: In this method, the subject's stationary FC network is first constructed. Then the local clustering coefficients of all 116 ROIs from the constructed stationary FC network are extracted as features. We use a <italic>t</italic>-test and linear SVM with default parameters for feature selection and classification, respectively.</p>
        <p>(3) <bold>M</bold><sup><bold>2</bold></sup><bold>TFS</bold>: Similar to our proposed CRNN, this method first constructs a set of <italic>T</italic> dynamic FC networks for each subject. Then, following (Jie et al., <xref rid="B20" ref-type="bibr">2018</xref>), the temporal and spatial mean features of the dynamic FC network are extracted. The manifold regularized multi-task feature selection (M<sup>2</sup>TFS) method and multi-kernel SVM are used for feature selection and classification, respectively.</p>
        <p>(4) <bold>CNN</bold>: This method is a state-of-the-art approach for rs-fMRI analysis. For a fair comparison, the CNN method employs the same architecture as our method, but without using recurrent neural networks to extract sequential features. That is, CNN does not use the LSTM layer, but instead uses an average pooling layer, followed by three fully connected layers for classification.</p>
      </sec>
      <sec>
        <title>4.3. Classification Performance</title>
        <p><xref rid="T2" ref-type="table">Tables 2</xref>, <xref rid="T3" ref-type="table">3</xref> report the quantitative results of different methods in two binary classifications and a multi-class classification task, respectively. The receiver operating characteristic (ROC) curves of two binary classification tasks are plotted in <xref rid="F2" ref-type="fig">Figure 2</xref>. It can be seen from <xref rid="F2" ref-type="fig">Figure 2</xref> and <xref rid="T2" ref-type="table">Tables 2</xref>, <xref rid="T3" ref-type="table">3</xref> that our proposed CRNN method is generally better than the four competing methods in the three classification tasks. For example, the ACC values of our proposed CRNN in eMCI vs. NC classification and AD vs. NC classification are 84.5 and 92.8%, respectively, while the second best ACC results obtained by CNN are 76.2 and 87.8%, respectively. For the challenging AD vs. lMCI vs. eMCI vs. NC classification task, the overall accuracy of our CRNN is 61.7%, which is an increase of 8.9% compared with CNN. These results indicate that our proposed CRNN method is effective in predicting the progression of brain diseases based on rs-fMRI.</p>
        <table-wrap position="float" id="T2">
          <label>Table 2</label>
          <caption>
            <p>Performance of five methods in two binary classification tasks, i.e., eMCI vs. NC and AD vs. NC classifications (Mean Â± SD).</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="2" colspan="1">
<bold>Method</bold>
</th>
                <th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1">
<bold>eMCI vs. NC (%)</bold>
</th>
                <th rowspan="1" colspan="1"/>
                <th valign="top" align="center" colspan="3" style="border-bottom: thin solid #000000;" rowspan="1">
<bold>AD vs. NC (%)</bold>
</th>
              </tr>
              <tr>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>SPE</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>SEN</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>SPE</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>SEN</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">baseline</td>
                <td valign="top" align="center" rowspan="1" colspan="1">57.1 Â± 0.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">48.1 Â± 11.5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">65.6 Â± 11.3</td>
                <td valign="top" align="center" rowspan="1" colspan="1">73.3 Â± 12.6</td>
                <td valign="top" align="center" rowspan="1" colspan="1">77.8 Â± 1.9</td>
                <td valign="top" align="center" rowspan="1" colspan="1">66.7 Â± 0.0</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">63.6 Â± 5.7</td>
                <td valign="top" align="center" rowspan="1" colspan="1">50.0 Â± 14.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">75.0 Â± 15.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">75.0 Â± 15.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">80.0 Â± 8.3</td>
                <td valign="top" align="center" rowspan="1" colspan="1">66.7 Â± 17.1</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">M<sup>2</sup>TFS</td>
                <td valign="top" align="center" rowspan="1" colspan="1">67.7 Â± 2.0</td>
                <td valign="top" align="center" rowspan="1" colspan="1">47.3 Â± 5.8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">84.7 Â± 1.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">76.4 Â± 5.8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>100.0 Â± 0.0</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">33.3 Â± 19.2</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CNN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">76.2 Â± 8.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">77.3 Â± 7.7</td>
                <td valign="top" align="center" rowspan="1" colspan="1">75.2 Â± 19.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">87.8 Â± 6.9</td>
                <td valign="top" align="center" rowspan="1" colspan="1">92.0 Â± 11.5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">80.0 Â± 19.2</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CRNN (ours)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>84.5 Â± 4.7</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>84.0 Â± 11.5</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>84.8 Â± 14.3</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>92.8 Â± 6.9</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">96.7 Â± 0.0</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>86.7 Â± 18.3</bold>
</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>The bold values indicate the one with the largest mean among all methods</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="T3">
          <label>Table 3</label>
          <caption>
            <p>Performance of five methods in the multi-class classification task, i.e., AD vs. lMCI vs. eMCI vs. NC classification.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="2" colspan="1">
<bold>Method</bold>
</th>
                <th valign="top" align="center" colspan="5" style="border-bottom: thin solid #000000;" rowspan="1">
<bold>AD vs. lMCI vs. eMCI vs. NC (%)</bold>
</th>
              </tr>
              <tr>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC<sub><italic>NC</italic></sub></bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC<sub><italic>eMCI</italic></sub></bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC<sub><italic>lMCI</italic></sub></bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>ACC<sub><italic>AD</italic></sub></bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Baseline</td>
                <td valign="top" align="center" rowspan="1" colspan="1">30.6 Â± 9.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">20.0 Â± 7.8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">38.9 Â± 18.5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">30.0 Â± 6.8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">33.3 Â± 13.6</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">35.0 Â± 10.5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">22.0 Â± 11.9</td>
                <td valign="top" align="center" rowspan="1" colspan="1">69.5 Â± 16.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">21.0 Â± 17.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">6.7 Â± 14.9</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">M<sup>2</sup>TFS</td>
                <td valign="top" align="center" rowspan="1" colspan="1">44.0 Â± 1.2</td>
                <td valign="top" align="center" rowspan="1" colspan="1">36.0 Â± 20.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>87.6 Â± 9.6</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">22.0 Â± 28.9</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0 Â± 0.0</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CNN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">52.8 Â± 10.8</td>
                <td valign="top" align="center" rowspan="1" colspan="1">44.7 Â± 30.6</td>
                <td valign="top" align="center" rowspan="1" colspan="1">53.8 Â± 4.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">65.0 Â± 8.7</td>
                <td valign="top" align="center" rowspan="1" colspan="1">46.7 Â± 19.2</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CRNN (ours)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>61.7 Â± 2.8</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>65.3 Â± 3.8</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">63.3 Â± 5.5</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>65.0 Â± 12.6</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>46.7 Â± 19.2</bold>
</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p><italic>ACC, Accuracy. The bold values indicate the one with the largest mean among all methods</italic>.</p>
          </table-wrap-foot>
        </table-wrap>
        <fig position="float" id="F2">
          <label>Figure 2</label>
          <caption>
            <p>Receiver operating characteristic (ROC) curves achieved by five different methods in <bold>(A)</bold> eMCI vs. NC classification and <bold>(B)</bold> AD vs. NC classification.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0002" position="float"/>
        </fig>
        <p>In addition, from <xref rid="F2" ref-type="fig">Figure 2</xref> and <xref rid="T2" ref-type="table">Tables 2</xref>, <xref rid="T3" ref-type="table">3</xref>, we can also have three interesting observations. <italic>First</italic>, methods based on dynamic FC networks (i.e., M<sup>2</sup>TFS, CNN, and CRNN) are generally superior to methods based on static FC networks (i.e., baseline and CC). This suggests that the dynamic changes of the rs-fMRI time series can provide useful information for a better understanding of the pathology of brain diseases. <italic>Second</italic>, compared with traditional machine learning methods (i.e., baseline, CC, and M<sup>2</sup>TFS), deep learning methods (i.e., CNN and CRNN) can achieve better performance. This shows that deep learning can capture the potential discriminative features of brain networks. <italic>Finally</italic>, compared with the CNN method, our CRNN can obtain better performance, which proves the advantage of mining sequential features from a dynamic FC network.</p>
        <p>On the other hand, <xref rid="F3" ref-type="fig">Figure 3</xref> plots the total loss curve of training subjects and validation subjects in each fold of cross-validation for the task of AD vs. lMCI vs. eMCI vs. NC classification. It can be seen from <xref rid="F3" ref-type="fig">Figure 3</xref> that our proposed CRNN method can quickly converge within 80 epochs.</p>
        <fig position="float" id="F3">
          <label>Figure 3</label>
          <caption>
            <p>Total loss of the proposed method with 200 epochs in each fold cross-validation (from left to right) for AD vs. lMCI vs. eMCI vs. NC classification task. Here, <bold>(A)</bold> total loss of training data, and <bold>(B)</bold> total loss on validation data.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0003" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.4. Discriminative Functional Connectivity</title>
        <p>We further conduct experiments to identify discriminative brain regions that contribute the most to a specific classification task and identify the informative functional connectivity between discriminative brain regions.</p>
        <p>Specifically, in our proposed CRNN method, the output of the first convolutional layer is a 4-dimensional tensor of size (<italic>T</italic>â1) Ã 1 Ã <italic>N</italic> Ã <italic>K</italic><sub>1</sub>, representing the feature vector of each subject in <italic>T</italic>â1 time series segments. For simplicity, we average the feature vectors of <italic>T</italic>â1 time series segments. Since there are <italic>K</italic><sub>1</sub> = 8 channels in the first convolutional layer, we can construct 8 feature vectors for each subject, and each feature vector corresponds to a specific channel. Then, the standard <italic>t</italic>-test was used to measure the group difference between eMCI vs. NC and AD vs. NC, respectively. It is worth noting that the feature vector obtained in this way may be different in each fold of cross-validation. For each channel, we use the standard <italic>t</italic>-test for each fold cross-validation to integrate all brain regions with <italic>p</italic>-values less than 0.05 in 5-fold cross-validation, and select brain regions that appear 3 times or more as discriminative brain regions.</p>
        <p><xref rid="SM1" ref-type="supplementary-material">Supplementary Tables S1, S2</xref> in the Supporting Information list the names and abbreviations of discriminative brain regions in the eMCI vs. NC group and AD vs. NC group, respectively. <xref rid="F4" ref-type="fig">Figure 4</xref> plots those discriminative brain regions in the template space. From <xref rid="F4" ref-type="fig">Figure 4</xref> and <xref rid="SM1" ref-type="supplementary-material">Supplementary Tables S1, S2</xref>, we first can see that) the discriminative brain regions of the two groups (i.e., eMCI vs. NC group and AD vs. NC group) all contain the cerebellum, indicating that the cerebellum may be related to MCI/AD and may provide useful information for brain diseases prognosis (Thomann et al., <xref rid="B47" ref-type="bibr">2008</xref>). Second, the discriminative brain regions in the eMCI vs. NC group are largely located in the left hemisphere. We speculate that during the evolution of AD, the left half part of some brain regions of eMCI patients may first begin to have brain atrophy, which leads to changes in their functional connectivity (Thompson et al., <xref rid="B49" ref-type="bibr">2003</xref>; Daianu et al., <xref rid="B13" ref-type="bibr">2013</xref>). Finally, the discriminative brain regions selected by our proposed method in two classification tasks are consistent with previous studies. For example, the brain regions detected in the AD vs. NC classification, including posterior cingulate gyrus, parahippocampal gyrus, fusiform gyrus, and temporal pole, have been reported to be useful in discriminating patients with AD from NCs (Jie et al., <xref rid="B19" ref-type="bibr">2020</xref>). Also, the precentral gyrus identified by our method processes auditory error signals during speech production to maintain fluency (Ozker et al., <xref rid="B34" ref-type="bibr">2022</xref>), and the orbitofrontal cortex plays an important role in decision-making and emotion processing (Bechara et al., <xref rid="B5" ref-type="bibr">2000</xref>; Rolls, <xref rid="B37" ref-type="bibr">2004</xref>). Abnormal changes in these regions can lead to the development of brain disease and also suggest that the discriminative brain regions identified by our method are associated with MCI/AD.</p>
        <fig position="float" id="F4">
          <label>Figure 4</label>
          <caption>
            <p>Discriminative brain regions identified by the proposed method in <bold>(A)</bold> eMCI vs. NC classification and <bold>(B)</bold> AD vs. NC classification.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0004" position="float"/>
        </fig>
        <p>Furthermore, we performed a standard <italic>t</italic>-test on the functional connectivity between selected discriminative brain regions. <xref rid="F5" ref-type="fig">Figure 5</xref> plots the group difference in the connectivity strength between the discriminative brain regions in the eMCI vs. NC group and the AD vs. NC group in <xref rid="SM1" ref-type="supplementary-material">Supplementary Tables S1, S2</xref>. Here, the color indicates the corresponding <italic>p</italic>-value, we set <italic>p</italic>-values more than 0.05 to 1 for clarity. From <xref rid="F5" ref-type="fig">Figure 5</xref>, we can clearly observe that there are strong correlations between the two brain regions of lobules IV and V of the vermis and the left rolandic operculum with other discriminative brain regions in the eMCI vs. NC group. In addition, we can also observe that compared with the eMCI vs. NC group, the AD vs. NC group has more connectivity strength with <italic>p</italic>-values less than 0.05 (corresponding to the blue part in <xref rid="F5" ref-type="fig">Figure 5</xref>). This suggests that the change in the connectivity strength in the AD vs. NC group is more pronounced than that in the eMCI vs. NC group, reflecting that AD's impairment of the brain gradually increases as the disease progresses.</p>
        <fig position="float" id="F5">
          <label>Figure 5</label>
          <caption>
            <p>The difference in connectivity strength between the discriminative brain regions for <bold>(A)</bold> eMCI vs. NC group and <bold>(B)</bold> AD vs. NC group. Here, <italic>p</italic>-values larger than 0.05 are set to 1 (corresponding to the yellow part in the figure).</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0005" position="float"/>
        </fig>
        <p>Besides, we identified the functional connectivities with <italic>p</italic>-values less than 0.05 between discriminative brain regions as the most discriminative functional connectivity. <xref rid="F6" ref-type="fig">Figure 6</xref> plots the most discriminative functional connectivities on the 5th and 7th channels for eMCI vs. NC group and AD vs. NC group. As shown in <xref rid="F6" ref-type="fig">Figure 6</xref>, for eMCI vs. NC classification, the brain regions we selected include the left fusiform gyrus, the left lobule VI of the cerebellar hemisphere, and lobule VII of the vermis. The functional connectivity of these brain regions is significantly reduced in MCI patients, which is consistent with previous studies by Bokde et al. (<xref rid="B6" ref-type="bibr">2006</xref>) and Thomann et al. (<xref rid="B47" ref-type="bibr">2008</xref>). For AD vs. NC classification, there are two discriminative brain regions selected by our method, including the left crus I of the cerebellar hemisphere and the right lobule IV, V of the cerebellar hemisphere. According to previous studies by Thomann et al. (<xref rid="B47" ref-type="bibr">2008</xref>), these two brain regions may be biologically related to AD. These results further confirm that our method is potentially helpful in discovering fMRI biomarkers for MCI and AD identification.</p>
        <fig position="float" id="F6">
          <label>Figure 6</label>
          <caption>
            <p>Discriminative functional connectivities for <bold>(A)</bold> eMCI vs. NC and <bold>(B)</bold> AD vs. NC classification. Each arc shows the selected connectivity between two ROIs, where colors are randomly allocated for better visualization and the thickness of each arc indicates its discriminative power that is inversely proportional to the corresponding <italic>p</italic>-value in the <italic>t</italic>-test.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0006" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>4.5. Discriminative Power of Learned Features</title>
        <p>In this section, we study the discriminative power of the features learned in our proposed CRNN method. Specifically, in the multi-class classification task, we first extract the learned sequential features from the model (corresponding to the output of the LSTM layer in our proposed CRNN method). Here, each sequential feature learned is a feature mapping of the dynamic FC network with respect to time changes. Then, we use the standard <italic>t</italic>-test to calculate the discriminative power of all sequential features in the eMCI vs. NC group and AD vs. NC group, with <italic>p</italic>-values shown in <xref rid="F7" ref-type="fig">Figures 7</xref>, <xref rid="F8" ref-type="fig">8</xref>, respectively. For comparison, we also report the discriminative power of the features learned by the comparison methods (i.e., baseline, CC, M<sup>2</sup>TFS, and CNN). There are a total of 6,670 connectivity strength features in the baseline method, 16 features in SVM-based methods (i.e., CC and M<sup>2</sup>TFS), 32 features in CNN, and 64 features in our CRNN, respectively. In addition, <xref rid="T4" ref-type="table">Table 4</xref> reports the average and median values of <italic>p</italic>-values for all features in both group pairs.</p>
        <fig position="float" id="F7">
          <label>Figure 7</label>
          <caption>
            <p>The discriminative power of features between eMCI and NC groups learned by <bold>(A)</bold> baseline, <bold>(B)</bold> CC, <bold>(C)</bold> M<sup>2</sup>TFS, <bold>(D)</bold> CNN, and <bold>(E)</bold> CRNN.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0007" position="float"/>
        </fig>
        <fig position="float" id="F8">
          <label>Figure 8</label>
          <caption>
            <p>The discriminative power of features between AD and NC groups learned by <bold>(A)</bold> baseline, <bold>(B)</bold> CC, <bold>(C)</bold> M<sup>2</sup>TFS, <bold>(D)</bold> CNN, and <bold>(E)</bold> CRNN.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0008" position="float"/>
        </fig>
        <table-wrap position="float" id="T4">
          <label>Table 4</label>
          <caption>
            <p>The average and median of <italic>p</italic>-value for learning features in both group pairs (i.e., eMCI vs. NC groups, and AD vs. NC groups).</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <th valign="top" align="left" rowspan="2" colspan="1">
<bold>Method</bold>
</th>
                <th valign="top" align="center" colspan="2" style="border-bottom: thin solid #000000;" rowspan="1">
<bold>eMCI vs. NC</bold>
</th>
                <th rowspan="1" colspan="1"/>
                <th valign="top" align="center" colspan="2" style="border-bottom: thin solid #000000;" rowspan="1">
<bold>AD vs. NC</bold>
</th>
              </tr>
              <tr>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Mean</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Median</bold>
</th>
                <th rowspan="1" colspan="1"/>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Mean</bold>
</th>
                <th valign="top" align="center" rowspan="1" colspan="1">
<bold>Median</bold>
</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Baseline</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.38</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.32</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.36</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.28</td>
                <td rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CC</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.29</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.24</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.44</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.40</td>
                <td rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">M<sup>2</sup>TFS</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.47</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.48</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.49</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.48</td>
                <td rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CNN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.02</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">CRNN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">&lt;1Eâ3</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">&lt;1Eâ33</td>
                <td rowspan="1" colspan="1"/>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>From <xref rid="F7" ref-type="fig">Figures 7</xref>, <xref rid="F8" ref-type="fig">8</xref> and <xref rid="T4" ref-type="table">Table 4</xref>, we can observe that the <italic>p</italic>-values of the features learned by the CNN and CRNN methods are mostly close to 0 (i.e., very sparsity) compared to other methods. It implies that both methods are capable of distinguishing patients from NCs. Second, the <italic>p</italic>-value of our proposed CRNN method is more sparsity than that of the CNN method, indicating the features learned by the CRNN method are more discriminative than those learned by other methods, which also explains why our method can achieve better classification performance. The above results further demonstrate the effectiveness of the sequential features extracted by our CRNN method.</p>
      </sec>
    </sec>
    <sec sec-type="discussion" id="s5">
      <title>5. Discussion</title>
      <sec>
        <title>5.1. Effect of Sliding Window Parameters</title>
        <p>Existing studies have shown that FC time series based on rs-fMRI have regular temporal variability (Huang et al., <xref rid="B17" ref-type="bibr">2016</xref>). In our proposed CRNN, we use the overlapping sliding window technology (stride: 2) to divide the time series, where the parameter <italic>L</italic> determines the length of the time window in the construction of a dynamic FC network. To investigate the effects of the sliding time window length on the classification performance of our proposed CRNN, we set the parameters <italic>L</italic> to 30, 50, and 70 for classification, respectively. In <xref rid="F9" ref-type="fig">Figure 9</xref>, we report the classification accuracy of the CRNN method under different <italic>L</italic> values on two binary classification tasks and one four-class classification task (i.e., eMCI vs. NC group, AD vs. NC group, and AD vs. lMCI vs. eMCI vs. NC group), respectively. At the same time, we also report the classification accuracy of CNN using different sliding window lengths.</p>
        <fig position="float" id="F9">
          <label>Figure 9</label>
          <caption>
            <p>Classification accuracy of the CRNN and CNN methods using different lengths of sliding windows in three tasks: <bold>(A)</bold> eMCI vs. NC classification, <bold>(B)</bold> AD vs. NC classification, and <bold>(C)</bold> AD vs. lMCI vs. eMCI vs. NC classification.</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0009" position="float"/>
        </fig>
        <p>As shown in <xref rid="F9" ref-type="fig">Figure 9</xref>, for all given parameter values, our proposed CRNN method outperforms CNN on the three classification tasks, which further illustrates the effectiveness of the sequential features extracted by our method. In addition, the classification accuracy of the proposed CRNN on the three classification tasks is not greatly affected by the different values of <italic>L</italic>, which shows that our method has strong robustness and stability.</p>
        <p>Furthermore, in order to evaluate the effect of stride size on the classification of our proposed CRNN, we fix the sliding window length <italic>L</italic> = 70, and set the parameters <italic>S</italic> to 2, 4, and 6 for classification. <xref rid="F10" ref-type="fig">Figure 10</xref> illustrates the obtained accuracies of our CRNN method with three <italic>S</italic> values on three classification tasks. From <xref rid="F10" ref-type="fig">Figure 10</xref>, the curve of the accuracy of our proposed CRNN method with different values of <italic>S</italic> is very smooth on the three classification tasks, indicating the robustness of our proposed CRNN method for different <italic>S</italic> values.</p>
        <fig position="float" id="F10">
          <label>Figure 10</label>
          <caption>
            <p>Accuracy of the proposed CRNN method with different stride sizes on three classification tasks (i.e., eMCI vs. NC, AD vs. NC, and AD vs. lMCI vs. eMCI vs. NC classifications).</p>
          </caption>
          <graphic xlink:href="fnins-16-933660-g0010" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>5.2. Temporal Dynamic Analysis</title>
        <p>Previous studies have shown that rs-fMRI scan data is the synchronous fluctuation of the BOLD signal in the internal functional network of the entire brain (Lee et al., <xref rid="B29" ref-type="bibr">2013</xref>), which has a high degree of temporal correlation. On the other hand, an LSTM with a chain of repeated neural network modules can analyze sequential information and learn long-term dependencies. From the perspective of model training, LSTM can effectively solve the problem of gradient explosion or gradient disappearance by using several gating units to control information flow. Based on the above reasons, we use LSTM to analyze the brain network, learn the sequential characteristics of the dynamic FC network, and use it for the classification of AD-related brain diseases.</p>
        <p>From <xref rid="F9" ref-type="fig">Figure 9</xref> and <xref rid="T2" ref-type="table">Tables 2</xref>, <xref rid="T3" ref-type="table">3</xref>, compared with CNN, our proposed CRNN method can obtain better classification performance. This also proves that learning sequential features through LSTM (as we do in CRNN) helps boost the classification performance. The possible reason could be that LSTM is able to model the underlying relationship between the time series of each subject and make decisions based on all time points instead of each single time point.</p>
      </sec>
      <sec>
        <title>5.3. Limitations and Future Study</title>
        <p>Several limitations need to be considered. <italic>First</italic>, we focus on using only rs-fMRI time series data to automatically identify AD/MCI in this study. In fact, different imaging methods (e.g., structural MRI and PET) can provide complementary information for disease diagnosis. The use of multi-modal information for brain network analysis will be our future work. <italic>Second</italic>, the construction of dynamic FC networks is independent of feature learning and classifier training, which may affect the prediction performance. It is interesting to integrate dynamic FC network construction, network feature learning, and classification into to unified framework. <italic>Furthermore</italic>, even though we used all rs-fMRI scans from all subjects of ADNI, the sample size in this work is still limited. In future study, we will evaluate the proposed method on a larger data set, such as attention deficit hyperactivity disorder (ADHD) with rs-fMRI data.</p>
      </sec>
    </sec>
    <sec sec-type="conclusions" id="s6">
      <title>6. Conclusion</title>
      <p>In this article, we developed a convolutional recurrent neural network (CRNN) for dynamic analysis of rs-fMRI time series data and automated diagnosis of AD-related brain diseases. In CRNN, we first construct dynamic functional connectivity (dFC) networks for each subject using an overlapping sliding time window strategy. These dFC networks are then fed into three convolutional layers for extracting the temporal features and an LSTM layer to capture the sequential information of temporal features along multiple time periods, followed by three fully connected layers for classification. Experimental results on 174 subjects with rs-fMRI from ADNI demonstrate the effectiveness of the proposed CRNN method in two binary classifications and one multi-class classification task.</p>
    </sec>
    <sec sec-type="data-availability" id="s7">
      <title>Data Availability Statement</title>
      <p>Publicly available datasets were analyzed in this study. This data can be found here: Alzheimer's Disease Neuroimaging Initiative (ADNI) database (<ext-link xlink:href="https://adni.loni.usc.edu" ext-link-type="uri">https://adni.loni.usc.edu</ext-link>).</p>
    </sec>
    <sec id="s8">
      <title>Ethics Statement</title>
      <p>Ethical review and approval was not required for the study on human participants in accordance with the local legislation and institutional requirements. Written informed consent for participation was not required for this study in accordance with the national legislation and the institutional requirements.</p>
    </sec>
    <sec id="s9">
      <title>Author Contributions</title>
      <p>KL, BJ, and PD contributed to the conception and design of the study. BJ organized the database. KL performed the experimental analysis and wrote the first draft of the manuscript. PD, XD, WB, and ML wrote sections of the manuscript. All authors contributed to manuscript revision, read, and approved the submitted version.</p>
    </sec>
    <sec sec-type="funding-information" id="s10">
      <title>Funding</title>
      <p>KL, BJ, PD, XD, and WB were supported in part by NSFC (Nos. 61976006, 61573023, and 61902003), Anhui-NSFC (Nos. 1708085MF145 and 1808085MF171), and AHNU-FOYHE (No. gxyqZD2017010).</p>
    </sec>
    <sec sec-type="COI-statement" id="conf1">
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. The reviewer JH declared a past co-authorship with the authors BJ and ML to the handling editor.</p>
    </sec>
    <sec sec-type="disclaimer" id="s11">
      <title>Publisher's Note</title>
      <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
    </sec>
  </body>
  <back>
    <fn-group>
      <fn id="fn0001">
        <p>
<sup>1</sup>
<ext-link xlink:href="http://adni.loni.usc.edu/" ext-link-type="uri">http://adni.loni.usc.edu/</ext-link>
</p>
      </fn>
    </fn-group>
    <sec sec-type="supplementary-material" id="s12">
      <title>Supplementary Material</title>
      <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fnins.2022.933660/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fnins.2022.933660/full#supplementary-material</ext-link></p>
      <supplementary-material id="SM1" position="float" content-type="local-data">
        <media xlink:href="Data_Sheet_1.PDF">
          <caption>
            <p>Click here for additional data file.</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akkus</surname><given-names>Z.</given-names></name><name><surname>Galimzianova</surname><given-names>A.</given-names></name><name><surname>Hoogi</surname><given-names>A.</given-names></name><name><surname>Rubin</surname><given-names>D. L.</given-names></name><name><surname>Erickson</surname><given-names>B. J.</given-names></name></person-group> (<year>2017</year>). <article-title>Deep learning for brain MRI segmentation: state of the art and future directions</article-title>. <source>J. Digit. Imaging</source>
<volume>30</volume>, <fpage>449</fpage>â<lpage>459</lpage>. <pub-id pub-id-type="doi">10.1007/s10278-017-9983-4</pub-id><pub-id pub-id-type="pmid">28577131</pub-id></mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>J. S.</given-names></name><name><surname>Nielsen</surname><given-names>J. A.</given-names></name><name><surname>Froehlich</surname><given-names>A. L.</given-names></name><name><surname>DuBray</surname><given-names>M. B.</given-names></name><name><surname>Druzgal</surname><given-names>T. J.</given-names></name><name><surname>Cariello</surname><given-names>A. N.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Functional connectivity magnetic resonance imaging classification of autism</article-title>. <source>Brain</source>
<volume>134</volume>, <fpage>3742</fpage>â<lpage>3754</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awr263</pub-id><pub-id pub-id-type="pmid">22006979</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Association</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>2016 alzheimer's disease facts and figures</article-title>. <source>Alzheimer's &amp;Dementia</source>
<volume>12</volume>, <fpage>459</fpage>â<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1016/j.jalz.2016.03.001</pub-id><pub-id pub-id-type="pmid">27570871</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>F.</given-names></name><name><surname>Watson</surname><given-names>D. R.</given-names></name><name><surname>Yu</surname><given-names>H.</given-names></name><name><surname>Shi</surname><given-names>Y.</given-names></name><name><surname>Yuan</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name></person-group> (<year>2009</year>). <article-title>Abnormal resting-state functional connectivity of posterior cingulate cortex in amnestic type mild cognitive impairment</article-title>. <source>Brain Res</source>. <volume>1302</volume>, <fpage>167</fpage>â<lpage>174</lpage>. <pub-id pub-id-type="doi">10.1016/j.brainres.2009.09.028</pub-id><pub-id pub-id-type="pmid">19765560</pub-id></mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bechara</surname><given-names>A.</given-names></name><name><surname>Damasio</surname><given-names>H.</given-names></name><name><surname>Damasio</surname><given-names>A. R.</given-names></name></person-group> (<year>2000</year>). <article-title>Emotion, decision making and the orbitofrontal cortex</article-title>. <source>Cereb. Cortex</source>
<volume>10</volume>, <fpage>295</fpage>â<lpage>307</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/10.3.295</pub-id><pub-id pub-id-type="pmid">10731224</pub-id></mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bokde</surname><given-names>A. L. W.</given-names></name><name><surname>Lopez-Bayo</surname><given-names>P.</given-names></name><name><surname>Meindl</surname><given-names>T.</given-names></name><name><surname>Pechler</surname><given-names>S.</given-names></name><name><surname>Born</surname><given-names>C.</given-names></name><name><surname>Faltraco</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>Functional connectivity of the fusiform gyrus during a face-matching task in subjects with mild cognitive impairment</article-title>. <source>Brain</source>
<volume>129</volume>, <fpage>1113</fpage>â<lpage>1124</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awl051</pub-id><pub-id pub-id-type="pmid">16520329</pub-id></mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boveiri</surname><given-names>H. R.</given-names></name><name><surname>Khayami</surname><given-names>R.</given-names></name><name><surname>Javidan</surname><given-names>R.</given-names></name><name><surname>Mehdizadeh</surname><given-names>A.</given-names></name></person-group> (<year>2020</year>). <article-title>Medical image registration using deep neural networks: a comprehensive review</article-title>. <source>Comput. Electr. Eng</source>. <volume>87</volume>, <fpage>106767</fpage>. <pub-id pub-id-type="doi">10.1016/j.compeleceng.2020.106767</pub-id></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brier</surname><given-names>M. R.</given-names></name><name><surname>Thomas</surname><given-names>J. B.</given-names></name><name><surname>Fagan</surname><given-names>A. M.</given-names></name><name><surname>Hassenstab</surname><given-names>J.</given-names></name><name><surname>Holtzman</surname><given-names>D. M.</given-names></name><name><surname>Benzinger</surname><given-names>T. L.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Functional connectivity and graph theory in preclinical Alzheimer's disease</article-title>. <source>Neurobiol. Aging</source>
<volume>35</volume>, <fpage>757</fpage>â<lpage>768</lpage>. <pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2013.10.081</pub-id><pub-id pub-id-type="pmid">24216223</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C.</given-names></name><name><surname>Glover</surname><given-names>G. H.</given-names></name></person-group> (<year>2010</year>). <article-title>Time-frequency dynamics of resting-state brain connectivity measured with fmri</article-title>. <source>Neuroimage</source>
<volume>50</volume>, <fpage>81</fpage>â<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.011</pub-id><pub-id pub-id-type="pmid">20006716</pub-id></mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Chen</surname><given-names>M. C.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Duyn</surname><given-names>J. H.</given-names></name></person-group> (<year>2013</year>). <article-title>EEG correlates of time-varying BOLD functional connectivity</article-title>. <source>Neuroimage</source>
<volume>72</volume>, <fpage>227</fpage>â<lpage>236</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.01.049</pub-id><pub-id pub-id-type="pmid">23376790</pub-id></mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>G.</given-names></name><name><surname>Ward</surname><given-names>B. D.</given-names></name><name><surname>Xie</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Jones</surname><given-names>J. L.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Classification of alzheimer disease, mild cognitive impairment, and normal cognitive status with large-scale network analysis based on resting-state functional mr imaging</article-title>. <source>Radiology</source>
<volume>259</volume>, <fpage>213</fpage>â<lpage>221</lpage>. <pub-id pub-id-type="doi">10.1148/radiol.10100734</pub-id><pub-id pub-id-type="pmid">21248238</pub-id></mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>C.</given-names></name><name><surname>Lee</surname><given-names>S.-W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>Extraction of dynamic functional connectivity from brain grey matter and white matter for mci classification</article-title>. <source>Hum. Brain Mapp</source>. <volume>38</volume>, <fpage>5019</fpage>â<lpage>5034</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23711</pub-id><pub-id pub-id-type="pmid">28665045</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daianu</surname><given-names>M.</given-names></name><name><surname>Jahanshad</surname><given-names>N.</given-names></name><name><surname>Nir</surname><given-names>T. M.</given-names></name><name><surname>Toga</surname><given-names>A. W.</given-names></name><name><surname>Jack</surname><given-names>C. R.</given-names></name><name><surname>Weiner</surname><given-names>M. W.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Breakdown of brain connectivity between normal aging and alzheimer's disease: a structural k-core network analysis</article-title>. <source>Brain Connect</source>. <volume>3</volume>, <fpage>407</fpage>â<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1089/brain.2012.0137</pub-id><pub-id pub-id-type="pmid">23701292</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deepak</surname><given-names>S.</given-names></name><name><surname>Ameer</surname><given-names>P.</given-names></name></person-group> (<year>2019</year>). <article-title>Brain tumor classification using deep cnn features via transfer learning</article-title>. <source>Comput. Biol. Med</source>. <volume>111</volume>, <fpage>103345</fpage>. <pub-id pub-id-type="doi">10.1016/j.compbiomed.2019.103345</pub-id><pub-id pub-id-type="pmid">31279167</pub-id></mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gan</surname><given-names>J.</given-names></name><name><surname>Peng</surname><given-names>Z.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Hu</surname><given-names>R.</given-names></name><name><surname>Ma</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>G.</given-names></name></person-group> (<year>2021</year>). <article-title>Brain functional connectivity analysis based on multi-graph fusion</article-title>. <source>Med. Image Anal</source>. <volume>71</volume>, <fpage>102057</fpage>. <pub-id pub-id-type="doi">10.1016/j.media.2021.102057</pub-id><pub-id pub-id-type="pmid">33957559</pub-id></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>T.</given-names></name><name><surname>Kong</surname><given-names>R.</given-names></name><name><surname>Holmes</surname><given-names>A. J.</given-names></name><name><surname>Nguyen</surname><given-names>M.</given-names></name><name><surname>Sabuncu</surname><given-names>M. R.</given-names></name><name><surname>Eickhoff</surname><given-names>S. B.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Deep neural networks and kernel regression achieve comparable accuracies for functional connectivity prediction of behavior and demographics</article-title>. <source>Neuroimage</source>
<volume>206</volume>, <fpage>116276</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116276</pub-id><pub-id pub-id-type="pmid">31610298</pub-id></mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Qin</surname><given-names>P.</given-names></name><name><surname>Wu</surname><given-names>X.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Decoupled temporal variability and signal synchronization of spontaneous brain activity in loss of consciousness: an fmri study in anesthesia</article-title>. <source>Neuroimage</source>
<volume>124</volume>, <fpage>693</fpage>â<lpage>703</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.08.062</pub-id><pub-id pub-id-type="pmid">26343319</pub-id></mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchison</surname><given-names>R. M.</given-names></name><name><surname>Womelsdorf</surname><given-names>T.</given-names></name><name><surname>Allen</surname><given-names>E. A.</given-names></name><name><surname>Bandettini</surname><given-names>P. A.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Corbetta</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Dynamic functional connectivity: promise, issues, and interpretations</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>360</fpage>â<lpage>378</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.079</pub-id><pub-id pub-id-type="pmid">23707587</pub-id></mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Lian</surname><given-names>C.</given-names></name><name><surname>Shi</surname><given-names>F.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Designing weighted correlation kernels in convolutional neural networks for functional connectivity based brain disease diagnosis</article-title>. <source>Med. Image Anal</source>. <volume>63</volume>, <fpage>1</fpage>â<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2020.101709</pub-id><pub-id pub-id-type="pmid">32417715</pub-id></mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>Integration of temporal and spatial properties of dynamic connectivity networks for automatic diagnosis of brain disease</article-title>. <source>Med. Image Anal</source>. <volume>47</volume>, <fpage>81</fpage>â<lpage>94</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2018.03.013</pub-id><pub-id pub-id-type="pmid">29702414</pub-id></mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>Hyper-connectivity of functional networks for brain disease diagnosis</article-title>. <source>Med. Image Anal</source>. <volume>32</volume>, <fpage>84</fpage>â<lpage>100</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2016.03.003</pub-id><pub-id pub-id-type="pmid">27060621</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Gao</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2013</year>). <article-title>Integration of network topological and connectivity properties for neuroimaging classification</article-title>. <source>IEEE Trans. Biomed. Eng</source>. <volume>61</volume>, <fpage>576</fpage>â<lpage>589</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2013.2284195</pub-id><pub-id pub-id-type="pmid">24108708</pub-id></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jie</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2014</year>). <article-title>Topological graph kernel on multiple thresholded functional connectivity networks for mild cognitive impairment classification</article-title>. <source>Hum. Brain Mapp</source>. <volume>35</volume>, <fpage>2876</fpage>â<lpage>2897</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22353</pub-id><pub-id pub-id-type="pmid">24038749</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>D. T.</given-names></name><name><surname>Vemuri</surname><given-names>P.</given-names></name><name><surname>Murphy</surname><given-names>M. C.</given-names></name><name><surname>Gunter</surname><given-names>J. L.</given-names></name><name><surname>Senjem</surname><given-names>M. L.</given-names></name><name><surname>Machulda</surname><given-names>M. M.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Non-stationarity in the âresting brain'sâ modular architecture</article-title>. <source>PLoS ONE</source>
<volume>7</volume>, <fpage>e399731</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0039731</pub-id><pub-id pub-id-type="pmid">22761880</pub-id></mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ju</surname><given-names>R.</given-names></name><name><surname>Hu</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>Q.</given-names></name></person-group> (<year>2017</year>). <article-title>Early diagnosis of alzheimer's disease based on resting-state brain networks and deep learning</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinform</source>. <volume>16</volume>, <fpage>244</fpage>â<lpage>257</lpage>. <pub-id pub-id-type="doi">10.1109/TCBB.2017.2776910</pub-id><pub-id pub-id-type="pmid">29989989</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaiser</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>A tutorial in connectome analysis: Topological and spatial features of brain networks</article-title>. <source>Neuroimage</source>
<volume>57</volume>, <fpage>892</fpage>â<lpage>907</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.05.025</pub-id><pub-id pub-id-type="pmid">21605688</pub-id></mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawahara</surname><given-names>J.</given-names></name><name><surname>Brown</surname><given-names>C. J.</given-names></name><name><surname>Miller</surname><given-names>S. P.</given-names></name><name><surname>Booth</surname><given-names>B. G.</given-names></name><name><surname>Chau</surname><given-names>V.</given-names></name><name><surname>Grunau</surname><given-names>R. E.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>BrainNetCNN: convolutional neural networks for brain networks; towards predicting neurodevelopment</article-title>. <source>Neuroimage</source>
<volume>146</volume>, <fpage>1038</fpage>â<lpage>1049</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.09.046</pub-id><pub-id pub-id-type="pmid">27693612</pub-id></mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2015</year>). <article-title>Deep learning</article-title>. <source>Nature</source>
<volume>521</volume>, <fpage>436</fpage>â<lpage>444</lpage>. <pub-id pub-id-type="doi">10.1038/nature14539</pub-id><pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Smyser</surname><given-names>C.</given-names></name><name><surname>Shimony</surname><given-names>J.</given-names></name></person-group> (<year>2013</year>). <article-title>Resting-state fmri: a review of methods and clinical applications</article-title>. <source>Am. J. Neuroradiol</source>. <volume>34</volume>, <fpage>1866</fpage>â<lpage>1872</lpage>. <pub-id pub-id-type="doi">10.3174/ajnr.A3263</pub-id><pub-id pub-id-type="pmid">22936095</pub-id></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>K.</given-names></name><name><surname>Chunshui</surname><given-names>Y.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Liang</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Regional homogeneity, functional connectivity and imaging markers of alzheimer's disease: a review of resting-state fmri studies</article-title>. <source>Neuropsychologia</source>
<volume>46</volume>, <fpage>1648</fpage>â<lpage>1656</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.01.027</pub-id><pub-id pub-id-type="pmid">18346763</pub-id></mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MeszlÃ©nyi</surname><given-names>R. J.</given-names></name><name><surname>Buza</surname><given-names>K.</given-names></name><name><surname>VidnyÃ¡nszky</surname><given-names>Z.</given-names></name></person-group> (<year>2017</year>). <article-title>Resting state fMRI functional connectivity-based classification using a convolutional neural network architecture</article-title>. <source>Front. Neuroinform</source>. <volume>11</volume>, <fpage>61</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2017.00061</pub-id><pub-id pub-id-type="pmid">29089883</pub-id></mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Milletari</surname><given-names>F.</given-names></name><name><surname>Navab</surname><given-names>N.</given-names></name><name><surname>Ahmadi</surname><given-names>S.-A.</given-names></name></person-group> (<year>2016</year>). <article-title>âV-net: fully convolutional neural networks for volumetric medical image segmentation,â</article-title> in <source>2016 Fourth International Conference on 3D Vision (3DV)</source> (<publisher-loc>Stanford, CA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>565</fpage>â<lpage>571</lpage>.</mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nussbaum</surname><given-names>R. L.</given-names></name><name><surname>Ellis</surname><given-names>C. E.</given-names></name></person-group> (<year>2003</year>). <article-title>Alzheimer's disease and parkinson's disease</article-title>. <source>N. Engl. J. Med</source>. <volume>348</volume>, <fpage>1356</fpage>â<lpage>1364</lpage>. <pub-id pub-id-type="doi">10.1056/NEJM2003ra020003</pub-id><pub-id pub-id-type="pmid">12672864</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozker</surname><given-names>M.</given-names></name><name><surname>Doyle</surname><given-names>W.</given-names></name><name><surname>Devinsky</surname><given-names>O.</given-names></name><name><surname>Flinker</surname><given-names>A.</given-names></name></person-group> (<year>2022</year>). <article-title>A cortical network processes auditory error signals during human speech production to maintain fluency</article-title>. <source>PLoS Biol</source>. <volume>20</volume>, <fpage>e3001493</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.3001493</pub-id><pub-id pub-id-type="pmid">35113857</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>R. C.</given-names></name><name><surname>Doody</surname><given-names>R.</given-names></name><name><surname>Kurz</surname><given-names>A.</given-names></name><name><surname>Mohs</surname><given-names>R. C.</given-names></name><name><surname>Morris</surname><given-names>J. C.</given-names></name><name><surname>Rabins</surname><given-names>P. V.</given-names></name><etal/></person-group>. (<year>2001</year>). <article-title>Current concepts in mild cognitive impairment</article-title>. <source>Arch. Neurol</source>. <volume>58</volume>, <fpage>1985</fpage>â<lpage>1992</lpage>. <pub-id pub-id-type="doi">10.1001/archneur.58.12.1985</pub-id><pub-id pub-id-type="pmid">11735772</pub-id></mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Chen</surname><given-names>S.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>Data-driven graph construction and graph learning: a review</article-title>. <source>Neurocomputing</source>
<volume>312</volume>, <fpage>336</fpage>â<lpage>351</lpage>. <pub-id pub-id-type="doi">10.1016/j.neucom.2018.05.084</pub-id></mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>E. T.</given-names></name></person-group> (<year>2004</year>). <article-title>The functions of the orbitofrontal cortex</article-title>. <source>Brain Cogn</source>. <volume>55</volume>, <fpage>11</fpage>â<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1016/S0278-2626(03)00277-X</pub-id><pub-id pub-id-type="pmid">15134840</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sainath</surname><given-names>T. N.</given-names></name><name><surname>Vinyals</surname><given-names>O.</given-names></name><name><surname>Senior</surname><given-names>A.</given-names></name><name><surname>Sak</surname><given-names>H.</given-names></name></person-group> (<year>2015</year>). <article-title>âConvolutional, long short-term memory, fully connected deep neural networks,â</article-title> in <source>2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</source> (<publisher-loc>South Brisbane, QLD</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>4580</fpage>â<lpage>4584</lpage>.</mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakoglu</surname><given-names>U.</given-names></name><name><surname>Michael</surname><given-names>A.</given-names></name><name><surname>Calhoun</surname><given-names>V.</given-names></name></person-group> (<year>2009</year>). <article-title>Classification of schizophrenia patients vs healthy controls with dynamic functional network connectivity</article-title>. <source>Neuroimage</source>
<volume>47</volume>, <fpage>S39</fpage>-S41. <pub-id pub-id-type="doi">10.1016/S1053-8119(09)70216-2</pub-id><pub-id pub-id-type="pmid">33317408</pub-id></mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>SakoÄlu</surname><given-names>Ã.</given-names></name><name><surname>Pearlson</surname><given-names>G. D.</given-names></name><name><surname>Kiehl</surname><given-names>K. A.</given-names></name><name><surname>Wang</surname><given-names>Y. M.</given-names></name><name><surname>Michael</surname><given-names>A. M.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name></person-group> (<year>2010</year>). <article-title>A method for evaluating dynamic functional network connectivity and task-modulation: application to schizophrenia</article-title>. <source>Magn. Reson. Mater. Phys. Biol. Med</source>. <volume>23</volume>, <fpage>351</fpage>â<lpage>366</lpage>. <pub-id pub-id-type="doi">10.1007/s10334-010-0197-8</pub-id><pub-id pub-id-type="pmid">20162320</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>D.</given-names></name></person-group> (<year>2010</year>). <article-title>Discriminative analysis of resting-state functional connectivity patterns of schizophrenia using low dimensional embedding of fMRI</article-title>. <source>Neuroimage</source>
<volume>49</volume>, <fpage>3110</fpage>â<lpage>3121</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.11.011</pub-id><pub-id pub-id-type="pmid">19931396</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>W.</given-names></name><name><surname>Zhou</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>F.</given-names></name><name><surname>Yang</surname><given-names>C.</given-names></name><name><surname>Tian</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>Multi-scale convolutional neural networks for lung nodule classification</article-title>. <source>Inf. Process. Med. Imaging</source>
<volume>24</volume>, <fpage>588</fpage>â<lpage>599</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-19992-4_46</pub-id><pub-id pub-id-type="pmid">26221705</pub-id></mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sporns</surname><given-names>O.</given-names></name></person-group> (<year>2011</year>). <article-title>The human connectome: a complex network</article-title>. <source>Ann. N. Y. Acad. Sci</source>. <volume>1224</volume>, <fpage>109</fpage>â<lpage>125</lpage>. <pub-id pub-id-type="doi">10.1111/j.1749-6632.2010.05888.x</pub-id><pub-id pub-id-type="pmid">21251014</pub-id></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stam</surname><given-names>C.</given-names></name><name><surname>De Haan</surname><given-names>W.</given-names></name><name><surname>Daffertshofer</surname><given-names>A.</given-names></name><name><surname>Jones</surname><given-names>B.</given-names></name><name><surname>Manshanden</surname><given-names>I.</given-names></name><name><surname>van Cappellen van Walsum</surname><given-names>A.-M.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>Graph theoretical analysis of magnetoencephalographic functional connectivity in Alzheimer's disease</article-title>. <source>Brain</source>
<volume>132</volume>, <fpage>213</fpage>â<lpage>224</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awn262</pub-id><pub-id pub-id-type="pmid">18952674</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Supekar</surname><given-names>K.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name><name><surname>Rubin</surname><given-names>D.</given-names></name><name><surname>Musen</surname><given-names>M.</given-names></name><name><surname>Greicius</surname><given-names>M. D.</given-names></name></person-group> (<year>2008</year>). <article-title>Network analysis of intrinsic functional brain connectivity in Alzheimer's disease</article-title>. <source>PLoS Comput. Biol</source>. <volume>4</volume>, <fpage>e1000100</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000100</pub-id><pub-id pub-id-type="pmid">18584043</pub-id></mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tarawneh</surname><given-names>R.</given-names></name><name><surname>Holtzman</surname><given-names>D. M.</given-names></name></person-group> (<year>2012</year>). <article-title>The clinical problem of symptomatic alzheimer disease and mild cognitive impairment</article-title>. <source>Cold Spring Harb Perspect. Med</source>. <volume>2</volume>, <fpage>a006148</fpage>. <pub-id pub-id-type="doi">10.1101/cshperspect.a006148</pub-id><pub-id pub-id-type="pmid">22553492</pub-id></mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomann</surname><given-names>P. A.</given-names></name><name><surname>SchlÃ¤fer</surname><given-names>C.</given-names></name><name><surname>Seidl</surname><given-names>U.</given-names></name><name><surname>Santos</surname><given-names>V. D.</given-names></name><name><surname>Essig</surname><given-names>M.</given-names></name><name><surname>SchrÃ¶der</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). <article-title>The cerebellum in mild cognitive impairment and alzheimer's disease-a structural mri study</article-title>. <source>J. Psychiatr. Res</source>. <volume>42</volume>, <fpage>1198</fpage>â<lpage>1202</lpage>. <pub-id pub-id-type="doi">10.1016/j.jpsychires.2007.12.002</pub-id><pub-id pub-id-type="pmid">18215400</pub-id></mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>G. J.</given-names></name><name><surname>Magnuson</surname><given-names>M. E.</given-names></name><name><surname>Merritt</surname><given-names>M. D.</given-names></name><name><surname>Schwarb</surname><given-names>H.</given-names></name><name><surname>Pan</surname><given-names>W.-J.</given-names></name><name><surname>McKinley</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Short-time windows of correlation between large-scale functional brain networks predict vigilance intraindividually and interindividually</article-title>. <source>Hum. Brain Mapp</source>. <volume>34</volume>, <fpage>3280</fpage>â<lpage>3298</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22140</pub-id><pub-id pub-id-type="pmid">22736565</pub-id></mixed-citation>
      </ref>
      <ref id="B49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>P. M.</given-names></name><name><surname>Hayashi</surname><given-names>K. M.</given-names></name><name><surname>de Zubicaray</surname><given-names>G.</given-names></name><name><surname>Janke</surname><given-names>A. L.</given-names></name><name><surname>Rose</surname><given-names>S. E.</given-names></name><name><surname>Semple</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2003</year>). <article-title>Dynamics of gray matter loss in Alzheimer's disease</article-title>. <source>J. Neurosci</source>. <volume>23</volume>, <fpage>994</fpage>â<lpage>1005</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-03-00994.2003</pub-id><pub-id pub-id-type="pmid">12574429</pub-id></mixed-citation>
      </ref>
      <ref id="B50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Heuvel</surname><given-names>M. P.</given-names></name><name><surname>Hulshoff Pol</surname><given-names>H. E.</given-names></name></person-group> (<year>2010</year>). <article-title>Exploring the brain network: a review on resting-state fmri functional connectivity</article-title>. <source>Eur. Neuropsychopharmacol</source>. <volume>20</volume>, <fpage>519</fpage>â<lpage>534</lpage>. <pub-id pub-id-type="doi">10.1016/j.euroneuro.2010.03.008</pub-id><pub-id pub-id-type="pmid">20471808</pub-id></mixed-citation>
      </ref>
      <ref id="B51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>El-Fiqi</surname><given-names>H.</given-names></name><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Abbass</surname><given-names>H. A.</given-names></name></person-group> (<year>2019a</year>). <article-title>Convolutional neural networks using dynamic functional connectivity for eeg-based person identification in diverse human states</article-title>. <source>IEEE Trans. Inf. Forensics Security</source>
<volume>14</volume>, <fpage>3259</fpage>â<lpage>3272</lpage>. <pub-id pub-id-type="doi">10.1109/TIFS.2019.2916403</pub-id></mixed-citation>
      </ref>
      <ref id="B52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Lian</surname><given-names>C.</given-names></name><name><surname>Yao</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2019b</year>). <article-title>Spatial-temporal dependency modeling and network hub detection for functional MRI analysis via convolutional-recurrent network</article-title>. <source>IEEE Trans. Biomed. Eng</source>. <volume>67</volume>, <fpage>2241</fpage>â<lpage>2252</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2019.2957921</pub-id><pub-id pub-id-type="pmid">31825859</pub-id></mixed-citation>
      </ref>
      <ref id="B53">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Yap</surname><given-names>P.-T.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2019c</year>). <article-title>Identifying autism spectrum disorder with multi-site fMRI via low-rank domain adaptation</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>39</volume>, <fpage>644</fpage>â<lpage>655</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2019.2933160</pub-id><pub-id pub-id-type="pmid">31395542</pub-id></mixed-citation>
      </ref>
      <ref id="B54">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Yang</surname><given-names>S.</given-names></name><name><surname>Yap</surname><given-names>P.-T.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Initiative</surname><given-names>A. D. N.</given-names></name></person-group> (<year>2016</year>). <article-title>Sparse temporally dynamic resting-state functional connectivity networks for early mci identification</article-title>. <source>Brain Imaging Behav</source>. <volume>10</volume>, <fpage>342</fpage>â<lpage>356</lpage>. <pub-id pub-id-type="doi">10.1007/s11682-015-9408-2</pub-id><pub-id pub-id-type="pmid">26123390</pub-id></mixed-citation>
      </ref>
      <ref id="B55">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Yap</surname><given-names>P.-T.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Denny</surname><given-names>K.</given-names></name><name><surname>Browndyke</surname><given-names>J. N.</given-names></name><name><surname>Potter</surname><given-names>G. G.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Identification of mci individuals using structural and functional connectivity networks</article-title>. <source>Neuroimage</source>
<volume>59</volume>, <fpage>2045</fpage>â<lpage>2056</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.015</pub-id><pub-id pub-id-type="pmid">22019883</pub-id></mixed-citation>
      </ref>
      <ref id="B56">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Rekik</surname><given-names>I.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Combining disrupted and discriminative topological properties of functional connectivity networks as neuroimaging biomarkers for accurate diagnosis of early tourette syndrome children</article-title>. <source>Mol. Neurobiol</source>. <volume>55</volume>, <fpage>3251</fpage>â<lpage>3269</lpage>. <pub-id pub-id-type="doi">10.1007/s12035-017-0519-1</pub-id><pub-id pub-id-type="pmid">28478510</pub-id></mixed-citation>
      </ref>
      <ref id="B57">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>J.</given-names></name><name><surname>Thibeau-Sutre</surname><given-names>E.</given-names></name><name><surname>Diaz-Melo</surname><given-names>M.</given-names></name><name><surname>Samper-GonzÃ¡lez</surname><given-names>J.</given-names></name><name><surname>Routier</surname><given-names>A.</given-names></name><name><surname>Bottani</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Convolutional neural networks for classification of Alzheimer's disease: overview and reproducible evaluation</article-title>. <source>Med. Image Anal</source>. <volume>63</volume>, <fpage>101694</fpage>. <pub-id pub-id-type="doi">10.1016/j.media.2020.101694</pub-id><pub-id pub-id-type="pmid">32417716</pub-id></mixed-citation>
      </ref>
      <ref id="B58">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>An</surname><given-names>N.</given-names></name><name><surname>Wang</surname><given-names>P.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Decreased functional connectivity of the amygdala in Alzheimer's disease revealed by resting-state fmri</article-title>. <source>Eur. J. Radiol</source>. <volume>82</volume>, <fpage>1531</fpage>â<lpage>1538</lpage>. <pub-id pub-id-type="doi">10.1016/j.ejrad.2013.03.019</pub-id><pub-id pub-id-type="pmid">23643516</pub-id></mixed-citation>
      </ref>
      <ref id="B59">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zanin</surname><given-names>M.</given-names></name><name><surname>Sousa</surname><given-names>P.</given-names></name><name><surname>Papo</surname><given-names>D.</given-names></name><name><surname>Bajo</surname><given-names>R.</given-names></name><name><surname>Garcia-Prieto</surname><given-names>J.</given-names></name><name><surname>del Pozo</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Optimizing functional network representation of multivariate time series</article-title>. <source>Sci. Rep</source>. <volume>2</volume>, <fpage>1</fpage>â<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1038/srep00630</pub-id><pub-id pub-id-type="pmid">22953051</pub-id></mixed-citation>
      </ref>
      <ref id="B60">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>L.-L.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Hu</surname><given-names>P.</given-names></name><name><surname>Yang</surname><given-names>B.</given-names></name><name><surname>Pu</surname><given-names>W.</given-names></name><name><surname>Shen</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Multi-site diagnostic classification of schizophrenia using discriminant deep learning with functional connectivity mri</article-title>. <source>EBioMedicine</source>
<volume>30</volume>, <fpage>74</fpage>â<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1016/j.ebiom.2018.03.017</pub-id><pub-id pub-id-type="pmid">29622496</pub-id></mixed-citation>
      </ref>
      <ref id="B61">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Cheng</surname><given-names>W.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>K.</given-names></name><name><surname>Lei</surname><given-names>X.</given-names></name><name><surname>Yao</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Neural, electrophysiological and anatomical basis of brain-network variability and its characteristic changes in mental disorders</article-title>. <source>Brain</source>
<volume>139</volume>, <fpage>2307</fpage>â<lpage>2321</lpage>. <pub-id pub-id-type="doi">10.1093/brain/aww143</pub-id><pub-id pub-id-type="pmid">27421791</pub-id></mixed-citation>
      </ref>
      <ref id="B62">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>A survey on deep learning for neuroimaging-based brain disorder analysis</article-title>. <source>Front. Neurosci</source>. <volume>14</volume>, <fpage>779</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2020.00779</pub-id><pub-id pub-id-type="pmid">33117114</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
