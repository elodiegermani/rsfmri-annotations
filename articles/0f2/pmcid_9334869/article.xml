<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Hum Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Hum Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Hum. Neurosci.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Human Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1662-5161</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">35911592</article-id>
      <article-id pub-id-type="pmc">9334869</article-id>
      <article-id pub-id-type="doi">10.3389/fnhum.2022.918969</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Multi-View Feature Enhancement Based on Self-Attention Mechanism Graph Convolutional Network for Autism Spectrum Disorder Diagnosis</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Feng</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/429030/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Na</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>Hongxin</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Xiaobo</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/462681/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Yuan</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">
<sup>2</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Haicheng</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Mao</surname>
            <given-names>Ning</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">
<sup>3</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/513893/overview"/>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <name>
            <surname>Cheng</surname>
            <given-names>Dapeng</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">
<sup>1</sup>
</xref>
          <xref rid="c001" ref-type="corresp">
<sup>*</sup>
</xref>
          <uri xlink:href="http://loop.frontiersin.org/people/1252029/overview"/>
        </contrib>
      </contrib-group>
      <aff id="aff1"><sup>1</sup><institution>School of Computer Science and Technology, Shandong Technology and Business University</institution>, <addr-line>Yantai</addr-line>, <country>China</country></aff>
      <aff id="aff2"><sup>2</sup><institution>School of Management Science and Engineering, Shandong Technology and Business University</institution>, <addr-line>Yantai</addr-line>, <country>China</country></aff>
      <aff id="aff3"><sup>3</sup><institution>Department of Radiology, Yantai Yuhuangding Hospital</institution>, <addr-line>Yantai</addr-line>, <country>China</country></aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: Delin Sun, Duke University, United States</p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: Junling Gao, The University of Hong Kong, Hong Kong SAR, China; Xu Zhang, Duke University, United States</p>
        </fn>
        <corresp id="c001">*Correspondence: Dapeng Cheng, <email>chengdapeng@sdtbu.edu.cn</email></corresp>
        <fn fn-type="other" id="fn004">
          <p>This article was submitted to Cognitive Neuroscience, a section of the journal Frontiers in Human Neuroscience</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>15</day>
        <month>7</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2022</year>
      </pub-date>
      <volume>16</volume>
      <elocation-id>918969</elocation-id>
      <history>
        <date date-type="received">
          <day>13</day>
          <month>4</month>
          <year>2022</year>
        </date>
        <date date-type="accepted">
          <day>16</day>
          <month>6</month>
          <year>2022</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2022 Zhao, Li, Pan, Chen, Li, Zhang, Mao and Cheng.</copyright-statement>
        <copyright-year>2022</copyright-year>
        <copyright-holder>Zhao, Li, Pan, Chen, Li, Zhang, Mao and Cheng</copyright-holder>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Functional connectivity (FC) network based on resting-state functional magnetic resonance imaging (rs-fMRI) has become an important tool to explore and understand the brain, which can provide objective basis for the diagnosis of neurodegenerative diseases, such as autism spectrum disorder (ASD). However, most functional connectivity (FC) networks only consider the unilateral features of nodes or edges, and the interaction between them is ignored. In fact, their integration can provide more comprehensive and crucial information in the diagnosis. To address this issue, a new multi-view brain network feature enhancement method based on self-attention mechanism graph convolutional network (SA-GCN) is proposed in this article, which can enhance node features through the connection relationship among different nodes, and then extract deep-seated and more discriminative features. Specifically, we first plug the pooling operation of self-attention mechanism into graph convolutional network (GCN), which can consider the node features and topology of graph network at the same time and then capture more discriminative features. In addition, the sample size is augmented by a “sliding window” strategy, which is beneficial to avoid overfitting and enhance the generalization ability. Furthermore, to fully explore the complex connection relationship among brain regions, we constructed the low-order functional graph network (Lo-FGN) and the high-order functional graph network (Ho-FGN) and enhance the features of the two functional graph networks (FGNs) based on SA-GCN. The experimental results on benchmark datasets show that: (1) SA-GCN can play a role in feature enhancement and can effectively extract more discriminative features, and (2) the integration of Lo-FGN and Ho-FGN can achieve the best ASD classification accuracy (79.9%), which reveals the information complementarity between them.</p>
      </abstract>
      <kwd-group>
        <kwd>resting-state functional magnetic resonance imaging (rs-fMRI)</kwd>
        <kwd>graph convolutional network (GCN)</kwd>
        <kwd>pooling operation</kwd>
        <kwd>feature enhancement</kwd>
        <kwd>autism spectrum disorder (ASD)</kwd>
      </kwd-group>
      <funding-group>
        <award-group>
          <funding-source id="cn001">
            <institution-wrap>
              <institution>National Natural Science Foundation of China</institution>
              <institution-id institution-id-type="doi">10.13039/501100001809</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id award-type="contract" rid="cn001">62176140</award-id>
        </award-group>
      </funding-group>
      <counts>
        <fig-count count="9"/>
        <table-count count="3"/>
        <equation-count count="8"/>
        <ref-count count="53"/>
        <page-count count="11"/>
        <word-count count="7212"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec sec-type="intro" id="S1">
      <title>Introduction</title>
      <p>Brain disease is regarded as a public health challenge with an alarming proportion (<xref rid="B43" ref-type="bibr">Yao et al., 2021</xref>). Among them, autism spectrum disorder (ASD) is a complex genetic heterogeneous neurological disease with high incidence rate, usually coexisting with other diseases (<xref rid="B19" ref-type="bibr">Lord et al., 2020</xref>; <xref rid="B12" ref-type="bibr">Hiremath et al., 2021</xref>). According to the latest report of the Centers for Disease Control and Prevention, there is one autistic in every 44 American children (<xref rid="B20" ref-type="bibr">Maenner et al., 2021</xref>). So far, there is no effective method to completely cure autism, and the rehabilitation treatment of autism is a lifelong training, which causes heavy economic burden to the families and society (<xref rid="B7" ref-type="bibr">Eslami et al., 2019</xref>; <xref rid="B47" ref-type="bibr">Zhao et al., 2020</xref>). Thus, early diagnosis and intervention of autism is of great clinical and social value (<xref rid="B48" ref-type="bibr">Zhao et al., 2018</xref>; <xref rid="B36" ref-type="bibr">Wang et al., 2019</xref>; <xref rid="B12" ref-type="bibr">Hiremath et al., 2021</xref>).</p>
      <p>Resting-state functional magnetic resonance imaging (rs-fMRI) based on blood oxygen level dependent (BOLD) signal imaging is an important tool to explore brain mechanism and pathology (<xref rid="B3" ref-type="bibr">Chen et al., 2016</xref>; <xref rid="B8" ref-type="bibr">Gan et al., 2021</xref>). Rs-fMRI can realize non-invasive study of brain function high spatial resolution, which cannot only reflect the local spatial function information of the brain, but also maintain detailed functional connectivity maps of the brain (<xref rid="B50" ref-type="bibr">Zhi et al., 2018</xref>). Rs-fMRI has been widely used to detect and characterize functional interconnection among different region of interests (ROIs), revealing potential patterns to distinguish between patients and healthy controls (<xref rid="B43" ref-type="bibr">Yao et al., 2021</xref>).</p>
      <p>Currently, many extracting feature methods based on rs-fMRI are presented from different angles for disease diagnosis. Generally, they can be divided into two categories.</p>
      <p>The first category focuses on extracting the features from each brain region without considering their connection relationship to each other; that is, the time-domain and frequency-domain features of each brain region of interest (ROI) are directly extracted based on the original BOLD. For example, <xref rid="B29" ref-type="bibr">Sartipi et al. (2018)</xref> proposed that based on generalized autoregressive conditional heteroscedasticity, the time-frequency sub-bands obtained by decomposing the brain ROI of subjects were extracted to diagnose ASD; <xref rid="B32" ref-type="bibr">Sidhu (2019)</xref> proposed the local linear embedding method, and the information measure of potential neuronal activity was extracted from BOLD time series for disease classification; <xref rid="B6" ref-type="bibr">Easson and McIntosh (2019)</xref> measured the variability of resting BOLD based on mean square continuous difference of time series and evaluated its complexity based on sample entropy to find predictors of ASD diagnosis. The above methods rely on brain ROIs, and the pathogenesis of brain diseases is explored by measuring the activities of various brain regions to assist the diagnosis of ASD. However, such methods ignore the connections among brain ROIs. Since the brain is a complex biological information system, each brain area is not isolated, but is interconnected on multiple spatial and temporal scales, working in coordination, the relationship among brain areas contains rich useful information for disease diagnosis.</p>
      <p>The second category is committed to explore the functional connectivity among ROIs, through constructing functional connectivity (FC) network and conduct classification according to the differences in FC patterns among brain ROIs. For example, <xref rid="B46" ref-type="bibr">Zhang et al. (2020)</xref> learned multi-view features with multiatlas-based FC network to improve MCI diagnosis; <xref rid="B52" ref-type="bibr">Zhou et al. (2018)</xref> enhanced the high-order FC network based on regularization learning framework to identify the patients with MCI and ASD; <xref rid="B49" ref-type="bibr">Zhao et al. (2021)</xref> extracted the temporal-invariant properties contained in low-order and high-order dynamic FC networks based on the central moment method, revealing that different networks can identify the fingerprint of the autistic brain at different connection levels; <xref rid="B37" ref-type="bibr">Wang N. et al. (2022)</xref> identified ASD using multi-point clustering and nested feature extraction of rs-fMRI. Despite the effectiveness of the above methods captures features, they ignore the features of each brain ROIs and do not organically integrate the features of nodes (each brain region) and edges (the connection relationship among brain regions), and thus, they cannot extract relatively comprehensive and powerful discriminative features. Therefore, how to enhance the node features through the connection relationship between nodes and realize the organic combination of nodes and edges is an important research topic for ASD diagnosis.</p>
      <p>In recent years, graph convolutional network (GCN) has achieved great success in dealing with non-Euclidean spatial data in the form of graph data (<xref rid="B40" ref-type="bibr">Xu et al., 2020</xref>, <xref rid="B41" ref-type="bibr">2022</xref>; <xref rid="B16" ref-type="bibr">Li L. et al., 2021</xref>; <xref rid="B33" ref-type="bibr">Song et al., 2021</xref>; <xref rid="B9" ref-type="bibr">Ghorbani et al., 2022</xref>). GCN is able to automatically extract feature of brain network through an end-to-end manner, which is used for the recognition and classification of brain disease (<xref rid="B35" ref-type="bibr">Wang et al., 2021</xref>; <xref rid="B53" ref-type="bibr">Zhu et al., 2022</xref>). Specifically, GCN has the capability of transmitting, aggregating, and updating the node information in the graph, which can use the connection relationship of the nodes in the graph to enhance the node features, explicitly capture the node information and topology of the graph network, and mine useful brain connection network patterns for disease classification (<xref rid="B13" ref-type="bibr">Ktena et al., 2018</xref>). For example, <xref rid="B2" ref-type="bibr">Cao et al. (2021)</xref> used DeepGCN to identify ASD from multi-site resting-state data; <xref rid="B38" ref-type="bibr">Wang Y. et al. (2022)</xref> conducted diagnosis of ASD based on multi-spectral convolution network and ensemble learning. However, the existing GCNs still have some drawbacks listed as following when applied to brain FC networks.</p>
      <p>(1) For high-dimensional small sample, GCN may not work well. A large number of training samples are often required for GCN training to avoid overfitting, which is hard to be satisfied in the single site of medical imaging. For example, the Autism Brain Imaging Data Exchange (ABIDE) database consists of 17 international imaging sites, of which New York University site has the most rs-fMRI data, including only 92 subjects (<xref rid="B5" ref-type="bibr">Di Martino et al., 2014</xref>). To solve this problem, previous studies usually collect data from multiple sites and put multiple data sources together (<xref rid="B2" ref-type="bibr">Cao et al., 2021</xref>). However, the problem of inconsistent parameters of multiple data sources may affect the learning performance of GCN.</p>
      <p>(2) GCNs generally focus on the node information in the brain function connectivity network, but ignore the network topology and lack efficient graph pooling operation. GCN for graph classification mainly predicts the class labels of the whole graph by combining the learning methods of graph convolution layer, graph pooling layer, and readout layer (<xref rid="B23" ref-type="bibr">Pan et al., 2015</xref>, <xref rid="B22" ref-type="bibr">2017</xref>; <xref rid="B44" ref-type="bibr">Ying et al., 2018</xref>; <xref rid="B45" ref-type="bibr">Zhang et al., 2018</xref>). Among them, the graph volume layer is responsible for accurate high-level node representation, whereas the graph pool layer learns the hierarchical representation of the network and reduces the parameters (<xref rid="B14" ref-type="bibr">Lee et al., 2019</xref>).</p>
      <p>(3) In terms of graph network construction, previous studies usually start from a single level and then to extract features. They ignored two facts in the setting of node feature matrix and adjacency matrix of initial graph network. First, in the selection of node features, the FC network reflecting the connection relationship between nodes is considered, while ignoring the original blood oxygen signals in each brain region (<xref rid="B33" ref-type="bibr">Song et al., 2021</xref>); second, in the topological structure of the graph network, the connection between the two brain regions is considered, whereas the deep connection among nodes is ignored. For the ease of understanding, we use social networks as an analogy. Each brain region is regarded as an individual. In addition to its own unique features, each individual also has his/her own friends. Previous studies have focused on the interaction between individuals and their friends, but ignored individual unique features and the interaction between the circle of friends.</p>
      <p>To handle the above issues, we propose a novel multi-view brain network feature enhancement method based on self-attention mechanism graph convolutional network (SA-GCN). Specifically, we first adopt the “sliding window” strategy to expand the sample size, i.e., the whole rs-fMRI time series is divided into multiple overlapping sub-segments by “sliding window” methods, and each sub-segment constructs a graph network, so that more samples are generated from one rs-fMRI time series for improving the overfitting problem caused by small samples and solved the problem of inconsistent parameters of multiple data sources in previous studies, making the experimental performance more stable; Then, we facilitate the graph pooling operation <italic>via</italic> self-attention mechanism in GCN, which considers both node features and network topology, and can filter useless informatics, leave more advanced, deeper and more discriminative node features; Furthermore, two different levels of FGN, i.e., Lo-FGN and Ho-FGN, are constructed from fMRI data to comprehensively capture the information contained in the brain network. The Lo-FGN reflects the changes of original BOLD in each brain region in terms of node features, and the connection strength between two brain regions in terms of network structure. The Ho-FGN reflects the interaction among brain regions in terms of node features and the deeper connection among multiple brain regions in terms of network structure. Finally, the multi-level features extracted based on SA-GCN are fused to realize the information complementarity between features, which is helpful to identify brain diseases, such as autism.</p>
      <p>The rest of this article is organized as follows. In the Introduction section, we introduce related works of GCN in graph-level processing tasks. In the Proposed Methods section, our approach is described in detail, including data augmentation, self-attention pooling operations, and network construction. In the Experiments part, we present the experimental results, discuss different feature evaluation methods, and compare our strategy with other state-of-the-arts. Finally, conclusions are given.</p>
    </sec>
    <sec sec-type="intro" id="S2">
      <title>Introduction of Graph Convolutional Network</title>
      <p>At present, GCN is one of the favorites in graph data learning tasks, which has wide applicability and is suitable for nodes and graphs with any topological structure (<xref rid="B28" ref-type="bibr">Rubinov and Sporns, 2010</xref>; <xref rid="B51" ref-type="bibr">Zhou et al., 2020</xref>; <xref rid="B17" ref-type="bibr">Li X. et al., 2021</xref>). Here, we focus on GCN for graph level tasks. GCN is essentially Laplacian smoothing on the network, which takes the weighted sum of neighbors and self-expressions of each node as the feature (<xref rid="B24" ref-type="bibr">Parisot et al., 2018</xref>; <xref rid="B31" ref-type="bibr">Shao et al., 2021</xref>).</p>
      <p>The typical architecture of graph-level task GCN is shown in <xref rid="F1" ref-type="fig">Figure 1</xref>. Firstly, the node feature matrix and adjacency matrix of the initial graph network are input into GCN; Then, the graph convolution operation is conducted at each layer to characterize the local structure of the node, and extract high-level node representation (<xref rid="B10" ref-type="bibr">Gu et al., 2021</xref>); After that, the graph pooling operation is facilitated to learn the hierarchical representation of the network (<xref rid="B11" ref-type="bibr">Henaff et al., 2015</xref>); Finally, with certain loss functions, gradient back propagation is used to train the network. All convolution layers share the same adjacency matrix. To increase non-linearity, the <italic>ReLU</italic> activation function is added after each layer. The iterative update operation can be expressed as:</p>
      <disp-formula id="S2.E1">
<label>(1)</label>
<mml:math id="M1" overflow="scroll"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula>
      <fig position="float" id="F1">
        <label>FIGURE 1</label>
        <caption>
          <p>GCN with pooling layer and readout layer for graph level tasks.</p>
        </caption>
        <graphic xlink:href="fnhum-16-918969-g001" position="float"/>
      </fig>
      <p>where <italic>A</italic> ∈ <italic>R</italic><sup><italic>n</italic>×<italic>n</italic></sup> is an adjacency matrix, which defines the connection between nodes, and in an undirected graph <italic>A</italic><sub>i,j</sub> = <italic>A</italic><sub>j,i</sub>. <italic>I</italic><sub>n</sub>ϵ<italic>R</italic><sup><italic>n</italic>×<italic>n</italic></sup>is an identity matrix, and<inline-formula><mml:math id="INEQ6" overflow="scroll"><mml:mrow><mml:mpadded lspace="2.8pt" width="+2.8pt"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mpadded><mml:mo>=</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mtext>n</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. <italic><bold>D</bold></italic> is a diagonal matrix, <italic>D</italic><sub>i,j</sub> represents the degree of the <italic>i</italic>−<italic>th</italic>node and<inline-formula><mml:math id="INEQ9" overflow="scroll"><mml:mrow><mml:msub><mml:mpadded lspace="2.8pt" width="+2.8pt"><mml:mover accent="true"><mml:mi>D</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mpadded><mml:mrow><mml:mtext>ii</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mtext>j</mml:mtext></mml:mrow></mml:munder><mml:msub><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. <italic><bold>W</bold></italic> is the trainable weight, <italic>X</italic><sup>(<italic>l</italic>)</sup>is the <italic>l-th</italic> node feature matrix, where <italic>X</italic><sup>(0)</sup>is the original node feature matrix. The complete GCN can be obtained after L iterations of training <sup>(</sup><xref rid="B24" ref-type="bibr">Parisot et al., 2018</xref>; <xref rid="B10" ref-type="bibr">Gu et al., 2021</xref>).</p>
      <p>Although GCN can do feature extraction and enhancement by considering both nodes and edges in the graph network, it cannot be directly applied to our task. Specifically, there are two limitations: (1) The performance of GCN heavily depends on training samples, and our sample size is small. To solve this problem, we must expand the sample size; (2) Previous graph pooling methods either only consider the topology of graphs, or have high spatial complexity (<xref rid="B4" ref-type="bibr">Defferrard et al., 2016</xref>; <xref rid="B27" ref-type="bibr">Rhee et al., 2017</xref>; <xref rid="B1" ref-type="bibr">Cangea et al., 2018</xref>; <xref rid="B44" ref-type="bibr">Ying et al., 2018</xref>; <xref rid="B45" ref-type="bibr">Zhang et al., 2018</xref>). To reduce the learning parameters and computational complexity, it is necessary to improve the graph pooling operation. To tackle these two problems, we give the corresponding solutions in the proposed methods.</p>
    </sec>
    <sec id="S3">
      <title>Proposed Methods</title>
      <p>To make GCN adapts to our task and data, we propose a novel multi-view brain network feature enhancement method based on GCN with self-attention mechanism (SA-GCN). The overall framework of our model is illustrated in <xref rid="F2" ref-type="fig">Figure 2</xref>. To be specific, we first use the “sliding window” strategy to enlarge the sample size, and the low-order functional graph network (Lo-FGN) and high-order functional graph network (Ho-FGN) are constructed; Then, the pooling operation of self-attention mechanism is added to the GCN architecture to extract more discriminative features; Finally, the Lo-FGN and Ho-FGN are integrated based on SA-GCN to capture more comprehensive and discriminative features. <xref rid="F2" ref-type="fig">Figure 2</xref> illustrates the overall framework of our model.</p>
      <fig position="float" id="F2">
        <label>FIGURE 2</label>
        <caption>
          <p>Overall frame diagram, where <italic>FCN</italic>: functional connectivity networks;<italic>Lo</italic>−<italic>FGN</italic>: Low-order functional graph network; <italic>Ho-FGN</italic>: <italic>High</italic>−<italic>orderfunctionalgraphnetwork</italic>; <italic>A</italic><sub><italic>roi</italic></sub> represents the adjacency matrix of Lo-FGN; <italic>X</italic><sub><italic>roi</italic></sub> represents the node feature matrix of Lo-FGN, others are the same as above.</p>
        </caption>
        <graphic xlink:href="fnhum-16-918969-g002" position="float"/>
      </fig>
      <sec id="S3.SS1">
        <title>Data Augmentation</title>
        <p>To solve the small sample size of rs-fMRI data, we adopt a “sliding window” method for data augmentation, as shown in <xref rid="F3" ref-type="fig">Figure 3</xref>, where the abscissa represents the acquisition time of the fMRI time series, and the ordinate represents the blood oxygen signal in the brain region. For each subject, the average rs-fMRI time series of all voxels in the <italic>i-th</italic> brain ROI is defined as follows:</p>
        <disp-formula id="S3.E2">
<label>(2)</label>
<mml:math id="M2" overflow="scroll"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>i</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i1</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i2</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>iN</mml:mtext></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>
</disp-formula>
        <fig position="float" id="F3">
          <label>FIGURE 3</label>
          <caption>
            <p>Sliding window method diagram.</p>
          </caption>
          <graphic xlink:href="fnhum-16-918969-g003" position="float"/>
        </fig>
        <p>where <italic>R</italic> is the total number of regions of interest and <italic>N</italic> represents the total number of image volumes during rs-fMRI scanning. The whole rs-fMRI time series is divided into <italic>K</italic> overlapping sub-segments. Each sub-rs-fMRI time series can build a graph network. The value of <italic>K</italic> is calculated according to the following:</p>
        <disp-formula id="S3.E3">
<label>(3)</label>
<mml:math id="M3" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mi>W</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math>
</disp-formula>
        <p>where <italic>M</italic> is the length of the entire rs-fMRI time series, and <italic>W</italic> is the length of the sliding window. To ensure that each sub-window owns relatively more rs-fMRI time information, <italic>W</italic> can be set to a relatively large value, and <italic>s</italic> is the step length of each slide of the sliding window. Therefore, the augmentation of the experimental data can be achieved through the “sliding window” method.</p>
      </sec>
      <sec id="S3.SS2">
        <title>Pooling Operation for Graph Classification</title>
        <p>To better reflect the hierarchical structure of the input data and reduce the learning parameters for higher computation efficiency, we add the self-attention pooling operation after the graph convolution. The network architecture is shown in <xref rid="F4" ref-type="fig">Figure 4</xref>. The updating formulas of node feature matrix and adjacency matrix are given by equation (4):</p>
        <disp-formula id="S3.E4">
<label>(4)</label>
<mml:math id="M4" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo rspace="5.8pt">)</mml:mo></mml:mrow><mml:mo rspace="5.8pt">=</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>N</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>
</disp-formula>
        <fig position="float" id="F4">
          <label>FIGURE 4</label>
          <caption>
            <p>Pooling operation. Where <italic>x</italic><sub>i</sub> represents the feature vector of the <italic>i-th</italic> node, <inline-formula><mml:math id="INEQ14" overflow="scroll"><mml:mpadded width="+2.8pt"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mtext>i</mml:mtext></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mpadded></mml:math></inline-formula>represents the feature vector of the <italic>i-th</italic> new node obtained after the graph convolution. After the pooling operation, a new graph is obtained, in which the dotted line indicates that the corresponding node should be discarded.</p>
          </caption>
          <graphic xlink:href="fnhum-16-918969-g004" position="float"/>
        </fig>
        <p>To understand the pooling operations in the graph network, <xref rid="F5" ref-type="fig">Figure 5</xref> shows the changes in brain connectivity before and after the pooling, where thickness of lines represents the strength of connectivity among brain regions, and the fork sign represents that the pooling operation can discard some less important nodes and retain the nodes with more discriminative features. From <xref rid="F5" ref-type="fig">Figure 5</xref>, self-attention graph pooling method cannot only use relatively few parameters to learn hierarchical representation in end-to-end manner, but also use self-attention to distinguish among nodes that should be deleted and retained. SA-GCN not only considers the node features, but also reflects the topology of the graph, which is conducive to improve the accuracy of downstream classification task.</p>
        <fig position="float" id="F5">
          <label>FIGURE 5</label>
          <caption>
            <p>Self-attention graph pooling method diagram, where <bold>(A)</bold> represents the connectivity among brain regions before the pooling operation, <bold>(B)</bold> represents the connectivity among brain regions after the pooling operation, and thickness of lines represents the strength of connectivity among brain regions, the fork sign represents that the pooling operation can discard some less important nodes and retain the nodes with more discriminative features.</p>
          </caption>
          <graphic xlink:href="fnhum-16-918969-g005" position="float"/>
        </fig>
      </sec>
      <sec id="S3.SS3">
        <title>Construction of Multi-Level Graph Network</title>
        <p>Feature extraction based on GCN requires the construction of function graph network from fMRI data. The complete function graph network includes two parts: node feature matrix and adjacency matrix. Conventional methods ignore the complementarity of features among different levels. Our method constructs the function graph network from multiple levels, as shown in <xref rid="F6" ref-type="fig">Figure 6</xref>, where the left part is the construction process of low-order functional graph network (Lo-FGN), and the right part illustrates the construction of high-order functional graph network (Ho-FGN).</p>
        <fig position="float" id="F6">
          <label>FIGURE 6</label>
          <caption>
            <p>Construction of multi-level function graph network, where ➀ represents get K sub fMRI time series; ➁ represents the construction of Lo-FGN from fMRI time series; ➂ represents the use of Pearson correlation to build a functional connectivity network (FCN); ➃ represents the construction of Ho-FGN from FCN.ρ<sub>i</sub> represents Pearson correlation between the <italic>i-th</italic> ROI and other ROIs.<italic>C</italic>−<italic>FCN</italic><sub>i</sub> represents the <italic>i-th</italic> traditional functional connectivity network.</p>
          </caption>
          <graphic xlink:href="fnhum-16-918969-g006" position="float"/>
        </fig>
        <sec id="S3.SS3.SSS1">
          <title>Construction of Low-Order Functional Graph Network</title>
          <p>Let <italic>x</italic><sub>i</sub>(<italic>l</italic>) and <italic>x</italic><sub><italic>j</italic></sub>(<italic>l</italic>) represent the subsequences of the <italic>i-th</italic> and <italic>j-th</italic> ROI in the <italic>l-th</italic> window, respectively. The correlation between time series is calculated by Pearson correlation to obtain FC, and the FC is thresholded by adjusting parameters to obtain the adjacency matrix of Lo-FGN, that is:</p>
          <disp-formula id="S3.E5">
<label>(5)</label>
<mml:math id="M5" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mtext>Lo</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">φ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>i</mml:mtext></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mtext>j</mml:mtext></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.8pt">)</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.8pt">=</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">ρ</mml:mi><mml:mrow><mml:mtext>ij</mml:mtext></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math>
</disp-formula>
          <p>where φ denotes a thresholding operation.</p>
          <p>To capture the temporal changes in the original BOLD in the brain area and avoid the timing structure of rs-fMRI is being destructed, we take the mean and variance of the original data <italic>X</italic><sub><italic>roi</italic></sub> as the node features <italic>X</italic><sub><italic>Lo</italic></sub> of Lo-FGN as:</p>
          <disp-formula id="S3.E6">
<label>(6)</label>
<mml:math id="M6" overflow="scroll"><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mpadded><mml:mo rspace="5.8pt">=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>
</disp-formula>
        </sec>
        <sec id="S3.SS3.SSS2">
          <title>Construction of High-Order Functional Graph Network</title>
          <p>To characterize the organizational features of the brain and reflect the functional connectivity interaction mode among multiple ROIs, we explore the connection relationship of edges in the graph network to enhance discrimination ability of node features. Based on the “one-time Pearson correlation,” the high-order function connection (Ho-FC) is obtained based on the idea of “correlation of correlation,” and the Ho-FC is thresholded by adjusting parameters to obtain the adjacency matrix of the Ho-FGN as follows:</p>
          <disp-formula id="S3.E7">
<label>(7)</label>
<mml:math id="M7" overflow="scroll"><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mpadded><mml:mo rspace="5.8pt">=</mml:mo><mml:mrow><mml:mi mathvariant="normal">φ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">ρ</mml:mi><mml:mrow><mml:mtext>ij</mml:mtext></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math>
</disp-formula>
          <p>To better capture the deep-seated node features, the functional connectivity matrix is used as the node feature matrix of Ho-FGN, that is:</p>
          <disp-formula id="S3.E8">
<label>(8)</label>
<mml:math id="M8" overflow="scroll"><mml:mrow><mml:mpadded width="+3.3pt"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mpadded><mml:mo rspace="5.8pt">=</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">ρ</mml:mi><mml:mrow><mml:mtext>ij</mml:mtext></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math>
</disp-formula>
        </sec>
      </sec>
    </sec>
    <sec id="S4">
      <title>Experiments Analysis</title>
      <sec id="S4.SS1">
        <title>Experimental Data</title>
        <p>The rs-fMRI dataset used in this article is from the ABIDE database, which consists of 17 international imaging sites (<xref rid="B5" ref-type="bibr">Di Martino et al., 2014</xref>). To mitigate data heterogeneity, the rs-fMRI data of NUY site with the largest sample size are selected to verify the feasibility of our proposed method. Specifically, rs-fMRI scanning data of 45 patients with ASD and 47 normal control (NC) subjects were included. The subjects ages are between 7 and 15 years, and there are no excessive head movements in any three directions, displacement less than 1.5 mm or angular rotation less than 1.5°. The detailed demographic information of these subjects is summarized in <xref rid="T1" ref-type="table">Table 1</xref>. There are no significant differences in age, gender, IQ, diagnostic interview, and diagnostic observation (<italic>p</italic> &gt; 0.05) between the two groups.</p>
        <table-wrap position="float" id="T1">
          <label>TABLE 1</label>
          <caption>
            <p>Demographic information of the subjects.</p>
          </caption>
          <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
            <thead>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Characteristic</td>
                <td valign="top" align="center" rowspan="1" colspan="1">ASD</td>
                <td valign="top" align="center" rowspan="1" colspan="1">NC</td>
                <td valign="top" align="center" rowspan="1" colspan="1"><italic>p</italic>-values</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Gender (M/F)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">36/9</td>
                <td valign="top" align="center" rowspan="1" colspan="1">36/11</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.2135<xref rid="t1fna" ref-type="table-fn"><italic><sup>a</sup></italic></xref></td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Age (mean ± SD)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">11.1±2.3</td>
                <td valign="top" align="center" rowspan="1" colspan="1">11.0±2.3</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.773<xref rid="t1fnb" ref-type="table-fn"><italic><sup>b</sup></italic></xref></td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">FIQ (mean ± SD)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">106.8±17.4</td>
                <td valign="top" align="center" rowspan="1" colspan="1">113.3±14.1</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0510<xref rid="t1fnb" ref-type="table-fn"><italic><sup>b</sup></italic></xref></td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ADI-R (mean ± SD)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">32.2±14.3<xref rid="t1fnc" ref-type="table-fn"><italic><sup>c</sup></italic></xref></td>
                <td valign="top" align="center" rowspan="1" colspan="1">−</td>
                <td valign="top" align="center" rowspan="1" colspan="1">−</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ADOS (mean ± SD)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">13.7±5.0</td>
                <td valign="top" align="center" rowspan="1" colspan="1">-</td>
                <td valign="top" align="center" rowspan="1" colspan="1">−</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">FD (mean ± SD)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.14±0.05</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.15±0.07</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.36<xref rid="t1fnb" ref-type="table-fn"><italic><sup>b</sup></italic></xref></td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn>
              <p>
<italic>M, male; F, female; FIQ, Full Intelligence Quotient; ADI-R, Autism Diagnostic Interview-Revised; ADOS, autism diagnostic observation schedule.</italic>
</p>
            </fn>
            <fn id="t1fna">
              <p>
<italic><sup>a</sup>The p-value was obtained by χ2-test.</italic>
</p>
            </fn>
            <fn id="t1fnb">
              <p>
<italic><sup>b</sup>The p-value was obtained by two-sample two-tailed t-test.</italic>
</p>
            </fn>
            <fn id="t1fnc">
              <p>
<italic><sup>c</sup>Two patients do not have the ADI-R score.</italic>
</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>The data acquisition and preprocessing follow a standard pipeline, including head movement, normalization, denoising, and other processes and related parameters, which same as some previous pieces of literature (<xref rid="B21" ref-type="bibr">Murdaugh et al., 2012</xref>; <xref rid="B30" ref-type="bibr">Satterthwaite et al., 2013</xref>; <xref rid="B42" ref-type="bibr">Yan et al., 2013</xref>; <xref rid="B39" ref-type="bibr">Washington et al., 2014</xref>; <xref rid="B15" ref-type="bibr">Leung et al., 2015</xref>; <xref rid="B18" ref-type="bibr">Lin et al., 2015</xref>; <xref rid="B25" ref-type="bibr">Ray et al., 2015</xref>; <xref rid="B34" ref-type="bibr">Urbain et al., 2016</xref>; <xref rid="B26" ref-type="bibr">Reinhart and Nguyen, 2019</xref>). Finally, we use the automatic anatomical marker (AAL) map to divide the brain into 116 brain ROIs and calculate the mean value of rs-fMRI time series of each brain ROI, which is represented by the data matrix <italic>X</italic> ∈ <italic>R</italic><sup>170×116</sup> for subsequent experiments. Note that 170 represents the total volume of time images and 116 is the total number of all brain ROIs.</p>
      </sec>
      <sec id="S4.SS2">
        <title>Evaluation Methodology</title>
        <p>To verify the effectiveness of the method, we conducted eight experiments based on rs-fMRI data. In the experiment, ASD and NC are considered as positive and negative classes, respectively. All experiments were evaluated by 10 times of fivefold cross-validation. Specifically, we first divide all subjects into 5 subsets (roughly the same size). Then, we take one subset as the test set and the other four subsets as the training data. This process is repeated 10 times to avoid the deviation of random data division in cross-validation. The classification results of all iterations are averaged and evaluated by six metrics: classification accuracy (ACC), sensitivity or true positive rate (TPR), specificity or true negative rate (TNR), positive predictive value (PPV), negative predictive value (NPV), and F1 score. In addition, we performed the statistical significance test (<italic>t</italic>-test) on the accuracy obtained by seven comparison methods and SA-GCN, and the <italic>p</italic>-values of the test are also listed in <xref rid="T2" ref-type="table">Table 2</xref>. When the <italic>p</italic>-value is less than 0.05, it indicates that there is a significant difference between the two methods.</p>
        <table-wrap position="float" id="T2">
          <label>TABLE 2</label>
          <caption>
            <p>ASD classification results with different feature strategies.</p>
          </caption>
          <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
            <thead>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Model</td>
                <td valign="top" align="center" rowspan="1" colspan="1">ACC (%)</td>
                <td valign="top" align="center" rowspan="1" colspan="1"><italic>P</italic>-value</td>
                <td valign="top" align="center" rowspan="1" colspan="1">TPR (%)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">TNR (%)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PPV (%)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">NPV (%)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">F1 (%)</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">
<italic>CBN</italic>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">65.4 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0161498</td>
                <td valign="top" align="center" rowspan="1" colspan="1">67.3 ± 0.12</td>
                <td valign="top" align="center" rowspan="1" colspan="1">62.7 ± 0.06</td>
                <td valign="top" align="center" rowspan="1" colspan="1">59.8 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">71.2 ± 0.06</td>
                <td valign="top" align="center" rowspan="1" colspan="1">63.0 ± 0.01</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">
<italic>GCN</italic>
<sub>
<italic>(Lo)</italic>
</sub>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">68.0 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0034533</td>
                <td valign="top" align="center" rowspan="1" colspan="1">67.8 ± 0.12</td>
                <td valign="top" align="center" rowspan="1" colspan="1">66.5 ± 0.04</td>
                <td valign="top" align="center" rowspan="1" colspan="1">67.3 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">68.1 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">67.0 ± 0.04</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Lo</italic>)</sub></td>
                <td valign="top" align="center" rowspan="1" colspan="1">73.0 ± 0.03</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0306230</td>
                <td valign="top" align="center" rowspan="1" colspan="1">65.0 ± 0.07</td>
                <td valign="top" align="center" rowspan="1" colspan="1">81.0 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">79.6 ± 0.08</td>
                <td valign="top" align="center" rowspan="1" colspan="1">71.0 ± 0.08</td>
                <td valign="top" align="center" rowspan="1" colspan="1">69.4 ± 0.04</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">FCN</td>
                <td valign="top" align="center" rowspan="1" colspan="1">72.6 ± 0.02</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0301950</td>
                <td valign="top" align="center" rowspan="1" colspan="1">88.2 ± 0.02</td>
                <td valign="top" align="center" rowspan="1" colspan="1">56.0 ± 0.07</td>
                <td valign="top" align="center" rowspan="1" colspan="1">64.3 ± 0.05</td>
                <td valign="top" align="center" rowspan="1" colspan="1">87.9 ± 0.05</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.0 ± 0.01</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">
<italic>GCN</italic>
<sub>
<italic>(Ho)</italic>
</sub>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.5 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0462659</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.7 ± 0.02</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.4 ± 0.04</td>
                <td valign="top" align="center" rowspan="1" colspan="1">76.5 ± 0.03</td>
                <td valign="top" align="center" rowspan="1" colspan="1">75.0 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">75.0 ± 0.08</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Ho</italic>)</sub></td>
                <td valign="top" align="center" rowspan="1" colspan="1">75.0 ± 0.04</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0453326</td>
                <td valign="top" align="center" rowspan="1" colspan="1">70.1 ± 0.12</td>
                <td valign="top" align="center" rowspan="1" colspan="1">77.3 ± 0.05</td>
                <td valign="top" align="center" rowspan="1" colspan="1">77.9 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.0 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">72.0 ± 0.04</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>GCN</italic><sub>(<italic>Lo</italic>)</sub> + <italic>GCN</italic><sub>(<italic>Ho</italic>)</sub></td>
                <td valign="top" align="center" rowspan="1" colspan="1">77.0 ± 0.01</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.0421363</td>
                <td valign="top" align="center" rowspan="1" colspan="1">71.3 ± 0.08</td>
                <td valign="top" align="center" rowspan="1" colspan="1">78.5 ± 0.04</td>
                <td valign="top" align="center" rowspan="1" colspan="1">77.9 ± 0.02</td>
                <td valign="top" align="center" rowspan="1" colspan="1">74.7 ± 0.07</td>
                <td valign="top" align="center" rowspan="1" colspan="1">73.6 ± 0.04</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"><italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Lo</italic>)</sub> + <italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Ho</italic>)</sub></td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>79.9 ± 0.03</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>/</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>75.6 ± 0.03</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>78.6 ± 0.04</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>78.7 ± 0.01</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>78.6 ± 0.01</bold>
</td>
                <td valign="top" align="center" rowspan="1" colspan="1">
<bold>76.1 ± 0.04</bold>
</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn>
              <p>
<italic>The bold values represent the results of our proposed method under different evaluation metrics.</italic>
</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <sec id="S4.SS2.SSS1">
          <title>Influence of Parameters on Feature Extraction</title>
          <p>Since the proposed SA-GCN is a deep learning method, to avoid overfitting, the “sliding window” strategy is adopted to increase the sample size. There are two free parameters, namely, sliding window width (<italic>W</italic>) and translation step size (<italic>s</italic>), which may affect the final classification performance. We set the range of these parameters to <italic>W</italic> ∈ [120,125,130,135,140,145], <italic>s</italic> ∈ [5,6,7,8]. In addition, in the process of constructing Lo-FGN and Ho-FGN, because the brain network is considered to have sparse connection structure, the adjacency matrix is thresholded by adjusting parameters. In the construction of Lo-FGN, the range of threshold <italic>L</italic><sub><italic>corr </italic></sub>is set as <italic>L</italic><sub><italic>corr</italic></sub> ∈ {(−0.4,0.4),(−0.45,0.45),…,(−0.65,0.65)}. In the construction of Ho-FGN, the range of threshold <italic>H</italic><sub>corr</sub> is set as <italic>H</italic><sub>corr</sub> ∈ {(−0.4,0.4),(−0.45,0.45),…,(−0.65,0.65)}. To check the influence of threshold <italic>L</italic><sub><italic>corr</italic></sub> and <italic>H</italic><sub><italic>corr</italic></sub> on the results, we make <italic>t</italic> = <italic>L</italic><sub>corr </sub> = <italic>H</italic><sub>corr</sub> for comparative experiment, as shown in <xref rid="F7" ref-type="fig">Figure 7</xref>.</p>
          <fig position="float" id="F7">
            <label>FIGURE 7</label>
            <caption>
              <p>Average classification accuracy (ACC) of SA-GCN with different free parameter combinations (i.e., <italic>W, s</italic>, and <italic>t</italic>).</p>
            </caption>
            <graphic xlink:href="fnhum-16-918969-g007" position="float"/>
          </fig>
          <p>From <xref rid="F7" ref-type="fig">Figure 7</xref>, we have the following conclusions: (1) The classification performance is quite sensitive to free parameters, so it is necessary to continuously adjust parameters to obtain the best performance. We can see that when <italic>W</italic> = 130,<italic>s</italic> = 5,<italic>L</italic><sub><italic>corr</italic></sub> = <italic>H</italic><sub><italic>corr</italic></sub> = 0.6, the maximum value of ACC is 79.9%, and when <italic>W</italic> = 125,<italic>s</italic> = 6,<italic>L</italic><sub><italic>corr</italic></sub> = <italic>H</italic><sub><italic>corr</italic></sub> = 0.6, the minimum value of ACC is 63.3%; (2) Different thresholds determine different network topologies, which can provide different useful information for ASD identification and obtain different classification performances.</p>
        </sec>
        <sec id="S4.SS2.SSS2">
          <title>Comparison for Autism Spectrum Disorder Diagnosis Using Different Feature Extraction</title>
          <p>To verify the effectiveness of the proposed method, we set <italic>W</italic> = 130,<italic>s</italic> = 5,<italic>t</italic> = <italic>L</italic><sub><italic>corr</italic></sub> = <italic>H</italic><sub><italic>corr</italic></sub> = 0.6 and conducted extensive experimental comparison based on the following eight methods. <xref rid="T2" ref-type="table">Table 2</xref> shows the average classification performance of the above eight methods. Among them, the conventional brain network (CBN) represents the use of the mean and variance of the time series of rs-fMRI as the characteristics;<italic>GCN</italic><sub>(<italic>Lo</italic>)</sub>indicates that the constructed <italic>Lo</italic>−<italic>FGN</italic>is sent into the GCN network architecture;<italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Lo</italic>)</sub>indicates that <italic>Lo-FGN</italic> is sent into the GCN network architecture with self-attention pooling operation; FCN represents the characteristics of traditional FC network based on Pearson correlation; “ + ” denotes the fusion operation and the other expressions of similarity.</p>
          <p>From <xref rid="T2" ref-type="table">Table 2</xref>, we can draw three conclusions: (1) The feature extraction using GCN architecture is superior to the traditional feature extraction methods, indicating that GCN can enhance the node features through the connection among nodes, and has strong feature extraction ability; (2) the GCN with pooling operation <italic>via</italic> self-attention mechanism can take into account node features and network topology structure and extract more discriminative features; (3) for Lo-FGN and Ho-FGN, the performance of feature extraction and feature layer fusion based on SA-GCN achieves the best performance, indicating that the effectiveness of feature fusion.</p>
        </sec>
      </sec>
      <sec id="S4.SS3">
        <title>The Most Distinguishing Features in Autism Spectrum Disorder Diagnosis</title>
        <p>To further analyze the pooling operation in GCN with self-attention mechanism, we fed the test datasets into the SA-GCN architecture and counted the probability of occurrence of each node in the remaining nodes after the pooling operation of all test sets scored based on the self-attention mechanism to rank the nodes’ importance, as shown in <xref rid="T3" ref-type="table">Table 3</xref>.</p>
        <table-wrap position="float" id="T3">
          <label>TABLE 3</label>
          <caption>
            <p>The 10 most discriminating features and their frequency of occurrence.</p>
          </caption>
          <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
            <thead>
              <tr>
                <td valign="top" align="left" colspan="2" rowspan="1"><italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Lo</italic>)</sub><hr/></td>
                <td valign="top" align="center" colspan="2" rowspan="1"><italic>SA</italic>−<italic>GCN</italic><sub>(<italic>Ho</italic>)</sub><hr/></td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ROI</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Probability of occurrence</td>
                <td valign="top" align="center" rowspan="1" colspan="1">ROI</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Probability of occurrence</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">VIIB-Cb.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7717</td>
                <td valign="top" align="center" rowspan="1" colspan="1">INS.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7554</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">VIIB-Cb.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7704</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PUT.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7337</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">HIP.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7663</td>
                <td valign="top" align="center" rowspan="1" colspan="1">SFGmed.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.73505</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">II-Cb.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7649</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PAL.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7269</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">VIII-Cb.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7541</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PAL.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.71875</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">II-Cb.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7527</td>
                <td valign="top" align="center" rowspan="1" colspan="1">PUT.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7174</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">VIII-Cb.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7412</td>
                <td valign="top" align="center" rowspan="1" colspan="1">THA.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7119</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">I-Cb.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.72146</td>
                <td valign="top" align="center" rowspan="1" colspan="1">THA.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7119</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">PreCG.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7269</td>
                <td valign="top" align="center" rowspan="1" colspan="1">SFGmed.L</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.70106</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">THA.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.7228</td>
                <td valign="top" align="center" rowspan="1" colspan="1">INS.R</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.649</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The top 10 nodes (ROIs) of the Lo-FGN screened by the SA-GCN architecture are VIIB-Cb.R, VIIB-Cb.L, HIP.R, II-Cb.R, VIII-Cb.R, II-Cb.L, VIII-Cb.L, I-Cb.L, PreCG.L, and THA.R, as shown in <xref rid="F8" ref-type="fig">Figure 8</xref>. Some studies have shown that all these brain regions are associated with ASD.</p>
        <fig position="float" id="F8">
          <label>FIGURE 8</label>
          <caption>
            <p>The top 10 nodes (ROIs) of the Lo-FGN screened by the SA-GCN architecture.</p>
          </caption>
          <graphic xlink:href="fnhum-16-918969-g008" position="float"/>
        </fig>
        <p>The top 10 nodes (ROIs) of the Ho-FGN filtered by the SA-GCN architecture are INS.L, PUT.L, SFGmed.R, PAL.L, PAL.R, PUT.R, THA.L, THA.R, SFGmed.L, and INS.R, as shown in <xref rid="F9" ref-type="fig">Figure 9</xref>. It has been shown that there are significant differences between autistic and normal individuals in SFGmed and INS; SFGmed belongs to the DMN, which is widely believed to play an important role in higher cognitive functions, and abnormalities in the DMN can be observed in a range of neurological disorders (<xref rid="B21" ref-type="bibr">Murdaugh et al., 2012</xref>; <xref rid="B39" ref-type="bibr">Washington et al., 2014</xref>); INS is highly associated with communication and affective deficits in ASD (<xref rid="B15" ref-type="bibr">Leung et al., 2015</xref>; <xref rid="B34" ref-type="bibr">Urbain et al., 2016</xref>). In summary, our proposed method can extract deeper and more discriminative features.</p>
        <fig position="float" id="F9">
          <label>FIGURE 9</label>
          <caption>
            <p>The top 10 nodes (ROIs) of the Ho-FGN screened by the SA-GCN architecture.</p>
          </caption>
          <graphic xlink:href="fnhum-16-918969-g009" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec sec-type="conclusion" id="S5">
      <title>Conclusion</title>
      <p>In this article, we propose a novel multi-view feature enhancement method based on SA-GCN. Multi-view discriminative features are extracted from the constructed Lo-FGN and Ho-FGN based on SA-GCN, respectively, and feature layer fusion enables the model to achieve the best classification results. The experimental results show that (1) with the “sliding window” strategy, the sample size can be effectively expanded to avoid the overfitting problem; (2) compared with the other methods, the pooling operation in GCN with self-attention mechanism can extract deeper and more discriminative features, which can help to explore disease-related information for ASD diagnosis; (3) complementary information among features can be achieved from multiple perspectives to improve the disease identification rate.</p>
      <p>Finally, SA-GCN can be easily extended for diagnosis of other highly heterogeneous neurodevelopmental disorders, such as Alzheimer’s disease, and depressive illness. Of course, the findings of this study are still preliminary and require further study in the future. As for future work, we plan to extend SA-GCN to other modalities in brain connectomics.</p>
    </sec>
    <sec sec-type="data-availability" id="S6">
      <title>Data Availability Statement</title>
      <p>Publicly available datasets were analyzed in this study. This data can be found here: <ext-link xlink:href="http://fcon_1000.projects.nitrc.org/indi/abide/abide_I.html" ext-link-type="uri">http://fcon_1000.projects.nitrc.org/indi/abide/abide_I.html</ext-link>.</p>
    </sec>
    <sec id="S7">
      <title>Author Contributions</title>
      <p>FZ: conceptualization, methodology, and writing-review and editing. NL: conceptualization, software, writing-original draft, methodology, formal analysis, investigation, and validation. HP: validation. XC, YL, HZ, NM, and DC: writing-review and editing. All authors contributed to the article and approved the submitted version.</p>
    </sec>
    <sec sec-type="COI-statement" id="conf1">
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
    <sec sec-type="disclaimer" id="pudiscl1">
      <title>Publisher’s Note</title>
      <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
    </sec>
  </body>
  <back>
    <sec sec-type="funding-information" id="S8">
      <title>Funding</title>
      <p>This work was supported in part by the National Natural Science Foundation of China (nos. 62176140, 82001775, 61772319, 61873177, 61972235, 61976125, and 61976124) and Doctoral Scientific Research Foundation of Shandong Technology and Business University (no. BS202016).</p>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cangea</surname><given-names>C.</given-names></name><name><surname>Veličković</surname><given-names>P.</given-names></name><name><surname>Jovanović</surname><given-names>N.</given-names></name><name><surname>Kipf</surname><given-names>T.</given-names></name><name><surname>Liò</surname><given-names>P.</given-names></name></person-group> (<year>2018</year>). <article-title>Towards sparse hierarchical graph classifiers.</article-title>
<source><italic>arXiv</italic></source>
<comment>[preprint]</comment>. <pub-id pub-id-type="doi">10.48550/arXiv.1811.01287</pub-id></mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>M.</given-names></name><name><surname>Qin</surname><given-names>C.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Using DeepGCN to identify the autism spectrum disorder from multi-site resting-state data.</article-title>
<source><italic>Biomed. Signal Proc. Control</italic></source>
<volume>70</volume>:<issue>103015</issue>. <pub-id pub-id-type="doi">10.1016/j.bspc.2021.103015</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Gao</surname><given-names>Y.</given-names></name><name><surname>Wee</surname><given-names>C.-Y.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2016</year>). <article-title>High-order resting-state functional connectivity network for MCI classification.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>37</volume>
<fpage>3282</fpage>–<lpage>3296</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23240</pub-id>
<pub-id pub-id-type="pmid">27144538</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Defferrard</surname><given-names>M.</given-names></name><name><surname>Bresson</surname><given-names>X.</given-names></name><name><surname>Vandergheynst</surname><given-names>P.</given-names></name></person-group> (<year>2016</year>). <article-title>Convolutional neural networks on graphs with fast localized spectral filtering.</article-title>
<source><italic>Adv. Neural Inform. Proc. Syst.</italic></source>
<volume>29</volume>, <fpage>3844</fpage>–<lpage>3852</lpage>.</mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>A.</given-names></name><name><surname>Yan</surname><given-names>C. G.</given-names></name><name><surname>Li</surname><given-names>Q.</given-names></name><name><surname>Denio</surname><given-names>E.</given-names></name><name><surname>Castellanos</surname><given-names>F. X.</given-names></name><name><surname>Alaerts</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism.</article-title>
<source><italic>Mol. Psychiatr.</italic></source>
<volume>19</volume>
<fpage>659</fpage>–<lpage>667</lpage>. <pub-id pub-id-type="doi">10.1038/mp.2013.78</pub-id>
<pub-id pub-id-type="pmid">23774715</pub-id></mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Easson</surname><given-names>A. K.</given-names></name><name><surname>McIntosh</surname><given-names>A. R.</given-names></name></person-group> (<year>2019</year>). <article-title>BOLD signal variability and complexity in children and adolescents with and without autism spectrum disorder.</article-title>
<source><italic>Dev. Cogn. Neurosci.</italic></source>
<volume>36</volume>:<issue>100630</issue>. <pub-id pub-id-type="doi">10.1016/j.dcn.2019.100630</pub-id>
<pub-id pub-id-type="pmid">30878549</pub-id></mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eslami</surname><given-names>T.</given-names></name><name><surname>Mirjalili</surname><given-names>V.</given-names></name><name><surname>Fong</surname><given-names>A.</given-names></name><name><surname>Laird</surname><given-names>A. R.</given-names></name><name><surname>Saeed</surname><given-names>F.</given-names></name></person-group> (<year>2019</year>). <article-title>ASD-DiagNet: a hybrid learning approach for detection of autism spectrum disorder using fMRI data.</article-title>
<source><italic>Front. Neuroinform.</italic></source>
<volume>13</volume>:<issue>70</issue>. <pub-id pub-id-type="doi">10.3389/fninf.2019.00070</pub-id>
<pub-id pub-id-type="pmid">31827430</pub-id></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gan</surname><given-names>J.</given-names></name><name><surname>Peng</surname><given-names>Z.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Hu</surname><given-names>R.</given-names></name><name><surname>Ma</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>G.</given-names></name></person-group> (<year>2021</year>). <article-title>Brain functional connectivity analysis based on multi-graph fusion.</article-title>
<source><italic>Med. Image Anal.</italic></source>
<volume>71</volume>:<issue>102057</issue>. <pub-id pub-id-type="doi">10.1016/j.media.2021.102057</pub-id>
<pub-id pub-id-type="pmid">33957559</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghorbani</surname><given-names>M.</given-names></name><name><surname>Kazi</surname><given-names>A.</given-names></name><name><surname>Baghshah</surname><given-names>M. S.</given-names></name><name><surname>Rabiee</surname><given-names>H. R.</given-names></name><name><surname>Navab</surname><given-names>N.</given-names></name></person-group> (<year>2022</year>). <article-title>Ra-gcn: graph convolutional network for disease prediction problems with imbalanced data.</article-title>
<source><italic>Medical Image Analysis</italic></source>
<volume>75</volume>
<issue>102272</issue>. <pub-id pub-id-type="doi">10.1016/j.media.2021.102272</pub-id>
<pub-id pub-id-type="pmid">34731774</pub-id></mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>P.</given-names></name><name><surname>Xu</surname><given-names>X.</given-names></name><name><surname>Luo</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>P.</given-names></name><name><surname>Lu</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). “<article-title>BCN-GCN: A Novel Brain Connectivity Network Classification Method via Graph Convolution Neural Network for Alzheimer’s Disease</article-title>,” in <source><italic>International Conference on Neural Information Processing</italic></source>, (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>657</fpage>–<lpage>668</lpage>. <pub-id pub-id-type="doi">10.3233/JAD-201163</pub-id>
</mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henaff</surname><given-names>M.</given-names></name><name><surname>Bruna</surname><given-names>J.</given-names></name><name><surname>LeCun</surname><given-names>Y.</given-names></name></person-group> (<year>2015</year>). <article-title>Deep convolutional networks on graph-structured data.</article-title>
<source><italic>arXiv</italic></source>
<comment>[preprint]</comment>. <pub-id pub-id-type="doi">10.48550/arXiv.1506.05163</pub-id></mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hiremath</surname><given-names>C. S.</given-names></name><name><surname>Sagar</surname><given-names>K. J. V.</given-names></name><name><surname>Yamini</surname><given-names>B. K.</given-names></name><name><surname>Girimaji</surname><given-names>A. S.</given-names></name><name><surname>Kumar</surname><given-names>R.</given-names></name><name><surname>Sravanti</surname><given-names>S. L.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Emerging behavioral and neuroimaging biomarkers for early and accurate characterization of autism spectrum disorders: a systematic review.</article-title>
<source><italic>Transl. Psychiatr.</italic></source>
<volume>11</volume>
<fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1038/s41398-020-01178-6</pub-id>
<pub-id pub-id-type="pmid">33441539</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ktena</surname><given-names>S. I.</given-names></name><name><surname>Parisot</surname><given-names>S.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Rajchl</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Glocker</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Metric learning with spectral graph convolutions on brain connectivity networks.</article-title>
<source><italic>NeuroImage</italic></source>
<volume>169</volume>
<fpage>431</fpage>–<lpage>442</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.12.052</pub-id>
<pub-id pub-id-type="pmid">29278772</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>I.</given-names></name><name><surname>Kang</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). “<article-title>Self-attention graph pooling</article-title>,” in <source><italic>36th International Conference on Machine Learning, ICML 2019</italic></source>, (<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IMLS</publisher-name>).</mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leung</surname><given-names>R. C.</given-names></name><name><surname>Pang</surname><given-names>E. W.</given-names></name><name><surname>Cassel</surname><given-names>D.</given-names></name><name><surname>Brian</surname><given-names>J. A.</given-names></name><name><surname>Smith</surname><given-names>M. L.</given-names></name><name><surname>Taylor</surname><given-names>M. J.</given-names></name></person-group> (<year>2015</year>). <article-title>Early neural activation during facial affect processing in adolescents with Autism Spectrum Disorder.</article-title>
<source><italic>NeuroImage: Clin.</italic></source>
<volume>7</volume>
<fpage>203</fpage>–<lpage>212</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2014.11.009</pub-id>
<pub-id pub-id-type="pmid">25610782</pub-id></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L.</given-names></name><name><surname>Jiang</surname><given-names>H.</given-names></name><name><surname>Wen</surname><given-names>G.</given-names></name><name><surname>Cao</surname><given-names>P.</given-names></name><name><surname>Xu</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>TE-HI-GCN: an Ensemble of Transfer Hierarchical Graph Convolutional Networks for Disorder Diagnosis.</article-title>
<source><italic>Neuroinformatics</italic></source>
<fpage>1</fpage>–<lpage>23</lpage>. <comment>[Epub ahead of print]</comment>. <pub-id pub-id-type="doi">10.1007/s12021-021-09548-1</pub-id>
<pub-id pub-id-type="pmid">32728882</pub-id></mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Dvornek</surname><given-names>N.</given-names></name><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Gao</surname><given-names>S.</given-names></name><name><surname>Zhuang</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Braingnn: Interpretable brain graph neural network for fmri analysis.</article-title>
<source><italic>Med. Image Anal.</italic></source>
<volume>74</volume>:<issue>102233</issue>. <pub-id pub-id-type="doi">10.1016/j.media.2021.102233</pub-id>
<pub-id pub-id-type="pmid">34655865</pub-id></mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>H. Y.</given-names></name><name><surname>Tseng</surname><given-names>W. Y. I.</given-names></name><name><surname>Lai</surname><given-names>M. C.</given-names></name><name><surname>Matsuo</surname><given-names>K.</given-names></name><name><surname>Gau</surname><given-names>S. S. F.</given-names></name></person-group> (<year>2015</year>). <article-title>Altered resting-state frontoparietal control network in children with attention-deficit/hyperactivity disorder.</article-title>
<source><italic>J. Int. Neuropsychol. Soc.</italic></source>
<volume>21</volume>
<fpage>271</fpage>–<lpage>284</lpage>.<pub-id pub-id-type="pmid">25928822</pub-id></mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lord</surname><given-names>C.</given-names></name><name><surname>Brugha</surname><given-names>T. S.</given-names></name><name><surname>Charman</surname><given-names>T.</given-names></name><name><surname>Cusack</surname><given-names>J.</given-names></name><name><surname>Dumas</surname><given-names>G.</given-names></name><name><surname>Frazier</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Autism spectrum disorder.</article-title>
<source><italic>Nat. Rev. Dis. Prim.</italic></source>
<volume>6</volume>
<fpage>1</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1038/s41572-019-0138-4</pub-id>
<pub-id pub-id-type="pmid">31907359</pub-id></mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maenner</surname><given-names>M. J.</given-names></name><name><surname>Shaw</surname><given-names>K. A.</given-names></name><name><surname>Bakian</surname><given-names>A. V.</given-names></name><name><surname>Bilder</surname><given-names>D. A.</given-names></name><name><surname>Durkin</surname><given-names>M. S.</given-names></name><name><surname>Esler</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Prevalence and characteristics of autism spectrum disorder among children aged 8 years—autism and developmental disabilities monitoring network, 11 sites.</article-title>
<source><italic>United States, 2018. MMWR Surveill. Sum.</italic></source>
<volume>70</volume>
<fpage>1</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.15585/mmwr.ss7011a1</pub-id>
<pub-id pub-id-type="pmid">34855725</pub-id></mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murdaugh</surname><given-names>D. L.</given-names></name><name><surname>Shinkareva</surname><given-names>S. V.</given-names></name><name><surname>Deshpande</surname><given-names>H. R.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Pennick</surname><given-names>M. R.</given-names></name><name><surname>Kana</surname><given-names>R. K.</given-names></name></person-group> (<year>2012</year>). <article-title>Differential deactivation during mentalizing and classification of autism based on default mode network connectivity.</article-title>
<source><italic>PloS one</italic></source>
<volume>7</volume>:<issue>e50064</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0050064</pub-id>
<pub-id pub-id-type="pmid">23185536</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>S.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Long</surname><given-names>G.</given-names></name><name><surname>Zhang</surname><given-names>C.</given-names></name></person-group> (<year>2017</year>). “<article-title>Task sensitive feature exploration and learning for multitask graph classification</article-title>,”. <source><italic>IEEE Transac. Cybernet.</italic></source>
<volume>47</volume>
<fpage>744</fpage>–<lpage>758</lpage></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>S.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Philip</surname><given-names>S. Y.</given-names></name></person-group> (<year>2015</year>). <article-title>Joint structure feature exploration and regularization for multi-task graph classification.</article-title>
<source><italic>IEEE Transactions Knowl. Data Eng.</italic></source>
<volume>28</volume>, <fpage>715</fpage>–<lpage>728</lpage>. <pub-id pub-id-type="doi">10.1109/TKDE.2015.2492567</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parisot</surname><given-names>S.</given-names></name><name><surname>Ktena</surname><given-names>S. I.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Guerrero</surname><given-names>R.</given-names></name><name><surname>Glocker</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Disease prediction using graph convolutional networks: application to autism spectrum disorder and Alzheimer’s disease.</article-title>
<source><italic>Med. Image Anal.</italic></source>
<volume>48</volume>
<fpage>117</fpage>–<lpage>130</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2018.06.001</pub-id>
<pub-id pub-id-type="pmid">29890408</pub-id></mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname><given-names>S.</given-names></name><name><surname>Gohel</surname><given-names>S.</given-names></name><name><surname>Biswal</surname><given-names>B. B.</given-names></name></person-group> (<year>2015</year>). <article-title>Altered functional connectivity strength in abstinent chronic cocaine smokers compared to healthy controls.</article-title>
<source><italic>Brain Connect.</italic></source>
<volume>5</volume>
<fpage>476</fpage>–<lpage>486</lpage>. <pub-id pub-id-type="doi">10.1089/brain.2014.0240</pub-id>
<pub-id pub-id-type="pmid">26005203</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinhart</surname><given-names>R. M.</given-names></name><name><surname>Nguyen</surname><given-names>J. A.</given-names></name></person-group> (<year>2019</year>). <article-title>Working memory revived in older adults by synchronizing rhythmic brain circuits.</article-title>
<source><italic>Nat. Neurosci.</italic></source>
<volume>22</volume>
<fpage>820</fpage>–<lpage>827</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-019-0371-x</pub-id>
<pub-id pub-id-type="pmid">30962628</pub-id></mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rhee</surname><given-names>S.</given-names></name><name><surname>Seo</surname><given-names>S.</given-names></name><name><surname>Kim</surname><given-names>S.</given-names></name></person-group> (<year>2017</year>). <article-title>Hybrid approach of relation network and localized graph convolutional filtering for breast cancer subtype classification.</article-title>
<source><italic>arXiv</italic></source>
<comment>[preprint]</comment>. <pub-id pub-id-type="doi">10.48550/arXiv.1711.05859</pub-id></mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M.</given-names></name><name><surname>Sporns</surname><given-names>O.</given-names></name></person-group> (<year>2010</year>). <article-title>Complex network measures of brain connectivity: uses and interpretations.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>52</volume>
<fpage>1059</fpage>–<lpage>1069</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id>
<pub-id pub-id-type="pmid">19819337</pub-id></mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sartipi</surname><given-names>S.</given-names></name><name><surname>Shayesteh</surname><given-names>M. G.</given-names></name><name><surname>Kalbkhani</surname><given-names>H.</given-names></name></person-group> (<year>2018</year>). “<article-title>Diagnosing of Autism Spectrum Disorder based on GARCH Variance Series for rs-fMRI data[C]//</article-title>,” in <source><italic>2018 9th International Symposium on Telecommunications (IST).</italic></source></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satterthwaite</surname><given-names>T. D.</given-names></name><name><surname>Elliott</surname><given-names>M. A.</given-names></name><name><surname>Gerraty</surname><given-names>R. T.</given-names></name><name><surname>Ruparel</surname><given-names>K.</given-names></name><name><surname>Loughead</surname><given-names>J.</given-names></name><name><surname>Calkins</surname><given-names>M. E.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>An improved framework for confound regression and filtering for control of motion artifact in the preprocessing of resting-state functional connectivity data.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>64</volume>
<fpage>240</fpage>–<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.08.052</pub-id>
<pub-id pub-id-type="pmid">22926292</pub-id></mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>L.</given-names></name><name><surname>Fu</surname><given-names>C.</given-names></name><name><surname>You</surname><given-names>Y.</given-names></name><name><surname>Fu</surname><given-names>D.</given-names></name></person-group> (<year>2021</year>). <article-title>Classification of ASD based on fMRI data with deep learning.</article-title>
<source><italic>Cogn. Neurodynam.</italic></source>
<volume>15</volume>
<fpage>961</fpage>–<lpage>974</lpage>. <pub-id pub-id-type="doi">10.1007/s11571-021-09683-0</pub-id>
<pub-id pub-id-type="pmid">34790264</pub-id></mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sidhu</surname><given-names>G.</given-names></name></person-group> (<year>2019</year>). <article-title>Locally linear embedding and fMRI feature selection in psychiatric classification.</article-title>
<source><italic>IEEE J. Transl. Eng. Health Medicine</italic></source>
<volume>7</volume>
<fpage>1</fpage>–<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1109/JTEHM.2019.2936348</pub-id>
<pub-id pub-id-type="pmid">31497410</pub-id></mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>F.</given-names></name><name><surname>Frangi</surname><given-names>A. F.</given-names></name><name><surname>Cao</surname><given-names>J.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Lei</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Graph convolution network with similarity awareness and adaptive calibration for disease-induced deterioration prediction.</article-title>
<source><italic>Med. Image Anal.</italic></source>
<volume>69</volume>:<issue>101947</issue>. <pub-id pub-id-type="doi">10.1016/j.media.2020.101947</pub-id>
<pub-id pub-id-type="pmid">33388456</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbain</surname><given-names>C.</given-names></name><name><surname>Vogan</surname><given-names>V. M.</given-names></name><name><surname>Ye</surname><given-names>A. X.</given-names></name><name><surname>Pang</surname><given-names>E. W.</given-names></name><name><surname>Doesburg</surname><given-names>S. M.</given-names></name><name><surname>Taylor</surname><given-names>M. J.</given-names></name></person-group> (<year>2016</year>). <article-title>Desynchronization of fronto-temporal networks during working memory processing in autism.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>37</volume>
<fpage>153</fpage>–<lpage>164</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23021</pub-id>
<pub-id pub-id-type="pmid">26485059</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name><name><surname>Hu</surname><given-names>X. P.</given-names></name></person-group> (<year>2021</year>). <article-title>Graph convolutional network for fMRI analysis based on connectivity neighborhood.</article-title>
<source><italic>Netw. Neurosci.</italic></source>
<volume>5</volume>
<fpage>83</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1162/netn_a_00171</pub-id><pub-id pub-id-type="pmid">33688607</pub-id></mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Huang</surname><given-names>J.</given-names></name><name><surname>Yap</surname><given-names>P. T.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2019</year>). <article-title>Identifying autism spectrum disorder with multi-site fMRI via low-rank domain adaptation.</article-title>
<source><italic>IEEE Transac. Med. Imaging</italic></source>
<volume>39</volume>
<fpage>644</fpage>–<lpage>655</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2019.2933160</pub-id>
<pub-id pub-id-type="pmid">31395542</pub-id></mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>N.</given-names></name><name><surname>Yao</surname><given-names>D.</given-names></name><name><surname>Ma</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name></person-group> (<year>2022</year>). <article-title>Multi-site clustering and nested feature extraction for identifying autism spectrum disorder with resting-state fMRI.</article-title>
<source><italic>Med. Image Anal.</italic></source>
<volume>75</volume>:<issue>102279</issue>. <pub-id pub-id-type="doi">10.1016/j.media.2021.102279</pub-id>
<pub-id pub-id-type="pmid">34731776</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Xiang</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>Q.</given-names></name><name><surname>Chong</surname><given-names>J.</given-names></name></person-group> (<year>2022</year>). <article-title>MAGE: automatic diagnosis of autism spectrum disorders using multi-atlas graph convolutional networks and ensemble learning.</article-title>
<source><italic>Neurocomputing</italic></source>
<volume>469</volume>
<fpage>346</fpage>–<lpage>353</lpage>. <pub-id pub-id-type="doi">10.1016/j.neucom.2020.06.152</pub-id></mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Washington</surname><given-names>S. D.</given-names></name><name><surname>Gordon</surname><given-names>E. M.</given-names></name><name><surname>Brar</surname><given-names>J.</given-names></name><name><surname>Warburton</surname><given-names>S.</given-names></name><name><surname>Sawyer</surname><given-names>A. T.</given-names></name><name><surname>Wolfe</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Dysmaturation of the default mode network in autism.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>35</volume>
<fpage>1284</fpage>–<lpage>1296</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22252</pub-id>
<pub-id pub-id-type="pmid">23334984</pub-id></mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Yuan</surname><given-names>C.</given-names></name><name><surname>Zhai</surname><given-names>Q.</given-names></name><name><surname>Tian</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Identifying diseases that cause psychological trauma and social avoidance by GCN-Xgboost.</article-title>
<source><italic>BMC Bioinform.</italic></source>
<volume>21</volume>:<fpage>1</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1186/s12859-020-03847-1</pub-id>
<pub-id pub-id-type="pmid">33323103</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>C.</given-names></name><name><surname>Xu</surname><given-names>S.</given-names></name><name><surname>Meng</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name></person-group> (<year>2022</year>). <article-title>Instance segmentation of biological images using graph convolutional network.</article-title>
<source><italic>Eng. Appl. Artif. Intell.</italic></source>
<volume>110</volume>:<issue>104739</issue>. <pub-id pub-id-type="doi">10.1016/j.engappai.2022.104739</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>C. G.</given-names></name><name><surname>Cheung</surname><given-names>B.</given-names></name><name><surname>Kelly</surname><given-names>C.</given-names></name><name><surname>Colcombe</surname><given-names>S.</given-names></name><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>Di Martino</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>A comprehensive assessment of regional variation in the impact of head micromovements on functional connectomics.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>76</volume>
<fpage>183</fpage>–<lpage>201</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.03.004</pub-id>
<pub-id pub-id-type="pmid">23499792</pub-id></mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>D.</given-names></name><name><surname>Sui</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Yang</surname><given-names>E.</given-names></name><name><surname>Jiaerken</surname><given-names>Y.</given-names></name><name><surname>Luo</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>A mutual multi-scale triplet graph convolutional network for classification of brain disorders using functional or structural connectivity.</article-title>
<source><italic>IEEE Transac. Med. Imaging</italic></source>
<volume>40</volume>
<fpage>1279</fpage>–<lpage>1289</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2021.3051604</pub-id>
<pub-id pub-id-type="pmid">33444133</pub-id></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ying</surname><given-names>Z.</given-names></name><name><surname>You</surname><given-names>J.</given-names></name><name><surname>Morris</surname><given-names>C.</given-names></name><name><surname>Ren</surname><given-names>X.</given-names></name><name><surname>Hamilton</surname><given-names>W.</given-names></name><name><surname>Leskovec</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). <article-title>Hierarchical graph representation learning with differentiable pooling.</article-title>
<source><italic>Adv. Neural Inform. Processing systems</italic></source>
<volume>31</volume>
<fpage>1</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.3390/s21186070</pub-id>
<pub-id pub-id-type="pmid">34577277</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M.</given-names></name><name><surname>Cui</surname><given-names>Z.</given-names></name><name><surname>Neumann</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name></person-group> (<year>2018</year>). “<article-title>“An end-to-end deep learning architecture for graph classification,”</article-title>,” in <source><italic>The Thirty-Second AAAI Conference on Artificial Intelligence</italic></source>, (<publisher-loc>Washington</publisher-loc>: <publisher-name>Washington University</publisher-name>).</mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Adeli</surname><given-names>E.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Multiview feature learning with multiatlas-based functional connectivity networks for MCI diagnosis.</article-title>
<source><italic>IEEE Transac. Cybernet.</italic></source>
<comment>[Epub ahead ofprint]</comment>. <pub-id pub-id-type="doi">10.1109/TCYB.2020.3016953</pub-id>
<pub-id pub-id-type="pmid">33306476</pub-id></mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>F.</given-names></name><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Rekik</surname><given-names>I.</given-names></name><name><surname>Lee</surname><given-names>S. W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>Diagnosis of autism spectrum disorder using central-moment features from low-and high-order dynamic resting-state functional connectivity networks.</article-title>
<source><italic>Front. Neurosci.</italic></source>
<volume>14</volume>:<issue>258</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2020.00258</pub-id>
<pub-id pub-id-type="pmid">32410930</pub-id></mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>F.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Rekik</surname><given-names>I.</given-names></name><name><surname>An</surname><given-names>Z.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>Diagnosis of autism spectrum disorders using multi-level high-order functional networks derived from resting-state functional MRI.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>12</volume>:<issue>184</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2018.00184</pub-id>
<pub-id pub-id-type="pmid">29867410</pub-id></mixed-citation>
      </ref>
      <ref id="B49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>F.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Thung</surname><given-names>K. H.</given-names></name><name><surname>Mao</surname><given-names>N.</given-names></name><name><surname>Lee</surname><given-names>S. W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2021</year>). <article-title>Constructing Multi-view High-order Functional Connectivity Networks for Diagnosis of Autism Spectrum Disorder.</article-title>
<source><italic>IEEE Transac. Biomed. Eng.</italic></source>
<volume>69</volume>
<fpage>1237</fpage>–<lpage>1250</lpage>.</mixed-citation>
      </ref>
      <ref id="B50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhi</surname><given-names>D.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Lv</surname><given-names>L.</given-names></name><name><surname>Ma</surname><given-names>X.</given-names></name><name><surname>Ke</surname><given-names>Q.</given-names></name><name><surname>Fu</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Aberrant dynamic functional network connectivity and graph properties in major depressive disorder.</article-title>
<source><italic>Front. Psychiatr.</italic></source>
<volume>9</volume>:<issue>339</issue>. <pub-id pub-id-type="doi">10.3389/fpsyt.2018.00339</pub-id>
<pub-id pub-id-type="pmid">30108526</pub-id></mixed-citation>
      </ref>
      <ref id="B51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Cui</surname><given-names>G.</given-names></name><name><surname>Hu</surname><given-names>S.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Yang</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Graph neural networks: a review of methods and applications.</article-title>
<source><italic>AI Open</italic></source>
<volume>1</volume>
<fpage>57</fpage>–<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1016/j.aiopen.2021.01.001</pub-id></mixed-citation>
      </ref>
      <ref id="B52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Teng</surname><given-names>S.</given-names></name><name><surname>Qiao</surname><given-names>L.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>Improving sparsity and modularity of high-order functional connectivity networks for MCI and ASD identification.</article-title>
<source><italic>Front. Neurosci.</italic></source>
<volume>12</volume>:<issue>959</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2018.00959</pub-id>
<pub-id pub-id-type="pmid">30618582</pub-id></mixed-citation>
      </ref>
      <ref id="B53">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Ma</surname><given-names>J.</given-names></name><name><surname>Yuan</surname><given-names>C.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name></person-group> (<year>2022</year>). <article-title>Interpretable learning based dynamic graph convolutional networks for alzheimer’s disease analysis.</article-title>
<source><italic>Inform. Fusion</italic></source>
<volume>77</volume>
<fpage>53</fpage>–<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1016/j.inffus.2021.07.013</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
