<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" id="hbm26112" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Hum Brain Mapp</journal-id>
      <journal-id journal-id-type="iso-abbrev">Hum Brain Mapp</journal-id>
      <journal-id journal-id-type="doi">10.1002/(ISSN)1097-0193</journal-id>
      <journal-id journal-id-type="publisher-id">HBM</journal-id>
      <journal-title-group>
        <journal-title>Human Brain Mapping</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1065-9471</issn>
      <issn pub-type="epub">1097-0193</issn>
      <publisher>
        <publisher-name>John Wiley &amp; Sons, Inc.</publisher-name>
        <publisher-loc>Hoboken, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">36371779</article-id>
      <article-id pub-id-type="pmc">9783448</article-id>
      <article-id pub-id-type="doi">10.1002/hbm.26112</article-id>
      <article-id pub-id-type="publisher-id">HBM26112</article-id>
      <article-categories>
        <subj-group subj-group-type="overline">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="heading">
          <subject>Research Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Differences in functional connectivity distribution after transcranial direct‐current stimulation: A connectivity density point of view</article-title>
        <alt-title alt-title-type="left-running-head">Tang et al.</alt-title>
      </title-group>
      <contrib-group>
        <contrib id="hbm26112-cr-0001" contrib-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>Bohao</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9322-4438</contrib-id>
          <xref rid="hbm26112-aff-0001" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib id="hbm26112-cr-0002" contrib-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>Yi</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4766-5934</contrib-id>
          <xref rid="hbm26112-aff-0002" ref-type="aff">
<sup>2</sup>
</xref>
        </contrib>
        <contrib id="hbm26112-cr-0003" contrib-type="author">
          <name>
            <surname>Venkataraman</surname>
            <given-names>Archana</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2653-5591</contrib-id>
          <xref rid="hbm26112-aff-0003" ref-type="aff">
<sup>3</sup>
</xref>
        </contrib>
        <contrib id="hbm26112-cr-0004" contrib-type="author">
          <name>
            <surname>Tsapkini</surname>
            <given-names>Kyrana</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-6020-5532</contrib-id>
          <xref rid="hbm26112-aff-0004" ref-type="aff">
<sup>4</sup>
</xref>
          <xref rid="hbm26112-aff-0005" ref-type="aff">
<sup>5</sup>
</xref>
        </contrib>
        <contrib id="hbm26112-cr-0005" contrib-type="author">
          <name>
            <surname>Lindquist</surname>
            <given-names>Martin A.</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-2289-0828</contrib-id>
          <xref rid="hbm26112-aff-0001" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib id="hbm26112-cr-0006" contrib-type="author">
          <name>
            <surname>Pekar</surname>
            <given-names>James</given-names>
          </name>
          <xref rid="hbm26112-aff-0006" ref-type="aff">
<sup>6</sup>
</xref>
          <xref rid="hbm26112-aff-0007" ref-type="aff">
<sup>7</sup>
</xref>
        </contrib>
        <contrib id="hbm26112-cr-0007" contrib-type="author" corresp="yes">
          <name>
            <surname>Caffo</surname>
            <given-names>Brian</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0793-9497</contrib-id>
          <xref rid="hbm26112-aff-0001" ref-type="aff">
<sup>1</sup>
</xref>
          <address>
            <email>bcaffo@gmail.com</email>
          </address>
        </contrib>
      </contrib-group>
      <aff id="hbm26112-aff-0001">
<label>
<sup>1</sup>
</label>
<named-content content-type="organisation-division">Department of Biostatistics</named-content>
<institution>Johns Hopkins University</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff>
      <aff id="hbm26112-aff-0002">
<label>
<sup>2</sup>
</label>
<named-content content-type="organisation-division">Department of Biostatistics and Health Data Science</named-content>
<institution>Indiana University School of Medicine</institution>
<city>Indianapolis</city>
<named-content content-type="country-part">Indiana</named-content>
<country country="US">USA</country>
</aff>
      <aff id="hbm26112-aff-0003">
<label>
<sup>3</sup>
</label>
<named-content content-type="organisation-division">Department of Electrical and Computer Engineering</named-content>
<institution>Johns Hopkins University</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff>
      <aff id="hbm26112-aff-0004">
<label>
<sup>4</sup>
</label>
<named-content content-type="organisation-division">Department of Neurology</named-content>
<institution>Johns Hopkins Medicine</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff>
      <aff id="hbm26112-aff-0005">
<label>
<sup>5</sup>
</label>
<named-content content-type="organisation-division">Department of Cognitive Science</named-content>
<institution>Johns Hopkins Medicine</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff>
      <aff id="hbm26112-aff-0006">
<label>
<sup>6</sup>
</label>
<named-content content-type="organisation-division">F.M. Kirby Research Center for Functional Brain Imaging</named-content>
<institution>Kennedy Krieger Institute</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff>
      <aff id="hbm26112-aff-0007">
<label>
<sup>7</sup>
</label>
<named-content content-type="organisation-division">Department of Radiology and Radiological Science</named-content>
<institution>Johns Hopkins University Medicine</institution>
<city>Baltimore</city>
<named-content content-type="country-part">Maryland</named-content>
<country country="US">USA</country>
</aff>
      <author-notes>
        <corresp id="correspondenceTo">
<label>*</label>
<bold>Correspondence</bold>
<break/>
Brian Caffo, Department of Biostatistics, Johns Hopkins University, Baltimore, MD, USA.<break/>
Email: <email>bcaffo@gmail.com</email>
<break/>
</corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>13</day>
        <month>11</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="collection">
        <month>1</month>
        <year>2023</year>
      </pub-date>
      <volume>44</volume>
      <issue seq="140">1</issue>
      <issue-id pub-id-type="doi">10.1002/hbm.v44.1</issue-id>
      <fpage>170</fpage>
      <lpage>185</lpage>
      <history>
<date date-type="rev-recd"><day>09</day><month>9</month><year>2022</year></date>
<date date-type="received"><day>25</day><month>1</month><year>2022</year></date>
<date date-type="accepted"><day>02</day><month>10</month><year>2022</year></date>
</history>
      <permissions>
        <!--&#x000a9; 2023 Wiley Periodicals LLC.-->
        <copyright-statement content-type="article-copyright">© 2022 The Authors. <italic toggle="yes">Human Brain Mapping</italic> published by Wiley Periodicals LLC.</copyright-statement>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p>
        </license>
      </permissions>
      <self-uri content-type="pdf" xlink:href="file:HBM-44-170.pdf"/>
      <abstract>
        <title>Abstract</title>
        <p>In this manuscript, we consider the problem of relating functional connectivity measurements viewed as statistical distributions to outcomes. We demonstrate the utility of using the distribution of connectivity on a study of resting‐state functional magnetic resonance imaging association with an intervention. The method uses the estimated density of connectivity between nodes of interest as a functional covariate. Moreover, we demonstrate the utility of the procedure in an instance where connectivity is naturally considered an outcome by reversing the predictor/response relationship using case/control methodology. The method utilizes the density quantile, the density evaluated at empirical quantiles, instead of the empirical density directly. This improved the performance of the method by highlighting tail behavior, though we emphasize that by being flexible and non‐parametric, the technique can detect effects related to the central portion of the density. To demonstrate the method in an application, we consider 47 primary progressive aphasia patients with various levels of language abilities. These patients were randomly assigned to two treatment arms, transcranial direct‐current stimulation and language therapy versus sham (language therapy only), in a clinical trial. We use the method to analyze the effect of direct stimulation on functional connectivity. As such, we estimate the density of correlations among the regions of interest and study the difference in the density post‐intervention between treatment arms. We discover that it is the tail of the density, rather than the mean or lower order moments of the distribution, that demonstrates a significant impact in the classification. The new approach has several benefits. Among them, it drastically reduces the number of multiple comparisons compared with edge‐wise analysis. In addition, it allows for the investigation of the impact of functional connectivity on the outcomes where the connectivity is not geometrically localized.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <p>In this manuscript, we develop a method utilizing the distribution of resting‐state fMRI connectivity measurements to study the effect of a direct stimulation. The method can drastically reduce the number of multiple comparisons compared with edge‐wise analysis. In addition, it allows for the investigation of the impact of functional connectivity on the outcomes where the connectivity is not geometrically localized.<boxed-text position="anchor" content-type="graphic" id="hbm26112-blkfxd-0001"><graphic xlink:href="HBM-44-170-g001.jpg" position="anchor" id="jats-graphic-1"/></boxed-text>
</p>
      </abstract>
      <kwd-group kwd-group-type="author-generated">
        <kwd id="hbm26112-kwd-0001">density regression</kwd>
        <kwd id="hbm26112-kwd-0002">functional connectivity</kwd>
        <kwd id="hbm26112-kwd-0003">random graph</kwd>
      </kwd-group>
      <funding-group>
        <award-group id="funding-0001">
          <funding-source>NSF CAREER</funding-source>
          <award-id>1845430</award-id>
        </award-group>
        <award-group id="funding-0002">
          <funding-source>NSF CRCNS</funding-source>
          <award-id>1822575</award-id>
        </award-group>
        <award-group id="funding-0003">
          <funding-source>
            <institution-wrap>
              <institution>National institutes of health
</institution>
              <institution-id institution-id-type="doi">10.13039/100000002</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id>P41EB015909</award-id>
          <award-id>P41EB031771</award-id>
        </award-group>
        <award-group id="funding-0004">
          <funding-source>
            <institution-wrap>
              <institution>NIH
</institution>
              <institution-id institution-id-type="doi">10.13039/501100012264</institution-id>
            </institution-wrap>
          </funding-source>
          <award-id>R01 DC014475</award-id>
          <award-id>R01 EB016061</award-id>
          <award-id>R01 EB026549</award-id>
          <award-id>R01 EB029977</award-id>
        </award-group>
      </funding-group>
      <counts>
        <fig-count count="8"/>
        <table-count count="3"/>
        <page-count count="16"/>
        <word-count count="11981"/>
      </counts>
      <custom-meta-group>
        <custom-meta>
          <meta-name>source-schema-version-number</meta-name>
          <meta-value>2.0</meta-value>
        </custom-meta>
        <custom-meta>
          <meta-name>cover-date</meta-name>
          <meta-value>January 2023</meta-value>
        </custom-meta>
        <custom-meta>
          <meta-name>details-of-publishers-convertor</meta-name>
          <meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:6.2.3 mode:remove_FC converted:23.12.2022</meta-value>
        </custom-meta>
      </custom-meta-group>
    </article-meta>
    <notes>
      <p content-type="self-citation">
<mixed-citation publication-type="journal" id="hbm26112-cit-9001">
<string-name>
<surname>Tang</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Zhao</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Venkataraman</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Tsapkini</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Lindquist</surname>, <given-names>M. A.</given-names>
</string-name>, <string-name>
<surname>Pekar</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Caffo</surname>, <given-names>B.</given-names>
</string-name> (<year>2023</year>). <article-title>Differences in functional connectivity distribution after transcranial direct‐current stimulation: A connectivity density point of view</article-title>. <source>Human Brain Mapping</source>, <volume>44</volume>(<issue>1</issue>), <fpage>170</fpage>–<lpage>185</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.26112</pub-id>
</mixed-citation>
</p>
      <fn-group>
        <fn id="hbm26112-note-1002">
          <p>
<bold>Funding information</bold> NSF CAREER, Grant/Award Number: 1845430; NSF CRCNS, Grant/Award Number: 1822575; National institutes of health, Grant/Award Numbers: P41EB015909, P41EB031771; NIH, Grant/Award Numbers: R01 DC014475, R01 EB016061, R01 EB026549, R01 EB029977</p>
        </fn>
      </fn-group>
    </notes>
  </front>
  <body id="hbm26112-body-0001">
    <sec id="hbm26112-sec-0001">
      <label>1</label>
      <title>INTRODUCTION</title>
      <p>The study of resting‐state brain connectivity via functional magnetic resonance imaging (fMRI) involves the investigation of correlations between cortical seeds, regions, or voxels (henceforth referred to as foci). Friston, in particular, defined functional connectivity as the correlations, over time, between spatially distinct brain regions (Friston, <xref rid="hbm26112-bib-0018" ref-type="bibr">2011</xref>). Nearly all inter‐subject investigations of connectivity have focused on <italic toggle="yes">localized correlations</italic>. That is, they consider correlations between foci treated consistently across subjects. Mathematically, this can be described as saying that the methods are not invariant to subject‐specific relabeling of the foci. In fact, for most methods, such as pairwise regressions on correlations across subjects or decomposition methods, shuffling foci labels within subjects is a form of null distribution. Furthermore, this lack of invariance applies regardless of the degree of granularity of the analysis, from regions to seeds to voxels (Bastos &amp; Schoffelen, <xref rid="hbm26112-bib-0001" ref-type="bibr">2016</xref>; Damoiseaux &amp; Greicius, <xref rid="hbm26112-bib-0010" ref-type="bibr">2009</xref>; Friston, <xref rid="hbm26112-bib-0018" ref-type="bibr">2011</xref>). The methods and choice of granularity all center the focus on geographic consistency of correlations across groups of similar subjects. Individual topography (Kong et al., <xref rid="hbm26112-bib-0032" ref-type="bibr">2019</xref>) and functional connectivity alignment (Haxby et al., <xref rid="hbm26112-bib-0029" ref-type="bibr">2020</xref>) are another set of methods that allow for spatially inconsistent relationships beyond subject‐specific structure. However, their effort of finding subject‐specific parcellation/transformation is still for the purpose of localization. Other exceptions include many variations of graph theory‐based methods, where graphical features may not be localized across subjects in the sense of summarizing multiple connections (Shen et al., <xref rid="hbm26112-bib-0049" ref-type="bibr">2017</xref>) or being invariant to subject‐specific foci labels (Koutra et al., <xref rid="hbm26112-bib-0033" ref-type="bibr">2013</xref>; Vogelstein et al., <xref rid="hbm26112-bib-0055" ref-type="bibr">2012</xref>).</p>
      <p>To illustrate the idea of label invariance, consider a scenario where one reduces the connectivity measures to subject‐specific binary graphs (by thresholding). If the effect of the graphs on the outcomes is invariant to the nodes (foci) corresponding to the edges, then clearly it is sufficient to know the number of edges that are present for each subject's graph, since given that information one can create the set of equivalent graphs under node invariance. This is equivalent to saying the relationship between the outcome and connectivity graph, is solely dependent on the estimated probability distribution for the edges under an assumed independent and identically distributed edge distribution, since that distribution only depends on the total number of edges. (This is the Erdős‐Rényi random graph model.) Our approach formally builds on this idea. But we further consider a random weighted graph model rather than thresholding to obtain binary edges, and propose a specific functional linear model for the relationship between outcomes and the connectivity density.</p>
      <p>We demonstrate the benefits of using the distribution of resting state correlations as covariates using functional data analysis tools. We suggest the use of the quantile density, the density of connections evaluated at evenly spaced quantiles of the connections, as this improves performance. Regardless of these choices, utilizing connectivity density regression has several benefits. A primary one is the relaxation of the consistent localization assumption across subjects. In the Appendix <xref rid="hbm26112-app-0001" ref-type="app">A</xref>, we demonstrate mathematically how connection densities achieve this invariance. Localization analyses make the, often unchallenged, assumption that pairs of foci represent the same correlated functional specialization across exchangeable subjects. This assumption is grounded in the neurological theory of functional specialization dating back to the foundational works of Broca and Weirnicke (Broca, <xref rid="hbm26112-bib-0005" ref-type="bibr">1861</xref>; Wernicke, <xref rid="hbm26112-bib-0057" ref-type="bibr">1874</xref>). However, it is clear that in specific applications and biological settings, the neural geography of functional specialization can vary. As an extreme example, subjects with brain damage in their youth often have the neuroplasticity that remaps a function to atypical areas (Finger &amp; Almli, <xref rid="hbm26112-bib-0017" ref-type="bibr">1985</xref>).</p>
      <p>Hyperalignment (Haxby et al., <xref rid="hbm26112-bib-0029" ref-type="bibr">2020</xref>) also allows for a high degree of subject‐specific functional specialization. However, unlike connectivity density regression, localization remains the goal in hyperalignment, and therefore, a multiparameter alignment transformation must be estimated per subject. Connectivity density analysis can be seen as a complementary, technique that does not require the estimation of subject‐specific alignment. Further, focusing on connectivity densities drastically simplifies the problem and reduces multiplicity concerns. Of course, these benefits come at the cost of not considering potentially relevant localization information, and so the technique cannot be more sensitive to the detection of localized effects with a reduced search space and correct a priori localization hypotheses. It would be accurate to say that focusing on connectivity densities in analysis lies at one end of the spectrum of model localization assumptions, whereas pair at a time models lie at the other extreme and hyperalignment lying somewhere in the middle.</p>
      <p>There are existing studies that utilize the distribution of resting state correlations. For example, Petersen and Muüller (<xref rid="hbm26112-bib-0040" ref-type="bibr">2016</xref>) consider the distribution of correlations between a seed voxel and all other voxels within regions of interest (ROI), to summarize the ROI state. Also, Scheinost et al. (<xref rid="hbm26112-bib-0048" ref-type="bibr">2012</xref>) further considered such distributions across all pairs of voxels. This work derived a degree function from the connection density as a summary of the connectivity of each voxel. As a result, these studies continue to focus on localized effects, where the use of the connectivity density is mainly to achieve a more informative localized summary of brain connectivity.</p>
      <p>This study is motivated by a resting‐state fMRI study of primary progressive aphasia (PPA) patients, where it is feasible to want to relax the geometric localization assumption. In the study, the patients were randomly assigned into two treatment groups, (a) transcranial direct‐current stimulation (tDCS; Nitsche et al., <xref rid="hbm26112-bib-0037" ref-type="bibr">2008</xref>) and language therapy versus (b) a sham tDCS and language therapy only. In the tDCS group, the nominal stimulation target was the left inferior frontal gyrus (IFG). Since the actual area of stimulation may vary, even if only slightly, it is relevant to consider models that are less dependent on localization. In addition, the stimulation electrode patches were size of 5 × 5 = 25 cm<sup>2</sup>. Thus, the stimulation areas may have extended beyond the left IFG in a way that may induce additional variation across subjects that would also motivate considering techniques that are robust to violations of localization assumptions. Here, we propose a novel approach to represent the effect of stimulation on functional connectivity. By ignoring spatial heterogeneity, we directly study the change on the distribution of correlation between the ROIs.</p>
      <p>The manuscript is organized as follows. In Section <xref rid="hbm26112-sec-0002" ref-type="sec">2</xref>, the experimental design and approach are introduced. Results both for simulated and real data are shown in Section <xref rid="hbm26112-sec-0009" ref-type="sec">3</xref>. Section <xref rid="hbm26112-sec-0014" ref-type="sec">4</xref> contains a summary and discussion.</p>
    </sec>
    <sec sec-type="materials-and-methods" id="hbm26112-sec-0002">
      <label>2</label>
      <title>MATERIAL AND METHODS</title>
      <sec id="hbm26112-sec-0003">
        <label>2.1</label>
        <title>Experimental design</title>
        <p>The data analyzed in this study were part of a larger randomized, double‐blinded, sham‐controlled, crossover study on aphasia treatment using tDCS. All of the analyzed subjects had at least 2 years of progressive language deficit and no history of any other neurological condition that may have affected their language ability. Subjects had atrophy predominantly in the left hemisphere. Subjects were diagnosed via neuropsychological testing, language testing, MRI, and clinical assessment according to consensus criteria (Gorno‐Tempini et al., <xref rid="hbm26112-bib-0025" ref-type="bibr">2011</xref>). The study was approved by the Johns Hopkins Hospital Institutional review board and all subjects provided informed consent to participate in the study.</p>
        <p>Each subject was diagnosed with one of the PPA variant types: logopenic, nonfluent, or semantic. Randomization was conducted within each variant type with an equal probability assigned to either the tDCS or sham group. As shown in Table <xref rid="hbm26112-tbl-0001" ref-type="table">1</xref>, the two groups are balanced in both demographic and clinical characteristics. The language component of severity was evaluated based on the revised fronto‐temporal dementia clinical dementia rating (FTD‐CDR) used to rate severity in PPA (Knopman et al., <xref rid="hbm26112-bib-0031" ref-type="bibr">2008</xref>). To calculate severity, three raters independently scored each item based on the interaction with the participant and family, language, cognitive testing, and questionnaires, followed by a discussion to produce a consensus score. In the tDCS group, the Soterix Transcranial Direct Current Stimulation 1 × 1 Clinical Trials device (Model 1500) was used to deliver tDCS (for tDCS setup details, see Tsapkini et al., <xref rid="hbm26112-bib-0054" ref-type="bibr">2018</xref>). The anode was placed over the left frontal lobe and the cathode was placed over the right cheek. The size of the nonmetallic, conductive rubber electrodes (fitted with saline‐soaked sponges to limit skin‐electrode reactions) is 5 cm × 5 cm, which covers the whole left IFG. In each tDCS session, the density of the delivered current was 2 mA and the delivery lasted for 20 min. Simultaneous with the tDCS delivery, language therapy was initiated and continued for an additional 20–25 min beyond the cessation of tDCS. The sham group had 30 s of current ramping up to 2 mA and then backing down to 0 mA simultaneous with the start of language therapy. These procedures have successfully blinded participants to the stimulation condition (Gandiga et al., <xref rid="hbm26112-bib-0019" ref-type="bibr">2006</xref>), as well as the speech‐language therapist. The protocol required 15 consecutive weekday sessions for each participant. Efforts were made to adhere to the schedule, though some participants had to leave a few days earlier because of other commitments (median number of sessions: <mml:math id="jats-math-1" display="inline" overflow="scroll"><mml:mrow><mml:mtext>sham</mml:mtext><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:math>, <mml:math id="jats-math-2" display="inline" overflow="scroll"><mml:mrow><mml:mtext>tDCS</mml:mtext><mml:mo>=</mml:mo><mml:mn>13</mml:mn></mml:mrow></mml:math>). In the language therapy, we combined the spell‐study‐spell procedure with an oral and written naming paradigm and developed individualized trained and untrained word sets (Ficek et al., <xref rid="hbm26112-bib-0016" ref-type="bibr">2018</xref>), where trained and untrained sets (10–30 words depending on individual severity) were matched in length and frequency. Each participant was shown a picture on a computer, asked to orally name it, and to write the name. If the participant could not name the picture (orally or in writing), they were asked to provide three characteristics of the item to evaluate and reinforce semantic knowledge. If they still could not describe the word orally, they were offered the correct word and asked to repeat for three times. Likewise, if the participant could not write the word, or wrote it incorrectly, the therapist would offer the correct spelling in a spell–study–spell procedure. That is, the therapist wrote the correct word, reviewed each letter's sound, and then asked the participant to copy the word three times. Letter accuracy was determined based on a scoring system (Goodman &amp; Caramazza, <xref rid="hbm26112-bib-0024" ref-type="bibr">1985</xref>) that considered letter deletions, additions, substitutions, and movements. Rather than whole‐word accuracy, letter accuracy was considered as a more precise evaluation as it captures the effects of different types of errors. Each letter was evaluated with 1 point, 0.5 points for correct identification, and 0.5 points for correct position. Scores for trained and untrained words were transformed to percentage points for each participant.</p>
        <table-wrap position="float" id="hbm26112-tbl-0001" content-type="TABLE">
          <label>TABLE 1</label>
          <caption>
            <p>Patient demographics</p>
          </caption>
          <table frame="hsides" rules="groups">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <thead valign="bottom">
              <tr style="border-bottom:solid 1px #000000">
                <th align="left" valign="bottom" rowspan="1" colspan="1"/>
                <th align="left" valign="bottom" rowspan="1" colspan="1">Combined (<italic toggle="yes">n</italic> = 47)</th>
                <th align="left" valign="bottom" rowspan="1" colspan="1">tDCS (<italic toggle="yes">n</italic> = 25)</th>
                <th align="left" valign="bottom" rowspan="1" colspan="1">Sham (<italic toggle="yes">n</italic> = 22)</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Sex</td>
                <td align="left" valign="top" rowspan="1" colspan="1">22F, 25M</td>
                <td align="left" valign="top" rowspan="1" colspan="1">11F, 14M</td>
                <td align="left" valign="top" rowspan="1" colspan="1">11F, 11M</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">PPA variant</td>
                <td align="left" valign="top" rowspan="1" colspan="1">15L, 23N, 9S</td>
                <td align="left" valign="top" rowspan="1" colspan="1">9L, 12N, 4S</td>
                <td align="left" valign="top" rowspan="1" colspan="1">6L, 11N, 5S</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Age</td>
                <td align="left" valign="top" rowspan="1" colspan="1">67.3 (6.8)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">65.8 (8.1)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">69.1 (5.0)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Year post onset</td>
                <td align="left" valign="top" rowspan="1" colspan="1">4.2 (2.8)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">4.3 (3.2)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">4.0 (2.3)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Language severity</td>
                <td align="left" valign="top" rowspan="1" colspan="1">1.7 (0.8)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">1.7 (0.9)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">1.8 (0.8)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Total severity</td>
                <td align="left" valign="top" rowspan="1" colspan="1">6.3 (4.5)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">5.7 (3.9)</td>
                <td align="left" valign="top" rowspan="1" colspan="1">7.0 (5.2)</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot id="hbm26112-ntgp-0001">
            <fn id="hbm26112-note-0001">
              <p>
<italic toggle="yes">Note</italic>: For age, years post‐onset, severity, values shown are mean (SD). The <italic toggle="yes">p</italic>‐values are from the Welch two sample <italic toggle="yes">t</italic>‐tests for continuous outcomes and Fisher's exact test for categorical outcomes. Language severity is based on the language subset from the FTD‐CDR scale. Total severity refers to the sum of boxes, including language and behavior as added in Knopman et al. (<xref rid="hbm26112-bib-0031" ref-type="bibr">2008</xref>).</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>A total of 50 right‐handed, native English‐speaking patients had a pre‐intervention scan (scan1) and 48 had a post‐intervention scan (scan2). One patient was deleted from the analysis because of missing values in the connectivity matrix. Among the remaining 47 post‐intervention scanned patients, 25 had transcranial direct‐current stimulation + language therapy and the remaining 22 patients had the sham treatment plus language therapy. Several baseline covariates were recorded including gender, disease onset (years), age at the start of therapy, and language severity. These patients were diagnosed with three variant types, including: logopenic, nonfluent, and semantic. Diagnoses were based on which function(s) were compromised. Patients with the <italic toggle="yes">Logopenic</italic> variant PPA (lvPPA) present with word‐finding difficulties and disproportionately impaired sentence repetition. Patients with <italic toggle="yes">nonfluent</italic> variant PPA (nfvPPA) present with difficulty producing grammatical sentences and/or exhibit motor speech impairment (apraxia of speech). Finally, patients with <italic toggle="yes">semantic</italic> variant PPA (svPPA) present with fluent speech, but impaired word comprehension. See Table <xref rid="hbm26112-tbl-0001" ref-type="table">1</xref> for a summary of demographic and clinical information on the participants.</p>
      </sec>
      <sec id="hbm26112-sec-0004">
        <label>2.2</label>
        <title>Data preprocessing</title>
        <p>MRI scans were obtained at the Kennedy Krieger Institute at Johns Hopkins University, using a 3 T Philips Achieva MRI scanner equipped with a 32‐channel head coil. Resting‐state fMRI (rsfMRI) data were acquired for ~9 min (210 time‐point acquisitions) post‐intervention. We used a 2D EPI sequence with SENSE partial‐parallel imaging acceleration to obtain an in‐plane resolution of 3.3 × 3.3 mm<sup>2</sup> (64 × 64 voxels; TR/TE = 2500/30 ms; flip angle = 75°; SENSE acceleration factor = 2; SPIR for fat suppression, 3‐mm slice thickness). The data were co‐registered with structural scans into the same anatomical space. Structural scans, acquired axially with a scan time of 6 min (150 slices), used a T1‐weighted MPRAGE sequence with 3D inversion recovery, magnetization‐prepared rapid gradient, isotropic with a resolution of 1 × 1 × 1 mm<sup>3</sup> (FOV = 224 × 224 mm<sup>2</sup>; TR/TE = 8.1/3.7 ms; flip angle = 8°; SENSE acceleration factor = 2).</p>
        <p>Using MRICloud, a cloud‐platform for automated image parcellation approach (atlas‐based analysis), the MPRAGE scan was parcellated into 283 structures (Mori et al., <xref rid="hbm26112-bib-0036" ref-type="bibr">2016</xref>). In detail, each participant's high‐resolution MPRAGE was segmented by using a multi‐atlas fusion label algorithm (MALF) and large deformation diffeomorphic metric mapping, LDDMM (Ceritoglu et al., <xref rid="hbm26112-bib-0008" ref-type="bibr">2013</xref>; Miller et al., <xref rid="hbm26112-bib-0035" ref-type="bibr">2005</xref>; Tang et al., <xref rid="hbm26112-bib-0053" ref-type="bibr">2013</xref>). This highly accurate diffeomorphic algorithm, associated with multiple atlases, minimizes the mapping inaccuracies due to atrophy or local shape deformations. All analyses were performed in native space. To control for relative regional atrophy, volumes for each ROI were normalized by the total intracerebral volume (total brain tissue without myelencephalon and cerebrospinal fluid). The resting‐state fMRI was also processed in MRICloud and analyzed in a seed‐by‐seed manner. Image processing is described in Faria et al. (<xref rid="hbm26112-bib-0015" ref-type="bibr">2012</xref>) including routines imported from the SPM connectivity toolbox for coregistration, motion, and slice timing correction, physiological nuisance correction using CompCor (Behzadi et al., <xref rid="hbm26112-bib-0002" ref-type="bibr">2007</xref>), and motion and intensity TR outlier rejection using ART (<ext-link xlink:href="https://www.nitrc.org/projects/artifact_detect/" ext-link-type="uri">https://www.nitrc.org/projects/artifact_detect/</ext-link>). The MRICloud pipeline followed established steps for rsfMRI processing as follows. After exclusion of outlier TRs per the ART routine (parameters: 2 SDs for motion and 4 SDs for intensity, more severe than the default of 9), the movement matrix combined with the physiological nuisance matrix was used in the deconvolution regression for the remaining TRs. Outlier rejection and regression of motion parameters minimize potential motion effects. The parcels resulting from the high‐resolution T1 segmentation were brought to the resting state dynamics by co‐registration. Time‐courses of 78 cortical and deep gray matter ROIs were extracted and the correlations among them were calculated.</p>
      </sec>
      <sec id="hbm26112-sec-0005">
        <label>2.3</label>
        <title>Density regression</title>
        <p>We propose to quantify the effect of possibly non‐localized stimulation on functional connectivity through a density regression. Let <mml:math id="jats-math-3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> be a connectivity measure, such as the correlation of the BOLD time series, between foci <mml:math id="jats-math-4" display="inline" overflow="scroll"><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-5" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:math> for <mml:math id="jats-math-6" display="inline" overflow="scroll"><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>…</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-7" display="inline" overflow="scroll"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:mi>…</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:math> and then let <mml:math id="jats-math-8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> be the collection of connectivity measurements, typically represented by a symmetric matrix, but in our case simply an ordered vector. We study the distributional summary of the collections of <mml:math id="jats-math-9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> exactly as if they were drawn independently from a distribution. Let <mml:math id="jats-math-10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> be the estimate of the associated density <mml:math id="jats-math-11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> of connections for subject <mml:math id="jats-math-12" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math>. Our proposal is to analyze <mml:math id="jats-math-13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> with functional regression methods. A motivation for studying <mml:math id="jats-math-14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> can be obtained by the weaker assumption of exchangeability of the labels. Such exchangeability translates in this context to the relevant information for predicting the outcome being in the proportion of stronger and weaker connections, regardless of where they occur.</p>
        <p>The process of proceeding from fMRI scans to the connectivity density is outlined in Figure <xref rid="hbm26112-fig-0001" ref-type="fig">1</xref>. We estimated the connectivity matrix via temporal correlations of BOLD signals between ROIs after parcellation, which were then passed to a density estimation algorithm. Specifically, we used the vectorized elements in the upper triangular portion of the connectivity matrix to estimate the density using smoothing splines (Gu &amp; Qiu, <xref rid="hbm26112-bib-0027" ref-type="bibr">1993</xref>). This performs maximum likelihood estimation on the spline coefficients for estimating the logarithm of the density function under a smoothness penalty. We chose this approach as it directly returns the splines, which are both mathematically and practically convenient, especially for performing a functional regression. In addition, it sets a boundary on the support for the estimated density, which is beneficial here, as correlation coefficients are bounded between <mml:math id="jats-math-15" display="inline" overflow="scroll"><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> and <mml:math id="jats-math-16" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:math>. Kernel density estimators (Silverman, <xref rid="hbm26112-bib-0050" ref-type="bibr">1986</xref>) were also implemented as a comparison.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26112-fig-0001">
          <label>FIGURE 1</label>
          <caption>
            <p>From MRI scan to connectivity density.</p>
          </caption>
          <graphic xlink:href="HBM-44-170-g003" position="anchor" id="jats-graphic-3"/>
        </fig>
        <p>Our proposal is to use <mml:math id="jats-math-17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> to characterize <mml:math id="jats-math-18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> and subsequently study the relationship between <mml:math id="jats-math-19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> and variables of interest. In the tDCS study, the variable of interest is treatment status. Since the <mml:math id="jats-math-20" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="{" close="}"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math> are (infinite dimensional) functional data, we employ functional data analysis tools (McLean et al., <xref rid="hbm26112-bib-0034" ref-type="bibr">2014</xref>; Ramsay, <xref rid="hbm26112-bib-0042" ref-type="bibr">2004</xref>; Ramsay &amp; Silverman, <xref rid="hbm26112-bib-0043" ref-type="bibr">2007</xref>). Logically, one would model that treatment status predicts connectivity. However, treating complex data as covariates is typically more convenient than treating them as the outcomes. For example, the ability to incorporate other covariates is simply adding terms in a regression model. Unlike models for complex multivariate structured outcomes, an outcome reversed functional approach can be easily implemented with existing software tools available in any statistical package. As such, the method extends easily to longitudinal models, whereas longitudinal models for complex structured outcomes are not fully developed. Putting connectivity densities as covariates also makes the method directly extendable to predicting subject‐specific behavior scores. Therefore, we adopt the ideas in case–control inverse regression (Prentice &amp; Pyke, <xref rid="hbm26112-bib-0041" ref-type="bibr">1979</xref>; Rothman et al., <xref rid="hbm26112-bib-0047" ref-type="bibr">2008</xref>), and predict whether a subject is in the treatment arm using the connectivity density and the baseline covariates as predictors. Let <mml:math id="jats-math-21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> denote the treatment assignment with <mml:math id="jats-math-22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> for tDCS and <mml:math id="jats-math-23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> for sham, and <mml:math id="jats-math-24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>q</mml:mi></mml:msup></mml:mrow></mml:math> denote the <italic toggle="yes">q</italic>‐dimensional covariate vector with the first element one for the intercept. The linear model considered is the following:<disp-formula id="hbm26112-disp-0001">
<label>(1)</label>
<mml:math id="jats-math-25" display="block" overflow="scroll"><mml:mrow><mml:mtext>logit</mml:mtext><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>Τ</mml:mi></mml:msubsup><mml:mi>β</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:mo>∫</mml:mo><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mi>g</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-26" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math> is a given operator from <mml:math id="jats-math-27" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℒ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math> to <mml:math id="jats-math-28" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℒ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math> aiming to capture a specific characteristic of the density functions. <mml:math id="jats-math-29" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math> can also be used to control the impact of possible outliers of connectivity measures, such as using quantile‐based transformations. The function <mml:math id="jats-math-30" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math> is a coefficient function representing the effect of the tDCS used in this experiment, which can potentially change for different simulation settings. The parameter <mml:math id="jats-math-31" display="inline" overflow="scroll"><mml:mrow><mml:mi>β</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="normal">ℝ</mml:mi><mml:mi>q</mml:mi></mml:msup></mml:mrow></mml:math> is the coefficient vector of the covariates, both to be estimated.</p>
        <p>Various choices of <mml:math id="jats-math-32" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math> and the shape of <mml:math id="jats-math-33" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math> have different interpretations on the resulting model. For example, setting <mml:math id="jats-math-34" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:mi>f</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math>, the identity function, the linear predictor is <mml:math id="jats-math-35" display="inline" overflow="scroll"><mml:mrow><mml:mo>∫</mml:mo><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>g</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>, where <mml:math id="jats-math-36" display="inline" overflow="scroll"><mml:mrow><mml:mi>E</mml:mi><mml:mfenced open="[" close="]"><mml:mo>⋅</mml:mo></mml:mfenced></mml:mrow></mml:math> is the expectation of a random variable and <mml:math id="jats-math-37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> is a random variable drawn from <mml:math id="jats-math-38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>. With a sufficiently flexible choice of <mml:math id="jats-math-39" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math>, Model (1) covers a broad range of possible model fits. However, many of them may not focus on non‐central components of the density, where effects would likely occur because of the stimulation procedure. For example, if <mml:math id="jats-math-40" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math> is a polynomial, the model considers the moments of the density (mean, variance, skewness, etc.) as predictors. However, it offers no benefit over the direct usage of the moment estimates of the connectivities. Thus, polynomial bases will not be discussed further, though they do demonstrate an interesting special case of the approach.</p>
        <p>As for the choice of <mml:math id="jats-math-41" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math>, using <mml:math id="jats-math-42" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:mi>f</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="(" close=")"><mml:mi>f</mml:mi></mml:mfenced></mml:mrow></mml:math> is similar to the use of the identity function. It loses the expected value interpretation, while instead, performs regression on the space of densities with Aitchison geometry (Egozcue et al., <xref rid="hbm26112-bib-0014" ref-type="bibr">2006</xref>). Thus, it may better detect the influence of the tail behavior on the outcome.</p>
        <p>Another choice is the quantile mapping, <mml:math id="jats-math-43" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>f</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math>, where <mml:math id="jats-math-44" display="inline" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:math> is the cumulative distribution function associated with the density <mml:math id="jats-math-45" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math>. With a sufficient number of foci, this approach is approximately equivalent to using the empirical quantiles of the connectivity data as the regressors. Our proposed approach is quite similar to this. However, we further propose to weight the quantiles via density quantile. Specifically, we set <mml:math id="jats-math-46" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi mathvariant="italic">ldq</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>f</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mo>∘</mml:mo><mml:mi>f</mml:mi><mml:mo>∘</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mfenced open="[" close="]"><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mi mathvariant="italic">dF</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mi mathvariant="italic">dt</mml:mi></mml:mrow></mml:mfenced></mml:mfenced></mml:mrow></mml:math> where <mml:math id="jats-math-47" display="inline" overflow="scroll"><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:math> is the function composition operator. The latter equality is easy to derive by taking derivatives via the chain rule to the identity function, <mml:math id="jats-math-48" display="inline" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi><mml:mo>∘</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math>. Note that the density quantile <mml:math id="jats-math-49" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∘</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> can be regarded as a quantile synchronized version of the density function, and therefore is more sensitive to the changing tails. The logarithm transforms maps density quantile to a Hilbert space, which is practically useful for linear models. This idea has been explored before as a potentially preferable method for utilizing quantiles as regressors. Specifically, it is equivalent to the Hilbert space mapping, suggested by Petersen and Muüller (<xref rid="hbm26112-bib-0040" ref-type="bibr">2016</xref>). Figure <xref rid="hbm26112-fig-0002" ref-type="fig">2</xref> shows original densities, log transformed densities and log density quantiles of 10 random sampled subjects in our tDCS study.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26112-fig-0002">
          <label>FIGURE 2</label>
          <caption>
            <p>An illustration of connectivity densities, its log transformation and its log density quantiles. Plots shown for 10 random sampled subjects in our tDCS study and functions are standardized across all subjects to have similar <mml:math id="jats-math-50" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math> scales along <italic toggle="yes">x</italic>‐axis.</p>
          </caption>
          <graphic xlink:href="HBM-44-170-g002" position="anchor" id="jats-graphic-5"/>
        </fig>
      </sec>
      <sec id="hbm26112-sec-0006">
        <label>2.4</label>
        <title>Reversing the predictor/response relationship</title>
        <p>It is typical in regression models to consider the hypothetically functionally antecedent variable as a predictor, independent or exogenous variable, rather than an outcome, dependent or endogenous variable. A counterexample is in outcome‐dependent sampling, such as in retrospective studies. We utilize the same strategy of reversing the typical predictor/response relationship, as is more convenient for modeling with high dimensional and complex quantities (such as brain connectivity) as the predictor. In the tDCS study, we model treatment assignment as the outcome using a logit model with the connectivity density and other covariates as the independent variables. This avoids the need to construct probability distributions on the connectivity densities themselves.</p>
        <p>To elaborate, using Bayes' rule and <mml:math id="jats-math-51" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math> (due to the randomization), for any function <mml:math id="jats-math-52" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math> and transformation <mml:math id="jats-math-53" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math>, we have:<disp-formula id="hbm26112-disp-0002">
<mml:math id="jats-math-54" display="block" overflow="scroll"><mml:mrow><mml:mtext>Odds</mml:mtext><mml:mfenced open="(" close=")" separators="|,"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="⟨" close="⟩" separators=","><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi>g</mml:mi></mml:mfenced></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mfenced open="⟨" close="⟩" separators=","><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi>g</mml:mi></mml:mfenced><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mfenced open="⟨" close="⟩" separators=","><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi>g</mml:mi></mml:mfenced><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-55" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="⟨" close="⟩" separators=","><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo></mml:mfenced></mml:mrow></mml:math> is any inner product of two functions. In our application, we consider logit models on <mml:math id="jats-math-56" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>, which depend on <mml:math id="jats-math-57" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> only though the form <mml:math id="jats-math-58" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="⟨" close="⟩" separators=","><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi>g</mml:mi></mml:mfenced></mml:mrow></mml:math>. Also, thanks to the randomized design, we can be aggressive in excluding potential confounders as covariates. This is especially helpful given the modest sample size. As the above relationship shows, our treatment assignment outcome model, <mml:math id="jats-math-59" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>, is consistent with any connectivity outcome model, <mml:math id="jats-math-60" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mfenced open="⟨" close="⟩" separators=","><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mi>g</mml:mi></mml:mfenced><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math>, where the likelihood ratio comparing treated to controls is approximately log linear with our linear separable density model given in Equation (<xref rid="hbm26112-disp-0001" ref-type="disp-formula">1</xref>).</p>
      </sec>
      <sec id="hbm26112-sec-0007">
        <label>2.5</label>
        <title>Estimation of the coefficient function</title>
        <p>To estimate the coefficient function, <mml:math id="jats-math-61" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math> in Model (1), we performed a functional principal components analysis (fPCA, see Reiss &amp; Ogden, <xref rid="hbm26112-bib-0046" ref-type="bibr">2007</xref>, for a review). This reduces the dimension of the functional regressor using a set of data‐derived bases. In this approach, one calculates the PCA decomposition of the functions, <mml:math id="jats-math-62" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>, using the Karhunen/Loève transformation (Ghanem &amp; Spanos, <xref rid="hbm26112-bib-0020" ref-type="bibr">2003</xref>), where the covariance function is smoothed (Di et al., <xref rid="hbm26112-bib-0013" ref-type="bibr">2009</xref>). We selected the leading principal components which explained over 99% of the variation as the basis functions. Notice that the version of fPCA utilized here does not honor possible density implied constraints of <mml:math id="jats-math-63" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math>. Generalized cross‐validation (GCV) was used to choose the smoothing parameters (for detailed discussion, see section 4.5.4 of Wood, <xref rid="hbm26112-bib-0058" ref-type="bibr">2004</xref>). Confidence bands were derived using a Bayes approach (McLean et al., <xref rid="hbm26112-bib-0034" ref-type="bibr">2014</xref>; Nychka, <xref rid="hbm26112-bib-0038" ref-type="bibr">1988</xref>; Wahba, <xref rid="hbm26112-bib-0056" ref-type="bibr">1983</xref>).</p>
      </sec>
      <sec id="hbm26112-sec-0008">
        <label>2.6</label>
        <title>Comparison</title>
        <p>To illustrate the benefit of conducting a delocalized analysis, a simulation study based on the fMRI data collected in the tDCS study was conducted. We demonstrate an extreme example where non‐localized brain stimulation decreases statistical power, or even makes it impossible to identify ROI pairs with a significant effect when implementing a localization method. However, using connectivity densities retains the relevant information. Our goal in this simulation was to create a caricature of non‐localized effects, to demonstrate the statistical direction that the procedure highlights.</p>
        <p>As a correlation coefficient, connectivity can be written as <mml:math id="jats-math-64" display="inline" overflow="scroll"><mml:mrow><mml:mi>cos</mml:mi><mml:mfenced open="(" close=")"><mml:mi>θ</mml:mi></mml:mfenced></mml:mrow></mml:math> where <mml:math id="jats-math-65" display="inline" overflow="scroll"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:math> is the angle between two signals. In the simulation, consider a brain connectivity map with 20 regions, <mml:math id="jats-math-66" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>…</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mn>20</mml:mn></mml:msub></mml:mrow></mml:math>. For every map, let <mml:math id="jats-math-67" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:math> be the angle between signals in location <mml:math id="jats-math-68" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-69" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math>; we simplified the data generating distribution by assuming that the angles, <mml:math id="jats-math-70" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:math>, are i.i.d. following a von‐Mises distribution, <mml:math id="jats-math-71" display="inline" overflow="scroll"><mml:mrow><mml:mi>M</mml:mi><mml:mfenced open="(" close=")" separators=","><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:mfenced></mml:mrow></mml:math>, where the density is <mml:math id="jats-math-72" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mi>θ</mml:mi><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>cos</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>k</mml:mi></mml:mfenced></mml:mrow></mml:math>, with <mml:math id="jats-math-73" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> as the modified Bessel function of order 0. The parameters, <mml:math id="jats-math-74" display="inline" overflow="scroll"><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:math>, <mml:math id="jats-math-75" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> were estimated from pre‐intervention patients by maximum likelihood. This was done to have a realistic null distribution on densities.</p>
        <p>A non‐localized “stimulation” was simulated by perturbing region <mml:math id="jats-math-76" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> with equal probability across <mml:math id="jats-math-77" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math>. After stimulation, we simplified the effect via a degree rotation, <mml:math id="jats-math-78" display="inline" overflow="scroll"><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:math>, for the signal at <mml:math id="jats-math-79" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>. Correspondingly, all <mml:math id="jats-math-80" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:math> change the same amount and the final post‐stimulation connectivity was a convex combination of this stimulated matrix and the pre‐stimulation matrix, where the weight was used to control the signal level and therefore controls the degree of difficulty in detecting the effect. Denote <mml:math id="jats-math-81" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:math> the pre‐stimulation correlation between region <mml:math id="jats-math-82" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-83" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math>, that <mml:math id="jats-math-84" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>cos</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math>. A stimulation on region <mml:math id="jats-math-85" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> yield a symmetric post‐stimulation connectivity <mml:math id="jats-math-86" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi mathvariant="italic">ij</mml:mi><mml:mi mathvariant="italic">sti</mml:mi></mml:msubsup></mml:mrow></mml:math> as<disp-formula id="hbm26112-disp-0003">
<mml:math id="jats-math-87" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi mathvariant="italic">ij</mml:mi><mml:mi mathvariant="italic">sti</mml:mi></mml:msubsup><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfenced open="(" close=""><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>i</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="italic">wC</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">−</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:mi>cos</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>i</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:math>
</disp-formula>Notice that, although uniform stimulation on all regions of <mml:math id="jats-math-88" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> is unpractical in many situations, this simulation is a boundary case to understand the effect of lacking localization. Mover, it is still consistent with other kinds of non‐localized effects that are random mixture of localized effects. In Appendix <xref rid="hbm26112-app-0001" ref-type="app">A</xref>, we also describe and examine another intuitive simulation setting, and we observed similar results.</p>
        <p>For every run of the simulation, we sampled 50 pre‐stimulation maps from the pre‐intervention scans and fit the parameters <mml:math id="jats-math-89" display="inline" overflow="scroll"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math> for each. We subsequently simulated 50 connectivity maps from samples of fitted von‐Mises distributions, and applied the stimulation above for a random half of these maps. We chose <mml:math id="jats-math-90" display="inline" overflow="scroll"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mi>π</mml:mi></mml:mrow></mml:math>, and the weight <mml:math id="jats-math-91" display="inline" overflow="scroll"><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:math> in the convex combination was chosen to be 75%. Other values, ranging from 90% to 50%, were also tried and similar patterns were observed. Weights under 50% made the signal detection too easy and methods are indistinguishable. Significance results for edgewise testing, principal component regression, and density regression were compared, with different density regression transformations for 1000 simulations. For completeness, we also considered instances with no stimulation effect and when the stimulation was localized at a specific region.</p>
        <p>The edgewise regression approach considers the following model:<disp-formula id="hbm26112-disp-0004">
<label>(2)</label>
<mml:math id="jats-math-92" display="block" overflow="scroll"><mml:mrow><mml:mtext>logit</mml:mtext><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>Τ</mml:mi></mml:msubsup><mml:mi>β</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:msub><mml:mi>α</mml:mi><mml:mi mathvariant="italic">st</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-93" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math>. The second approach was a regression model with dimension reduced predictors:<disp-formula id="hbm26112-disp-0005">
<label>(3)</label>
<mml:math id="jats-math-94" display="block" overflow="scroll"><mml:mrow><mml:mtext>logit</mml:mtext><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>Τ</mml:mi></mml:msubsup><mml:mi>β</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi mathvariant="bold">S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>α</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math>
</disp-formula>where, <mml:math id="jats-math-95" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> are the leading principal components of the vectorized connectivity matrix, <mml:math id="jats-math-96" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>. We refer to this model as the PC model.</p>
      </sec>
    </sec>
    <sec sec-type="results" id="hbm26112-sec-0009">
      <label>3</label>
      <title>RESULTS</title>
      <sec id="hbm26112-sec-0010">
        <label>3.1</label>
        <title>Simulation</title>
        <p>Figures <xref rid="hbm26112-fig-0003" ref-type="fig">3a</xref> and <xref rid="hbm26112-fig-0004" ref-type="fig">4a</xref> show example connectivity matrices and the difference after stimulation from an example simulation. The virtual stimulation was applied at region 10 in the right panel plot, while the left panel is the pre‐stimulation map. We report the rate of positive findings for all methods. Results are shown in Table <xref rid="hbm26112-tbl-0002" ref-type="table">A1</xref>. Localization methods, including the dimension reduction method, do not find any significant region pairs in the non‐localized simulations. In contrast, in this setting, the density method detected the stimulation impact on the connectivity densities. Among all the transformations, the log density‐quantile transformation was significantly better than others. We would like to reiterate that the simulation is contrived to highlight an extreme setting. Connectivity density methods will not necessarily increase the sensitivity of the analysis. If the true effect is localized, it cannot be better than well‐specified localized method.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26112-fig-0003">
          <label>FIGURE 3</label>
          <caption>
            <p>Part figure (a) shows the simulated pre‐stimulation connectivity matrix of a subject and part figure (b) is the simulated post‐pre difference in the connectivity matrix of the same subject.</p>
          </caption>
          <graphic xlink:href="HBM-44-170-g008" position="anchor" id="jats-graphic-7"/>
        </fig>
        <fig position="float" fig-type="FIGURE" id="hbm26112-fig-0004">
          <label>FIGURE 4</label>
          <caption>
            <p>Model results on the tDCS experiment. The black solid line is the fitted coefficient function, <mml:math id="jats-math-97" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math>, with the black dashed line referencing the associated 95% confidence interval. Densities were estimated from smoothing splines implemented in the <bold>fda</bold> R‐package with 19 degrees of freedom for the spline basis. A kernel density estimator (KDE, d) is also computed and compared with smoothing spline (panel c) method. Contrasting c and d show that the density estimation technique did not impact results.</p>
          </caption>
          <graphic xlink:href="HBM-44-170-g005" position="anchor" id="jats-graphic-9"/>
        </fig>
      </sec>
      <sec id="hbm26112-sec-0011">
        <label>3.2</label>
        <title>Analysis of the <styled-content style="fixed-case" toggle="no">tDCS</styled-content> data using localized methods</title>
        <p>For the tDCS data, we tested the significance of the edgewise regression [Model (2)], a principal components regression [Model (3)] and a LASSO post‐inference model (Dezeure et al., <xref rid="hbm26112-bib-0012" ref-type="bibr">2015</xref>) using connectivity of all ROI pairs. No foci‐pair or principal components was identified as significant in either regression model, at Type I error rate levels of 0.05 or even 0.1. Of note, previous localization work on related data (Ficek et al., <xref rid="hbm26112-bib-0016" ref-type="bibr">2018</xref>), yielded significant findings. However, the total number of regions were restricted, thus dramatically reducing multiplicity concerns. In this analysis, 78 regions were used, resulting in a more stringent correction factor based on 78 choose 2, or 3003 comparisons. In addition, a more restrictive inclusion criteria in Ficek et al. (<xref rid="hbm26112-bib-0016" ref-type="bibr">2018</xref>) led to a different study population.</p>
      </sec>
      <sec id="hbm26112-sec-0012">
        <label>3.3</label>
        <title>Analysis of <styled-content style="fixed-case" toggle="no">tDCS</styled-content> data using density regression</title>
        <p>In this section, we present the analysis results of the tDCS study using the density regression Model (1) with different transformations (<mml:math id="jats-math-98" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math>). The fitted coefficient function, <mml:math id="jats-math-99" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:math>, and its 95% confidence interval are presented in Figure <xref rid="hbm26112-fig-0004" ref-type="fig">4</xref>. Functional linear regression was performed using the refund R‐package with default parameter of smoothed covariance fPCA, which chooses the number of components that explains over 99% of the data variation.</p>
        <p>Regressing on the density after applying the log‐density quantile transform yielded the highest number of significant signals, which reaches its maximum around the 85th percentile. This potentially indicates that stimulation has a consistent tail effect, which is more likely to be aligned by quantile, rather than absolute value. Since the estimated coefficient function is significantly non‐zero only in the positive tail this suggests that the tDCS group had higher connection densities in the tail than the sham group. That is, connectivity among the most connected regions was higher in the tDCS group.</p>
        <p>A likelihood ratio test was performed to compare logistic regression with only baseline variables and our model including both the baseline variables and the log density quantile term. The resulting <italic toggle="yes">p</italic>‐value was .0052, indicating a statistically significant gain of information from connectivity density at the 0.05 benchmark type I error rate. The conclusion remains true if one applies a Bonferroni <italic toggle="yes">p</italic>‐value correction. Specifically, three transformations were compared and therefore the corrected <italic toggle="yes">p</italic>‐value is .017. Notice that this is already a conservative value. The result agrees with a non‐parametric permutation test where we do the same regression but connectivity densities of subjects are randomly shuffled. Using AUC as test statistic, we observe that the AUC of log density quantile model is also significant larger than that of null distribution, which is the AUCs with shuffled connectivity densities. The <italic toggle="yes">p</italic>‐value is <mml:math id="jats-math-100" display="inline" overflow="scroll"><mml:mrow><mml:mn>.015</mml:mn><mml:mo>±</mml:mo><mml:mn>.0009</mml:mn></mml:mrow></mml:math> estimated from 20,000 runs. A further reanalysis of subgroups shows that the effect is driven primarily by the <italic toggle="yes">nonfluent</italic> subtype which comprises 23 over total 47 subjects. There is not enough data to investigate the possibility of different effects of other subtypes, the least of which only has 9 subjects. We also performed a sensitivity analysis examining the impact of hyperparameters in the density estimation. We changed the smoothing parameter in spline smoothing and bandwidth in kernel density estimation method, both in the range of <mml:math id="jats-math-101" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="[" close="]" separators=","><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math>, where <mml:math id="jats-math-102" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> is the corresponding default value. For smoothing splines this value was selected by the approximated cross‐validation method suggested in Gu and Wang (<xref rid="hbm26112-bib-0028" ref-type="bibr">2003</xref>) and for KDE this value is suggested by Silverman (<xref rid="hbm26112-bib-0050" ref-type="bibr">1986</xref>). We observed that the log density quantile transformed model constantly gives significant information gain with <italic toggle="yes">p</italic>‐value &lt;.05 in all settings, comparing with the demographic‐only baseline model. Therefore, the method is not sensitive to reasonable deviations in hyperparameter selection.</p>
        <p>We also studied the effect of the estimated function on behavior change. We found that the variable <mml:math id="jats-math-103" display="inline" overflow="scroll"><mml:mrow><mml:mo>∫</mml:mo><mml:mi>T</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math> is significant (<italic toggle="yes">p</italic> &lt; .05) for predicting the change of language ability, measured by untrained items, after transcranial direct‐current stimulation. Here <mml:math id="jats-math-104" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:math> is the coefficient function estimated above for <mml:math id="jats-math-105" display="inline" overflow="scroll"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi mathvariant="italic">ldq</mml:mi></mml:msub></mml:mrow></mml:math> and, recall, <mml:math id="jats-math-106" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> are the connectivity densities for post‐intervention scans. The result shows a necessary condition for connectivity density mediating the effect of stimulation on language ability, which can motivate a future formal mediation analysis.</p>
      </sec>
      <sec id="hbm26112-sec-0013">
        <label>3.4</label>
        <title>Induced connectivity</title>
        <p>Consider the best model using the log density quantile transform, <mml:math id="jats-math-107" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi mathvariant="italic">ldq</mml:mi></mml:msub></mml:mrow></mml:math>. We have<disp-formula id="hbm26112-disp-0006">
<mml:math id="jats-math-108" display="block" overflow="scroll"><mml:mrow><mml:mtext>logit</mml:mtext><mml:mfenced open="{" close="}"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced open="(" close=")" separators="|,"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>Τ</mml:mi></mml:msubsup><mml:mi>β</mml:mi><mml:mo linebreak="goodbreak">+</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mi>log</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∘</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mi>q</mml:mi></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>g</mml:mi><mml:mfenced open="(" close=")"><mml:mi>q</mml:mi></mml:mfenced><mml:mi mathvariant="italic">dq</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>Notice that for the connectivity matrix, <mml:math id="jats-math-109" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>, we have <mml:math id="jats-math-110" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="{" close="}"><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mo>∼</mml:mo><mml:mi>U</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math>, a uniform distribution on <mml:math id="jats-math-111" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="[" close="]"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math> via the probability integral transform. Let <mml:math id="jats-math-112" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>. Then, it follows that:<disp-formula id="hbm26112-disp-0007">
<mml:math id="jats-math-113" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mi>log</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="{" close="}"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:mi>q</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>g</mml:mi><mml:mfenced open="(" close=")"><mml:mi>q</mml:mi></mml:mfenced><mml:mi mathvariant="italic">dq</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>g</mml:mi><mml:mfenced open="(" close=")"><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mi>log</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="{" close="}"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced open="(" close=")"><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="hbm26112-disp-0008">
<mml:math id="jats-math-114" display="block" overflow="scroll"><mml:mrow><mml:mo>≍</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>N</mml:mi><mml:mo linebreak="goodbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mi>g</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>log</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="[" close="]"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>Therefore, for this subject, one can assign <mml:math id="jats-math-115" display="inline" overflow="scroll"><mml:mrow><mml:mi>g</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mi>log</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="[" close="]"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math> as the effect size for region pair <mml:math id="jats-math-116" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math>. Averaging this effect across all patients yields an important metric for every region pair in the model. We call this stimulation‐induced connectivity, since it describes how influential the correlation of each region pair is in predicting stimulation status. The induced connectivity matrix is shown in Figure <xref rid="hbm26112-fig-0005" ref-type="fig">5</xref>, together with a summary of effect agreement across subjects, where for each patient, region pairs are selected with top 5% absolute effect size and the frequency of each region pair being selected is calculated.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26112-fig-0005">
          <label>FIGURE 5</label>
          <caption>
            <p>Part figure (a) shows the induced connectivity described in Section <xref rid="hbm26112-sec-0013" ref-type="sec">3.4</xref>. IFG regions (the tDCS target) are noted in the red box. Part figure (b) shows some region pairs with the most consistent contribution, measured by the frequency of having top 5% absolute effect size across all patients.</p>
          </caption>
          <graphic xlink:href="HBM-44-170-g004" position="anchor" id="jats-graphic-11"/>
        </fig>
        <p>This technique, of course, returns to a discussion of localized effects. However, by investigating this measure one can ascertain the degree of localization consistency across subjects—an impossibility with pure localization analysis.</p>
      </sec>
    </sec>
    <sec sec-type="discussion" id="hbm26112-sec-0014">
      <label>4</label>
      <title>DISCUSSION</title>
      <p>In this manuscript, a new framework for analyzing functional connectivity was explored. Functional data analysis of log quantile connectivity densities investigates possible nonlocalized effects associated with subject‐level variables. It is clear that our method can be directly applied to other kinds of numerical measurements. For example, partial correlations or entropy‐based measures. However, it continues to be only useful suitable if connection exchangeability represents a useful model. A sizable by‐product of this style of analysis is the drastic reduction of multiplicity considerations. This is of great importance in connectivity analysis, where the number of comparisons grows at a rate of the square of the number of foci being considered. In the data application, we find associations between stimulation and connectivity density. In contrast, edgewise methods fail to find any results, because of multiplicity issues. This is partially due to a wide search of all possible region pairs from the parcellation. Of course, one could also reduce multiplicity concerns by restricting attention to regions associated with a priori hypotheses of interest, as was done in Ficek et al. (<xref rid="hbm26112-bib-0016" ref-type="bibr">2018</xref>). In contrast, investigating connection densities is an omnibus approach that benefits from a reduction in the number of tests over exploratory edge‐wise approaches, a robustness to non‐localized effects and a robustness to the inclusion of unnecessary foci. These benefits come at the expense of the loss of power and interpretability over analyses considering only a small set of tightly specified edge‐wise hypotheses. Our method can also be extended to seed‐based connectivity and voxel‐by‐voxel connectivity without any modification. However, the assumption of complete node invariance discards a potential sizable amount of relevant localization information. Therefore, we believe that the method would be primarily useful as an easy and simple early‐stage omnibus test, or after light localization efforts, such as considering connectivity densities between voxels within sets of ROI. To further emphasize the ease and simplicity of the method, we stress that density regression can be coded from scratch in only a few lines of code in any modern scripting environment with PCA and GLM functions.</p>
      <p>Density regression, as a prediction model, can be view as a generalization of connectome‐based predictive modeling (Shen et al., <xref rid="hbm26112-bib-0049" ref-type="bibr">2017</xref>). Connectome‐based predictive modeling (CPM) uses individual connectivity matrices to predict behavioral measures. The method first selects location‐pairs that are most significantly correlated with the outcome, then summarizes the matrix by adding up connectivity measures in selected pairs, and this sum is used as a predictor in a regression model. In CPM, there is no localized effect and CPM can be viewed as a regression on connectivity density using only a constant basis. Here we generalize it by utilizing more distributional information.</p>
      <p>An interesting direction to pursue with connectivity density methods is to consider potential robustness to spatial registration (Oliveira &amp; Tavares, <xref rid="hbm26112-bib-0039" ref-type="bibr">2014</xref>). The connectivity density can relatively easily be shown to be invariant to relabeling and affine transformations (see Theorem <xref rid="hbm26112-mthst-0001" ref-type="statement">1</xref> in the Appendix <xref rid="hbm26112-app-0001" ref-type="app">A</xref>). In contrast, localization methods heavily rely on both accurate registration and biological functional localization across subjects. Therefore, it is interesting to posit that density regression could be used after only mild affine registration efforts prior to the more time‐consuming non‐linear registration.</p>
      <p>However, to reiterate, ignoring potentially useful localization information can reduce power and sensitivity. Surely, the optimal strategy removes subject‐specific artifacts and reduces the search space with—correct—strong a priori hypotheses and then tests only those edges. However, in the absence of this ideal case, one is often confronted with a massive unstructured search problem with localization analyses. In contrast, density regression is more akin to an omnibus <italic toggle="yes">F</italic>‐test, looking over a large range of edges, dramatically mitigating multiple comparison issues in the favor of testing one overview hypothesis, rather than a large collection of highly specific ones. Therefore, we suggest the method as an early‐stage tool in a neuroimaging data analyst's toolbox.</p>
      <p>We used functional data analysis to relate connection densities to outcomes. Functional data analysis tools (Ramsay &amp; Silverman, <xref rid="hbm26112-bib-0043" ref-type="bibr">2007</xref>) have grown to be quite flexible. Thus, density regression approaches can be relatively easily generalized to handle different settings, such as any typical statistical outcome model and longitudinal data. Also, density estimates may naturally make adjustments for missing data, in the form of missing foci, since the density can remain the same in some contexts. This has potential broad implications for the study of stroke and other diseases with abnormal brain pathology. Localization methods are not available if the ROI is damaged or missing. In contrast, density‐based methods are easy to apply. In addition, we used PCA on the log quantile densities as the basis for functional regression. The result is that the method can be applied using standard software without modification. Other bases and penalization strategies may improve the approach. In fact, the utility and application of functional regression in neuroimaging has been greatly improved via recent research efforts (e.g., see Goldsmith, Crainiceanu, et al., <xref rid="hbm26112-bib-0022" ref-type="bibr">2011</xref>, Goldsmith, Wand, &amp; Crainiceanu, <xref rid="hbm26112-bib-0023" ref-type="bibr">2011</xref>, Goldsmith et al., <xref rid="hbm26112-bib-0021" ref-type="bibr">2012</xref>; Reiss et al., <xref rid="hbm26112-bib-0044" ref-type="bibr">2017</xref>).</p>
      <p>Utilizing functional regression also has the benefit of producing more interpretable models as compared with machine learning approaches. However, this is achieved at a likely cost of prediction performance. It is possible that ML approaches could navigate the trade‐offs between localization and exchangeability non‐parametrically and possibly achieve better prediction performance. Thus, we view density regression as a parsimonious modeling choice rather than a method to optimize prediction performance.</p>
      <p>Statistically, we assumed independence between subjects and relied on the randomization to invert the predictor/response relationship using logit models. This borrows techniques from case‐referent sampling from epidemiology dating back to the seminal work of Cornfield (see Breslow, <xref rid="hbm26112-bib-0004" ref-type="bibr">1996</xref>; Greenhouse, <xref rid="hbm26112-bib-0026" ref-type="bibr">1982</xref>, for overviews). A benefit of doing this is that it is generally easier to have the more complex variable as the predictor rather than a response. To elaborate, to have a density as an outcome, predictions from the model must be functions that are both positive and integrate to one. Most existing functional approaches, especially point‐wise ones, would satisfy neither criteria nor modeling distributional outcomes is an active area of statistical research. The probability space containing the outcome is necessarily a probability distribution on distributions, such as a Dirichlet process. While this is not a problem per se, it makes inference more technically challenging. In contrast, by conditioning on the density, as we have done, its distribution does not need to be modeled and the fitting and inference require little more than well‐known generalized linear model techniques. In Appendix 3 we further the discussion in comparison with function on scalar regression. It is seen that, with almost no effort, one obtains the use of easier models (GLMs) and appropriate inferences by reversing the relationship and the resulting estimates are similar to those of function on scalar regression. However, because the constraints are not accounted for in the function on scalar model, inferences remain in question.</p>
      <p>Nonetheless, we reiterate that the use of connectivity density as a regressor remains useful, even if one prefers not to flip the predictor/response relationship. For example, in our tDCS example, connecting the connectivity density to behavioral outcomes would be relevant, where the natural predictor would be functional connectivity.</p>
      <p>Independence between subjects was used for inference. We also used density estimates for connection densities, techniques that implicitly require sampling assumptions for theoretical convergence. However, we contend that connectivity densities are intrinsically of interest, and therefore no appeals to super‐population inference and sampling assumptions are needed for estimation. This is analogous to spatial group ICA, where productive estimates are obtained via independence assumptions on voxels over space, without a true sampling or super‐population model for inference (Calhoun et al., <xref rid="hbm26112-bib-0007" ref-type="bibr">2001</xref>). An interesting future direction of research would investigate dependencies between foci correlations.</p>
      <p>Our recommended approach uses log quantile densities as the functional predictor, rather than the density, distribution function, or quantile function directly (Petersen &amp; Muüller, <xref rid="hbm26112-bib-0040" ref-type="bibr">2016</xref>). This approach has convenient theoretical properties, but also the practical benefit of focusing attention on tail behavior, where effects are most likely to be seen. Utilizing the quantile density also creates robustness to irrelevant foci pairs being included in the analysis.</p>
      <p>Our simulations and data results focus on settings that highlight the benefits of an omnibus density regression approach. In the simulations, we investigated a non‐localized caricature of typical effects. Similarly, in our data analysis, we performed no filtering of regions prior to analysis (thus magnifying multiple comparison concerns). It was shown in the simulation, that functional density regression approaches can find real non‐localized effects, whereas, as expected, edgewise methods do not find any. It should be emphasized that the performance of the density regression approach is invariant to the distribution of effects across subjects, whereas edgewise approaches become viable as the degree of localization increases.</p>
      <p>In addition, the flexibility of the approach finds effects in the real data, even though there are a great deal of irrelevant connections (i.e., unnecessarily included region pairs) being studied. Edgewise and other regression approaches are highly sensitive to unnecessary null connections being included in the analysis. A benefit of the data being considered is the likely existence of an effect related to the stimulation. However, we emphasize that a single omnibus approach does not represent a full analysis of the data. We recommend this approach as a global analysis to be performed prior to edgewise or other localization methods. This mirrors the classic ANOVA (analysis of variance) approach of performing an overall F test before investigating pairs of explanatory factor levels. It would be most useful in exploratory model building where foci selection is not restrictive. In cases of tightly coupled statistical hypotheses involving relatively few regions or foci, density regression would not be needed or particularly helpful.</p>
      <p>This methodology raises many avenues for future research. For example, one the idea of non‐localized effects in dynamic connectivity (Hutchison et al., <xref rid="hbm26112-bib-0030" ref-type="bibr">2013</xref>) via stochastic processes of connectivity densities (by time). In addition, there are multiple alternatives for densities estimated from correlation of each region pair for contralateral regions. Here, it should be acknowledged that there is strong homotopic correlations from symmetric regions. One should then deal with multivariate densities estimated from pairs of correlations. This same logic could be applied to geographically close regions and for instances with longitudinal scans. The connectivity density of spectral information (de Haan et al., <xref rid="hbm26112-bib-0011" ref-type="bibr">2012</xref>), like leading principal component scores, should also be studied to potentially extract relevant brain graph properties.</p>
      <p>Finally, there is the role that connectivity‐density methods could play in fMRI analysis of subjects with missing brain tissue, such as studies of stroke or surgical interventions. Connectivity density methods may be resilient to the missing data impact of differential brain structure in a way that localization methods are not. In fact, it is interesting to conjecture what localization methods even mean in these settings where a subset of subjects are missing areas of localization. In contrast, density methods may provide a more robust and well‐defined methodology. It is worthy of note that components of graph methodology (Bullmore &amp; Sporns, <xref rid="hbm26112-bib-0006" ref-type="bibr">2009</xref>; Sporns, <xref rid="hbm26112-bib-0051" ref-type="bibr">2010</xref>) often considers summary metrics that do not require or assume localization. Density regression can be considered a subset of weighted graph metric analysis.</p>
    </sec>
    <sec sec-type="COI-statement" id="hbm26112-sec-0016">
      <title>CONFLICT OF INTEREST</title>
      <p>The authors declare that there is no conflict of interest.</p>
    </sec>
  </body>
  <back>
    <ack id="hbm26112-sec-0015">
      <title>ACKNOWLEDGMENTS</title>
      <p>We would like to thank our participants and referring physicians for their dedication, helpful comments and interest in our study. All the data reported here were collected through grants from the Science of Learning Institute at Johns Hopkins University and NIH (National Institute of Deafness and Communication Disorders) through award R01 DC014475, R01 AG068881, R01 AG075404, and R01 AG075111 to KT. A.V. was supported by National Science Foundation CRCNS award 1822575 and National Science Foundation CAREER award 1845430. M.A.L. was supported by NIH grants R01 EB016061, EB029977 and EB026549 from the National Institute of Biomedical Imaging and Bioengineering. J.P was supported by NIH/NIBIB grants P41EB015909 and P41EB031771, both to P. van Zijl.</p>
    </ack>
    <sec sec-type="data-availability" id="hbm26112-sec-0018">
      <title>DATA AVAILABILITY STATEMENT</title>
      <p>Data sharing agreement: We will make the data and associated documentation available to ;users only under a data‐sharing agreement that provides for: (1) a commitment to using the ;data only for research purposes and not to identify any individual participant; (2) a commitment ;to securing the data using appropriate computer technology; (3) proper acknowledgment of data ;source; and (4) a commitment to destroying or returning the data after analyses are completed. Data requests should be sent to <email>tsapkini@jhmi.edu</email>.</p>
    </sec>
    <ref-list id="hbm26112-bibl-0001" content-type="cited-references">
      <title>REFERENCES</title>
      <ref id="hbm26112-bib-0001">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0001">
<string-name>
<surname>Bastos</surname>, <given-names>A. M.</given-names>
</string-name>, &amp; <string-name>
<surname>Schoffelen</surname>, <given-names>J.‐M.</given-names>
</string-name> (<year>2016</year>). <article-title>A tutorial review of functional connectivity analysis methods and their interpretational pitfalls</article-title>. <source>Frontiers in Systems Neuroscience</source>, <volume>9</volume>, <fpage>175</fpage>.<pub-id pub-id-type="pmid">26778976</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0002">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0002">
<string-name>
<surname>Behzadi</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Restom</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Liau</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Liu</surname>, <given-names>T. T.</given-names>
</string-name> (<year>2007</year>). <article-title>A component based noise correction method (compcor) for bold and perfusion based fmri</article-title>. <source>NeuroImage</source>, <volume>37</volume>, <fpage>90</fpage>–<lpage>101</lpage>.<pub-id pub-id-type="pmid">17560126</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0003">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0003">
<string-name>
<surname>Benjamini</surname>, <given-names>Y.</given-names>
</string-name>, &amp; <string-name>
<surname>Hochberg</surname>, <given-names>Y.</given-names>
</string-name> (<year>1995</year>). <article-title>Controlling the false discovery rate: A practical and powerful approach to multiple testing</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>, <volume>57</volume>, <fpage>289</fpage>–<lpage>300</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0004">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0004">
<string-name>
<surname>Breslow</surname>, <given-names>N. E.</given-names>
</string-name> (<year>1996</year>). <article-title>Statistics in epidemiology: The case‐control study</article-title>. <source>Journal of the American Statistical Association</source>, <volume>91</volume>, <fpage>14</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">12155399</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0005">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0005">
<string-name>
<surname>Broca</surname>, <given-names>P.</given-names>
</string-name> (<year>1861</year>). <article-title>Remarques sur le siège de la faculté du langage articulé, suivies d'une observation d'aphémie (perte de la parole)</article-title>. <source>Bulletin et Memoires de la Societe Anatomique de Paris</source>, <volume>6</volume>, <fpage>330</fpage>–<lpage>357</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0006">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0006">
<string-name>
<surname>Bullmore</surname>, <given-names>E.</given-names>
</string-name>, &amp; <string-name>
<surname>Sporns</surname>, <given-names>O.</given-names>
</string-name> (<year>2009</year>). <article-title>Complex brain networks: Graph theoretical analysis of structural and functional systems</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>, <fpage>186</fpage>–<lpage>198</lpage>.<pub-id pub-id-type="pmid">19190637</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0007">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0007">
<string-name>
<surname>Calhoun</surname>, <given-names>V. D.</given-names>
</string-name>, <string-name>
<surname>Adali</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Pearlson</surname>, <given-names>G. D.</given-names>
</string-name>, &amp; <string-name>
<surname>Pekar</surname>, <given-names>J. J.</given-names>
</string-name> (<year>2001</year>). <article-title>A method for making group inferences from functional mri data using independent component analysis</article-title>. <source>Human Brain Mapping</source>, <volume>14</volume>, <fpage>140</fpage>–<lpage>151</lpage>.<pub-id pub-id-type="pmid">11559959</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0008">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0008">
<string-name>
<surname>Ceritoglu</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Tang</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Chow</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Hadjiabadi</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Shah</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Brown</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Burhanullah</surname>, <given-names>M. H.</given-names>
</string-name>, <string-name>
<surname>Trinh</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Hsu</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Ament</surname>, <given-names>K. A.</given-names>
</string-name>, <string-name>
<surname>Crocetti</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Mori</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Mostofsky</surname>, <given-names>S. H.</given-names>
</string-name>, <string-name>
<surname>Yantis</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Miller</surname>, <given-names>M. I.</given-names>
</string-name>, &amp; <string-name>
<surname>Ratnanather</surname>, <given-names>J. T.</given-names>
</string-name> (<year>2013</year>). <article-title>Computational analysis of lddmm for brain mapping</article-title>. <source>Frontiers in Neuroscience</source>, <volume>7</volume>, <fpage>151</fpage>.<pub-id pub-id-type="pmid">23986653</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0009">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0009">
<string-name>
<surname>Chen</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Lin</surname>, <given-names>Z.</given-names>
</string-name>, &amp; <string-name>
<surname>Müller</surname>, <given-names>H.‐G.</given-names>
</string-name> (<year>2021</year>). <article-title>Wasserstein regression</article-title>. <source>Journal of the American Statistical Association</source>, <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">35757777</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0010">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0010">
<string-name>
<surname>Damoiseaux</surname>, <given-names>J. S.</given-names>
</string-name>, &amp; <string-name>
<surname>Greicius</surname>, <given-names>M. D.</given-names>
</string-name> (<year>2009</year>). <article-title>Greater than the sum of its parts: A review of studies combining structural connectivity and resting‐state functional connectivity</article-title>. <source>Brain Structure and Function</source>, <volume>213</volume>, <fpage>525</fpage>–<lpage>533</lpage>.<pub-id pub-id-type="pmid">19565262</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0011">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0011">
<string-name>
<surname>de Haan</surname>, <given-names>W.</given-names>
</string-name>, <string-name>
<surname>van der Flier</surname>, <given-names>W. M.</given-names>
</string-name>, <string-name>
<surname>Wang</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Van Mieghem</surname>, <given-names>P. F.</given-names>
</string-name>, <string-name>
<surname>Scheltens</surname>, <given-names>P.</given-names>
</string-name>, &amp; <string-name>
<surname>Stam</surname>, <given-names>C. J.</given-names>
</string-name> (<year>2012</year>). <article-title>Disruption of functional brain networks in alzheimer's disease: What can we learn from graph spectral analysis of resting‐state magnetoencephalography?</article-title>
<source>Brain Connectivity</source>, <volume>2</volume>, <fpage>45</fpage>–<lpage>55</lpage>.<pub-id pub-id-type="pmid">22480296</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0012">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0012">
<string-name>
<surname>Dezeure</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Bühlmann</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Meier</surname>, <given-names>L.</given-names>
</string-name>, &amp; <string-name>
<surname>Meinshausen</surname>, <given-names>N.</given-names>
</string-name> (<year>2015</year>). <article-title>High‐dimensional inference: Confidence intervals, p‐values and r‐software hdi</article-title>. <source>Statistical Science</source>, <volume>30</volume>, <fpage>533</fpage>–<lpage>558</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0013">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0013">
<string-name>
<surname>Di</surname>, <given-names>C.‐Z.</given-names>
</string-name>, <string-name>
<surname>Crainiceanu</surname>, <given-names>C. M.</given-names>
</string-name>, <string-name>
<surname>Caffo</surname>, <given-names>B. S.</given-names>
</string-name>, &amp; <string-name>
<surname>Punjabi</surname>, <given-names>N. M.</given-names>
</string-name> (<year>2009</year>). <article-title>Multilevel functional principal component analysis</article-title>. <source>The Annals of Applied Statistics</source>, <volume>3</volume>, <fpage>458</fpage>–<lpage>488</lpage>.<pub-id pub-id-type="pmid">20221415</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0014">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0014">
<string-name>
<surname>Egozcue</surname>, <given-names>J. J.</given-names>
</string-name>, <string-name>
<surname>Díaz‐Barrero</surname>, <given-names>J. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Pawlowsky‐Glahn</surname>, <given-names>V.</given-names>
</string-name> (<year>2006</year>). <article-title>Hilbert space of probability density functions based on Aitchison geometry</article-title>. <source>Acta Mathematica Sinica</source>, <volume>22</volume>, <fpage>1175</fpage>–<lpage>1182</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0015">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0015">
<string-name>
<surname>Faria</surname>, <given-names>A. V.</given-names>
</string-name>, <string-name>
<surname>Joel</surname>, <given-names>S. E.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Oishi</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>van Zjil</surname>, <given-names>P. C.</given-names>
</string-name>, <string-name>
<surname>Miller</surname>, <given-names>M. I.</given-names>
</string-name>, <string-name>
<surname>Pekar</surname>, <given-names>J. J.</given-names>
</string-name>, &amp; <string-name>
<surname>Mori</surname>, <given-names>S.</given-names>
</string-name> (<year>2012</year>). <article-title>Atlas‐based analysis of resting‐state functional connectivity: Evaluation for reproducibility and multi‐modal anatomy–function correlation studies</article-title>. <source>NeuroImage</source>, <volume>61</volume>, <fpage>613</fpage>–<lpage>621</lpage>.<pub-id pub-id-type="pmid">22498656</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0016">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0016">
<string-name>
<surname>Ficek</surname>, <given-names>B. N.</given-names>
</string-name>, <string-name>
<surname>Wang</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Zhao</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Webster</surname>, <given-names>K. T.</given-names>
</string-name>, <string-name>
<surname>Desmond</surname>, <given-names>J. E.</given-names>
</string-name>, <string-name>
<surname>Hillis</surname>, <given-names>A. E.</given-names>
</string-name>, <string-name>
<surname>Frangakis</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Faria</surname>, <given-names>A. V.</given-names>
</string-name>, <string-name>
<surname>Caffo</surname>, <given-names>B.</given-names>
</string-name>, &amp; <string-name>
<surname>Tsapkini</surname>, <given-names>K.</given-names>
</string-name> (<year>2018</year>). <article-title>The effect of tdcs on functional connectivity in primary progressive aphasia</article-title>. <source>NeuroImage: Clinical</source>, <volume>19</volume>, <fpage>703</fpage>–<lpage>715</lpage>.<pub-id pub-id-type="pmid">30009127</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0017">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0017">
<string-name>
<surname>Finger</surname>, <given-names>S.</given-names>
</string-name>, &amp; <string-name>
<surname>Almli</surname>, <given-names>C. R.</given-names>
</string-name> (<year>1985</year>). <article-title>Brain damage and neuroplasticity: Mechanisms of recovery or development?</article-title>
<source>Brain Research Reviews</source>, <volume>10</volume>, <fpage>177</fpage>–<lpage>186</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0018">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0018">
<string-name>
<surname>Friston</surname>, <given-names>K. J.</given-names>
</string-name> (<year>2011</year>). <article-title>Functional and effective connectivity: A review</article-title>. <source>Brain Connectivity</source>, <volume>1</volume>, <fpage>13</fpage>–<lpage>36</lpage>.<pub-id pub-id-type="pmid">22432952</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0019">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0019">
<string-name>
<surname>Gandiga</surname>, <given-names>P. C.</given-names>
</string-name>, <string-name>
<surname>Hummel</surname>, <given-names>F. C.</given-names>
</string-name>, &amp; <string-name>
<surname>Cohen</surname>, <given-names>L. G.</given-names>
</string-name> (<year>2006</year>). <article-title>Transcranial dc stimulation (tdcs): A tool for double‐blind sham‐controlled clinical studies in brain stimulation</article-title>. <source>Clinical Neurophysiology</source>, <volume>117</volume>, <fpage>845</fpage>–<lpage>850</lpage>.<pub-id pub-id-type="pmid">16427357</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0020">
        <mixed-citation publication-type="book" id="hbm26112-cit-0020">
<string-name>
<surname>Ghanem</surname>, <given-names>R. G.</given-names>
</string-name>, &amp; <string-name>
<surname>Spanos</surname>, <given-names>P. D.</given-names>
</string-name> (<year>2003</year>). <source>Stochastic finite elements: A spectral approach</source>. <publisher-name>Courier Corporation</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0021">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0021">
<string-name>
<surname>Goldsmith</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Crainiceanu</surname>, <given-names>C. M.</given-names>
</string-name>, <string-name>
<surname>Caffo</surname>, <given-names>B.</given-names>
</string-name>, &amp; <string-name>
<surname>Reich</surname>, <given-names>D.</given-names>
</string-name> (<year>2012</year>). <article-title>Longitudinal penalized functional regression for cognitive outcomes on neuronal tract measurements</article-title>. <source>Journal of the Royal Statistical Society: Series C (Applied Statistics)</source>, <volume>61</volume>, <fpage>453</fpage>–<lpage>469</lpage>.<pub-id pub-id-type="pmid">22679339</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0022">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0022">
<string-name>
<surname>Goldsmith</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Crainiceanu</surname>, <given-names>C. M.</given-names>
</string-name>, <string-name>
<surname>Caffo</surname>, <given-names>B. S.</given-names>
</string-name>, &amp; <string-name>
<surname>Reich</surname>, <given-names>D. S.</given-names>
</string-name> (<year>2011</year>). <article-title>Penalized functional regression analysis of white‐matter tract profiles in multiple sclerosis</article-title>. <source>NeuroImage</source>, <volume>57</volume>, <fpage>431</fpage>–<lpage>439</lpage>.<pub-id pub-id-type="pmid">21554962</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0023">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0023">
<string-name>
<surname>Goldsmith</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Wand</surname>, <given-names>M. P.</given-names>
</string-name>, &amp; <string-name>
<surname>Crainiceanu</surname>, <given-names>C.</given-names>
</string-name> (<year>2011</year>). <article-title>Functional regression via variational Bayes</article-title>. <source>Electronic Journal of Statistics</source>, <volume>5</volume>, <fpage>572</fpage>–<lpage>602</lpage>.<pub-id pub-id-type="pmid">22163061</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0024">
        <mixed-citation publication-type="book" id="hbm26112-cit-0024">
<string-name>
<surname>Goodman</surname>, <given-names>R.</given-names>
</string-name>, &amp; <string-name>
<surname>Caramazza</surname>, <given-names>A.</given-names>
</string-name> (<year>1985</year>). <source>The Johns Hopkins University dysgraphia battery</source>. <publisher-name>Johns Hopkins University</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0025">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0025">
<string-name>
<surname>Gorno‐Tempini</surname>, <given-names>M. L.</given-names>
</string-name>, <string-name>
<surname>Hillis</surname>, <given-names>A. E.</given-names>
</string-name>, <string-name>
<surname>Weintraub</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Kertesz</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Mendez</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Cappa</surname>, <given-names>S. F.</given-names>
</string-name>, <string-name>
<surname>Ogar</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Rohrer</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Black</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Boeve</surname>, <given-names>B. F.</given-names>
</string-name>, <string-name>
<surname>Manes</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Dronkers</surname>, <given-names>N. F.</given-names>
</string-name>, <string-name>
<surname>Vandenberghe</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Rascovsky</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Patterson</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Miller</surname>, <given-names>B. L.</given-names>
</string-name>, <string-name>
<surname>Knopman</surname>, <given-names>D. S.</given-names>
</string-name>, <string-name>
<surname>Hodges</surname>, <given-names>J. R.</given-names>
</string-name>, <string-name>
<surname>Mesulam</surname>, <given-names>M. M.</given-names>
</string-name>, &amp; <string-name>
<surname>Grossman</surname>, <given-names>M.</given-names>
</string-name> (<year>2011</year>). <article-title>Classification of primary progressive aphasia and its variants</article-title>. <source>Neurology</source>, <volume>76</volume>, <fpage>1006</fpage>–<lpage>1014</lpage>.<pub-id pub-id-type="pmid">21325651</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0026">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0026">
<string-name>
<surname>Greenhouse</surname>, <given-names>S. W.</given-names>
</string-name> (<year>1982</year>). <article-title>Jerome Cornfield's contributions to epidemiology</article-title>. <source>Biometrics</source>, <volume>38</volume>, <fpage>33</fpage>–<lpage>45</lpage>.<pub-id pub-id-type="pmid">7046823</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0027">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0027">
<string-name>
<surname>Gu</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Qiu</surname>, <given-names>C.</given-names>
</string-name> (<year>1993</year>). <article-title>Smoothing spline density estimation: Theory</article-title>. <source>The Annals of Statistics</source>, <volume>21</volume>, <fpage>217</fpage>–<lpage>234</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0028">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0028">
<string-name>
<surname>Gu</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Wang</surname>, <given-names>J.</given-names>
</string-name> (<year>2003</year>). <article-title>Penalized likelihood density estimation: Direct cross‐validation and scalable approximation</article-title>. <source>Statistica Sinica</source>, <volume>31</volume>, <fpage>811</fpage>–<lpage>826</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0029">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0029">
<string-name>
<surname>Haxby</surname>, <given-names>J. V.</given-names>
</string-name>, <string-name>
<surname>Guntupalli</surname>, <given-names>J. S.</given-names>
</string-name>, <string-name>
<surname>Nastase</surname>, <given-names>S. A.</given-names>
</string-name>, &amp; <string-name>
<surname>Feilong</surname>, <given-names>M.</given-names>
</string-name> (<year>2020</year>). <article-title>Hyperalignment: Modeling shared information encoded in idiosyncratic cortical topographies</article-title>. <source>eLife</source>, <volume>9</volume>, <elocation-id>e56601</elocation-id>.<pub-id pub-id-type="pmid">32484439</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0030">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0030">
<string-name>
<surname>Hutchison</surname>, <given-names>R. M.</given-names>
</string-name>, <string-name>
<surname>Womelsdorf</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Allen</surname>, <given-names>E. A.</given-names>
</string-name>, <string-name>
<surname>Bandettini</surname>, <given-names>P. A.</given-names>
</string-name>, <string-name>
<surname>Calhoun</surname>, <given-names>V. D.</given-names>
</string-name>, <string-name>
<surname>Cor betta</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Penna</surname>, <given-names>S. D.</given-names>
</string-name>, <string-name>
<surname>Duyn</surname>, <given-names>J. H.</given-names>
</string-name>, <string-name>
<surname>Glover</surname>, <given-names>G. H.</given-names>
</string-name>, <string-name>
<surname>Gonzalez‐Castillo</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Handwerker</surname>, <given-names>D. A.</given-names>
</string-name>, <string-name>
<surname>Keilholz</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Kiviniemi</surname>, <given-names>V.</given-names>
</string-name>, <string-name>
<surname>Leopold</surname>, <given-names>D. A.</given-names>
</string-name>, <string-name>
<surname>de Pasquale</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Sporns</surname>, <given-names>O.</given-names>
</string-name>, <string-name>
<surname>Walter</surname>, <given-names>M.</given-names>
</string-name>, &amp; <string-name>
<surname>Chang</surname>, <given-names>C.</given-names>
</string-name> (<year>2013</year>). <article-title>Dynamic functional connectivity: Promise, issues, and interpretations</article-title>. <source>NeuroImage</source>, <volume>80</volume>, <fpage>360</fpage>–<lpage>378</lpage>.<pub-id pub-id-type="pmid">23707587</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0031">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0031">
<string-name>
<surname>Knopman</surname>, <given-names>D. S.</given-names>
</string-name>, <string-name>
<surname>Kramer</surname>, <given-names>J. H.</given-names>
</string-name>, <string-name>
<surname>Boeve</surname>, <given-names>B. F.</given-names>
</string-name>, <string-name>
<surname>Caselli</surname>, <given-names>R. J.</given-names>
</string-name>, <string-name>
<surname>Graff‐Radford</surname>, <given-names>N. R.</given-names>
</string-name>, <string-name>
<surname>Mendez</surname>, <given-names>M. F.</given-names>
</string-name>, <string-name>
<surname>Miller</surname>, <given-names>B. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Mercaldo</surname>, <given-names>N.</given-names>
</string-name> (<year>2008</year>). <article-title>Development of methodology for conducting clinical trials in frontotemporal lobar degeneration</article-title>. <source>Brain</source>, <volume>131</volume>, <fpage>2957</fpage>–<lpage>2968</lpage>.<pub-id pub-id-type="pmid">18829698</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0032">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0032">
<string-name>
<surname>Kong</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Orban</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Sabuncu</surname>, <given-names>M. R.</given-names>
</string-name>, <string-name>
<surname>Liu</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Schaefer</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Sun</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Zuo</surname>, <given-names>X.‐N.</given-names>
</string-name>, <string-name>
<surname>Holmes</surname>, <given-names>A. J.</given-names>
</string-name>, <string-name>
<surname>Eickhoff</surname>, <given-names>S. B.</given-names>
</string-name>, &amp; <string-name>
<surname>Yeo</surname>, <given-names>B. T. T.</given-names>
</string-name> (<year>2019</year>). <article-title>Spatial topography of individual‐specific cortical networks predicts human cognition, personality, and emotion</article-title>. <source>Cerebral Cortex</source>, <volume>29</volume>, <fpage>2533</fpage>–<lpage>2551</lpage>.<pub-id pub-id-type="pmid">29878084</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0033">
        <mixed-citation publication-type="miscellaneous" id="hbm26112-cit-0033">
<string-name>
<surname>Koutra</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Vogelstein</surname>, <given-names>J. T.</given-names>
</string-name>, &amp; <string-name>
<surname>Faloutsos</surname>, <given-names>C.</given-names>
</string-name> (<year>2013</year>). <article-title>Deltacon: A principled massive‐graph similarity function. In Proceedings of the 2013 SIAM International Conference on Data Mining, SIAM</article-title>, pp. <fpage>162</fpage>–<lpage>170</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0034">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0034">
<string-name>
<surname>McLean</surname>, <given-names>M. W.</given-names>
</string-name>, <string-name>
<surname>Hooker</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Staicu</surname>, <given-names>A.‐M.</given-names>
</string-name>, <string-name>
<surname>Scheipl</surname>, <given-names>F.</given-names>
</string-name>, &amp; <string-name>
<surname>Ruppert</surname>, <given-names>D.</given-names>
</string-name> (<year>2014</year>). <article-title>Functional generalized additive models</article-title>. <source>Journal of Computational and Graphical Statistics</source>, <volume>23</volume>, <fpage>249</fpage>–<lpage>269</lpage>.<pub-id pub-id-type="pmid">24729671</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0035">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0035">
<string-name>
<surname>Miller</surname>, <given-names>M. I.</given-names>
</string-name>, <string-name>
<surname>Beg</surname>, <given-names>M. F.</given-names>
</string-name>, <string-name>
<surname>Ceritoglu</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Stark</surname>, <given-names>C.</given-names>
</string-name> (<year>2005</year>). <article-title>Increasing the power of functional maps of the medial temporal lobe by using large deformation diffeomorphic metric mapping</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>102</volume>, <fpage>9685</fpage>–<lpage>9690</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0036">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0036">
<string-name>
<surname>Mori</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Wu</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Ceritoglu</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Kolasny</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Vaillant</surname>, <given-names>M. A.</given-names>
</string-name>, <string-name>
<surname>Faria</surname>, <given-names>A. V.</given-names>
</string-name>, <string-name>
<surname>Oishi</surname>, <given-names>K.</given-names>
</string-name>, &amp; <string-name>
<surname>Miller</surname>, <given-names>M. I.</given-names>
</string-name> (<year>2016</year>). <article-title>MRIcloud: Delivering high‐throughput MRI neuroinformatics as cloud‐based software as a service</article-title>. <source>Computing in Science &amp; Engineering</source>, <volume>18</volume>, <fpage>21</fpage>–<lpage>35</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0037">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0037">
<string-name>
<surname>Nitsche</surname>, <given-names>M. A.</given-names>
</string-name>, <string-name>
<surname>Cohen</surname>, <given-names>L. G.</given-names>
</string-name>, <string-name>
<surname>Wassermann</surname>, <given-names>E. M.</given-names>
</string-name>, <string-name>
<surname>Priori</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Lang</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Antal</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Paulus</surname>, <given-names>W.</given-names>
</string-name>, <string-name>
<surname>Hummel</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Boggio</surname>, <given-names>P. S.</given-names>
</string-name>, <string-name>
<surname>Fregni</surname>, <given-names>F.</given-names>
</string-name>, &amp; <string-name>
<surname>Pascual‐Leone</surname>, <given-names>A.</given-names>
</string-name> (<year>2008</year>). <article-title>Transcranial direct current stimulation: State of the art 2008</article-title>. <source>Brain Stimulation</source>, <volume>1</volume>, <fpage>206</fpage>–<lpage>223</lpage>.<pub-id pub-id-type="pmid">20633386</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0038">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0038">
<string-name>
<surname>Nychka</surname>, <given-names>D.</given-names>
</string-name> (<year>1988</year>). <article-title>Bayesian confidence intervals for smoothing splines</article-title>. <source>Journal of the American Statistical Association</source>, <volume>83</volume>, <fpage>1134</fpage>–<lpage>1143</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0039">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0039">
<string-name>
<surname>Oliveira</surname>, <given-names>F. P.</given-names>
</string-name>, &amp; <string-name>
<surname>Tavares</surname>, <given-names>J. M. R.</given-names>
</string-name> (<year>2014</year>). <article-title>Medical image registration: A review</article-title>. <source>Computer Methods in Biomechanics and Biomedical Engineering</source>, <volume>17</volume>, <fpage>73</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">22435355</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0040">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0040">
<string-name>
<surname>Petersen</surname>, <given-names>A.</given-names>
</string-name>, &amp; <string-name>
<surname>Muüller</surname>, <given-names>H.‐G.</given-names>
</string-name> (<year>2016</year>). <article-title>Functional data analysis for density functions by transformation to a Hilbert space</article-title>. <source>The Annals of Statistics</source>, <volume>44</volume>, <fpage>183</fpage>–<lpage>218</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0041">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0041">
<string-name>
<surname>Prentice</surname>, <given-names>R. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Pyke</surname>, <given-names>R.</given-names>
</string-name> (<year>1979</year>). <article-title>Logistic disease incidence models and case‐control studies</article-title>. <source>Biometrika</source>, <volume>66</volume>, <fpage>403</fpage>–<lpage>411</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0042">
        <mixed-citation publication-type="book" id="hbm26112-cit-0042">
<string-name>
<surname>Ramsay</surname>, <given-names>J. O.</given-names>
</string-name> (<year>2004</year>). <part-title>Functional data analysis</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>S.</given-names>
<surname>Kotz</surname>
</string-name>
</person-group>, <person-group person-group-type="editor">
<string-name>
<given-names>C. B.</given-names>
<surname>Read</surname>
</string-name>
</person-group>, <person-group person-group-type="editor">
<string-name>
<given-names>N.</given-names>
<surname>Balakrishnan</surname>
</string-name>
</person-group>, <person-group person-group-type="editor">
<string-name>
<given-names>B.</given-names>
<surname>Vidakovic</surname>
</string-name>
</person-group>, &amp; <person-group person-group-type="editor">
<string-name>
<given-names>N. L.</given-names>
<surname>Johnson</surname>
</string-name>
</person-group> (Eds.), <source>Encyclopedia of statistical sciences</source> (Vol. <volume>4</volume>). <publisher-name>John Wiley &amp; Sons</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0043">
        <mixed-citation publication-type="book" id="hbm26112-cit-0043">
<string-name>
<surname>Ramsay</surname>, <given-names>J. O.</given-names>
</string-name>, &amp; <string-name>
<surname>Silverman</surname>, <given-names>B. W.</given-names>
</string-name> (<year>2007</year>). <source>Applied functional data analysis: Methods and case studies</source>. <publisher-name>Springer</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0044">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0044">
<string-name>
<surname>Reiss</surname>, <given-names>P. T.</given-names>
</string-name>, <string-name>
<surname>Goldsmith</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Shang</surname>, <given-names>H. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Ogden</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2017</year>). <article-title>Methods for scalar‐on‐function regression</article-title>. <source>International Statistical Review</source>, <volume>85</volume>, <fpage>228</fpage>–<lpage>249</lpage>.<pub-id pub-id-type="pmid">28919663</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0045">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0045">
<string-name>
<surname>Reiss</surname>, <given-names>P. T.</given-names>
</string-name>, <string-name>
<surname>Huang</surname>, <given-names>L.</given-names>
</string-name>, &amp; <string-name>
<surname>Mennes</surname>, <given-names>M.</given-names>
</string-name> (<year>2010</year>). <article-title>Fast function‐on‐scalar regression with penalized basis expansions</article-title>. <source>The International Journal of Biostatistics</source>, <volume>6</volume>, <elocation-id>28</elocation-id>.<pub-id pub-id-type="pmid">21969982</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0046">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0046">
<string-name>
<surname>Reiss</surname>, <given-names>P. T.</given-names>
</string-name>, &amp; <string-name>
<surname>Ogden</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2007</year>). <article-title>Functional principal component regression and functional partial least squares</article-title>. <source>Journal of the American Statistical Association</source>, <volume>102</volume>, <fpage>984</fpage>–<lpage>996</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0047">
        <mixed-citation publication-type="book" id="hbm26112-cit-0047">
<string-name>
<surname>Rothman</surname>, <given-names>K. J.</given-names>
</string-name>, <string-name>
<surname>Greenland</surname>, <given-names>S.</given-names>
</string-name>, &amp; <string-name>
<surname>Lash</surname>, <given-names>T. L.</given-names>
</string-name> (<year>2008</year>). <part-title>Case–control studies</part-title>. In <person-group person-group-type="editor">
<string-name>
<given-names>E. L.</given-names>
<surname>Melnick</surname>
</string-name>
</person-group> &amp; <person-group person-group-type="editor">
<string-name>
<given-names>B. S.</given-names>
<surname>Everitt</surname>
</string-name>
</person-group> (Eds.), <source>Encyclopedia of quantitative risk analysis and assessment</source> (Vol. <volume>1</volume>). <publisher-name>John Wiley &amp; Sons, Ltd</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0048">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0048">
<string-name>
<surname>Scheinost</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Benjamin</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Lacadie</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Vohr</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Schneider</surname>, <given-names>K. C.</given-names>
</string-name>, <string-name>
<surname>Ment</surname>, <given-names>L. R.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, &amp; <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2012</year>). <article-title>The intrinsic connectivity distribution: A novel contrast measure reflecting voxel level functional connectivity</article-title>. <source>NeuroImage</source>, <volume>62</volume>, <fpage>1510</fpage>–<lpage>1519</lpage>.<pub-id pub-id-type="pmid">22659477</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0049">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0049">
<string-name>
<surname>Shen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Finn</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Scheinost</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Rosenberg</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Chun</surname>, <given-names>M. M.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, &amp; <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2017</year>). <article-title>Using connectome‐based predictive modeling to predict individual behavior from brain connectivity</article-title>. <source>Nature Protocols</source>, <volume>12</volume>, <fpage>506</fpage>–<lpage>518</lpage>.<pub-id pub-id-type="pmid">28182017</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0050">
        <mixed-citation publication-type="book" id="hbm26112-cit-0050">
<string-name>
<surname>Silverman</surname>, <given-names>B. W.</given-names>
</string-name> (<year>1986</year>). <source>Density estimation for statistics and data analysis</source> (Vol. <volume>26</volume>). <publisher-name>CRC Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0051">
        <mixed-citation publication-type="book" id="hbm26112-cit-0051">
<string-name>
<surname>Sporns</surname>, <given-names>O.</given-names>
</string-name> (<year>2010</year>). <source>Networks of the brain</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0052">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0052">
<string-name>
<surname>Szabó</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Sriperumbudur</surname>, <given-names>B. K.</given-names>
</string-name>, <string-name>
<surname>Póczos</surname>, <given-names>B.</given-names>
</string-name>, &amp; <string-name>
<surname>Gretton</surname>, <given-names>A.</given-names>
</string-name> (<year>2016</year>). <article-title>Learning theory for distribution regression</article-title>. <source>Journal of Machine Learning Research</source>, <volume>17</volume>, <fpage>5272</fpage>–<lpage>5311</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0053">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0053">
<string-name>
<surname>Tang</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Oishi</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Faria</surname>, <given-names>A. V.</given-names>
</string-name>, <string-name>
<surname>Hillis</surname>, <given-names>A. E.</given-names>
</string-name>, <string-name>
<surname>Albert</surname>, <given-names>M. S.</given-names>
</string-name>, <string-name>
<surname>Mori</surname>, <given-names>S.</given-names>
</string-name>, &amp; <string-name>
<surname>Miller</surname>, <given-names>M. I.</given-names>
</string-name> (<year>2013</year>). <article-title>Bayesian parameter estimation and segmentation in the multi‐atlas random orbit model</article-title>. <source>PLoS One</source>, <volume>8</volume>, <elocation-id>e65591</elocation-id>.<pub-id pub-id-type="pmid">23824159</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0054">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0054">
<string-name>
<surname>Tsapkini</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Webster</surname>, <given-names>K. T.</given-names>
</string-name>, <string-name>
<surname>Ficek</surname>, <given-names>B. N.</given-names>
</string-name>, <string-name>
<surname>Desmond</surname>, <given-names>J. E.</given-names>
</string-name>, <string-name>
<surname>Onyike</surname>, <given-names>C. U.</given-names>
</string-name>, <string-name>
<surname>Rapp</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Frangakis</surname>, <given-names>C. E.</given-names>
</string-name>, &amp; <string-name>
<surname>Hillis</surname>, <given-names>A. E.</given-names>
</string-name> (<year>2018</year>). <article-title>Electrical brain stimulation in different variants of primary progressive aphasia: A randomized clinical trial</article-title>. <source>Alzheimer's &amp; Dementia: Translational Research &amp; Clinical Interventions</source>, <volume>4</volume>, <fpage>461</fpage>–<lpage>472</lpage>.<pub-id pub-id-type="pmid">30258975</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0055">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0055">
<string-name>
<surname>Vogelstein</surname>, <given-names>J. T.</given-names>
</string-name>, <string-name>
<surname>Roncal</surname>, <given-names>W. G.</given-names>
</string-name>, <string-name>
<surname>Vogelstein</surname>, <given-names>R. J.</given-names>
</string-name>, &amp; <string-name>
<surname>Priebe</surname>, <given-names>C. E.</given-names>
</string-name> (<year>2012</year>). <article-title>Graph classification using signal‐subgraphs: Applications in statistical connectomics</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>, <volume>35</volume>, <fpage>1539</fpage>–<lpage>1551</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0056">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0056">
<string-name>
<surname>Wahba</surname>, <given-names>G.</given-names>
</string-name> (<year>1983</year>). <article-title>Bayesian “confidence intervals” for the cross‐validated smoothing spline</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>, <volume>45</volume>, <fpage>133</fpage>–<lpage>150</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0057">
        <mixed-citation publication-type="book" id="hbm26112-cit-0057">
<string-name>
<surname>Wernicke</surname>, <given-names>C.</given-names>
</string-name> (<year>1874</year>). <source>Der aphasische symptomencomplex: eine psychologische studie auf anatomischer basis</source>. <publisher-name>Cohn &amp; Weigert</publisher-name>.</mixed-citation>
      </ref>
      <ref id="hbm26112-bib-0058">
        <mixed-citation publication-type="journal" id="hbm26112-cit-0058">
<string-name>
<surname>Wood</surname>, <given-names>S. N.</given-names>
</string-name> (<year>2004</year>). <article-title>Stable and efficient multiple smoothing parameter estimation for generalized additive models</article-title>. <source>Journal of the American Statistical Association</source>, <volume>99</volume>, <fpage>673</fpage>–<lpage>686</lpage>.</mixed-citation>
      </ref>
    </ref-list>
    <app-group>
      <app id="hbm26112-app-0001" content-type="APPENDIX">
        <label>APPENDIX A</label>
        <sec id="hbm26112-sec-0020">
          <label>A.1</label>
          <title>Invariance properties</title>
          <p>Here we discuss some invariance properties of the connectivity density. Consider <mml:math id="jats-math-117" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> a connectivity measure where <mml:math id="jats-math-118" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> is measuring the connectivity between location <mml:math id="jats-math-119" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-120" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:math>. The connectivity density can be defined as the density of random variables <mml:math id="jats-math-121" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math>, where <mml:math id="jats-math-122" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> follows a sampling distribution on <mml:math id="jats-math-123" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">D</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:math>. Denote <mml:math id="jats-math-124" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mtext>sample</mml:mtext></mml:msub></mml:mrow></mml:math> as the density of that sampling distribution. It is easy to see that the connectivity density, <mml:math id="jats-math-125" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math>, defined in Section <xref rid="hbm26112-sec-0005" ref-type="sec">2.3</xref> also follows such a definition while using the uniform distribution as <mml:math id="jats-math-126" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mtext>sample</mml:mtext></mml:msub></mml:mrow></mml:math>. We prove that <mml:math id="jats-math-127" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:math> is invariant to re‐labeling in discrete cases (e.g., connectivity between ROIs) and to affine transformation in continuous cases (e.g., interpolation of connectivity between voxels). Denote <mml:math id="jats-math-128" display="inline" overflow="scroll"><mml:mrow><mml:mi>supp</mml:mi><mml:mfenced open="(" close=")"><mml:mi>C</mml:mi></mml:mfenced></mml:mrow></mml:math> be the support of connectivity measure <mml:math id="jats-math-129" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math>. After any invertible transformation, <mml:math id="jats-math-130" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">ℱ</mml:mi></mml:mrow></mml:math>, the connectivity measure <mml:math id="jats-math-131" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:mrow></mml:math> will be naturally defined as <mml:math id="jats-math-132" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mfenced open="(" close=")" separators=","><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced open="(" close=")"><mml:mi>y</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>. Then we have the following Theorem <xref rid="hbm26112-mthst-0001" ref-type="statement">1</xref>.<statement content-type="Theorem" id="hbm26112-mthst-0001"><label>Theorem 1</label><p>
<italic toggle="yes">Let</italic>
<mml:math id="jats-math-133" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mi>C</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math>
<italic toggle="yes">follow the uniform distribution on</italic>
<mml:math id="jats-math-134" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">supp</mml:mi><mml:mfenced open="(" close=")"><mml:mi>C</mml:mi></mml:mfenced></mml:mrow></mml:math>
<italic toggle="yes">. Then, the density of</italic>
<mml:math id="jats-math-135" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mi>C</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math>
<italic toggle="yes">has the same distribution with</italic>
<mml:math id="jats-math-136" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:msup></mml:mfenced></mml:mrow></mml:math>
<italic toggle="yes">, where</italic>
<mml:math id="jats-math-137" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">ℱ</mml:mi></mml:mrow></mml:math>
<italic toggle="yes">is any permutation map if</italic>
<mml:math id="jats-math-138" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">supp</mml:mi><mml:mfenced open="(" close=")"><mml:mi>C</mml:mi></mml:mfenced></mml:mrow></mml:math>
<italic toggle="yes">is a finite discrete set and</italic>
<mml:math id="jats-math-139" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">ℱ</mml:mi></mml:mrow></mml:math>
<italic toggle="yes">is any affine transformation if</italic>
<mml:math id="jats-math-140" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">supp</mml:mi><mml:mfenced open="(" close=")"><mml:mi>C</mml:mi></mml:mfenced></mml:mrow></mml:math>
<italic toggle="yes">is a closure of some open set in</italic>
<mml:math id="jats-math-141" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℛ</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math>
<italic toggle="yes">. Therefore, connectivity densities are invariant to these transformations</italic>.</p></statement>
</p>
          <p>
<italic toggle="yes">Proof</italic>. By change of variable calculus of random variables, we know that under a sampling distribution <mml:math id="jats-math-142" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mtext>sample</mml:mtext></mml:msub></mml:mrow></mml:math>, <mml:math id="jats-math-143" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> has the sample distribution with <mml:math id="jats-math-144" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mfenced></mml:mrow></mml:math> if <mml:math id="jats-math-145" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mfenced><mml:mo>∼</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mtext>sample</mml:mtext><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:math> where <mml:math id="jats-math-146" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mtext>sample</mml:mtext><mml:mo>′</mml:mo></mml:msubsup><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mfenced open="|" close="|"><mml:mi mathvariant="normal">ℱ</mml:mi></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mtext>sample</mml:mtext></mml:msub><mml:mfenced open="(" close=")" separators=","><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced open="(" close=")"><mml:mi>x</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfenced open="(" close=")"><mml:mi>y</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math>.</p>
          <p>In our uniform cases, the Jacobian <mml:math id="jats-math-147" display="inline" overflow="scroll"><mml:mrow><mml:mo>∣</mml:mo><mml:mi mathvariant="normal">ℱ</mml:mi><mml:mo>∣</mml:mo></mml:mrow></mml:math> and sampling distribution <mml:math id="jats-math-148" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msup><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>C</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msup><mml:mi>U</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:math> will always be a constant. Therefore, the condition above always holds and <mml:math id="jats-math-149" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:mi>C</mml:mi></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:mi>C</mml:mi></mml:msup></mml:mfenced></mml:mrow></mml:math> must follow a sample distribution with <mml:math id="jats-math-150" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub><mml:mfenced open="(" close=")" separators=","><mml:msup><mml:mi>U</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:msup><mml:msup><mml:mi>V</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">ℱ</mml:mi></mml:msub></mml:msup></mml:mfenced></mml:mrow></mml:math>.</p>
          <p>Since the uniform distribution is the only distribution invariant to all affine transformations / permutations, we know that the connectivity density defined in Section <xref rid="hbm26112-sec-0005" ref-type="sec">2.3</xref> is also the only possible distributional summary that has such an invariance property for arbitrary connectivity measures.</p>
        </sec>
        <sec id="hbm26112-sec-0021">
          <label>A.2</label>
          <title>Additional simulations</title>
          <p>Here we describe another intuitive simulation setting and show that a similar pattern is observed. Specifically, it shows that our methods can detect non‐localized effects, while edgewise method or dimension reduction methods, like PCA, cannot, although the best transformation of densities might change for different signal distributions.</p>
          <p>Again we consider connectivity matrix of 20 regions <mml:math id="jats-math-151" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>⋯</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mn>20</mml:mn></mml:msub></mml:mrow></mml:math>. A no‐stimulation connectivity matrix, <mml:math id="jats-math-152" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math>, is sampled uniformly from 50 pre‐intervention scans in our data and its 20 rows and columns are also uniformly sampled from an original 78 × 78 connectivity matrix. Now consider a localized stimulation as additive Gaussian signals to the Fisher‐<italic toggle="yes">z</italic> transformed correlation for specific region pairs. It then gives post‐stimulation connectivity matrix <mml:math id="jats-math-153" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>C</mml:mi><mml:mi mathvariant="italic">sti</mml:mi></mml:msup></mml:mrow></mml:math> differs with <mml:math id="jats-math-154" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> only on<disp-formula id="hbm26112-disp-0009">
<label>(A1)</label>
<mml:math id="jats-math-155" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mi>tanh</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mi mathvariant="italic">sti</mml:mi></mml:msubsup><mml:mo linebreak="goodbreak">=</mml:mo><mml:msup><mml:mi>tanh</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math>
</disp-formula>for <mml:math id="jats-math-156" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="{" close="}"><mml:mrow><mml:mfenced open="(" close=")" separators=","><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced><mml:mo>∣</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>⋯</mml:mi><mml:mi>K</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math> some specific region pairs and <mml:math id="jats-math-157" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> i.n.d. follows <mml:math id="jats-math-158" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mfenced open="(" close=")" separators=","><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mfenced></mml:mrow></mml:math>. Notice that this formulation corresponds with the underlying effect pattern in some common edgewise analysis of change in connectivity, for example Ficek et al. (<xref rid="hbm26112-bib-0016" ref-type="bibr">2018</xref>).</p>
          <p>In the simulation for localized analysis, the locations <mml:math id="jats-math-159" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")" separators=","><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math> are uniformly randomly selected from all 190 region pairs and then fixed for all samples. Naturally a stimulation with non‐localized effect would also follow Equation (<xref rid="hbm26112-disp-0009" ref-type="disp-formula">A1</xref>). But every time it is performed, <mml:math id="jats-math-160" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="{" close="}"><mml:mfenced open="(" close=")" separators=","><mml:msub><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:math> becomes another independent sample from the 190 regions. In the experiment, we choose <mml:math id="jats-math-161" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math> for all <mml:math id="jats-math-162" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math>. We also observed similar patterns for a variety of parameters settings. We ran the experiment for 10,000 independent simulations. For every run we sampled 100 no‐stimulation connectivity maps with another 100 each for localized stimulation, non‐localized stimulation and no stimulation. We studied how different methods work in these situations as described in Section <xref rid="hbm26112-sec-0008" ref-type="sec">2.6</xref>. The results for the simulation can be found in Table <xref rid="hbm26112-tbl-0002" ref-type="table">A1</xref>. We observe a similar pattern as Table <xref rid="hbm26112-tbl-0003" ref-type="table">A2</xref> that connectivity density based methods can detect non‐localized effect while edgewise analysis and principal component analysis cannot. It also shows that the optimal transformation might be different for different patterns of the effect, as the log transformation is the best in this situation while the log‐density‐quantile transformation is the best in Table <xref rid="hbm26112-tbl-0003" ref-type="table">A2</xref>.</p>
          <table-wrap position="anchor" id="hbm26112-tbl-0002" content-type="TABLE">
            <label>TABLE A1</label>
            <caption>
              <p>The table shows the ratio of significant positive findings over 10,000 runs</p>
            </caption>
            <table frame="hsides" rules="groups">
              <col align="left" span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <thead valign="bottom">
                <tr style="border-bottom:solid 1px #000000">
                  <th align="left" valign="bottom" rowspan="1" colspan="1"/>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">Bonferroni</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">FDR</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">PC</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">
<mml:math id="jats-math-163" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>
</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">
<mml:math id="jats-math-164" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math>
</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">
<mml:math id="jats-math-165" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi mathvariant="italic">ldq</mml:mi></mml:msub></mml:mrow></mml:math>
</th>
                </tr>
              </thead>
              <tbody valign="top">
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Non‐localized</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.060</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.065</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.089</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.618</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">1</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.870</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Localized</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.938</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.953</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.994</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.620</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">1</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.862</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">No‐stimulation</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.048</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.051</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.082</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.060</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.056</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.053</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot id="hbm26112-ntgp-0002">
              <fn id="hbm26112-note-0002">
                <p>
<italic toggle="yes">Note</italic>: <mml:math id="jats-math-166" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>, <mml:math id="jats-math-167" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math>, and <mml:math id="jats-math-168" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi mathvariant="italic">ldq</mml:mi></mml:msub></mml:mrow></mml:math> are density regressions with the identity, logarithm, and log density‐quantile transformations described in Section <xref rid="hbm26112-sec-0005" ref-type="sec">2.3</xref>. Bonferroni, FDR (Benjamini &amp; Hochberg, <xref rid="hbm26112-bib-0003" ref-type="bibr">1995</xref>) refer to edgewise regression with those associated multiplicity correction procedures. PC refers to principal component regression with the top 20 components.</p>
              </fn>
            </table-wrap-foot>
          </table-wrap>
          <table-wrap position="anchor" id="hbm26112-tbl-0003" content-type="TABLE">
            <label>TABLE A2</label>
            <caption>
              <p>Significant positive findings over 1000 runs. T0,Tl,Tldq are density regressions with the identity, logarithm, and log density‐quantile transformation described in Section 2.3. Bonferroni, FDR (Benjamini &amp; Hochberg, <xref rid="hbm26112-bib-0003" ref-type="bibr">1995</xref>) refer to edgewise regression with different multiplicity correction procedures. PC refers to the principal component regression with the top 10 components, the number chosen by minimizing the sum of type I error (significance ratio in non‐localized situation) and type II error (none significance ratio in localized situation).</p>
            </caption>
            <table frame="hsides" rules="groups">
              <col align="left" span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <col align="char" char="." span="1"/>
              <thead valign="bottom">
                <tr style="border-bottom:solid 1px #000000">
                  <th align="left" valign="bottom" rowspan="1" colspan="1"/>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">Bonferroni</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">FDR</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">PC</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">
<mml:math id="jats-math-169" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>
</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">
<mml:math id="jats-math-170" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:math>
</th>
                  <th align="left" valign="bottom" rowspan="1" colspan="1">
<mml:math id="jats-math-171" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi mathvariant="italic">ldq</mml:mi></mml:msub></mml:mrow></mml:math>
</th>
                </tr>
              </thead>
              <tbody valign="top">
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Non‐localized</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.073</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.078</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.118</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.638</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.117</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.717</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">Localized</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.638</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.669</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.754</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.629</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.112</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.714</td>
                </tr>
                <tr>
                  <td align="left" valign="top" rowspan="1" colspan="1">No‐stimulation</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.061</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.065</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.113</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.075</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.058</td>
                  <td align="char" valign="top" rowspan="1" colspan="1">0.059</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </sec>
        <sec id="hbm26112-sec-0022">
          <label>A.3</label>
          <title>Connectivity density as outcome</title>
          <p>In this section we detail why we reversing the predictor/response relationship is a compelling idea and thus compare the results with a typical function‐on‐scalar regression with connectivity densities as outcomes.</p>
          <p>Excepting the convenience, as discussed in Section <xref rid="hbm26112-sec-0014" ref-type="sec">4</xref>, the main reason for reversing the predictor/response is that typical function‐on‐scalar regression methods can not satisfy the integral constraints on the outcome, which are densities or isomorphic transformation of densities. Therefore, the specified distribution is not correct, creating concern regarding inferences.</p>
          <p>Consider the following typical linear functional model with outcome function <mml:math id="jats-math-172" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math> and features <mml:math id="jats-math-173" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:math>.<disp-formula id="hbm26112-disp-0010">
<label>(A2)</label>
<mml:math id="jats-math-174" display="block" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>ε</mml:mi><mml:mfenced open="(" close=")"><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-175" display="inline" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:math> is a density functions, log density function, or the log‐density‐quantile transformations. Recall, density functions must be both positive and integrate to 1. Log densities require integral of their exponential to be 1 and Log density quantiles require their corresponding quantiles be supported within [−1, 1], because they are quantiles of correlations. It is easy to see that within the linear functional framework 5, all these constraints cannot be translated into individual constraints on estimation of <mml:math id="jats-math-176" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:math>. Therefore, the model is specifying an easily demonstrably false distribution, resulting in possibly incorrect inferences even if estimation remains viable. Other methods exist to correct this problem, for example Szabó et al. (<xref rid="hbm26112-bib-0052" ref-type="bibr">2016</xref>); Chen et al. (<xref rid="hbm26112-bib-0009" ref-type="bibr">2021</xref>), but this is an active area of research and is thus challenging to implement for most practitioners.</p>
          <p>In Figure <xref rid="hbm26112-fig-0006" ref-type="fig">A1</xref>, we show the estimation results of model 5 on our data as a reference. These are the slope functions of the treatment assignment variable, the estimated differences before and after tDCS stimulation. We used the regression methods described in Reiss et al. (<xref rid="hbm26112-bib-0045" ref-type="bibr">2010</xref>) to solve the problem 5 and the penalty parameters selected by generalized cross validation. There is, as expected a high degree of similarity between the corresponding curves and those in Figure <xref rid="hbm26112-fig-0004" ref-type="fig">4a–d</xref>. But, as we explained above, the distributional assumptions are questionable in this context and the confidence bands remain in question, and therefore we do not report such results in the main article. We also note the distinction in convenience, whereby we obtain similar estimates using only a GLM, perhaps the most standard statistical model.</p>
          <fig position="anchor" fig-type="FIGURE" id="hbm26112-fig-0006">
            <label>FIGURE A1</label>
            <caption>
              <p>Estimated difference function of the transformed neural densities between treatment and control groups, holding all other variables the same. Similar patterns could be found compared with Figure <xref rid="hbm26112-fig-0004" ref-type="fig">4a–d</xref> but their confidence bands are biased because no constraints on the outcome function are satisfied.</p>
            </caption>
            <graphic xlink:href="HBM-44-170-g006" position="anchor" id="jats-graphic-13"/>
          </fig>
          <p>Figure <xref rid="hbm26112-fig-0007" ref-type="fig">A2</xref> shows one sample outcome function from the fitted model. We have checked that it breaks the positive constraints on both tails and its integral is <mml:math id="jats-math-177" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.99</mml:mn><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math>. Also it is clear that the confidence band from the model does not make sense because all densities should be non‐negative. Therefore the inference results from the model 5 are wrong.</p>
          <fig position="anchor" fig-type="FIGURE" id="hbm26112-fig-0007">
            <label>FIGURE A2</label>
            <caption>
              <p>A sample outcome function from the fitted model. It breaks the positive constraints on both tails and its integral is <mml:math id="jats-math-178" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.99</mml:mn><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math>. Also the confidence band from the model does not make sense because all densities are non‐negative.</p>
            </caption>
            <graphic xlink:href="HBM-44-170-g007" position="anchor" id="jats-graphic-15"/>
          </fig>
        </sec>
      </app>
    </app-group>
  </back>
</article>
