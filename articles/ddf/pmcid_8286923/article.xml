<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Cogn Neurodyn</journal-id>
      <journal-id journal-id-type="iso-abbrev">Cogn Neurodyn</journal-id>
      <journal-title-group>
        <journal-title>Cognitive Neurodynamics</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1871-4080</issn>
      <issn pub-type="epub">1871-4099</issn>
      <publisher>
        <publisher-name>Springer Netherlands</publisher-name>
        <publisher-loc>Dordrecht</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">34367362</article-id>
      <article-id pub-id-type="pmc">8286923</article-id>
      <article-id pub-id-type="publisher-id">9645</article-id>
      <article-id pub-id-type="doi">10.1007/s11571-020-09645-y</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Construction of embedded fMRI resting-state functional connectivity networks using manifold learning</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Gallos</surname>
            <given-names>Ioannis K.</given-names>
          </name>
          <address>
            <email>yiannis.gallos@gmail.com</email>
          </address>
          <xref ref-type="aff" rid="Aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Galaris</surname>
            <given-names>Evangelos</given-names>
          </name>
          <address>
            <email>evangelos.galaris@unina.it</email>
          </address>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9568-3355</contrib-id>
          <name>
            <surname>Siettos</surname>
            <given-names>Constantinos I.</given-names>
          </name>
          <address>
            <email>constantinos.siettos@unina.it</email>
          </address>
          <xref ref-type="aff" rid="Aff2">2</xref>
        </contrib>
        <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.4241.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 2185 9808</institution-id><institution>School of Applied Mathematical and Physical Sciences, </institution><institution>National Technical University of Athens, </institution></institution-wrap>Athens, Greece </aff>
        <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.4691.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 0790 385X</institution-id><institution>Dipartimento di Matematica e Applicazioni “Renato Caccioppoli”, </institution><institution>Università degli Studi di Napoli Federico II, </institution></institution-wrap>Napoli, Italy </aff>
      </contrib-group>
      <pub-date pub-type="epub">
        <day>3</day>
        <month>11</month>
        <year>2020</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>3</day>
        <month>11</month>
        <year>2020</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>8</month>
        <year>2021</year>
      </pub-date>
      <volume>15</volume>
      <issue>4</issue>
      <fpage>585</fpage>
      <lpage>608</lpage>
      <history>
        <date date-type="received">
          <day>30</day>
          <month>3</month>
          <year>2020</year>
        </date>
        <date date-type="rev-recd">
          <day>26</day>
          <month>9</month>
          <year>2020</year>
        </date>
        <date date-type="accepted">
          <day>6</day>
          <month>10</month>
          <year>2020</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>© The Author(s) 2020</copyright-statement>
        <license>
          <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
        </license>
      </permissions>
      <abstract id="Abs1">
        <p id="Par1">We construct embedded functional connectivity networks (FCN) from benchmark resting-state functional magnetic resonance imaging (rsfMRI) data acquired from patients with schizophrenia and healthy controls based on linear and nonlinear manifold learning algorithms, namely, Multidimensional Scaling, Isometric Feature Mapping, Diffusion Maps, Locally Linear Embedding and kernel PCA. Furthermore, based on key global graph-theoretic properties of the embedded FCN, we compare their classification potential using machine learning. We also assess the performance of two metrics that are widely used for the construction of FCN from fMRI, namely the Euclidean distance and the cross correlation metric. We show that diffusion maps with the cross correlation metric outperform the other combinations.</p>
      </abstract>
      <kwd-group xml:lang="en">
        <title>Keywords</title>
        <kwd>Resting-state fMRI</kwd>
        <kwd>Functional connectivity networks</kwd>
        <kwd>Schizophrenia</kwd>
        <kwd>Manifold learning</kwd>
        <kwd>Machine learning</kwd>
      </kwd-group>
      <funding-group>
        <award-group>
          <funding-source>
            <institution>Università degli Studi di Napoli Federico II</institution>
          </funding-source>
        </award-group>
        <open-access>
          <p>Open access funding provided by Università degli Studi di Napoli Federico II within the CRUI-CARE Agreement.</p>
        </open-access>
      </funding-group>
      <custom-meta-group>
        <custom-meta>
          <meta-name>issue-copyright-statement</meta-name>
          <meta-value>© Springer Nature B.V. 2021</meta-value>
        </custom-meta>
      </custom-meta-group>
    </article-meta>
  </front>
  <body>
    <sec id="Sec1">
      <title>Introduction</title>
      <p id="Par2">Over the past years, functional magnetic resonance imaging (fMRI) has been widely used for the identification of brain regions that are related to both functional segregation and integration. Regarding functional segregation, the conventional analysis relies on the identification of the activated voxels based on functional response models and multivariate statistics between experimental conditions (e.g. resting-state vs. task-stimulated activity). A representative example is the General Linear Model (GLM) that is implemented in well established software packages such as SPM (Friston et al. <xref ref-type="bibr" rid="CR26">1994</xref>) and FSL (Smith et al. <xref ref-type="bibr" rid="CR89">2004</xref>). On the other hand, for the assessment of functional integration, there is a distinction between functional and effective connectivity (Friston <xref ref-type="bibr" rid="CR25">2011</xref>). Functional connectivity (FC) analysis looks for statistical dependencies (e.g. correlations, coherence) between brain regions. Effective connectivity (EC) analysis tries to reveal the influence that one neural system exerts on another. A detailed review on the differences between FC and EC approaches can be found in Friston (<xref ref-type="bibr" rid="CR25">2011</xref>).</p>
      <p id="Par3">Here, we focus on the construction of functional connectivity networks (FCN) based on resting-state fMRI (rsfMRI) recordings. In rsfMRI, there is no stimuli and thus the assessment of functional integration is more complex and not so straightforward compared to task-related experiments (Khosla et al. <xref ref-type="bibr" rid="CR46">2019</xref>). Furthermore, spontaneous/ resting-state brain activity as measured with fMRI has been considered as a potential biomarker in psychiatric disorders (see e.g. the review of Zhou et al. <xref ref-type="bibr" rid="CR107">2010</xref>). In general, two basic frameworks are explored for the construction of FCN: (a) seed-based analysis (SBA) and (b) independent component-based analysis (ICA). In the SBA (Cole et al. <xref ref-type="bibr" rid="CR15">2010</xref>), the (averaged) fMRI signals of the regions of interest (ROIs) are correlated with each other; correlations above a threshold are considered functional connections between seeds/ROIs. Even though the SBA has been proved extremely useful in identifying functional networks of specific brain regions (Greicius et al. <xref ref-type="bibr" rid="CR31">2003</xref>; Fox et al. <xref ref-type="bibr" rid="CR24">2005</xref>; Margulies et al. <xref ref-type="bibr" rid="CR54">2007</xref>), its major disadvantage is the requirement of the a-priori knowledge of the functional organization of the brain, while possible correlations between seeds can be due to structured spatial confounds (e.g. scanner artifacts) (Cole et al. <xref ref-type="bibr" rid="CR15">2010</xref>). Furthermore, the definition of a seed is based on standard coordinates, while at the subject level, anatomical differences may lead to the consideration of functionally irrelevant voxels at the group level. Despite the use of normalization techniques, the accuracy of this approach is limited especially for brain regions, such as the hippocampus, where neurogenesis continues even in the adult life (Saxe et al. <xref ref-type="bibr" rid="CR78">2006</xref>). On the other hand, ICA (Hyvärinen and Oja <xref ref-type="bibr" rid="CR39">2000</xref>) has arisen as an alternative approach since the early 2000s (Beckmann et al. <xref ref-type="bibr" rid="CR8">2005</xref>; Beckmann and Smith <xref ref-type="bibr" rid="CR7">2005</xref>; Kim et al. <xref ref-type="bibr" rid="CR47">2010</xref>). ICA decomposes the 4D fMRI data to a set of spatial components with maximum statistical independence and their associated time series. Smith et al. (<xref ref-type="bibr" rid="CR90">2009</xref>) in a meta-analytic study of 30,000 rsfMRI scans with the aid of ICA revealed a functional “partition” of the brain into resting-state networks (RSNs), such as the sensorimotor, default mode and auditory networks. Applications of ICA include also data pre-processing, where noise-related components are regressed out from the original fMRI signals (Pruim et al. <xref ref-type="bibr" rid="CR65">2015</xref>). However, while ICA produces spatial components that are statistically independent to each other, there is no clear link between the spatial components and specific brain functions and spatial components cannot in general be ordered by relative importance (Cole et al. <xref ref-type="bibr" rid="CR15">2010</xref>). Another issue is that most of the standard algorithms that compute independent components (ICs) utilize gradient based optimization algorithms that use an iterative scheme; the initial guesses in these algorithms are generated randomly making the whole process stochastic. As a consequence, the obtained spatial components may differ significantly for the same dataset over repeated runs (Himberg et al. <xref ref-type="bibr" rid="CR36">2004</xref>). Hence, the reproducibility of the ICA results over repeated runs may be questioned.</p>
      <p id="Par4">In order to tackle the above issues, several techniques have been proposed for the classification of ICs and the construction of subject-specific ROIs (Pamplona et al. <xref ref-type="bibr" rid="CR63">2020</xref>; Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>). Advances have also been made regarding the selection of the model order of the ICA decomposition, such as the Bayesian dimensionality estimation technique (Beckmann et al. <xref ref-type="bibr" rid="CR8">2005</xref>) and the use of theoretic information criteria for model order selection (Li et al. <xref ref-type="bibr" rid="CR51">2007</xref>). Finally, the so-called ranking and averaging ICA by reproducibility (RAICAR) (Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>; Himberg et al. <xref ref-type="bibr" rid="CR36">2004</xref>) (see also Cole et al. (<xref ref-type="bibr" rid="CR15">2010</xref>) for a critical discussion) aims at resolving issues regarding stochasticity and robustness of the ICA decomposition. RAICAR utilizes a sufficient number of ICA realizations and based on the reproducibility of the ICs aims to rank them in terms of the most “reliable” components. Reliable ICs among realizations are assessed via correlations and the final estimate of each component is averaged.</p>
      <p id="Par5">Alternatively and/or complementary to the above analysis, linear manifold learning algorithms such as Principal Component Analysis (PCA) (Jollife <xref ref-type="bibr" rid="CR42">2002</xref>; Worsley et al. <xref ref-type="bibr" rid="CR104">2005</xref>; Baumgartner et al. <xref ref-type="bibr" rid="CR5">2000</xref>) and classical Multidimensional Scaling (MDS) (Kruskal <xref ref-type="bibr" rid="CR49">1964</xref>; Friston et al. <xref ref-type="bibr" rid="CR27">1996</xref>) have been also exploited. PCA has been succesfully applied in the pre-processing routine for dimensionality reduction (often prior to ICA) (Iraji et al. <xref ref-type="bibr" rid="CR40">2016</xref>). Applications of PCA include also the recovery of signals of interest (Viviani et al. <xref ref-type="bibr" rid="CR101">2005</xref>) and the construction of FCN from fMRI scans in task-related experiments (Worsley et al. <xref ref-type="bibr" rid="CR104">2005</xref>; Baumgartner et al. <xref ref-type="bibr" rid="CR5">2000</xref>). In these studies, the performance of PCA with respect to the detection of regions of correlated voxels has been shown to be satisfactory but not without problems. For example, a study by Baumgartner et al. (<xref ref-type="bibr" rid="CR5">2000</xref>) highlighted the limits of PCA to correctly identify activation of brain regions in cases of low contrast-to-noise ratios (CNR) appearing when signal sources of e.g. physiological noise are present.</p>
      <p id="Par6">MDS has been also widely used in fMRI (mostly for task-based studies) mainly for the identification of similarities between brain regions in terms of voxel-wise connectivity (Shinkareva et al. <xref ref-type="bibr" rid="CR82">2012</xref>, <xref ref-type="bibr" rid="CR83">2013</xref>; Tzagarakis et al. <xref ref-type="bibr" rid="CR96">2009</xref>; O’Toole et al. <xref ref-type="bibr" rid="CR62">2007</xref>; Haxby et al. <xref ref-type="bibr" rid="CR33">2001</xref>; de Beeck et al. <xref ref-type="bibr" rid="CR18">2010</xref>). The implementation of MDS in neuroimaging dates back to the work of Friston et al. (<xref ref-type="bibr" rid="CR27">1996</xref>), where embedded (voxel-wise) connectivity from PET data was investigated during word generation tasks between healthy and schizophrenia subjects. Salvador et al. (<xref ref-type="bibr" rid="CR75">2005</xref>) used MDS to investigate the embedded connectivity of anatomical regions of the brain from rsfMRI data. Benjaminsson et al. (<xref ref-type="bibr" rid="CR10">2010</xref>) used MDS to embed high-dimensional rsfMRI data from the mutual information space to a low dimensional Euclidean space for the identification of RSNs. Hervé et al. (<xref ref-type="bibr" rid="CR35">2012</xref>) used MDS to acquire a low dimensional approximation of interregional correlations for the investigation of the affective speech comprehension. Finally, in a meta-analytic study by Etkin and Wager (<xref ref-type="bibr" rid="CR23">2007</xref>), MDS was exploited to provide a low-dimensional visualization of co-activation interrelations of Regions of Interest (ROIs). MDS has been also used in studies investigating the functional (dys)connectivity associated with schizophrenia (Welchew et al. <xref ref-type="bibr" rid="CR102">2002</xref>) and Asperger’s Syndrome (Welchew et al. <xref ref-type="bibr" rid="CR103">2005</xref>).</p>
      <p id="Par7">However, thus far, only a few studies have exploited non-linear manifold learning algorithms such as Locally Linear Embedding (LLE) (Roweis and Saul <xref ref-type="bibr" rid="CR72">2000</xref>), Isometric Feature Mapping (ISOMAP) (Tenenbaum et al. <xref ref-type="bibr" rid="CR94">2000</xref>), diffusion maps (Coifman and Lafon <xref ref-type="bibr" rid="CR14">2006</xref>) and kernel PCA (kPCA) (Schölkopf et al. <xref ref-type="bibr" rid="CR79">1997</xref>) for the analysis of fMRI data and particularly for the construction of FCN. The LLE method has been applied in rsfMRI studies for the improvement of predictions in ageing (Qiu et al. <xref ref-type="bibr" rid="CR66">2015</xref>), for the classification of healthy subjects and patients with schizophrenia (Shen et al. <xref ref-type="bibr" rid="CR81">2010</xref>) and as an alternative method for dimensionality reduction before the application of ICA in task-related fMRI, where non-linear relationships in the BOLD signal are introduced (Mannfolk et al. <xref ref-type="bibr" rid="CR53">2010</xref>). The kPCA method has been recently applied to a fMRI study for non-linear feature extraction (Tsatsishvili et al. <xref ref-type="bibr" rid="CR95">2018</xref>). In this study, it was shown that certain important features could not be found by the standard PCA. kPCA has been also used for feature extraction towards the automated diagnosis of (Attention-Deficit Hyperactivity Disorder) ADHD (Sidhu et al. <xref ref-type="bibr" rid="CR84">2012</xref>). In Anderson and Cohen (<xref ref-type="bibr" rid="CR3">2013</xref>), ISOMAP was employed to a benchmark rsfMRI dataset of 146 subjects for the construction of embedded low-dimensional FCN for the classification of controls and schizophrenic subjects. ROIs were selected using single-subject ICA and the similarities between the ICs were assessed using a pseudo-distance measure based on cross correlation. Graph-theoretic measures were then used for the discrimination between patients and healthy controls. Another study based on single-subject ICA exploited ISOMAP to classify spatially unaligned fMRI scans (Anderson et al. <xref ref-type="bibr" rid="CR4">2010</xref>). The study focused on comparisons between patients with schizophrenia versus healthy controls and different age groups of healthy controls versus patients with alzheimer’s disease. Despite the relatively low sample sizes, results were promising with good classification rates. Recently, Haak et al. (<xref ref-type="bibr" rid="CR32">2018</xref>) utilized ISOMAP for the construction of individualised connectopies from rsfMRI recordings taken from the WU-Minn Human Connectome Project in a fully data-driven manner. Only a handful of studies have used diffusion maps for the analysis of fMRI data. These studies have been focused mainly on the clustering of spatial maps of task-related experiments (Shen and Meyer <xref ref-type="bibr" rid="CR80">2005</xref>; Sipola et al. <xref ref-type="bibr" rid="CR87">2013</xref>). Shen and Meyer (<xref ref-type="bibr" rid="CR80">2005</xref>), and Sipola et al. (<xref ref-type="bibr" rid="CR87">2013</xref>) used diffusion maps with a Gaussian kernel to cluster selected fMRI spatial maps that are derived by ICA. The approach was demonstrated using fMRI recordings acquired from healthy participants listening to a stimulus with a rich musical structure. Other applications of diffusion maps in neuroimaging include predicitions of epileptic seizures and the identification of the pre-seizure state in EEG timeseries (Lian et al. <xref ref-type="bibr" rid="CR52">2015</xref>; Duncan et al. <xref ref-type="bibr" rid="CR22">2013</xref>). A review on the intersection between manifold learning methods and the construction of FCN can be found in Siettos and Starke (<xref ref-type="bibr" rid="CR85">2016</xref>), and Richiardi et al. (<xref ref-type="bibr" rid="CR69">2013</xref>).</p>
      <p id="Par8">Here, we employed MDS, ISOMAP, diffusion maps, kPCA and LLE to construct embedded FCN from rsfMRI data taken from healthy controls and schizophrenia patients. For our demonstrations, we used the Center for Biomedical Research Excellence (COBRE) rsfMRI dataset that is publicly available and has been used recently in many studies (Calhoun et al. <xref ref-type="bibr" rid="CR12">2012</xref>; Mayer et al. <xref ref-type="bibr" rid="CR55">2013</xref>; Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>; Qureshi et al. <xref ref-type="bibr" rid="CR67">2017</xref>). Based on key global graph-theoretic measures of the embedded graphs, we assessed their classification efficiency using several machine learning algorithms, namely linear standard Support vector machines (LSVM), radial (radial basis function kernel) support vector machines (RSVM), k-nearest neighbours (k-NN) classifier, and artificial neural networks (ANN). We also investigated their performance considering two commonly used distance metrics, namely the cross correlation and the Euclidean distance. Our analysis showed that diffusion maps with the cross correlation outperformed all other combinations.</p>
      <p id="Par9">At this point, we should note, that our study does not aim at extracting the best classification performance by trying to find the best possible pre-processing pipe-line of the raw fMRI data and/or the selection of “best” subjects and/or the selection of the best set of graph-theoretic measures that provide the maximum classification. Yet, we aim at using state-of-the-art manifold learning methods for the construction of embedded FCN and compare their classification efficiency using only the three fundamental global graph measures, i.e. the average path length, the global clustering coefficient and the degree. Furthermore, our results can be compared to those obtained by similar studies (see e.g. Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>) using the same pipe-line for data pre-processing and single-subject ICA. To the best of our knowledge, this paper is the first to perform such a thorough comparative analysis of both linear and nonlinear manifold learning on rsfMRI data. It is also the first study to show how diffusion maps can be used for the construction of FCN from rsfMRI, assessing also the efficiency of two basic distance metrics, the cross correlation and the Euclidean distance.</p>
    </sec>
    <sec id="Sec2">
      <title>Materials and methods</title>
      <sec id="Sec3">
        <title>Data description</title>
        <p id="Par10">For our demonstrations we used the Schizophrenia COBRE dataset (http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html) comprised of rsfMRI data from 74 healthy and 72 Schizophrenic subjects of varying ages (18–65 years in both groups). All subjects were screened and excluded if they had history of neurological disorders, mental retardation, severe head trauma with more than 5 min loss of consciousness, substance abuse or dependence within the last 12 months. Diagnostic information was collected using the Structured Clinical Interview used for DSM Disorders (SCID).</p>
        <p id="Par11">For the anatomical imaging, a multi-echo Magnetization Prepared RApid Gradient Echo (MPRAGE) sequence was used with the following set of parameters: TR (repetition time)/TE (echo time)/TI (inversion time) = 2530/[1.64, 3.5, 5.36, 7.22, 9.08]/900 ms, flip angle = 7<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^{\circ }$$\end{document}</tex-math><mml:math id="M2"><mml:msup><mml:mrow/><mml:mo>∘</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq1.gif"/></alternatives></inline-formula>, Field Of View (FOV) = <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$256\times 256$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq2.gif"/></alternatives></inline-formula> mm<sup>2</sup>, Slab thickness = 176 mm, data matrix = <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$256\times 256\times 176$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>256</mml:mn><mml:mo>×</mml:mo><mml:mn>176</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq3.gif"/></alternatives></inline-formula>, Voxel size = <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1\times 1\times 1$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq4.gif"/></alternatives></inline-formula> mm<sup>3</sup>, Number of echos=5, Pixel bandwidth=650 Hz, Total scan time = 6 min. With 5 echoes, the TR, TI and time to encode partitions for the multi-echo MPRAGE are similar to that of a conventional MPRAGE, resulting in similar Gray Matter (GM)/ White Matter (WM)/ CelebroSpinal Fluid (CSF) contrast. The rsfMRI data-set was collected with single-shot full k-space Echo-Planar Imaging (EPI) with ramp sampling correction using the intercomissural line (AC-PC) as a reference (TR: 2 s, TE: 29 ms, slice size: 64x64, number of slices: 32, voxel size: <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$3\times 3\times 4$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mn>3</mml:mn><mml:mo>×</mml:mo><mml:mn>3</mml:mn><mml:mo>×</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq5.gif"/></alternatives></inline-formula> mm<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$^3$$\end{document}</tex-math><mml:math id="M12"><mml:msup><mml:mrow/><mml:mn>3</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq6.gif"/></alternatives></inline-formula>).</p>
      </sec>
      <sec id="Sec4">
        <title>Pre-processing and signal extraction</title>
        <p id="Par12">As also implemented in other studies (see e.g. Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>), we first performed a basic pre-processing of the raw fMRI data using FSL (FMRIB’s Software Library, <ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl">www.fmrib.ox.ac.uk/fsl</ext-link>). In particular, the following pre-processing steps were applied: motion correction using Fsl’s linear registration tool (MCFLIRT) (Jenkinson et al. <xref ref-type="bibr" rid="CR41">2002</xref>), slice-timing correction using Fourier-space time-series phase-shifting; non-brain removal using the brain extraction tool (BET) (Smith <xref ref-type="bibr" rid="CR88">2002</xref>), spatial smoothing using a 5 mm full-width at half-maximum (FWHM) Gaussian kernel, grand-mean intensity normalization of the entire 4D dataset by a single multiplicative factor (10,000 divided by the grand mean intensity, Fsl’s default). Furthermore, we used ICA automatic removal of motion artifacts (AROMA) (Pruim et al. <xref ref-type="bibr" rid="CR65">2015</xref>) to detect and factor out noise-related (motion artifacts and other structured noise components like cardiac pulsation confounds) ICs. After the implementation of ICA AROMA, we applied a high-pass temporal filtering at 0.01 Hz (100 s) as it is highly recommended (Pruim et al. <xref ref-type="bibr" rid="CR65">2015</xref>).</p>
        <p id="Par13">We then proceeded with the decomposition of the pre-processed fMRI data to spatial ICs (for each subject) using the RAICAR methodology (Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>). In this way, we computed the most reproducible spatial ICs over repeated runs as a solution to the well known problem of the variability of the ICA decomposition (Himberg et al. <xref ref-type="bibr" rid="CR36">2004</xref>). This choice is related to the benchmark fMRI data per se as there is only a single session per subject with relatively small duration (6 min); therefore we wouldn’t expect a robust ICA decomposition for all subjects (see also the discussion in Cole et al. <xref ref-type="bibr" rid="CR15">2010</xref>). Another choice would be to perform group-ICA analysis [which is subject to other limitations (see in the “<xref rid="Sec27" ref-type="sec">Discussion</xref>” section)], but we decided to use single-subject ICA in order to have a common ground with the methodologically similar work presented in Anderson and Cohen (<xref ref-type="bibr" rid="CR3">2013</xref>).</p>
      </sec>
      <sec id="Sec5">
        <title>Ranking and averaging ICA by reproducibility (RAICAR)</title>
        <sec id="Sec6">
          <title>Independent component analysis (ICA)</title>
          <p id="Par14">ICA is a linear data-driven technique that reduces the high-dimensional fMRI <italic>F</italic>(<italic>t</italic>, <italic>x</italic>, <italic>y</italic>, <italic>z</italic>) space in a set of <italic>M</italic> statistically independent components. This reduction can be represented as:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F(t,x,y,z)=\sum _{i=1}^{M} A_{i}(t) C_{i}(x,y,z), \end{aligned}$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>F</italic>(<italic>t</italic>, <italic>x</italic>, <italic>y</italic>, <italic>z</italic>) is the measured BOLD signal, <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${A_{i}(t)}$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq7.gif"/></alternatives></inline-formula> is the temporal amplitude (the matrix <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}$$\end{document}</tex-math><mml:math id="M18"><mml:mi mathvariant="bold">A</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq8.gif"/></alternatives></inline-formula> containing all temporal amplitudes is known as mixing matrix) and <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C_{i}(x,y,z)}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq9.gif"/></alternatives></inline-formula> is the spatial magnitude of the i-th ICA component. While PCA requires that the principal components are uncorrelated and orthogonal, ICA asks for statistical independence between the ICs. Generally, ICA algorithms are based either on the minimization of mutual information or the maximization of non-Gaussianity among components. As discussed in the introduction, most of the standard implementations of ICA, such as the one in MELODIC (Multivariate Exploratory Linear Optimized Decomposition into Independent Components) (Beckmann and Smith <xref ref-type="bibr" rid="CR6">2004</xref>), which is part of FSL (fMRIB’s Software Library) share similar gradient-based optimization algorithms using an iterative scheme whose initial values are generated randomly, thus making the whole process stochastic. As a consequence, results over repeated runs may differ significantly (Himberg et al. <xref ref-type="bibr" rid="CR36">2004</xref>). A solution to this problem is provided by the so-called Ranking and Averaging ICA by Reproducibility (RAICAR) (Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>) that we briefly describe in the following section.</p>
        </sec>
        <sec id="Sec7">
          <title>Ranking and averaging ICA by reproducibility (RAICAR)</title>
          <p id="Par15">The RAICAR methodology developed by Yang et al. (<xref ref-type="bibr" rid="CR106">2008</xref>) was introduced to tackle the problem of the ICs variability by performing <italic>K</italic> ICA realizations. Thus, RAICAR leads to <italic>K</italic> “slightly” different mixing matrices <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_{1},{\mathbf {A}}_{2} \dots {\mathbf {A}}_{K}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq10.gif"/></alternatives></inline-formula> and <italic>K</italic> different sets of spatial maps <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {S}}_{1},{\mathbf {S}}_{2} \dots {\mathbf {S}}_{K}$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:msub><mml:mi mathvariant="bold">S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">S</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi mathvariant="bold">S</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq11.gif"/></alternatives></inline-formula>. Each realization finds a fixed number <italic>M</italic> of spatial ICs. Then, a cross realization correlation matrix (<inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {CRCM}$$\end{document}</tex-math><mml:math id="M26"><mml:mi mathvariant="bold">CRCM</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq12.gif"/></alternatives></inline-formula>) of size <inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M\cdot K{\times }M\cdot K$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mi>M</mml:mi><mml:mo>·</mml:mo><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi><mml:mo>·</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq13.gif"/></alternatives></inline-formula> is constructed and the alignment (ICA produces unaligned components) of ICs across realizations takes place on the basis of the absolute maximum spatial correlation among components. Thus, the cross realization correlation matrix reads:<disp-formula id="Equ28"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {CRCM}} = \left[ \begin{array}{ccccc} {\mathbf {R}}_{1,1} &amp;{} {\mathbf {R}}_{1,2} &amp;{} \dots &amp;{} {\mathbf {R}}_{1,K-1} &amp;{} {\mathbf {R}}_{1,K} \\ {\mathbf {R}}_{2,1} &amp;{} &amp;{} \dots &amp;{} \dots &amp;{} {\mathbf {R}}_{2,K} \\ \vdots &amp;{} \dots &amp;{} \ddots &amp;{} \dots &amp;{} \vdots \\ {\mathbf {R}}_{K-1,1} &amp;{} \dots &amp;{} \dots &amp;{} &amp;{} {\mathbf {R}}_{K-1,K} \\ {\mathbf {R}}_{K,1} &amp;{} {\mathbf {R}}_{K,2} &amp;{} \dots &amp;{} {\mathbf {R}}_{K,K-1} &amp;{} {\mathbf {R}}_{K,K} \end{array}\right] \end{aligned}$$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">CRCM</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋱</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ28.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq14"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {R}}_{i,j}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq14.gif"/></alternatives></inline-formula> with <inline-formula id="IEq15"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i,j=1,2\ldots K$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>…</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq15.gif"/></alternatives></inline-formula> are submatrices of size <inline-formula id="IEq16"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M{\times }M$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq16.gif"/></alternatives></inline-formula> and their elements represent the absolute spatial correlation coefficients among components and across realizations. CRCM is a symmetric matrix and its diagonal consists of identity matrices which are ignored for the next steps of the algorithm.</p>
          <p id="Par16">The procedure starts with the identification of the global maximum of the CRCM, thus finding the matched component based on two realizations. At the next step, the methodology seeks for the highest absolute spatial correlation coefficients of the identified component in the remaining realizations factoring out all others. The procedure is repeated <italic>M</italic> times until <italic>M</italic> aligned components are found.</p>
          <p id="Par17">The next step involves the computation of the reproducibility index for each of the aligned components. This is done by constructing the histogram of the absolute spatial correlation coefficients of the upper triangle matrix of the CRCM. This histogram tends to be bimodal, as in general, we expect a low spatial correlation among most of the ICs and a high spatial correlation only for a few of them. A spatial correlation threshold is applied with the desired value lying in the valley of the histogram between the two modes (Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>). Finally, the reproducibility index is computed for each one of the aligned components. This is done by aggregating the supra-threshold absolute spatial correlation coefficients of the CRCM for each of the aligned components.</p>
          <p id="Par18">The last step of the algorithm is the ranking and averaging of the aligned components in descending order based on the reproducibility index. The selective averaging is applied so that the components are averaged if and only if, the given aligned component has at least one absolute spatial correlation coefficient above the threshold across realizations.</p>
          <p id="Par19">After applying RAICAR, the ICs are chosen via a cut-off threshold based on the reproducibility index (of each component) that indicates how consistent is the appearance of an IC across realizations.</p>
          <p id="Par20">Here, we have set <inline-formula id="IEq17"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K=30$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq17.gif"/></alternatives></inline-formula> realizations (same also in Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>); taking more realizations did not change the outcomes of the analysis. The spatial correlation threshold was chosen by localizing the minimum of the histogram of the absolute spatial correlation coefficients of the CRCM. This threshold was specified separately for each subject. The reproducible ICs were determined by calculating the reproducibility index. The cut-off threshold was set as the half of the maximum reproducibility index value possible <inline-formula id="IEq18"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{K(K-1)}{2}\cdot 0.5$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>·</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq18.gif"/></alternatives></inline-formula> (this choice is the same with the one used in Yang et al. <xref ref-type="bibr" rid="CR106">2008</xref>). This cut-off threshold was set equal for all subjects.</p>
          <p id="Par21">Subjects with less than 20 reproducible ICs were excluded from further analysis as this number of components resulted in disconnected graphs. Thus, we ended up with 104 subjects out of which 57 were healthy controls and 47 schizophrenia patients.</p>
        </sec>
      </sec>
      <sec id="Sec8">
        <title>Construction of functional connectivity networks</title>
        <p id="Par22">For the construction of FCN, we used all combinations between five manifold learning algorithms, namely MDS, ISOMAP, diffusion maps, LLE , kPCA and two widely used metrics, namely the cross correlation (Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>; Meszlényi et al. <xref ref-type="bibr" rid="CR56">2017</xref>; Hyde and Jesmanowicz <xref ref-type="bibr" rid="CR38">2012</xref>) and the Euclidean distance (Sipola et al. <xref ref-type="bibr" rid="CR87">2013</xref>; Venkataraman et al. <xref ref-type="bibr" rid="CR98">2009</xref>; Goutte et al. <xref ref-type="bibr" rid="CR30">1999</xref>).</p>
        <sec id="Sec9">
          <title>Construction of FCN based on cross correlation</title>
          <p id="Par23">For every pair of the associated time courses of the ICs, say <inline-formula id="IEq19"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_i$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq19.gif"/></alternatives></inline-formula> and <inline-formula id="IEq20"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_{j}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq20.gif"/></alternatives></inline-formula>, the cross correlation function (CCF) over <italic>l</italic> time lags reads:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} CCF({\mathbf {A}}_{i},{\mathbf {A}}_{j},l)=\frac{E[({\mathbf {A}}_{i,t+l}-\overline{{\mathbf {A}}}_{i})({\mathbf {A}}_{j,t}-\overline{{\mathbf {A}}}_{j})]}{\sqrt{E[({\mathbf {A}}_{i,t}-\overline{{\mathbf {A}}}_{i})^2]E[({\mathbf {A}}_{j,t}-\overline{{\mathbf {A}}}_{j}})^2]}, \end{aligned}$$\end{document}</tex-math><mml:math id="M46" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover><mml:mi mathvariant="bold">A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover><mml:mi mathvariant="bold">A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover><mml:mi mathvariant="bold">A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover><mml:mi mathvariant="bold">A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msqrt><mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>l</italic> is the time lag, and <inline-formula id="IEq21"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overline{{\mathbf {A}}}_{i}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mover><mml:mi mathvariant="bold">A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq21.gif"/></alternatives></inline-formula> is the mean value of the whole time series. Here, we considered a maximum of three time lags (as in Anderson and Cohen (<xref ref-type="bibr" rid="CR3">2013</xref>)).</p>
          <p id="Par24">For the construction of the connectivity/ correlation matrices, we used a pseudo-distance measure <inline-formula id="IEq22"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{c}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq22.gif"/></alternatives></inline-formula> defined as (see also Anderson and Cohen (<xref ref-type="bibr" rid="CR3">2013</xref>)):<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} d_{c}({\mathbf {A}}_{i},{\mathbf {A}}_{j})=1-\max _{l=0,1,2,3}(|CCF({\mathbf {A}}_{i},{\mathbf {A}}_{j},l)|). \end{aligned}$$\end{document}</tex-math><mml:math id="M52" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="true">max</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>The resulting (dis)similarity matrices are fully connected and therefore are hardly comparable between subjects (see the discussion in Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>). Thus, here as a standard practice, (and in all other algorithms described below), we applied thresholding to the (dis)similarity matrices in order to keep the strongest connections of the derived functional connectivity matrices. In order to factor out the influence of the variable network density on the computation and comparison of graph-theoretic measures across groups (van den Heuvel et al. <xref ref-type="bibr" rid="CR97">2017</xref>), we have implemented the approach of proportional thresholding (PT) (van den Heuvel et al. <xref ref-type="bibr" rid="CR97">2017</xref>). In particular, we considered a range of levels of PT from 20 to 70% with a step of 2%. Below the threshold of 20%, some graphs became too fragmented (i.e the graph breaks down to subgraphs with a small number of nodes), while thresholds above the 70% comprised of edges with low functional connections (see in Algunaid et al. <xref ref-type="bibr" rid="CR1">2018</xref>). Despite the fact that there is no consensus upon the ideal range of PT in the literature [studies typically report a PT range of 10–50% of the strongest edges (Algunaid et al. <xref ref-type="bibr" rid="CR1">2018</xref>; Xiang et al. <xref ref-type="bibr" rid="CR105">2020</xref>)], we decided to include a wide range of thresholds to assess the performance of each method/combination used. Using a narrow range of thresholds could result to incomplete or misleading results (Garrison et al. <xref ref-type="bibr" rid="CR29">2015</xref>).</p>
          <p id="Par25">Finally, if a graph was fragmented after thresholding, the largest component (i.e. the subgraph with the largest number of nodes) was used for further analysis.</p>
        </sec>
        <sec id="Sec10">
          <title>Construction of FCN based on the Euclidean distance</title>
          <p id="Par26">The Euclidean distance is used in many studies to assess (dis)similarities between fMRI time series (Sipola et al. <xref ref-type="bibr" rid="CR87">2013</xref>; Venkataraman et al. <xref ref-type="bibr" rid="CR98">2009</xref>; Goutte et al. <xref ref-type="bibr" rid="CR30">1999</xref>). For time series associated with the independent spatial maps, <inline-formula id="IEq23"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_{i}$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq23.gif"/></alternatives></inline-formula> and <inline-formula id="IEq24"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_{j}$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq24.gif"/></alternatives></inline-formula>, the Euclidean distance reads:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} L_{2}({\mathbf {A}}_{i},{\mathbf {A}}_{j})=\sqrt{\sum _{t=1}^{T}(A_{i,t}-A_{j,t})^2}. \end{aligned}$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>For the construction of FCN, PT was applied to the Euclidean distance matrices for each individual over the range of 20–70%.</p>
        </sec>
      </sec>
      <sec id="Sec11">
        <title>Construction of FCN with manifold learning algorithms</title>
        <p id="Par27">Below, we present how MDS, ISOMAP, diffusion maps, kernel PCA and LLE can be exploited to construct (embedded) FCN.</p>
        <sec id="Sec12">
          <title>Construction of FCN with MDS</title>
          <p id="Par28">The classical multidimensional scaling (Kruskal <xref ref-type="bibr" rid="CR49">1964</xref>) is a form of dimensionality reduction that can be used to find similarities between pairs of objects in a low-dimensional (embedded) space. Given a set of <italic>M</italic> objects/observables <inline-formula id="IEq25"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_1,{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq25.gif"/></alternatives></inline-formula>, MDS produces a low-dimensional data representation <inline-formula id="IEq26"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M} \in {\mathbf {R}}^p, p \ll N$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq26.gif"/></alternatives></inline-formula> minimizing the objective function:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \sum \limits _{i,j,\ i \ne j } \Big ( \Vert {\mathbf {x}}_{i}-{\mathbf {x}}_{j}\Vert -d({\mathbf {x}}_i,{\mathbf {x}}_j)\Big )^2, \end{aligned}$$\end{document}</tex-math><mml:math id="M64" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em" stretchy="true">(</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em" stretchy="true">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq27"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d({\mathbf {x}}_i,{\mathbf {x}}_j)$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq27.gif"/></alternatives></inline-formula> is the (dis)similarity obtained (eg. by any (dis)similarity measure of choice, however, when using the euclidean distance, the classical MDS produces a linear mapping equivalent to PCA) between all pairs of points <inline-formula id="IEq28"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_1,{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M68"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq28.gif"/></alternatives></inline-formula>. In our case, the observables <inline-formula id="IEq29"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq29.gif"/></alternatives></inline-formula> are the amplitudes of the spatial ICs <inline-formula id="IEq30"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_{i, \ i=1,\ldots M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq30.gif"/></alternatives></inline-formula>. Here, <inline-formula id="IEq31"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N=150$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>150</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq31.gif"/></alternatives></inline-formula> (number of time points).</p>
          <p id="Par29">The coordinates of the embedded manifold <inline-formula id="IEq32"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M}$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq32.gif"/></alternatives></inline-formula> are given by:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{}[{\mathbf {y}}_1,\dots ,{\mathbf {y}}_M]= \varvec{\Lambda }_{p\times p}\cdot {\mathbf {V}}^{T}_{p \times M}. \end{aligned}$$\end{document}</tex-math><mml:math id="M78" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq33"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\Lambda }_{p\times p}$$\end{document}</tex-math><mml:math id="M80"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq33.gif"/></alternatives></inline-formula> contains the square roots of the <italic>p</italic> largest eigenvalues, and <inline-formula id="IEq34"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {V}}^{T}_{p \times M}$$\end{document}</tex-math><mml:math id="M82"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq34.gif"/></alternatives></inline-formula> are the corresponding eigenvectors of the matrix:<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {B}}=-\frac{1}{2}{\mathbf {H}}{\mathbf {D}}^2 {\mathbf {H}}. \end{aligned}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi mathvariant="bold">H</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><inline-formula id="IEq35"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {H}}_{M \times M}$$\end{document}</tex-math><mml:math id="M86"><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq35.gif"/></alternatives></inline-formula> is the centering matrix defined as:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {H}}={\mathbf {I}}- \frac{1}{M} {\mathbf {1}} \cdot {\mathbf {1}}^T, \quad \mathbf {1}=\begin{bmatrix}1\\1\\\vdots\\1 \end{bmatrix}_{M\times 1}. \end{aligned}$$\end{document}</tex-math><mml:math id="M88" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">H</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mo>·</mml:mo><mml:msup><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mn mathvariant="bold">1</mml:mn><mml:mo>=</mml:mo><mml:msub><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋮</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>The dimensionality reduction of the original data <inline-formula id="IEq36"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {X}}={\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M90"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq36.gif"/></alternatives></inline-formula> yields the embedding of <inline-formula id="IEq37"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {Y}}={{\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M} \in {\mathbf {R}}^p}$$\end{document}</tex-math><mml:math id="M92"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq37.gif"/></alternatives></inline-formula>, <inline-formula id="IEq38"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \ll N$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq38.gif"/></alternatives></inline-formula>. Here, for the construction of the embedded FCN, we produced distance matrices <inline-formula id="IEq39"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {D_{Y}}$$\end{document}</tex-math><mml:math id="M96"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">Y</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq39.gif"/></alternatives></inline-formula> of size <inline-formula id="IEq40"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M \times M$$\end{document}</tex-math><mml:math id="M98"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq40.gif"/></alternatives></inline-formula>. For the implementation of the MDS algorithm, we used the “cmdscale” function contained in the package “Stats” in the R free Software Environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
        </sec>
        <sec id="Sec13">
          <title>Construction of FCN using ISOMAP</title>
          <p id="Par30">ISOMAP is a non-linear manifold learning algorithm that given a set of <italic>M</italic> objects/observables <inline-formula id="IEq41"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq41.gif"/></alternatives></inline-formula> produces a low-dimensional data representation <inline-formula id="IEq42"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M} \in {\mathbf {R}}^p$$\end{document}</tex-math><mml:math id="M102"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq42.gif"/></alternatives></inline-formula>, <inline-formula id="IEq43"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \ll N$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq43.gif"/></alternatives></inline-formula> minimizing the objective function:<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \sum \limits _{i,j, \ i \ne j } \Big ( \ d_G({\mathbf {x}}_i,{\mathbf {x}}_j)- d({\mathbf {x}}_{i},{\mathbf {x}}_{j})\Big )^2, \end{aligned}$$\end{document}</tex-math><mml:math id="M106" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em" stretchy="true">(</mml:mo></mml:mrow><mml:mspace width="4pt"/><mml:msub><mml:mi>d</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em" stretchy="true">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq44"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_G({\mathbf {x}}_i,{\mathbf {x}}_j)$$\end{document}</tex-math><mml:math id="M108"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq44.gif"/></alternatives></inline-formula> is the shortest path (geodesic distance) and <inline-formula id="IEq45"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d({\mathbf {x}}_i,{\mathbf {x}}_j)$$\end{document}</tex-math><mml:math id="M110"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq45.gif"/></alternatives></inline-formula> is the (dis)similarity obtained (by any (dis)similarity measure of choice) between all pairs of points <inline-formula id="IEq46"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M112"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq46.gif"/></alternatives></inline-formula>.</p>
          <p id="Par31">In our case, the observables <inline-formula id="IEq47"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i$$\end{document}</tex-math><mml:math id="M114"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq47.gif"/></alternatives></inline-formula> are the amplitudes of the spatial ICs <inline-formula id="IEq48"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_{i, \ i=1,\ldots M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M116"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq48.gif"/></alternatives></inline-formula>.</p>
          <p id="Par32">The above minimization problem is solved as follows (Tenenbaum et al. <xref ref-type="bibr" rid="CR94">2000</xref>):<list list-type="bullet"><list-item><p id="Par33">Construct a graph <inline-formula id="IEq49"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {G}}=(V,E)$$\end{document}</tex-math><mml:math id="M118"><mml:mrow><mml:mi mathvariant="bold">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq49.gif"/></alternatives></inline-formula>, where the vertices <italic>V</italic> are the ICs <inline-formula id="IEq50"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_i$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq50.gif"/></alternatives></inline-formula>; its links <italic>E</italic> are created by using either the <italic>k</italic>-nearest neighbors algorithm or a fixed distance between nodes, known as the <inline-formula id="IEq51"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><mml:math id="M122"><mml:mi>ϵ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq51.gif"/></alternatives></inline-formula> distance. For example, a link between two ICs is created if <inline-formula id="IEq52"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{i,j}\equiv d({\mathbf {A}}_i,{\mathbf {A}}_j)&lt; \epsilon \ , \ \forall \ i \ne j$$\end{document}</tex-math><mml:math id="M124"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>ϵ</mml:mi><mml:mspace width="4pt"/><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mo>∀</mml:mo><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq52.gif"/></alternatives></inline-formula>. Here, we used the <italic>k</italic> nearest neighbours algorithm with <inline-formula id="IEq53"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=3,4,5,6$$\end{document}</tex-math><mml:math id="M126"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq53.gif"/></alternatives></inline-formula> (Tenenbaum et al. <xref ref-type="bibr" rid="CR94">2000</xref>). A general rule of thumb is to select <italic>k</italic> as the square root of the number of samples (here the number of ICs per subject). In our study the number of samples varied over subjects in the range of 20–40. Additionally, Anderson and Cohen (<xref ref-type="bibr" rid="CR3">2013</xref>) use a similar approach by selecting <italic>k</italic> as 10% of the number of nodes. For <inline-formula id="IEq54"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=2$$\end{document}</tex-math><mml:math id="M128"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq54.gif"/></alternatives></inline-formula>, we had some graphs that were disconnected and so we chose not to include this value. Set the weight <inline-formula id="IEq55"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{i,j}$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq55.gif"/></alternatives></inline-formula> of the link (if any) between <inline-formula id="IEq56"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {A}}_i,{\mathbf {A}}_j$$\end{document}</tex-math><mml:math id="M132"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq56.gif"/></alternatives></inline-formula> as <inline-formula id="IEq57"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{i,j}= \frac{1}{d({\mathbf {A}}_i,{\mathbf {A}}_j)}$$\end{document}</tex-math><mml:math id="M134"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq57.gif"/></alternatives></inline-formula>. If there is not a link set: <inline-formula id="IEq58"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{i,j}=0$$\end{document}</tex-math><mml:math id="M136"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq58.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par34">Approximate the embedded manifold by estimating the shortest path (geodesic distance) <inline-formula id="IEq59"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_G ({\mathbf {A}}_i,{\mathbf {A}}_j)$$\end{document}</tex-math><mml:math id="M138"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq59.gif"/></alternatives></inline-formula> for each pair of nodes based on the distances <inline-formula id="IEq60"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{i,j}$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq60.gif"/></alternatives></inline-formula>; this step can be implemented for example using the Dijkstra algorithm (Dijkstra <xref ref-type="bibr" rid="CR21">1959</xref>). This procedure results in a matrix, <inline-formula id="IEq61"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {D_G}}$$\end{document}</tex-math><mml:math id="M142"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">G</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq61.gif"/></alternatives></inline-formula> whose elements are the shortest paths: <disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} D_{G_{ij}}\equiv &amp; {} d_G ({\mathbf {A}}_i,{\mathbf {A}}_j)\nonumber \\&amp;= min \big \{ d_{i,j},d_{i,k}+d_{k,j} \big \}, \,k=1,2,\dots ,M \quad k \ne i,j. \end{aligned}$$\end{document}</tex-math><mml:math id="M144" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>≡</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:msub><mml:mi>d</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">{</mml:mo></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em" stretchy="true">}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mspace width="1em"/><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p></list-item><list-item><p id="Par35">Estimate the coordinates of the low-dimensional (embedded) manifold <inline-formula id="IEq62"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_1,{\mathbf {y}}_2,\dots ,{\mathbf {y}}_M$$\end{document}</tex-math><mml:math id="M146"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq62.gif"/></alternatives></inline-formula> exploiting the MDS algorithm (Kruskal <xref ref-type="bibr" rid="CR49">1964</xref>) on the geodesic distance matrix <inline-formula id="IEq63"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {D_G}}$$\end{document}</tex-math><mml:math id="M148"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">G</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq63.gif"/></alternatives></inline-formula>.</p></list-item></list>Here, for the implementation of the ISOMAP algorithm, we used the package “vegan” (Oksanen et al. <xref ref-type="bibr" rid="CR61">2007</xref>) in the R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
        </sec>
        <sec id="Sec14">
          <title>Construction of FCN using diffusion maps</title>
          <p id="Par36">Diffusion maps (Coifman and Lafon <xref ref-type="bibr" rid="CR14">2006</xref>) is a non-linear manifold learning algorithm that given a set of <italic>M</italic> objects/observables <inline-formula id="IEq64"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {X}}={\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M150"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq64.gif"/></alternatives></inline-formula> produces a low-dimensional representation <inline-formula id="IEq65"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {Y}}={{\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M}} \in {\mathbf {R}}^p$$\end{document}</tex-math><mml:math id="M152"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq65.gif"/></alternatives></inline-formula>, <inline-formula id="IEq66"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \ll N$$\end{document}</tex-math><mml:math id="M154"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq66.gif"/></alternatives></inline-formula>, addressing the diffusion distance among data points as the preserved metric (Nadler et al. <xref ref-type="bibr" rid="CR59">2006</xref>). The embedding of the data in the low-dimensional space is obtained by the projections on the eigenvectors of a normalized Laplacian graph (Belkin and Niyogi <xref ref-type="bibr" rid="CR9">2003</xref>). The diffusion maps algorithm can be described in a nutshell in the following steps:<list list-type="bullet"><list-item><p id="Par37">Construction of the affinity matrix <inline-formula id="IEq67"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}}_{M \times M}$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq67.gif"/></alternatives></inline-formula>, here <italic>M</italic> is the number of ICs for each subject. The elements <inline-formula id="IEq68"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{ij}$$\end{document}</tex-math><mml:math id="M158"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq68.gif"/></alternatives></inline-formula> represent the weighted edges connecting nodes <italic>i</italic> and <italic>j</italic> using the so-called heat kernel: <disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} W_{i,j}= exp\left( - \frac{d({\mathbf {x}}_{i},{\mathbf {x}}_{j})^2}{\sigma } \right) , \end{aligned}$$\end{document}</tex-math><mml:math id="M160" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq69"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq69.gif"/></alternatives></inline-formula> is a <italic>N</italic>-dimensional point (here, N=150), <inline-formula id="IEq70"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d({\mathbf {x}}_i,{\mathbf {x}}_j)$$\end{document}</tex-math><mml:math id="M164"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq70.gif"/></alternatives></inline-formula> are the (dis)similarities obtained (by any dissimilarity measure of choice) between all pairs of points <inline-formula id="IEq71"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M166"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq71.gif"/></alternatives></inline-formula> and <inline-formula id="IEq72"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M168"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq72.gif"/></alternatives></inline-formula> is an appropriately chosen parameter which can be physically described as a scale parameter of the heat kernel (Coifman and Lafon <xref ref-type="bibr" rid="CR14">2006</xref>). The heat kernel <inline-formula id="IEq73"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}}$$\end{document}</tex-math><mml:math id="M170"><mml:mi mathvariant="bold">W</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq73.gif"/></alternatives></inline-formula> satisfies two important properties, the one of symmetry and the other of the positive semi-definite matrix. The latter property is crucial and allows the interpretation of weights as scaled probabilities of “jumping” from one node to another. The parameter <inline-formula id="IEq74"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M172"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq74.gif"/></alternatives></inline-formula> of the neighborhood size is data-dependent and here, it was determined by finding the linear region in the sum of all weights in <inline-formula id="IEq75"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}}$$\end{document}</tex-math><mml:math id="M174"><mml:mi mathvariant="bold">W</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq75.gif"/></alternatives></inline-formula>, say <inline-formula id="IEq76"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_w$$\end{document}</tex-math><mml:math id="M176"><mml:msub><mml:mi>S</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq76.gif"/></alternatives></inline-formula>, using different values of <inline-formula id="IEq77"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M178"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq77.gif"/></alternatives></inline-formula> (Singer et al. <xref ref-type="bibr" rid="CR86">2009</xref>; Sipola et al. <xref ref-type="bibr" rid="CR87">2013</xref>). <inline-formula id="IEq78"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_w$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mi>S</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq78.gif"/></alternatives></inline-formula> is calculated through the formula: <disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} S_w=\sum \limits _{i}^M\sum \limits _{j}^M{W_{ij}}, \end{aligned}$$\end{document}</tex-math><mml:math id="M182" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula> In order to use a single value of <inline-formula id="IEq79"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M184"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq79.gif"/></alternatives></inline-formula> for all participants, we computed a super-distribution of the sum of weights across subjects (taking the median value of the distributions) using different values of <inline-formula id="IEq80"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M186"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq80.gif"/></alternatives></inline-formula>. Thus, we considered values of <inline-formula id="IEq81"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M188"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq81.gif"/></alternatives></inline-formula> lying in the linear region of the super-distribution. Because the sum of weights is a sigmoidal function of <inline-formula id="IEq82"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M190"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq82.gif"/></alternatives></inline-formula>, we found the value of <inline-formula id="IEq83"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M192"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq83.gif"/></alternatives></inline-formula> where the maximum slope is attained. We then considered as “linear region”, the neighborhood of <inline-formula id="IEq84"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M194"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq84.gif"/></alternatives></inline-formula> with small bidirectional changes around that point (accounting to 5 % of the maximum slope).</p></list-item><list-item><p id="Par38">Formulation of the diagonal <inline-formula id="IEq85"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M \times M$$\end{document}</tex-math><mml:math id="M196"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq85.gif"/></alternatives></inline-formula> normalization matrix <inline-formula id="IEq86"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {K}}$$\end{document}</tex-math><mml:math id="M198"><mml:mi mathvariant="bold">K</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq86.gif"/></alternatives></inline-formula> along with the diffusion matrix <inline-formula id="IEq87"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M200"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq87.gif"/></alternatives></inline-formula>: <disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K_{ii}&amp;= \sum _{j=1}^{M} W_{ij}, \end{aligned}$$\end{document}</tex-math><mml:math id="M202" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi mathvariant="italic">ii</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {P}}&amp;= {\mathbf {K}}^{-1}{\mathbf {W}}. \end{aligned}$$\end{document}</tex-math><mml:math id="M204" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold">P</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula> Each element of the symmetric and normalized diffusion matrix <inline-formula id="IEq88"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M206"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq88.gif"/></alternatives></inline-formula> reflects the connectivity between two data points <inline-formula id="IEq89"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{i}$$\end{document}</tex-math><mml:math id="M208"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq89.gif"/></alternatives></inline-formula> and <inline-formula id="IEq90"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{j}$$\end{document}</tex-math><mml:math id="M210"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq90.gif"/></alternatives></inline-formula>. As an analogy, this connectivity can be seen as the probability of “jumping” from one point to another in a random walk process. Consequently, raising <inline-formula id="IEq91"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M212"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq91.gif"/></alternatives></inline-formula> to a power of <italic>t</italic> can be thought of as a diffusion process. As the number of <italic>t</italic> increases, paths with low probability tend to zero, while the connectivity between paths with high probability remains high enough governing the diffusion process (Coifman and Lafon <xref ref-type="bibr" rid="CR14">2006</xref>). Thus, the algorithm of diffusion maps preserves the diffusion distance among points in a low-dimensional Euclidean space. The diffusion distance is closely related to the diffusion matrix <inline-formula id="IEq92"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M214"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq92.gif"/></alternatives></inline-formula>; for two distinct points <inline-formula id="IEq93"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{i}$$\end{document}</tex-math><mml:math id="M216"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq93.gif"/></alternatives></inline-formula>, <inline-formula id="IEq94"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{j}$$\end{document}</tex-math><mml:math id="M218"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq94.gif"/></alternatives></inline-formula> and for specific time instance <italic>t</italic> is defined as (De la Porte et al. <xref ref-type="bibr" rid="CR19">2008</xref>): <disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} D_{t}({\mathbf {x}}_{i},{\mathbf {x}}_{j})=\sum _{m}|P_{im}^{t}-P_{mj}^{t}|^2. \end{aligned}$$\end{document}</tex-math><mml:math id="M220" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>m</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">im</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi mathvariant="italic">mj</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula> Unlike the geodesic distance, the diffusion distance is robust to noise perturbations, as it sums over all possible paths (of <italic>t</italic> steps) between points (Coifman and Lafon <xref ref-type="bibr" rid="CR14">2006</xref>).</p></list-item><list-item><p id="Par39">Construction of the conjugate matrix <disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\overline{\mathbf {P}}}= {\mathbf {K}}^{1/2}{\mathbf {P}}{\mathbf {K}}^{-1/2}, \end{aligned}$$\end{document}</tex-math><mml:math id="M222" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula> substituting Eq.(<xref rid="Equ14" ref-type="">14</xref>) to Eq.(<xref rid="Equ16" ref-type="">16</xref>) we get <disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\overline{\mathbf {P}}}= {\mathbf {K}}^{-1/2}{\mathbf {W}}{\mathbf {K}}^{-1/2}. \end{aligned}$$\end{document}</tex-math><mml:math id="M224" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ17.gif" position="anchor"/></alternatives></disp-formula> This is the so-called graph Laplacian matrix (Belkin and Niyogi <xref ref-type="bibr" rid="CR9">2003</xref>). The matrix <inline-formula id="IEq95"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {\ P}}$$\end{document}</tex-math><mml:math id="M226"><mml:mrow><mml:mspace width="4pt"/><mml:mi mathvariant="bold">P</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq95.gif"/></alternatives></inline-formula> is adjoint to the symmetric matrix <inline-formula id="IEq96"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathbf {P}}}$$\end{document}</tex-math><mml:math id="M228"><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq96.gif"/></alternatives></inline-formula>. Thus, <inline-formula id="IEq97"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {\ P}}$$\end{document}</tex-math><mml:math id="M230"><mml:mrow><mml:mspace width="4pt"/><mml:mi mathvariant="bold">P</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq97.gif"/></alternatives></inline-formula> and <inline-formula id="IEq98"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathbf {P}}}$$\end{document}</tex-math><mml:math id="M232"><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq98.gif"/></alternatives></inline-formula> share the same eigenvalues (Nadler et al. <xref ref-type="bibr" rid="CR60">2008</xref>).</p></list-item><list-item><p id="Par40">Singular Value Decomposition (SVD) of <inline-formula id="IEq99"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathbf {P}}}$$\end{document}</tex-math><mml:math id="M234"><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq99.gif"/></alternatives></inline-formula> yields <disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\overline{\mathbf {P}}}={\mathbf {U}}\varvec{\Lambda } {\mathbf {U}}^{*}, \end{aligned}$$\end{document}</tex-math><mml:math id="M236" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="bold">U</mml:mi><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ18.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq100"><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\Lambda }$$\end{document}</tex-math><mml:math id="M238"><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq100.gif"/></alternatives></inline-formula> is a diagonal matrix containing the <italic>M</italic> eigenvalues of <inline-formula id="IEq101"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M240"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq101.gif"/></alternatives></inline-formula> and <inline-formula id="IEq102"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {U}}$$\end{document}</tex-math><mml:math id="M242"><mml:mi mathvariant="bold">U</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq102.gif"/></alternatives></inline-formula> the eigenvectors of <inline-formula id="IEq103"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\overline{\mathbf {P}}}$$\end{document}</tex-math><mml:math id="M244"><mml:mover><mml:mi mathvariant="bold">P</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq103.gif"/></alternatives></inline-formula>. The eigenvectors <inline-formula id="IEq104"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {V}}$$\end{document}</tex-math><mml:math id="M246"><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq104.gif"/></alternatives></inline-formula> of <inline-formula id="IEq105"><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M248"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq105.gif"/></alternatives></inline-formula> can be found by (Nadler et al. <xref ref-type="bibr" rid="CR60">2008</xref>): <disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {\ V}}={\mathbf {K}}^{-1/2}{\mathbf {U}}. \end{aligned}$$\end{document}</tex-math><mml:math id="M250" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mspace width="4pt"/><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">U</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ19.gif" position="anchor"/></alternatives></disp-formula></p></list-item><list-item><p id="Par41">By taking out the trivial eigenvalue <inline-formula id="IEq106"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda =1$$\end{document}</tex-math><mml:math id="M252"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq106.gif"/></alternatives></inline-formula> of the matrix <inline-formula id="IEq107"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\Lambda }$$\end{document}</tex-math><mml:math id="M254"><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq107.gif"/></alternatives></inline-formula> and the corresponding eigenvector contained in <inline-formula id="IEq108"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {V}}$$\end{document}</tex-math><mml:math id="M256"><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq108.gif"/></alternatives></inline-formula>, the coordinates of the low dimensional embedded manifold <inline-formula id="IEq109"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M}$$\end{document}</tex-math><mml:math id="M258"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq109.gif"/></alternatives></inline-formula> are given by: <disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{}[{\mathbf {y}}_1,\dots ,{\mathbf {y}}_M]= \varvec{\Lambda }_{p\times p}\cdot {\mathbf {V}}^{T}_{p \times M}, \end{aligned}$$\end{document}</tex-math><mml:math id="M260" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ20.gif" position="anchor"/></alternatives></disp-formula> where <inline-formula id="IEq110"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\Lambda }_{p\times p}$$\end{document}</tex-math><mml:math id="M262"><mml:msub><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq110.gif"/></alternatives></inline-formula> contains the <italic>p</italic> largest eigenvalues, and <inline-formula id="IEq111"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {V}}^{T}_{p \times M}$$\end{document}</tex-math><mml:math id="M264"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq111.gif"/></alternatives></inline-formula> are the corresponding eigenvectors of the diffusion matrix <inline-formula id="IEq112"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {P}}$$\end{document}</tex-math><mml:math id="M266"><mml:mi mathvariant="bold">P</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq112.gif"/></alternatives></inline-formula>.</p></list-item></list>For the implementation of the above algorithm, we used the package “diffusionMap” (Richards <xref ref-type="bibr" rid="CR68">2014</xref>) in the R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
        </sec>
        <sec id="Sec15">
          <title>Construction of FCN using kernel principal component analysis</title>
          <p id="Par42">Kernel PCA (Schölkopf et al. <xref ref-type="bibr" rid="CR79">1997</xref>) is an extension of the linear PCA (Jollife <xref ref-type="bibr" rid="CR42">2002</xref>) to produce a non-linear mapping (Muller et al. <xref ref-type="bibr" rid="CR58">2001</xref>) of the data. Given a set of <italic>M</italic> objects/observables <inline-formula id="IEq113"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {X}}={\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M268"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq113.gif"/></alternatives></inline-formula>, kPCA produces a low-dimensional representation <inline-formula id="IEq114"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {Y}}={{\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M}} \in {\mathbf {R}}^p$$\end{document}</tex-math><mml:math id="M270"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq114.gif"/></alternatives></inline-formula>, <inline-formula id="IEq115"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \ll N$$\end{document}</tex-math><mml:math id="M272"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq115.gif"/></alternatives></inline-formula>. The standard procedure follows three simple steps:<list list-type="bullet"><list-item><p id="Par43">Introduce a non-linear mapping <inline-formula id="IEq116"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {X}} \rightarrow \phi ({\mathbf {x}})$$\end{document}</tex-math><mml:math id="M274"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq116.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par44">Calculate the covariance matrix <inline-formula id="IEq117"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {C}}=E \Big \{ \phi ({\mathbf {x}})\phi ({\mathbf {x}})^T \Big \}$$\end{document}</tex-math><mml:math id="M276"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em" stretchy="true">{</mml:mo></mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>ϕ</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em" stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq117.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par45">Solve the eigenvalue problem <inline-formula id="IEq118"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {C}}{\mathbf {u}}=\lambda {\mathbf {u}}$$\end{document}</tex-math><mml:math id="M278"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mi mathvariant="bold">u</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq118.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par46">project <inline-formula id="IEq119"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {C}}$$\end{document}</tex-math><mml:math id="M280"><mml:mi mathvariant="bold">C</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq119.gif"/></alternatives></inline-formula> on the eigenvectors that correspond to the largest eigenvalues (that account for most of the variance).</p></list-item></list>Using the so called “kernel” trick, we can rule out the actual mapping and dot product operations (Schölkopf et al. <xref ref-type="bibr" rid="CR79">1997</xref>). Instead, we simply have to estimate a kernel function. Here, we use the Gaussian kernel (following notation in Tsatsishvili et al. <xref ref-type="bibr" rid="CR95">2018</xref>):<disp-formula id="Equ21"><label>21</label><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K_{i,j}= exp\left( - \frac{d({\mathbf {x}}_{i},{\mathbf {x}}_{j})^2}{2\gamma ^2}\right) . \end{aligned}$$\end{document}</tex-math><mml:math id="M282" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ21.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq120"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d({\mathbf {x}}_i,{\mathbf {x}}_j)$$\end{document}</tex-math><mml:math id="M284"><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq120.gif"/></alternatives></inline-formula> are the (dis)similarities obtained (by any dissimilarity measure of choice) between all pairs of points <inline-formula id="IEq121"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M286"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq121.gif"/></alternatives></inline-formula> and <inline-formula id="IEq122"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M288"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq122.gif"/></alternatives></inline-formula> is a free parameter of the Gaussian kernel. For each subject, we considered <inline-formula id="IEq123"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M290"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq123.gif"/></alternatives></inline-formula> to be the median of the minimum values of distances among data points (as proposed also in Tsatsishvili et al. (<xref ref-type="bibr" rid="CR95">2018</xref>)). As <inline-formula id="IEq124"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {K}}$$\end{document}</tex-math><mml:math id="M292"><mml:mi mathvariant="bold">K</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq124.gif"/></alternatives></inline-formula> is not guaranteed to be centered, it is required to “centralize” <italic>K</italic> using the centering matrix <inline-formula id="IEq125"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {H}}$$\end{document}</tex-math><mml:math id="M294"><mml:mi mathvariant="bold">H</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq125.gif"/></alternatives></inline-formula> :<disp-formula id="Equ22"><label>22</label><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathbf {K}^{\prime }={\mathbf {H}}{\mathbf {K}} {\mathbf {H}}. \end{aligned}$$\end{document}</tex-math><mml:math id="M296" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mi mathvariant="bold">K</mml:mi><mml:mi mathvariant="bold">H</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ22.gif" position="anchor"/></alternatives></disp-formula>Next we need to solve the eigenvalue problem:<disp-formula id="Equ23"><label>23</label><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \mathbf {K}^{\prime } \cdot {\mathbf {V}}=\varvec{\Lambda } \cdot {\mathbf {V}} \end{aligned}$$\end{document}</tex-math><mml:math id="M298" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>·</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>·</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ23.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq126"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {V}}$$\end{document}</tex-math><mml:math id="M300"><mml:mi mathvariant="bold">V</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq126.gif"/></alternatives></inline-formula> contains the eigenvectors and the diagonal matrix <inline-formula id="IEq127"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\Lambda }$$\end{document}</tex-math><mml:math id="M302"><mml:mrow><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq127.gif"/></alternatives></inline-formula> contains the eigenvalues of <inline-formula id="IEq128"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {K}^{\prime }$$\end{document}</tex-math><mml:math id="M304"><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq128.gif"/></alternatives></inline-formula>.</p>
          <p id="Par47">The coordinates of the embedded manifold <inline-formula id="IEq129"><alternatives><tex-math id="M305">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M}$$\end{document}</tex-math><mml:math id="M306"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq129.gif"/></alternatives></inline-formula> are finally obtained by projecting the centered kernel matrix <inline-formula id="IEq130"><alternatives><tex-math id="M307">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {K}^{\prime }}$$\end{document}</tex-math><mml:math id="M308"><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq130.gif"/></alternatives></inline-formula> onto its eigenvectors that correspond to the <italic>p</italic> largest eigenvalues:<disp-formula id="Equ24"><label>24</label><alternatives><tex-math id="M309">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned}{}[{\mathbf {y}}_1,\dots ,{\mathbf {y}}_M]= ({\mathbf {K}^{\prime }}_{M\times M}\cdot {\mathbf {V}}_{M \times p})^{T}. \end{aligned}$$\end{document}</tex-math><mml:math id="M310" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="bold">V</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ24.gif" position="anchor"/></alternatives></disp-formula>For the implementation of the kernel PCA, we used the package ”kernlab” (Karatzoglou et al. <xref ref-type="bibr" rid="CR43">2004</xref>) in the R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
        </sec>
        <sec id="Sec16">
          <title>Construction of FCN using locally linear embedding</title>
          <p id="Par48">Locally Linear Embedding (LLE) (Roweis and Saul <xref ref-type="bibr" rid="CR72">2000</xref>) is a non-linear manifold learning technique that given a set of <italic>M</italic> objects/observables <inline-formula id="IEq131"><alternatives><tex-math id="M311">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {X}}={\mathbf {x}}_{1},{\mathbf {x}}_{2},\dots ,{\mathbf {x}}_{M} \in {\mathbf {R}}^N$$\end{document}</tex-math><mml:math id="M312"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq131.gif"/></alternatives></inline-formula> produces a low-dimensional representation <inline-formula id="IEq132"><alternatives><tex-math id="M313">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {Y}}={{\mathbf {y}}_{1},{\mathbf {y}}_{2},\dots ,{\mathbf {y}}_{M}} \in {\mathbf {R}}^p$$\end{document}</tex-math><mml:math id="M314"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq132.gif"/></alternatives></inline-formula>, <inline-formula id="IEq133"><alternatives><tex-math id="M315">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \ll N$$\end{document}</tex-math><mml:math id="M316"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq133.gif"/></alternatives></inline-formula>, that preserves the local topology (i.e the distance between neighbouring data points). The LLE assumes that even if the high dimensional data points lie on a highly non-linear manifold, the manifold can be still considered as locally linear. Provided that the manifold is well sampled, then we would expect that every data point has neighbours that lie on or close to a linear patch of the global manifold. According to this assumption, LLE approximates every data point in a low-dimensional space by calculating a weighted linear combination of its neighbours. Thus, LLE yields a low dimensional representation of data by learning the global structure, from local relationships (Roweis and Saul <xref ref-type="bibr" rid="CR72">2000</xref>).</p>
          <p id="Par49">The main procedure can be described in three steps:<list list-type="bullet"><list-item><p id="Par50">Find the nearest neighbours of data points by using either the <italic>k</italic>-nearest neighbors algorithm or a fixed distance between data points, known as the <inline-formula id="IEq134"><alternatives><tex-math id="M317">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><mml:math id="M318"><mml:mi>ϵ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq134.gif"/></alternatives></inline-formula> distance. Here, we used the <italic>k</italic>-nearest neighbors algorithm.</p></list-item><list-item><p id="Par51">Compute the weights <inline-formula id="IEq135"><alternatives><tex-math id="M319">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}}_{i}$$\end{document}</tex-math><mml:math id="M320"><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq135.gif"/></alternatives></inline-formula> that best reconstruct linearly each data point <inline-formula id="IEq136"><alternatives><tex-math id="M321">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{i}$$\end{document}</tex-math><mml:math id="M322"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq136.gif"/></alternatives></inline-formula> from its neighbours with respect to the following optimization problem: <disp-formula id="Equ25"><label>25</label><alternatives><tex-math id="M323">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {W}}_{i}=\hbox {argmin} \left\| {\mathbf {x}}_{i}-\sum \limits _{k} w_{ik}{\mathbf {x}}_{k}\right\| ^2. \end{aligned}$$\end{document}</tex-math><mml:math id="M324" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>argmin</mml:mtext><mml:msup><mml:mfenced close="∥" open="∥"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ25.gif" position="anchor"/></alternatives></disp-formula> Constraints to the above minimization scheme include: <inline-formula id="IEq137"><alternatives><tex-math id="M325">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{ik}=0$$\end{document}</tex-math><mml:math id="M326"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq137.gif"/></alternatives></inline-formula>, if <inline-formula id="IEq138"><alternatives><tex-math id="M327">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{k}$$\end{document}</tex-math><mml:math id="M328"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq138.gif"/></alternatives></inline-formula> is not a neighbour of <inline-formula id="IEq139"><alternatives><tex-math id="M329">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{i}$$\end{document}</tex-math><mml:math id="M330"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq139.gif"/></alternatives></inline-formula> (each data point is reconstructed only from its neighbours), <inline-formula id="IEq140"><alternatives><tex-math id="M331">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sum \nolimits _{k}w_{ik}=1$$\end{document}</tex-math><mml:math id="M332"><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq140.gif"/></alternatives></inline-formula> (all weights of neighbouring points <italic>k</italic> sum to 1).</p></list-item><list-item><p id="Par52">Embedding coordinates <inline-formula id="IEq141"><alternatives><tex-math id="M333">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_{i}$$\end{document}</tex-math><mml:math id="M334"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq141.gif"/></alternatives></inline-formula> that best preserve the local structure of neighbourhoods of <inline-formula id="IEq142"><alternatives><tex-math id="M335">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_{i}$$\end{document}</tex-math><mml:math id="M336"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq142.gif"/></alternatives></inline-formula> in the low dimensional space are given by: <disp-formula id="Equ26"><label>26</label><alternatives><tex-math id="M337">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathbf {y}}_{i}=\hbox {argmin} \left\| {\mathbf {y}}_{i}-\sum \limits _{k} w_{ik}{\mathbf {y}}_{k}\right\| ^2, \end{aligned}$$\end{document}</tex-math><mml:math id="M338" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>argmin</mml:mtext><mml:msup><mml:mfenced close="∥" open="∥"><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ26.gif" position="anchor"/></alternatives></disp-formula> with respect to <inline-formula id="IEq143"><alternatives><tex-math id="M339">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {y}}_i \in {\mathbf {R}}^p$$\end{document}</tex-math><mml:math id="M340"><mml:mrow><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq143.gif"/></alternatives></inline-formula>, <inline-formula id="IEq144"><alternatives><tex-math id="M341">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \ll N$$\end{document}</tex-math><mml:math id="M342"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq144.gif"/></alternatives></inline-formula>. For the problem to be well posed, the following constraints are set: <disp-formula id="Equ27"><label>27</label><alternatives><tex-math id="M343">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \dfrac{1}{M} \sum \limits _{i} \mathbf {y}_{i}\mathbf {y}_{i}^{T}={\mathbf {I}} , \quad \sum \limits _{i} \mathbf{y}_{i}=\mathbf{0} \end{aligned}$$\end{document}</tex-math><mml:math id="M344" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac></mml:mstyle><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ27.gif" position="anchor"/></alternatives></disp-formula> To find the embedding coordinates, we construct <inline-formula id="IEq145"><alternatives><tex-math id="M345">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}^{\prime }}={\mathbf {(I-W)}}^{T} {\mathbf {(I-W)}}$$\end{document}</tex-math><mml:math id="M346"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq145.gif"/></alternatives></inline-formula> and solve the eigenvalue problem. Here, <inline-formula id="IEq146"><alternatives><tex-math id="M347">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {I}}$$\end{document}</tex-math><mml:math id="M348"><mml:mi mathvariant="bold">I</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq146.gif"/></alternatives></inline-formula> is the identity matrix and <italic>M</italic> is the number of the eigenvalues of <inline-formula id="IEq147"><alternatives><tex-math id="M349">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}^{\prime }}$$\end{document}</tex-math><mml:math id="M350"><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq147.gif"/></alternatives></inline-formula>. The first constraint <inline-formula id="IEq148"><alternatives><tex-math id="M351">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\dfrac{1}{M} \sum \limits _{i} \mathbf {y}_{i}\mathbf {y}_{i}^{T}={\mathbf {I}}$$\end{document}</tex-math><mml:math id="M352"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>M</mml:mi></mml:mfrac></mml:mstyle><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant="bold">y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq148.gif"/></alternatives></inline-formula> forces the embedding vectors to have unit covariances to avoid degenerate solutions (Roweis and Saul <xref ref-type="bibr" rid="CR72">2000</xref>), while the second constraint requires the coordinates to be centered at the origin. The eigenvectors of <inline-formula id="IEq149"><alternatives><tex-math id="M353">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}^{\prime }}$$\end{document}</tex-math><mml:math id="M354"><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq149.gif"/></alternatives></inline-formula> are all solutions of <inline-formula id="IEq150"><alternatives><tex-math id="M355">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {Y}}$$\end{document}</tex-math><mml:math id="M356"><mml:mi mathvariant="bold">Y</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq150.gif"/></alternatives></inline-formula>, but those correspond to the <italic>p</italic> smallest eigenvalues are the ones that minimize (<xref rid="Equ26" ref-type="">26</xref>). The smallest eigenvalue of <inline-formula id="IEq151"><alternatives><tex-math id="M357">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {W}^{\prime }}$$\end{document}</tex-math><mml:math id="M358"><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq151.gif"/></alternatives></inline-formula> will always be zero and it is discarded. The next <inline-formula id="IEq152"><alternatives><tex-math id="M359">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M-1$$\end{document}</tex-math><mml:math id="M360"><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq152.gif"/></alternatives></inline-formula> eigenvalues can be used as the new dimensions of the transformed data. Estimation of the final dimensionality of the transformation can be made by selecting eigenvectors that correspond to the number of the smallest eigenvalues that form a cluster (Kayo <xref ref-type="bibr" rid="CR44">2006</xref>).</p></list-item></list>For the parameter <italic>k</italic>, we considered values of <inline-formula id="IEq153"><alternatives><tex-math id="M361">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=2,\dots 10$$\end{document}</tex-math><mml:math id="M362"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq153.gif"/></alternatives></inline-formula>. The number of nodes (for each subject) in this study varied in the range of 20–40. Thus, the largest <italic>k</italic> accounts for the 25–50% of the nodes of a subject. For larger values of <italic>k</italic> the LLE algorithm uses too many neighbours and each data point is no longer “locally” retrieved from its nearest neighbours.</p>
          <p id="Par53">Here, we employed a variant of the above LLE algorithm that takes as inputs only the pairwise distances (<inline-formula id="IEq154"><alternatives><tex-math id="M363">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {D_{X}}}$$\end{document}</tex-math><mml:math id="M364"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">X</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq154.gif"/></alternatives></inline-formula>) among the data points on the initial space (this extension of the LLE is thoroughly described in Saul and Roweis <xref ref-type="bibr" rid="CR76">2003</xref>). This was necessary as we wanted to test different metrics. For the implementation of this variant of the LLE algorithm, we modified the code offered by the “lle” package (Diedrich et al. <xref ref-type="bibr" rid="CR20">2012</xref>) in the R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
        </sec>
        <sec id="Sec17">
          <title>Choice of the embedding dimension</title>
          <p id="Par54">The embedding dimension was determined via the eigenspectrum of the final decomposition for every dimensionality reduction/manifold learning algorithm, as identified by the gap between the first few larger eigenvalues (smaller eigenvalues for the LLE) and the rest of the eigenspectrum. These first few eigenmodes capture most of the distance differences between data points and are able to represent and uncover intrinsic properties of the data structure (Nadler et al. <xref ref-type="bibr" rid="CR60">2008</xref>; Strange and Zwiggelaar <xref ref-type="bibr" rid="CR92">2014</xref>; Saul et al. <xref ref-type="bibr" rid="CR77">2006</xref>). In order to determine the embedding dimension for the methods described above, we considered the following steps: we sorted the eigenvalues in decreasing order <inline-formula id="IEq155"><alternatives><tex-math id="M365">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{1} \ge \lambda _{2} \ge \lambda _{3}$$\end{document}</tex-math><mml:math id="M366"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq155.gif"/></alternatives></inline-formula>
<inline-formula id="IEq156"><alternatives><tex-math id="M367">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\cdots \ge \lambda _{M}$$\end{document}</tex-math><mml:math id="M368"><mml:mrow><mml:mo>⋯</mml:mo><mml:mo>≥</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq156.gif"/></alternatives></inline-formula> (<inline-formula id="IEq157"><alternatives><tex-math id="M369">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{1}$$\end{document}</tex-math><mml:math id="M370"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq157.gif"/></alternatives></inline-formula> is discarded for diffusion maps and <inline-formula id="IEq158"><alternatives><tex-math id="M371">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{M}$$\end{document}</tex-math><mml:math id="M372"><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq158.gif"/></alternatives></inline-formula> for LLE). Then, for each subject, we calculated the pairwise differences <inline-formula id="IEq159"><alternatives><tex-math id="M373">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{1}-\lambda _{2}$$\end{document}</tex-math><mml:math id="M374"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq159.gif"/></alternatives></inline-formula>, <inline-formula id="IEq160"><alternatives><tex-math id="M375">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{2}-\lambda _{3},\ldots$$\end{document}</tex-math><mml:math id="M376"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq160.gif"/></alternatives></inline-formula>
<inline-formula id="IEq161"><alternatives><tex-math id="M377">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$,\lambda _{M-1}-\lambda _{M}$$\end{document}</tex-math><mml:math id="M378"><mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq161.gif"/></alternatives></inline-formula>. A large numerical gap between two elements of this sequence of pairwise differences indicates the dimension beyond which the relative contributions are redundant (or small contributions are made for the reconstruction of the embedded FCN).</p>
        </sec>
      </sec>
      <sec id="Sec18">
        <title>Graph-theoretic measures</title>
        <p id="Par55">We analyzed the topological properties of the binary FCN graphs on the basis of three fundamental graph measures for neuroscience, namely, the average path length, the global clustering coefficient, and the median degree (Stam and Reijneveld <xref ref-type="bibr" rid="CR91">2007</xref>; Khajehpour et al. <xref ref-type="bibr" rid="CR45">2019</xref>; Anderson et al. <xref ref-type="bibr" rid="CR4">2010</xref>; Parhizi et al. <xref ref-type="bibr" rid="CR64">2018</xref>). In particular, given a graph <inline-formula id="IEq162"><alternatives><tex-math id="M379">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {G}}=(V,E)$$\end{document}</tex-math><mml:math id="M380"><mml:mrow><mml:mi mathvariant="bold">G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq162.gif"/></alternatives></inline-formula> with <inline-formula id="IEq163"><alternatives><tex-math id="M381">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g_{ij}$$\end{document}</tex-math><mml:math id="M382"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq163.gif"/></alternatives></inline-formula> representing the link (0: unconnected or 1: connected) from node <italic>i</italic> to node <italic>j</italic> and <inline-formula id="IEq164"><alternatives><tex-math id="M383">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k_i= \sum ^{}_{j,{j\ne i}}g_{ij}$$\end{document}</tex-math><mml:math id="M384"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mrow><mml:mrow/></mml:msubsup><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq164.gif"/></alternatives></inline-formula> the degree of node i, the graph measures are computed as follows: <list list-type="alpha-lower"><list-item><p id="Par56">The average path length is defined by: <inline-formula id="IEq165"><alternatives><tex-math id="M385">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L= \frac{1}{N_V(N_V-1)}\sum _{i \ne j}D_{G_{ij}}$$\end{document}</tex-math><mml:math id="M386"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq165.gif"/></alternatives></inline-formula>, i.e. is the average number of steps along the shortest paths <inline-formula id="IEq166"><alternatives><tex-math id="M387">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_{G_{ij}}$$\end{document}</tex-math><mml:math id="M388"><mml:msub><mml:mi>D</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq166.gif"/></alternatives></inline-formula> for all possible pairs of the network nodes. This is a measure of the efficiency of information or mass transport on a network between all possible pairs of nodes.</p></list-item><list-item><p id="Par57">The global clustering coefficient is defined by: <inline-formula id="IEq167"><alternatives><tex-math id="M389">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_g= \frac{\sum _{} t_c}{\sum _{} t}$$\end{document}</tex-math><mml:math id="M390"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow/></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow/></mml:msub><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq167.gif"/></alternatives></inline-formula>, where <italic>t</italic> is a triplet and <inline-formula id="IEq168"><alternatives><tex-math id="M391">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_c$$\end{document}</tex-math><mml:math id="M392"><mml:msub><mml:mi>t</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq168.gif"/></alternatives></inline-formula> is a closed triplet. A triplet of a graph consists of three nodes that are connected by either open (i.e open triplet) or closed (i.e closed triplet) ties. In general, this measure indicates how random or structured a graph is (in our case, in terms of functional segregation).</p></list-item><list-item><p id="Par58">The median degree <inline-formula id="IEq169"><alternatives><tex-math id="M393">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{k}$$\end{document}</tex-math><mml:math id="M394"><mml:msub><mml:mi>M</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq169.gif"/></alternatives></inline-formula> is the median value of the degree distribution of <inline-formula id="IEq170"><alternatives><tex-math id="M395">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {G}}$$\end{document}</tex-math><mml:math id="M396"><mml:mi mathvariant="bold">G</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq170.gif"/></alternatives></inline-formula>. This measure reflects how well connected is the “median” network node in terms of the number of links that coincide with it.</p></list-item></list>An extensive review of the definitions and the meaning of the above key graph-theoretic measures with respect to brain functional networks can be found in Rubinov and Sporns (<xref ref-type="bibr" rid="CR73">2010</xref>), Stam and Reijneveld (<xref ref-type="bibr" rid="CR91">2007</xref>), Bullmore and Sporns (<xref ref-type="bibr" rid="CR11">2009</xref>).</p>
        <p id="Par59">The computations for the graph analysis were performed utilizing the “igraph” (Csardi and Nepusz <xref ref-type="bibr" rid="CR16">2006</xref>) package in the R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
      </sec>
      <sec id="Sec19">
        <title>Classification/ Machine Learning algorithms</title>
        <p id="Par60">Classification was assessed using machine learning algorithms, namely Linear Support Vector Machines (LSVM), Radial Support Vector Machines (RSVM), Artificial Neural Networks (ANN) and k-Nearest Neighbours (k-NN) classification (for a brief description of the above algorithms and their parameter grids see the “<xref rid="Sec28" ref-type="sec">Appendix</xref>”). The features that were considered for classification were the three key graph measures (as stated in “<xref rid="Sec18" ref-type="sec">Graph-theoretic measures</xref>” section) which are the most frequently used in neuroscience (Stam and Reijneveld <xref ref-type="bibr" rid="CR91">2007</xref>; Khajehpour et al. <xref ref-type="bibr" rid="CR45">2019</xref>; Anderson et al. <xref ref-type="bibr" rid="CR4">2010</xref>; Parhizi et al. <xref ref-type="bibr" rid="CR64">2018</xref>; Bullmore and Sporns <xref ref-type="bibr" rid="CR11">2009</xref>). Our intention was not to implement a feature selection algorithm but to assess the efficiency of the methods based only on these three fundamental measures. All three measures were given as input to the classifiers. The classification algorithms were trained, validated and tested using a tenfold cross validation scheme which was repeated 100 times. Thus, we separated the data in ten distinct sub-samples; nine of them were used as training sets and one of them was used for validation purposes. This process was repeated 10 times leaving out each time a different sub-sample which served as a validation set. The whole procedure was repeated 100 times. The overall classification rate was determined via the computation of the average classification rate over all the repetitions of the tenfold cross validation for each model.</p>
        <p id="Par61">The average confusion matrix (over all repetitions of the tenfold cross validation) was also computed for each classification model. The confusion matrix is a <inline-formula id="IEq171"><alternatives><tex-math id="M397">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2\times 2$$\end{document}</tex-math><mml:math id="M398"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq171.gif"/></alternatives></inline-formula> (in the case of binary classification) square matrix containing all true positives <italic>TP</italic>, false positives <italic>FP</italic>, true negatives <italic>TN</italic> and false negatives <italic>FN</italic>. Here, we considered as positives <italic>P</italic> the schizophrenia cases and as negatives <italic>N</italic> the healthy control cases. Sensitivity (also called the True Positive Rate) and specificity (also called the True Negative Rate) are basic statistical measures for the assessment of binary classifications. The sensitivity <italic>TPR</italic> is given by <inline-formula id="IEq172"><alternatives><tex-math id="M399">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$TPR= \frac{TP}{TP+FN}$$\end{document}</tex-math><mml:math id="M400"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq172.gif"/></alternatives></inline-formula>, while the specificity <italic>TNR</italic> is given by <inline-formula id="IEq173"><alternatives><tex-math id="M401">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$TNR= \frac{TN}{TN+FP}$$\end{document}</tex-math><mml:math id="M402"><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq173.gif"/></alternatives></inline-formula>. Here, sensitivity characterizes the ability of the classifier to correctly identify a schizophrenic subject, while specificity is the ability of the classifier to correctly identify a healthy subject.</p>
        <p id="Par62">Here, we used the algorithms contained in the package “caret” (Kuhn et al. <xref ref-type="bibr" rid="CR50">2008</xref>) in the R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
      </sec>
    </sec>
    <sec id="Sec20">
      <title>Results</title>
      <sec id="Sec21">
        <title>Signal extraction via RAICAR methodology</title>
        <p id="Par63">Out of 72 patients only 47 of them exhibited 20 or more reproducible components. In comparison, 57 out of 74 healthy controls had 20 or more reproducible components. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows the mean of the reproducible components found for the group of healthy controls (red,“HC”) and schizophrenic subjects (blue,“SC”) along with the standard deviation (error bars). No statistically significant differences were found in the number of reproducible components between groups (Welch’s <italic>t</italic> test: <italic>p</italic> = 0.43).<fig id="Fig1"><label>Fig. 1</label><caption><p>Reproducible components for the 57 healthy controls (red,“HC”) and 47 schizophrenic subjects (blue,“SC”) that resulted to 20 or more reproducible components. Each bar depicts the mean of the reproducible ICs extracted while the error bar represents the standard deviation for each group</p></caption><graphic xlink:href="11571_2020_9645_Fig1_HTML" id="MO29"/></fig></p>
      </sec>
      <sec id="Sec22">
        <title>Classification performance using the cross correlation metric</title>
        <p id="Par64">In Table <xref rid="Tab1" ref-type="table">1</xref>, we present the best classification accuracy, along with the corresponding sensitivity and specificity rate obtained for each manifold learning algorithm (see “<xref rid="Sec11" ref-type="sec">Construction of FCN with manifold learning algorithms</xref>” section), PT point and classifier (see “<xref rid="Sec19" ref-type="sec">Classification/ Machine Learning algorithms</xref>” section) with the cross correlation metric (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section). The optimal values of the parameters (i.e the embedding dimension <italic>p</italic> and method’s tuning parameter, see “<xref rid="Sec11" ref-type="sec">Construction of FCN with manifold learning algorithms</xref>” section) for each method are also shown. At the end of Table <xref rid="Tab1" ref-type="table">1</xref>, we also provide the results obtained by the “conventional” (thresholded) cross correlation matrix (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section). The best classification rate obtained for each method is marked with bold. Finally, the classification accuracy is reported along with the standard deviation (SD) over 100 repetitions of a tenfold cross validation scheme (see “<xref rid="Sec19" ref-type="sec">Classification/ Machine Learning algorithms</xref>” section).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Best classification rates over all manifold and machine learning methods using the cross correlation pseudo-distance measure <inline-formula id="IEq174"><alternatives><tex-math id="M403">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_c$$\end{document}</tex-math><mml:math id="M404"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq174.gif"/></alternatives></inline-formula>; optimal parameters are also shown for each method along with the corresponding PT, classifier, accuracy (Acc), sensitivity (Sens) and specificity (Spec) rate. Classifiers are noted as RSVM (Radial SVM), LSVM (Linear SVM), k-NN (k-NN classifier) and ANN (Artificial Neural Networks)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Parameters</th><th align="left">PT</th><th align="left">Classifier</th><th align="left">Acc ± SD (%)</th><th align="left">Sens (%)</th><th align="left">Spec (%)</th></tr></thead><tbody><tr><td align="left" rowspan="4"><italic>MDS</italic></td><td align="left" rowspan="4"><italic>p</italic> = 3</td><td char="." align="char">0.3</td><td align="left">RSVM</td><td align="left"><bold>68.4</bold> ± <bold>1.3</bold></td><td align="left">51.1</td><td align="left">77.8</td></tr><tr><td char="." align="char">0.36</td><td align="left">LSVM</td><td align="left">58.6 ± 1.7</td><td align="left">28.8</td><td align="left">78.9</td></tr><tr><td char="." align="char">0.3</td><td align="left">k-NN</td><td align="left">63.2 ± 2.1</td><td align="left">51</td><td align="left">68.8</td></tr><tr><td char="." align="char">0.3</td><td align="left">ANN</td><td align="left">63.6 ± 2.6</td><td align="left">50.7</td><td align="left">69.8</td></tr><tr><td align="left" rowspan="4"><italic>ISOMAP</italic></td><td align="left" rowspan="4"><italic>p</italic> = 2, <italic>k</italic> = 5</td><td char="." align="char">0.24</td><td align="left">RSVM</td><td align="left"><bold>74.4</bold> ± <bold>1.9</bold></td><td align="left">69.4</td><td align="left">73.1</td></tr><tr><td char="." align="char">0.28</td><td align="left">LSVM</td><td align="left">64.4 ± 1.7</td><td align="left">55.8</td><td align="left">67.1</td></tr><tr><td char="." align="char">0.24</td><td align="left">k-NN</td><td align="left">71 ± 2.1</td><td align="left">62.9</td><td align="left">72.7</td></tr><tr><td char="." align="char">0.24</td><td align="left">ANN</td><td align="left">68.8 ± 3</td><td align="left">63.1</td><td align="left">68.6</td></tr><tr><td align="left" rowspan="4"><italic>Diffusion maps</italic></td><td align="left" rowspan="4"><italic>p</italic> = 4, <inline-formula id="IEq175"><alternatives><tex-math id="M405">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M406"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq175.gif"/></alternatives></inline-formula> = 0.325</td><td char="." align="char">0.52</td><td align="left">RSVM</td><td align="left"><bold>79.3</bold> ± <bold>1.2</bold></td><td align="left">74.1</td><td align="left">77.9</td></tr><tr><td char="." align="char">0.56</td><td align="left">LSVM</td><td align="left">72.2 ± 1.7</td><td align="left">66.6</td><td align="left">71.8</td></tr><tr><td char="." align="char">0.52</td><td align="left">k-NN</td><td align="left">74.7 ± 1.4</td><td align="left">72.3</td><td align="left">71.5</td></tr><tr><td char="." align="char">0.52</td><td align="left">ANN</td><td align="left">78.6 ± 2</td><td align="left">74.1</td><td align="left">76.8</td></tr><tr><td align="left" rowspan="4"><italic>kPCA</italic></td><td align="left" rowspan="4"><italic>p</italic> = 4, <inline-formula id="IEq176"><alternatives><tex-math id="M407">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M408"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq176.gif"/></alternatives></inline-formula> = 0.575</td><td char="." align="char">0.42</td><td align="left">RSVM</td><td align="left"><bold>69.5</bold> ± <bold>1.6</bold></td><td align="left">45.4</td><td align="left">84.3</td></tr><tr><td char="." align="char">0.3</td><td align="left">LSVM</td><td align="left">59.5 ± 2.4</td><td align="left">19.1</td><td align="left">88.6</td></tr><tr><td char="." align="char">0.42</td><td align="left">k-NN</td><td align="left">67.1 ± 1.9</td><td align="left">51.7</td><td align="left">75.1</td></tr><tr><td char="." align="char">0.42</td><td align="left">ANN</td><td align="left">69.4 ± 2.4</td><td align="left">60.3</td><td align="left">72</td></tr><tr><td align="left" rowspan="4"><italic>LLE</italic></td><td align="left" rowspan="4"><italic>p</italic> = 4, <italic>k</italic> = 7</td><td char="." align="char">0.46</td><td align="left">RSVM</td><td align="left">68.3 ± 1.9</td><td align="left">49</td><td align="left">79.4</td></tr><tr><td char="." align="char">0.46</td><td align="left">LSVM</td><td align="left">69.2 ± 1.4</td><td align="left">48.6</td><td align="left">81.3</td></tr><tr><td char="." align="char">0.26</td><td align="left">k-NN</td><td align="left">66.1 ± 2.2</td><td align="left">52.8</td><td align="left">71.5</td></tr><tr><td char="." align="char">0.46</td><td align="left">ANN</td><td align="left"><bold>70.7</bold> ± <bold>1.3</bold></td><td align="left">56</td><td align="left">77.9</td></tr><tr><td align="left" rowspan="4"><italic>Cross corr. matrix</italic></td><td align="left" rowspan="4">–</td><td char="." align="char">0.52</td><td align="left">RSVM</td><td align="left">69.5 ± 1.5</td><td align="left">77.1</td><td align="left">58.3</td></tr><tr><td char="." align="char">0.52</td><td align="left">LSVM</td><td align="left"><bold>71</bold> ± <bold>1.5</bold></td><td align="left">75.8</td><td align="left">61.9</td></tr><tr><td char="." align="char">0.34</td><td align="left">k-NN</td><td align="left">67.2 ± 2.2</td><td align="left">57.8</td><td align="left">70.1</td></tr><tr><td char="." align="char">0.52</td><td align="left">ANN</td><td align="left">68.8 ± 1.6</td><td align="left">68.3</td><td align="left">64.3</td></tr></tbody></table></table-wrap></p>
        <p id="Par65">Figure <xref rid="Fig2" ref-type="fig">2</xref> provides a visualization of the cross correlation matrix of a patient and a healthy control across different values of PT (at 20%, 35%, 50% and 65% of the strongest edges). The metric used for the construction of the connectivity matrices is the pseudo-distance measure <inline-formula id="IEq177"><alternatives><tex-math id="M409">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{c}$$\end{document}</tex-math><mml:math id="M410"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq177.gif"/></alternatives></inline-formula> (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section) based on cross correlation. The lower the value of <inline-formula id="IEq178"><alternatives><tex-math id="M411">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{c}$$\end{document}</tex-math><mml:math id="M412"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq178.gif"/></alternatives></inline-formula> between 2 ICs, the more functionally connected they are.<fig id="Fig2"><label>Fig. 2</label><caption><p>Visualization of the cross correlation matrix based on the pseudo-distance measure <inline-formula id="IEq179"><alternatives><tex-math id="M413">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{c}$$\end{document}</tex-math><mml:math id="M414"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq179.gif"/></alternatives></inline-formula> (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section) of a patient and a healthy control across different values of PT</p></caption><graphic xlink:href="11571_2020_9645_Fig2_HTML" id="MO30"/></fig></p>
        <p id="Par66">Figure  <xref rid="Fig3" ref-type="fig">3</xref> shows the super-distribution of the sum of weights of all subjects with respect to different values of <inline-formula id="IEq180"><alternatives><tex-math id="M415">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M416"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq180.gif"/></alternatives></inline-formula> used for the construction of the FCN with diffusion maps; the red dotted vertical line shows the optimal <inline-formula id="IEq181"><alternatives><tex-math id="M417">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M418"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq181.gif"/></alternatives></inline-formula> (here, <inline-formula id="IEq182"><alternatives><tex-math id="M419">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M420"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq182.gif"/></alternatives></inline-formula> = 0.325) while the black vertical lines bound the linear region (<inline-formula id="IEq183"><alternatives><tex-math id="M421">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma \in (0.28,0.35)$$\end{document}</tex-math><mml:math id="M422"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0.28</mml:mn><mml:mo>,</mml:mo><mml:mn>0.35</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq183.gif"/></alternatives></inline-formula>). The results were robust to different choices of the time step of the diffusion maps algorithm, namely <inline-formula id="IEq184"><alternatives><tex-math id="M423">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t=0,1,2$$\end{document}</tex-math><mml:math id="M424"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq184.gif"/></alternatives></inline-formula>.<fig id="Fig3"><label>Fig. 3</label><caption><p>Super-distribution of all subjects of the sum of the weights (see Eq. <xref rid="Equ12" ref-type="">12</xref>). The red dashed vertical line shows the optimal <inline-formula id="IEq185"><alternatives><tex-math id="M425">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M426"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq185.gif"/></alternatives></inline-formula> that was found to be <inline-formula id="IEq186"><alternatives><tex-math id="M427">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M428"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq186.gif"/></alternatives></inline-formula> = 0.325. The other two vertical black lines bound the linear zone in which we investigated values of <inline-formula id="IEq187"><alternatives><tex-math id="M429">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M430"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq187.gif"/></alternatives></inline-formula></p></caption><graphic xlink:href="11571_2020_9645_Fig3_HTML" id="MO31"/></fig></p>
        <p id="Par67">Figure <xref rid="Fig4" ref-type="fig">4</xref> depicts the classification rates for all manifold learning algorithms and the cross correlation matrix for all classifiers and PTs. The overall classification pattern over all PT points based on the optimal embedding dimension <italic>p</italic> and parameter for each method (marked on the top of each panel) is also shown. PT points with the best classification rates for each method are marked with an asterisk.</p>
        <p id="Par68">Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the classification performance of all parametric manifold learning techniques with respect to different values of the corresponding parameters. This figure shows how sensitive each method is (ISOMAP, diffusion maps, kPCA and LLE) to the changes of the parameter values. Details on the parameter grid selection are given in “<xref rid="Sec11" ref-type="sec">Construction of FCN with manifold learning algorithms</xref>” section.</p>
        <p id="Par69">As shown, diffusion maps resulted in the best classification accuracy (79.3%, using RSVM and 52% PT), thus appearing more robust over a wide range of PTs (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). With respect to the maximum classification accuracy obtained by diffusion maps, results were robust over a wide range of values of <inline-formula id="IEq188"><alternatives><tex-math id="M431">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma \in (0.28,0.35)$$\end{document}</tex-math><mml:math id="M432"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0.28</mml:mn><mml:mo>,</mml:mo><mml:mn>0.35</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq188.gif"/></alternatives></inline-formula> as it can be seen in Fig. <xref rid="Fig5" ref-type="fig">5</xref>B. All classifiers had maximum classification rates above 70%.</p>
        <p id="Par70">ISOMAP performed relatively better for lower PTs (Fig. <xref rid="Fig4" ref-type="fig">4</xref>), with the best classification rate being at 74.4% (using RSVM and 24% PT). Its performance was however sensitive to the choice of the number <italic>k</italic> of nearest neighbors; with <inline-formula id="IEq189"><alternatives><tex-math id="M433">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=5$$\end{document}</tex-math><mml:math id="M434"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq189.gif"/></alternatives></inline-formula>, we got a 74.4% classification accuracy while for <inline-formula id="IEq190"><alternatives><tex-math id="M435">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=4$$\end{document}</tex-math><mml:math id="M436"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq190.gif"/></alternatives></inline-formula>, we got a classification rate below 70% for all classifiers (Fig. <xref rid="Fig5" ref-type="fig">5</xref>A). In terms of the maximum classification rate, kPCA and LLE performed similarly to the cross correlation matrix (see Table <xref rid="Tab1" ref-type="table">1</xref>). LLE was sensitive to the choice of <italic>k</italic> nearest neighbours; with <inline-formula id="IEq191"><alternatives><tex-math id="M437">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=7$$\end{document}</tex-math><mml:math id="M438"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq191.gif"/></alternatives></inline-formula>, LLE peaked at 70.7 % classification accuracy (using ANN and 52% PT ) while for most of the other values of <italic>k</italic>, the accuracy was below or nearly 65% (Fig. <xref rid="Fig5" ref-type="fig">5</xref>D). For kPCA and MDS the linear classifier (LSVM) consistently performed poorly resulting in most cases to a classification accuracy below 60% (Figs. <xref rid="Fig4" ref-type="fig">4</xref>, <xref rid="Fig5" ref-type="fig">5</xref>C). MDS was outperformed by all other methods (Table <xref rid="Tab1" ref-type="table">1</xref>); only the RSVM’s performance was relatively robust against thresholding (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). At most of the PT points, the performance of all the other classifiers was poor (the accuracy rates were below 60 %). On the other hand, diffusion maps and kPCA appeared more robust to the choice of parameter values (Fig. <xref rid="Fig5" ref-type="fig">5</xref>B, C).</p>
        <p id="Par71">For most of the manifold learning methods, the classifier that worked better was the RSVM classifier both in terms of the maximum classification rate but also with respect to different PT points (Table <xref rid="Tab1" ref-type="table">1</xref>, Fig. <xref rid="Fig4" ref-type="fig">4</xref>). RSVM gave the highest maximum classification rate for the four out of the five manifold learning methods. Only for LLE, the ANN produced the highest accuracy rate at 70.7%.<fig id="Fig4"><label>Fig. 4</label><caption><p>Overall classification performance for all thresholds (from 20 to 70% of the strongest edges with 2% as step) and classifiers using the optimal parameters. The metric used is the cross correlation based pseudo-distance measure <inline-formula id="IEq192"><alternatives><tex-math id="M439">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_c$$\end{document}</tex-math><mml:math id="M440"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq192.gif"/></alternatives></inline-formula> (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section). The PT point with the best classification rate is marked with an asterisk “*”</p></caption><graphic xlink:href="11571_2020_9645_Fig4_HTML" id="MO32"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>Classification performance of the parametric manifold learning techniques with respect to different parameter values. <bold>A</bold> ISOMAP (<italic>k</italic>), <bold>B</bold> diffusion maps (<inline-formula id="IEq193"><alternatives><tex-math id="M441">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M442"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq193.gif"/></alternatives></inline-formula>), <bold>C</bold> kPCA (<inline-formula id="IEq194"><alternatives><tex-math id="M443">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M444"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq194.gif"/></alternatives></inline-formula>), <bold>D</bold> LLE (<italic>k</italic>). The metric used is the pseudo-distance measure <inline-formula id="IEq195"><alternatives><tex-math id="M445">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_c$$\end{document}</tex-math><mml:math id="M446"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq195.gif"/></alternatives></inline-formula> (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section) based on cross correlation</p></caption><graphic xlink:href="11571_2020_9645_Fig5_HTML" id="MO33"/></fig></p>
        <p id="Par72">Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the characteristic eigenspectrum of MDS, ISOMAP, diffusion maps, kPCA and LLE. As it is shown, in most of the cases there are three gaps: the first gap appears between the first eigenvalue and the rest of the spectrum, the second gap between the first two eigenvalues and the rest of the spectrum, and a third gap appears between the first four-five eigenvalues and the rest of the spectrum. Especially for the case of the LLE, we are interested in the smallest eigenvalues (see “<xref rid="Sec16" ref-type="sec">Construction of FCN using locally linear embedding</xref>” section) of the final decomposition. For visualization purposes, we show the eigenspectrum in a similar manner using the function <inline-formula id="IEq196"><alternatives><tex-math id="M447">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu ({\mathbf {i,j}})=\frac{\mathbf {1}}{\lambda _{\mathbf {M-i}}-\lambda _{\mathbf {M-j}}}$$\end{document}</tex-math><mml:math id="M448"><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq196.gif"/></alternatives></inline-formula>, which is the inverse of the pairwise differences between the 15 smaller eigenvalues. In all cases, as dictated by the corresponding gaps, we considered a maximum of five eigendimensions for the construction of the embedded FCN (see “<xref rid="Sec17" ref-type="sec">Choice of the embedding dimension</xref>” section).<fig id="Fig6"><label>Fig. 6</label><caption><p>Mean differences of the 15 largest (smallest for the LLE) eigenvalues (see “<xref rid="Sec17" ref-type="sec">Choice of the embedding dimension</xref>” section) for all manifold learning algorithms using the cross correlation-based pseudo distance measure <inline-formula id="IEq197"><alternatives><tex-math id="M449">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_{c}$$\end{document}</tex-math><mml:math id="M450"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq197.gif"/></alternatives></inline-formula> (see “<xref rid="Sec9" ref-type="sec">Construction of FCN based on cross correlation</xref>” section). <bold>A</bold> MDS (see in “<xref rid="Sec12" ref-type="sec">Construction of FCN with MDS</xref>” section), <bold>B</bold> ISOMAP (see in “<xref rid="Sec13" ref-type="sec">Construction of FCN using ISOMAP</xref>” section), <bold>C</bold> diffusion maps (see in “<xref rid="Sec14" ref-type="sec">Construction of FCN using diffusion maps</xref>” section), <bold>D</bold> kPCA (see in “<xref rid="Sec15" ref-type="sec">Construction of FCN using kernel principal component analysis</xref>” section), <bold>E</bold> LLE (see in “<xref rid="Sec16" ref-type="sec">Construction of FCN using locally linear embedding</xref>” section) based on the optimal parameters. The red dashed vertical line marks the maximum number of dimensions considered in this study [i.e. the 5 dimensions (see “<xref rid="Sec17" ref-type="sec">Choice of the embedding dimension</xref>” section)]. For the case of LLE, the function <inline-formula id="IEq198"><alternatives><tex-math id="M451">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu ({\mathbf {i,j}})=\frac{\mathbf {1}}{\lambda _{\mathbf {M-i}}-\lambda _{\mathbf {M-j}}}$$\end{document}</tex-math><mml:math id="M452"><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq198.gif"/></alternatives></inline-formula> was used for visualization purposes as we are interested in the smallest eigenvalues (trivial eigenvalue <inline-formula id="IEq199"><alternatives><tex-math id="M453">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{M}=0$$\end{document}</tex-math><mml:math id="M454"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq199.gif"/></alternatives></inline-formula> is discarded). (Color figure online)</p></caption><graphic xlink:href="11571_2020_9645_Fig6_HTML" id="MO34"/></fig></p>
      </sec>
      <sec id="Sec23">
        <title>Classification performance using the Euclidean distance</title>
        <p id="Par73">The same analysis was performed for the Euclidean distance. The best classification rates using the Euclidean distance for all manifold learning methods and classifiers are presented in Table <xref rid="Tab2" ref-type="table">2</xref>. At the end of Table <xref rid="Tab2" ref-type="table">2</xref>, we present the results for the (thresholded) Euclidean matrix.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Best classification rates over all manifold learning methods and classifiers with the use of the Euclidean distance <inline-formula id="IEq200"><alternatives><tex-math id="M455">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M456"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq200.gif"/></alternatives></inline-formula> (see “<xref rid="Sec10" ref-type="sec">Construction of FCN based on the Euclidean distance</xref>” section); parameters, PT, classifier, accuracy (Acc), sensitivity (Sens) and specificity (Spec) rates. Classifiers are noted as RSVM (Radial SVM), LSVM (Linear SVM), k-NN (k-NN Classifier) and ANN (Artificial Neural Networks)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">Parameters</th><th align="left">PT</th><th align="left">Classifier</th><th align="left">Acc ± SD (%)</th><th align="left">Sens (%)</th><th align="left">Spec (%)</th></tr></thead><tbody><tr><td align="left" rowspan="4"><italic>MDS</italic></td><td align="left" rowspan="4"><italic>p</italic> = 3</td><td char="." align="char">0.54</td><td align="left">RSVM</td><td align="left"><bold>72.3</bold> ± <bold>1.7</bold></td><td align="left">52.8</td><td align="left">83.4</td></tr><tr><td char="." align="char">0.36</td><td align="left">LSVM</td><td align="left">57.9 ± 2.5</td><td align="left">26.6</td><td align="left">79.6</td></tr><tr><td char="." align="char">0.26</td><td align="left">k-NN</td><td align="left">65.7 ± 2.2</td><td align="left">59.6</td><td align="left">66.1</td></tr><tr><td char="." align="char">0.44</td><td align="left">ANN</td><td align="left">64.9 ± 2.6</td><td align="left">53.7</td><td align="left">69.5</td></tr><tr><td align="left" rowspan="4"><italic>ISOMAP</italic></td><td align="left" rowspan="4"><italic>p</italic> = 2, <italic>k</italic> = 5</td><td char="." align="char">0.68</td><td align="left">RSVM</td><td align="left"><bold>72.9</bold> ± <bold>2</bold></td><td align="left">55.8</td><td align="left">81.9</td></tr><tr><td char="." align="char">0.42</td><td align="left">LSVM</td><td align="left">54.6 ± 0.1</td><td align="left">0</td><td align="left">95.9</td></tr><tr><td char="." align="char">0.68</td><td align="left">k-NN</td><td align="left">65 ± 2.3</td><td align="left">47.7</td><td align="left">74.7</td></tr><tr><td char="." align="char">0.66</td><td align="left">ANN</td><td align="left">68.2 ± 1.8</td><td align="left">47.4</td><td align="left">80.4</td></tr><tr><td align="left" rowspan="4"><italic>Diffusion maps</italic></td><td align="left" rowspan="4"><italic>p</italic> = 5, <inline-formula id="IEq201"><alternatives><tex-math id="M457">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M458"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq201.gif"/></alternatives></inline-formula> = 110</td><td char="." align="char">0.66</td><td align="left">RSVM</td><td align="left"><bold>68.8</bold> ± <bold>2.2</bold></td><td align="left">57.7</td><td align="left">73.1</td></tr><tr><td char="." align="char">0.52</td><td align="left">LSVM</td><td align="left">62.9 ± 1.9</td><td align="left">56.7</td><td align="left">63.5</td></tr><tr><td char="." align="char">0.26</td><td align="left">k-NN</td><td align="left">65.1 ± 2.5</td><td align="left">63.3</td><td align="left">61.7</td></tr><tr><td char="." align="char">0.5</td><td align="left">ANN</td><td align="left">63.9 ± 2.6</td><td align="left">71.4</td><td align="left">53.2</td></tr><tr><td align="left" rowspan="4"><italic>kPCA</italic></td><td align="left" rowspan="4"><italic>p</italic> = 5, <inline-formula id="IEq202"><alternatives><tex-math id="M459">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M460"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq202.gif"/></alternatives></inline-formula> = 11.5</td><td char="." align="char">0.62</td><td align="left">RSVM</td><td align="left">67.1 ± 1.3</td><td align="left">37.1</td><td align="left">87.1</td></tr><tr><td char="." align="char">0.28</td><td align="left">LSVM</td><td align="left">62.1 ± 1.6</td><td align="left">56.8</td><td align="left">62.9</td></tr><tr><td char="." align="char">0.64</td><td align="left">k-NN</td><td align="left">62.7 ± 2.8</td><td align="left">56.7</td><td align="left">63.3</td></tr><tr><td char="." align="char">0.62</td><td align="left">ANN</td><td align="left"><bold>67.2</bold> ± <bold>1.6</bold></td><td align="left">62.1</td><td align="left">66.8</td></tr><tr><td align="left" rowspan="4"><italic>LLE</italic></td><td align="left" rowspan="4"><italic>p</italic> = 3, <italic>k</italic> = 3</td><td char="." align="char">0.48</td><td align="left">RSVM</td><td align="left"><bold>70.3</bold> ± <bold>2.6</bold></td><td align="left">67.9</td><td align="left">67.3</td></tr><tr><td char="." align="char">0.26</td><td align="left">LSVM</td><td align="left">70.2 ± 1.4</td><td align="left">68.9</td><td align="left">66.4</td></tr><tr><td char="." align="char">0.28</td><td align="left">k-NN</td><td align="left">65.3 ± 2.7</td><td align="left">59.4</td><td align="left">65.4</td></tr><tr><td char="." align="char">0.26</td><td align="left">ANN</td><td align="left">70 ± 2</td><td align="left">64.3</td><td align="left">70</td></tr><tr><td align="left" rowspan="4"><italic>Euclidean matrix</italic></td><td align="left" rowspan="4">–</td><td char="." align="char">0.64</td><td align="left">RSVM</td><td align="left">71.6 ± 1.7</td><td align="left">60.1</td><td align="left">76.1</td></tr><tr><td char="." align="char">0.58</td><td align="left">LSVM</td><td align="left">59.2 ± 2.5</td><td align="left">62.5</td><td align="left">52.3</td></tr><tr><td char="." align="char">0.64</td><td align="left">k-NN</td><td align="left"><bold>72</bold> ± <bold>2.2</bold></td><td align="left">67.5</td><td align="left">70.6</td></tr><tr><td char="." align="char">0.70</td><td align="left">ANN</td><td align="left">62.1 ± 2.6</td><td align="left">60.4</td><td align="left">59.1</td></tr></tbody></table></table-wrap></p>
        <p id="Par74">Figure <xref rid="Fig7" ref-type="fig">7</xref> provides a visualization of the connectivity matrices for the same patient and the same healthy control of Fig. <xref rid="Fig2" ref-type="fig">2</xref> across different values of PT (at 20%, 35%, 50% and 65% of the strongest edges). The metric used is the Euclidean distance <inline-formula id="IEq203"><alternatives><tex-math id="M461">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M462"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq203.gif"/></alternatives></inline-formula> (see “<xref rid="Sec10" ref-type="sec">Construction of FCN based on the Euclidean distance</xref>” section).<fig id="Fig7"><label>Fig. 7</label><caption><p>Visualization of the connectivity matrix constructed with the Euclidean distance <inline-formula id="IEq204"><alternatives><tex-math id="M463">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M464"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq204.gif"/></alternatives></inline-formula> (see “<xref rid="Sec10" ref-type="sec">Construction of FCN based on the Euclidean distance</xref>” section) of a patient and a healthy control for different values of PT</p></caption><graphic xlink:href="11571_2020_9645_Fig7_HTML" id="MO35"/></fig></p>
        <p id="Par75">Figure <xref rid="Fig8" ref-type="fig">8</xref> depicts the accuracy of all methods across all thresholds and classifiers. Figure <xref rid="Fig9" ref-type="fig">9</xref> shows the maximum classification accuracy of all parametric methods for different values of the parameters.</p>
        <p id="Par76">Here, the best classification accuracy was obtained with ISOMAP (72.9% using RSVM and 68 % PT ); ISOMAP slightly outperformed the Euclidean matrix (which yielded 72% using the k-nn classifier and 64% PT). The choice of <italic>k</italic> nearest neighbours affected the performance of ISOMAP as for any other <italic>k</italic> the accuracy was below 70% (Fig. <xref rid="Fig9" ref-type="fig">9</xref>A). The LSVM performed poorly for most manifold learning methods with the exception of the LLE (Fig. <xref rid="Fig8" ref-type="fig">8</xref>); LLE was more robust with respect to different thresholds (Fig. <xref rid="Fig8" ref-type="fig">8</xref>) with the maximum classification rates reaching 70% for the three out of the four classifiers used (only the k-NN classifier peaked at 65.3%); Its best performance was 70.3% using RSVM and 48% PT. LLE was again sensitive to the choice of <italic>k</italic> nearest neighbours as for larger numbers of <italic>k</italic>, the accuracy dropped for all classifiers (Fig. <xref rid="Fig9" ref-type="fig">9</xref>D). The kPCA was not robust against thresholding (Fig. <xref rid="Fig8" ref-type="fig">8</xref>) while different parameter values did not change much its performance (Fig. <xref rid="Fig9" ref-type="fig">9</xref>C). In terms of maximum classification accuracy kPCA performed worse than any other method used (Table <xref rid="Tab2" ref-type="table">2</xref>), with a peak at 67.2% using ANN and 62% PT. Diffusion maps yielded a maximum classification of 68.8 % using RSVM and 66% PT; the performance was generally similar to the one of the Euclidean matrix, yet with a lower maximum classification rate; different values of the parameter <inline-formula id="IEq205"><alternatives><tex-math id="M465">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M466"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq205.gif"/></alternatives></inline-formula> did not change a lot the classification rates for most classifiers (Fig. <xref rid="Fig9" ref-type="fig">9</xref>B). Finally, MDS yielded a 72.3% using RSVM and 54% PT. In terms of the maximum classification accuracy, MDS performed similarly to the Euclidean matrix and ISOMAP (Table <xref rid="Tab2" ref-type="table">2</xref>). Finally, RSVM produced again the highest classification accuracy for most of the manifold learning algorithms.<fig id="Fig8"><label>Fig. 8</label><caption><p>Classification performance using the Euclidean distance <inline-formula id="IEq206"><alternatives><tex-math id="M467">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M468"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq206.gif"/></alternatives></inline-formula> (see “<xref rid="Sec10" ref-type="sec">Construction of FCN based on the Euclidean distance</xref>” section) for all thresholds (from 20 to 70% of the strongest edges with 2% as step) and classifiers. The PT point with the best classification rate is marked with an asterisk “*”</p></caption><graphic xlink:href="11571_2020_9645_Fig8_HTML" id="MO36"/></fig><fig id="Fig9"><label>Fig. 9</label><caption><p>Classification performance of the parametric manifold learning techniques with respect to different parameter values. <bold>A</bold> ISOMAP (<italic>k</italic>), <bold>B</bold> diffusion maps (<inline-formula id="IEq207"><alternatives><tex-math id="M469">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M470"><mml:mi>σ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq207.gif"/></alternatives></inline-formula>), <bold>C</bold> kPCA (<inline-formula id="IEq208"><alternatives><tex-math id="M471">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M472"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq208.gif"/></alternatives></inline-formula>), <bold>D</bold> LLE (<italic>k</italic>). The metric used is the the Euclidean distance <inline-formula id="IEq209"><alternatives><tex-math id="M473">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M474"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq209.gif"/></alternatives></inline-formula> (see “<xref rid="Sec10" ref-type="sec">Construction of FCN based on the Euclidean distance</xref>” section)</p></caption><graphic xlink:href="11571_2020_9645_Fig9_HTML" id="MO37"/></fig><fig id="Fig10"><label>Fig. 10</label><caption><p>Mean differences of the 15 largest (smallest for the LLE) eigenvalues (see “<xref rid="Sec17" ref-type="sec">Choice of the embedding dimension</xref>” section) for all manifold learning algorithms using the Euclidean distance <inline-formula id="IEq210"><alternatives><tex-math id="M475">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M476"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq210.gif"/></alternatives></inline-formula>. <bold>A</bold> MDS (see  “<xref rid="Sec12" ref-type="sec">Construction of FCN with MDS</xref>” section), <bold>B</bold> ISOMAP (see  “<xref rid="Sec13" ref-type="sec">Construction of FCN using ISOMAP</xref>” section), <bold>C</bold> diffusion maps (see “<xref rid="Sec14" ref-type="sec">Construction of FCN using diffusion maps</xref>” section), <bold>D</bold> kPCA (see “<xref rid="Sec15" ref-type="sec">Construction of FCN using kernel principal component analysis</xref>” section), <bold>E</bold> LLE (see “<xref rid="Sec16" ref-type="sec">Construction of FCN using locally linear embedding</xref>” section) using the optimal parameters. The red dashed vertical line marks the maximum number of dimensions considered (i.e. 5 dimensions, see “<xref rid="Sec17" ref-type="sec">Choice of the embedding dimension</xref>” section). For the case of LLE, the function <inline-formula id="IEq211"><alternatives><tex-math id="M477">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu ({\mathbf {i,j}})=\frac{\mathbf {1}}{\lambda _{\mathbf {M-i}}-\lambda _{\mathbf {M-j}}}$$\end{document}</tex-math><mml:math id="M478"><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">M</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq211.gif"/></alternatives></inline-formula> was used for visualization purposes as we are interested in the smallest eigenvalues (trivial eigenvalue <inline-formula id="IEq212"><alternatives><tex-math id="M479">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _{M} = 0$$\end{document}</tex-math><mml:math id="M480"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq212.gif"/></alternatives></inline-formula> is discarded). (Color figure online)</p></caption><graphic xlink:href="11571_2020_9645_Fig10_HTML" id="MO38"/></fig></p>
        <p id="Par77">Finally, Fig. <xref rid="Fig10" ref-type="fig">10</xref> depicts characteristic eigenspectrums for all manifold learning algorithms.</p>
      </sec>
      <sec id="Sec24">
        <title>Comparison between metrics</title>
        <p id="Par78">Figure <xref rid="Fig11" ref-type="fig">11</xref> illustrates the accuracy rates (as boxplots) for every method used based on the optimal parameters. The first panel (A) shows the accuracy rates when using the cross correlation metric, (B) shows the accuracy rates when using the Euclidean distance. At the extreme left of each panel the accuracy rates of the cross correlation matrix (Fig. <xref rid="Fig11" ref-type="fig">11</xref>A, Corr.Matrix) and the Euclidean matrix (Fig. <xref rid="Fig11" ref-type="fig">11</xref>B, Eucl.Matrix) are also shown. For each method, there are four boxplots of different colours, one for each classifier (i.e Linear SVM, Radial SVM, k-NN classifier and artificial Neural Nets). The black points denote an outlier of the distribution (here, the classification rates across all PTs) while the black horizontal lines mark the median value of the distribution.</p>
        <sec id="Sec25">
          <title>Comparison between the cross correlation and the Euclidean matrix</title>
          <p id="Par79">The cross correlation matrix yielded in general better results compared to the Euclidean matrix judging by the overall performance [i.e the median classification rates depicted by the black horizontal lines (see Fig. <xref rid="Fig11" ref-type="fig">11</xref>A, B)].</p>
        </sec>
        <sec id="Sec26">
          <title>Performance comparison of manifold learning methods</title>
          <p id="Par80">The general performance of MDS was relatively poor for both metrics. When using the cross correlation metric, the MDS was outperformed by any other method [the maximum classification accuracy for every classifier was lower compared to other methods (see Table <xref rid="Tab1" ref-type="table">1</xref>)]. On the other hand, with the Euclidean metric, only the RSVM resulted in high classification rates, thus performing similarly and/or slightly better than the Euclidean matrix (see Table <xref rid="Tab2" ref-type="table">2</xref>). ISOMAP performed similarly to the correlation matrix [when using the cross correlation metric (see Fig. <xref rid="Fig11" ref-type="fig">11</xref>A)] and the Euclidean matrix [when using the Euclidean distance (Fig. <xref rid="Fig11" ref-type="fig">11</xref>B)] but in both cases yielded better single maximum classification rates (74.4 % when using the correlation metric and 72.9% when using the Euclidean). An exception was the LSVM’s poor performance, especially when the Euclidean metric was used.</p>
          <p id="Par81">The diffusion maps with the cross correlation metric was superior to all other methods with respect to the overall performance, robustness against thresholding (Fig. <xref rid="Fig4" ref-type="fig">4</xref>) and maximum classification rate (see Table <xref rid="Tab1" ref-type="table">1</xref>). The diffusion maps scored the best classification rate (79.3% using RSVM). However, this was not the case when using the Euclidean metric. The overall performance of diffusion maps with the Euclidean metric was similar to the one of the Euclidean matrix but with lower maximum classification rates for two (RSVM and k-NN) out of the four classifiers used.</p>
          <p id="Par82">The performance of kPCA was poor for both metrics. The linear classifier’s accuracy rates (in both cases) was in general under 60%. Only the RSVM classifier performed similarly and sometimes better than the cross correlation matrix when using the cross correlation metric. Using the Euclidean as a metric for kPCA all median classification rates for all classifiers was below 60% (Fig. <xref rid="Fig11" ref-type="fig">11</xref>B).</p>
          <p id="Par83">The LLE with the cross correlation metric performed relatively poor for three (knn classifier, LSVM and ANN) out of the four classifiers used. Only the RSVM classifier performed similarly to the cross correlation matrix. On the other hand, when using the Euclidean distance, the LLE performed better (Fig. <xref rid="Fig11" ref-type="fig">11</xref>B). Despite the fact that it did not produce the best maximum classification rate, LLE was more robust against different values of PT and reached 70 % classification accuracy for three out of the four classifiers used.<fig id="Fig11"><label>Fig. 11</label><caption><p>Boxplots of classification rates over all classifiers and thresholds, using the (<bold>A</bold>) cross correlation pseudo-distance <inline-formula id="IEq213"><alternatives><tex-math id="M481">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d_c$$\end{document}</tex-math><mml:math id="M482"><mml:msub><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq213.gif"/></alternatives></inline-formula>, (<bold>B</bold>) the Euclidean distance <inline-formula id="IEq214"><alternatives><tex-math id="M483">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L_{2}$$\end{document}</tex-math><mml:math id="M484"><mml:msub><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq214.gif"/></alternatives></inline-formula>. The labels at the bottom of each panel correspond to the method used for the construction of the FCN: the cross correlation matrix (Corr. Matrix), the Euclidean matrix (Eucl.Matrix), MDS, ISOMAP, diffusion maps(DMaps), kPCA, LLE. The black horizontal lines mark the median values of the distributions</p></caption><graphic xlink:href="11571_2020_9645_Fig11_HTML" id="MO39"/></fig></p>
        </sec>
      </sec>
    </sec>
    <sec id="Sec27">
      <title>Discussion</title>
      <p id="Par84">In this study, we constructed embedded FCN from rsfMRI data using linear and non-linear manifold learning techniques. Based on fundamental graph theoretic measures of the constructed FCN, we then used machine learning algorithms for classification purposes. We also compared the performance of two widely used metrics in neuroimaging, namely the cross correlation and the Euclidean distance. For our demonstrations, we used a publicly available dataset of resting-state fMRI recordings taken from healthy and patients with schizophrenia. This is the first study that performs such a systematic comparative analysis between various manifold learning algorithms, machine learning algorithms and metrics. To the best of our knowledge, it is also the first study that shows how the algorithm of diffusion maps can be exploited to construct FCN from rsfMRI data.</p>
      <p id="Par85">At this point we should note that our intention was not to try to obtain the best possible classification performance by “optimising” the pre-processing of the raw fMRI data and/or by trying to find the best set of graph-theoretic measures [other studies have already shed light towards this direction (Čukić et al. <xref ref-type="bibr" rid="CR17">2020</xref>; Xiang et al. <xref ref-type="bibr" rid="CR105">2020</xref>; Vergara et al. <xref ref-type="bibr" rid="CR100">2017</xref>)]. For example Čukić et al. (<xref ref-type="bibr" rid="CR17">2020</xref>) showed that successful discrimination of depression from EEG could be attributed to proper feature extraction and not to a particular classification method. Thus, here we aimed at comparing mainly the manifold learning methods by factoring out the influence of a specific feature selection method; classification was based only on three key global graph-theoretic measures that are widely used in neuroscience (Stam and Reijneveld <xref ref-type="bibr" rid="CR91">2007</xref>; Bullmore and Sporns <xref ref-type="bibr" rid="CR11">2009</xref>), namely, the average path length, the global clustering coefficient and the median degree of the embedded binary networks. Indeed as also discussed in Bullmore and Sporns (<xref ref-type="bibr" rid="CR11">2009</xref>) the general brain network can be described at a global scale by the shortest path length which is associated with the transfer of information, the clustering coefficient associated with robustness to random error, and the degree associated with the existence of hubs, and a modular community structure. Even though, we could consider a few more global graph measures, we decided not to do so, as other measures like the global efficiency (in essence, the inverse of average path length) or the diameter of a graph (the largest path length of a graph from one vertex to another) are highly correlated with one (or more) of the three basic measures stated above (e.g. the global efficiency is the inverse of characteristic path length and the diameter of a graph is likely to be higher as the average path length gets larger). Based on the above fundamental graph measures, our best reported accuracy obtained with diffusion maps and cross correlation was 79.3 % (evaluated with a 10 fold cross validation scheme, repeated 100 times). The conventional methodology was outperformed in both overall performance and with respect to the maximum classification accuracy as there was an 8.3% difference in classification accuracy in favor of the diffusion maps.</p>
      <p id="Par86">For the same benchmark fMRI dataset, Anderson and Cohen (<xref ref-type="bibr" rid="CR3">2013</xref>) used ISOMAP for the construction of embedded FCN for the classification between heatlhy controls and schizophrenia patients. ROIs were acquired as here using single subject ICA and functional connectivity was accessed using the cross correlation distance. The analysis revealed differences in small-world properties among groups and 13 graph theoretic features led to a reported 65% accuracy rate. Xiang et al. (<xref ref-type="bibr" rid="CR105">2020</xref>) reported a 93.1% accuracy (with sparse group Lasso and 78.6% with a Welch’s <italic>t</italic> test) testing more than 1000 graph-based features. An anatomical atlas was used for signal extraction and ROI selection, while an SVM-based classifier was used along with a “leave one out” scheme to evaluate its performance. In the same study, the authors compare their method with other novel approaches that have been previously proposed (Cheng et al. <xref ref-type="bibr" rid="CR13">2015</xref>; Huang et al. <xref ref-type="bibr" rid="CR37">2018</xref>) by applying them on the COBRE dataset. Cheng et al. (<xref ref-type="bibr" rid="CR13">2015</xref>) calculated the betweenness centrality of nodes and used their ranks to classify patients with schizophrenia and healthy controls. For the COBRE dataset, this approach yielded a 74.4% classification accuracy. Finally, Huang et al. (<xref ref-type="bibr" rid="CR37">2018</xref>) used a tree-guided group sparse learning method to extract key information in four frequency bands. Applied on the COBRE dataset, the classification performance peaked at 77.3%.</p>
      <p id="Par87">Our best reported accuracy (79.3% evaluated with tenfold cross validation repeated 100 times) is still higher than some of the previously proposed methods applied to the same dataset.</p>
      <p id="Par88">Some recent studies have suggested that the correlation matrices lie on a non-linear manifold (Venkatesh et al. <xref ref-type="bibr" rid="CR99">2020</xref>). Regarding our results, the diffusion maps algorithm (based on the diffusion distance) and the ISOMAP (based on the geodesic distance) managed to outperform the correlation matrix (that is most frequently used in constructing FCN from fMRI data) in terms of classification accuracy. However, other techniques such as the LLE (locally preserving the distance among neighbours), the gaussian kernel PCA (the non linear extension of PCA) and the MDS (which preserves the Euclidean distances on the embedded manifold) performed similarly or poorer compared to the cross correlation matrix. On the other hand, when using the Euclidean distance as a metric of functional connectivity none of the methods used in this study exhibited much higher results than the Euclidean matrix (which was slightly outperformed by ISOMAP and MDS). However, LLE provided a more robust classification pattern with most of the classifiers reaching a 70% accuracy. Though in general, there is no single best manifold learning method outperforming all the others for both metrics, our study showed that the diffusion maps result in higher classification accuracy when using the cross correlation distance (10.5% difference with respect to the Euclidean distance) outperforming the “conventional” method for constructing FCN from fMRI data.</p>
      <p id="Par89">However, this study does not come without limitations. For example, the method chosen for signal extraction is the single-subject ICA (Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>). While this methodology holds the advantage of yielding subject-specific ICs (taking into account the within-subject variation), yet, due to this fact, we could not utilize local features in our graph theoretic analysis as the ICs (the nodes in the constructed graphs) were not the same across participants (even the number of ICs were different just like in Anderson and Cohen <xref ref-type="bibr" rid="CR3">2013</xref>). Thus, in order to factor out the influence of specific features, as discussed above, we used the three fundamental global theoretical measures to quantify differences among groups in the global topology of the network (Stam and Reijneveld <xref ref-type="bibr" rid="CR91">2007</xref>; Bullmore and Sporns <xref ref-type="bibr" rid="CR11">2009</xref>). An alternative method for the signal extraction could be the use of group-ICA. For example, a group-ICA analysis has been recently applied in a large fMRI dataset (151 healthy controls and 163 schizophrenia patients) for classification purposes (Salman et al. <xref ref-type="bibr" rid="CR74">2019</xref>); under this methodology the authors reached a maximum of 76.4% classification accuracy. While studies have shown that group-ICA can capture inter-subject spatial variability, it is not without limitations (Allen et al. <xref ref-type="bibr" rid="CR2">2012</xref>). For example group-ICA makes the assumption that each subject makes the same contribution to the observed “group” ICs, discarding random subject to subject variations. Thus, one cannot generalize the conclusions to the population (Friston et al. <xref ref-type="bibr" rid="CR28">1999</xref>). Hence, different approaches (such as the Independent Vector Analysis) have been suggested that seek for an optimal trade-off between group and individual representation, trying to preserve subject’s variability within a group (Michael et al. <xref ref-type="bibr" rid="CR57">2014</xref>).</p>
    </sec>
  </body>
  <back>
    <app-group>
      <app id="App1">
        <sec id="Sec28">
          <title>Appendix</title>
          <p id="Par92">For classification we used Linear Support Vector Machines (LSVM), Radial (Radial basis function kernel) Support Vector Machines (RSVM), one hidden layer Artificial Neural Networks (ANN) and k-NN classifier (k-NN). All classifiers were trained and evaluated via repeated tenfold cross validation scheme repeated 100 times. For the classification we used the three key graph theoretic measures as described in “<xref rid="Sec18" ref-type="sec">Graph-theoretic measures</xref>” and “<xref rid="Sec2" ref-type="sec">Materials and methods</xref>” sections. Training and classification were implemented using algorithms contained in package “caret” (Kuhn et al. <xref ref-type="bibr" rid="CR50">2008</xref>) publicly available in R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
          <sec id="Sec29">
            <title>Support vector machines (SVM)</title>
            <p id="Par93">Support vector machines (SVM) aim at finding the optimal separating plane or hyperplane in the feature space among groups. In particular, for a set of points <inline-formula id="IEq215"><alternatives><tex-math id="M485">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\mathbf {x}}_i,y_i)_{i=1,2\ldots N}$$\end{document}</tex-math><mml:math id="M486"><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>…</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq215.gif"/></alternatives></inline-formula>, where <italic>N</italic> is the number of subjects, <inline-formula id="IEq216"><alternatives><tex-math id="M487">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i\in {\mathbf {R}}^d$$\end{document}</tex-math><mml:math id="M488"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq216.gif"/></alternatives></inline-formula> contains <italic>d</italic> attributes/features selected for subject <italic>i</italic> and <inline-formula id="IEq217"><alternatives><tex-math id="M489">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_i \in (-1,1)$$\end{document}</tex-math><mml:math id="M490"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq217.gif"/></alternatives></inline-formula> the subject’s class (here, either healthy or patient), SVM attempts to find the optimal plane or hyperplane that divides the two classes by maximizing the margin of separation. Any hyperplane can be modelled as <inline-formula id="IEq219"><alternatives><tex-math id="M491">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {w}}\cdot {\mathbf {x}}_i+b=0$$\end{document}</tex-math><mml:math id="M492"><mml:mrow><mml:mi mathvariant="bold">w</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq219.gif"/></alternatives></inline-formula> where <inline-formula id="IEq220"><alternatives><tex-math id="M493">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {w}}$$\end{document}</tex-math><mml:math id="M494"><mml:mi mathvariant="bold">w</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq220.gif"/></alternatives></inline-formula> represent the weights of features <inline-formula id="IEq221"><alternatives><tex-math id="M495">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i$$\end{document}</tex-math><mml:math id="M496"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq221.gif"/></alternatives></inline-formula>. Parallel hyperplanes can be described as <inline-formula id="IEq222"><alternatives><tex-math id="M497">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {w}}\cdot {\mathbf {x}}_i+b \ge 1$$\end{document}</tex-math><mml:math id="M498"><mml:mrow><mml:mi mathvariant="bold">w</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq222.gif"/></alternatives></inline-formula> if <inline-formula id="IEq223"><alternatives><tex-math id="M499">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_i=1$$\end{document}</tex-math><mml:math id="M500"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq223.gif"/></alternatives></inline-formula> and <inline-formula id="IEq224"><alternatives><tex-math id="M501">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {w}}\cdot {\mathbf {x}}_i+b \le -1$$\end{document}</tex-math><mml:math id="M502"><mml:mrow><mml:mi mathvariant="bold">w</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>≤</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq224.gif"/></alternatives></inline-formula> if <inline-formula id="IEq225"><alternatives><tex-math id="M503">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_i=-1$$\end{document}</tex-math><mml:math id="M504"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq225.gif"/></alternatives></inline-formula>. The optimization problem then aims at maximizing the margin between hyperplanes <inline-formula id="IEq226"><alternatives><tex-math id="M505">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{2}{\Vert {\mathbf {w}}\Vert }$$\end{document}</tex-math><mml:math id="M506"><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq226.gif"/></alternatives></inline-formula> such that for every <inline-formula id="IEq227"><alternatives><tex-math id="M507">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(y_i)_{i=1,2\ldots N}, \, y_i\cdot ({\mathbf {w}}\cdot {\mathbf {x}}_i+b) \ge 1$$\end{document}</tex-math><mml:math id="M508"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>…</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq227.gif"/></alternatives></inline-formula>.</p>
            <p id="Par94">One can take advantage of a regularization parameter <italic>C</italic> indicating the penalty of error <inline-formula id="IEq228"><alternatives><tex-math id="M509">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z_i$$\end{document}</tex-math><mml:math id="M510"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq228.gif"/></alternatives></inline-formula> that gives a trade-off between misclassifications and the width of the separating margin. This leads to the final optimization problem, which minimizes <inline-formula id="IEq229"><alternatives><tex-math id="M511">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{\Vert {\mathbf {w}}\Vert ^2}{2}+ C\cdot \sum _{i}z_i$$\end{document}</tex-math><mml:math id="M512"><mml:mrow><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq229.gif"/></alternatives></inline-formula> subject to <inline-formula id="IEq230"><alternatives><tex-math id="M513">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_i\cdot ({\mathbf {w}} \cdot {\mathbf {x}}_i+b) \ge 1-z_i$$\end{document}</tex-math><mml:math id="M514"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq230.gif"/></alternatives></inline-formula>,   <inline-formula id="IEq231"><alternatives><tex-math id="M515">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i=1,2\ldots N$$\end{document}</tex-math><mml:math id="M516"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>…</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq231.gif"/></alternatives></inline-formula>.</p>
            <p id="Par95">Based on the idea that the data maybe better separable in a higher dimensional space, SVM may utilize a kernel function to map <inline-formula id="IEq232"><alternatives><tex-math id="M517">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i\in {\mathbf {R}}^d$$\end{document}</tex-math><mml:math id="M518"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq232.gif"/></alternatives></inline-formula> to <inline-formula id="IEq233"><alternatives><tex-math id="M519">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi ({\mathbf {x}}_i)\in {\mathbf {R}}^D$$\end{document}</tex-math><mml:math id="M520"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq233.gif"/></alternatives></inline-formula>, <inline-formula id="IEq234"><alternatives><tex-math id="M521">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D&gt;d$$\end{document}</tex-math><mml:math id="M522"><mml:mrow><mml:mi>D</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq234.gif"/></alternatives></inline-formula>. In our study, besides standard linear SVM (LSVM), we also used radial SVM (RSVM) making use of the radial basis functions kernel given by <inline-formula id="IEq235"><alternatives><tex-math id="M523">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K({\mathbf {x}}_i,{\mathbf {x}}_j)=exp\left( -\frac{\Vert {\mathbf {x}}_i-{\mathbf {x}}_j\Vert ^{2}}{2\cdot \gamma ^2}\right)$$\end{document}</tex-math><mml:math id="M524"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>·</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq235.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq236"><alternatives><tex-math id="M525">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\gamma$$\end{document}</tex-math><mml:math id="M526"><mml:mi>γ</mml:mi></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq236.gif"/></alternatives></inline-formula> is the kernel’s scale parameter.</p>
          </sec>
          <sec id="Sec30">
            <title>k-Nearest neighbours classifier(k-NN)</title>
            <p id="Par96">k-Nearest neighbours algorithm is one of the simplest classification/machine learning algorithms. Given <inline-formula id="IEq237"><alternatives><tex-math id="M527">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({\mathbf {x}}_i,y_i)_ {i=1,2\ldots N}$$\end{document}</tex-math><mml:math id="M528"><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>…</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq237.gif"/></alternatives></inline-formula>, where <italic>N</italic> is the number of subjects, <inline-formula id="IEq238"><alternatives><tex-math id="M529">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf {x}}_i\in {\mathbf {R}}^d$$\end{document}</tex-math><mml:math id="M530"><mml:mrow><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq238.gif"/></alternatives></inline-formula> contains <italic>d</italic> attributes/features selected for subject <italic>i</italic> and <inline-formula id="IEq239"><alternatives><tex-math id="M531">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_i$$\end{document}</tex-math><mml:math id="M532"><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq239.gif"/></alternatives></inline-formula> the subject’s class (here, either healthy or patient), k-NN utilizes Euclidean distance in the feature space to perform a voting system among <italic>k</italic> closest neighbours. In this manner, each point is classified as “control”, if the number of “control” neighbours is greater than the number of “patient” neighbours and inversely. The number <italic>k</italic> of closest neighbours is a parameter of choice that plays a crucial role in method’s performance. In this study, it is important to note that we chose odd values of <italic>k</italic> (i.e how many neighbours we take into consideration) in order not to have to break possible ties in the voting system among neighbours</p>
          </sec>
          <sec id="Sec31">
            <title>Artificial neural networks (ANN)</title>
            <p id="Par97">In this study, we also used feed-forward artificial neural networks (ANN) consisting of one hidden layer. The input units were three as the number of the features considered for classification. We have chosen one hidden layer consisting from 1 to 5 neurons along with a bias term. The activation function used for all neurons was the logistic transfer function (Ripley <xref ref-type="bibr" rid="CR70">2007</xref>). The output was one node (reflecting simple binary classification control/patient). The training procedure of the model was done via back-propagation (Hecht-Nielsen <xref ref-type="bibr" rid="CR34">1992</xref>) using a tenfold cross validation scheme. Finally a weight decay parameter <italic>a</italic> (regularization parameter) was used to prevent over-fitting and improve generalization (Krogh and Hertz <xref ref-type="bibr" rid="CR48">1992</xref>) of the final model. For the implementation of the ANN we used the “nnet” software package (Ripley and Venables <xref ref-type="bibr" rid="CR71">2011</xref>) publicly available in R free software environment (Team <xref ref-type="bibr" rid="CR93">2014</xref>).</p>
          </sec>
          <sec id="Sec32">
            <title>Parameters tested for each classifier</title>
            <p id="Par98">We tuned the parameters of the algorithms via grid search.</p>
            <p id="Par99">For the SVM:<disp-formula id="Equ29"><alternatives><tex-math id="M533">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} C&amp;= (0.1,0.25,0.5,0.75,1,2.5,5,7.5,10,\\&amp;25,50,75,100,250,500,750,1000)\\ \gamma&amp;= (0.001,0.01,0.1,0.25,0.5,0.75,1,2.5,5,\\&amp;7.5,10,25,50,75,100,250,500,750,1000). \end{aligned}$$\end{document}</tex-math><mml:math id="M534" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mi>C</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.75</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>7.5</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo>,</mml:mo><mml:mn>75</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>500</mml:mn><mml:mo>,</mml:mo><mml:mn>750</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow/><mml:mi>γ</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mn>0.75</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>7.5</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo>,</mml:mo><mml:mn>75</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>250</mml:mn><mml:mo>,</mml:mo><mml:mn>500</mml:mn><mml:mo>,</mml:mo><mml:mn>750</mml:mn><mml:mo>,</mml:mo><mml:mn>1000</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="11571_2020_9645_Article_Equ29.gif" position="anchor"/></alternatives></disp-formula>For the k-NN classifier: <inline-formula id="IEq240"><alternatives><tex-math id="M535">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\kappa = (1,3,5,7,9)$$\end{document}</tex-math><mml:math id="M536"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>7</mml:mn><mml:mo>,</mml:mo><mml:mn>9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq240.gif"/></alternatives></inline-formula>.</p>
            <p id="Par100">For the ANN: number of neurons in the hidden layer <inline-formula id="IEq241"><alternatives><tex-math id="M537">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = (1,2,3,4,5)$$\end{document}</tex-math><mml:math id="M538"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq241.gif"/></alternatives></inline-formula>, decay level <inline-formula id="IEq242"><alternatives><tex-math id="M539">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a= (0.0001,0.001,0.01,0.025,0.05,0.075,0.1)$$\end{document}</tex-math><mml:math id="M540"><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0.0001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.001</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.025</mml:mn><mml:mo>,</mml:mo><mml:mn>0.05</mml:mn><mml:mo>,</mml:mo><mml:mn>0.075</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="11571_2020_9645_Article_IEq242.gif"/></alternatives></inline-formula>.</p>
          </sec>
        </sec>
      </app>
    </app-group>
    <fn-group>
      <fn>
        <p>
          <bold>Publisher's Note</bold>
        </p>
        <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
      </fn>
    </fn-group>
    <notes notes-type="author-contribution">
      <title>Author contributions</title>
      <p>Conceptualization:CS; Methodology: CS; Formal analysis and investigation: IG; Data processing: IG and EG; Writing- original draft preparation: IG; Writing - review and editing: CS and IG; Supervision:CS.</p>
    </notes>
    <notes notes-type="funding-information">
      <title>Funding</title>
      <p>Open access funding provided by Università degli Studi di Napoli Federico II within the CRUI-CARE Agreement. </p>
    </notes>
    <notes notes-type="data-availability">
      <title>Data availability</title>
      <p>The COBRE dataset is publicly available at http://fcon_1000.projects.nitrc.org/indi/retro/cobre.html. For our analysis, we used the “R” software subroutines as described in “<xref rid="Sec2" ref-type="sec">Materials and methods</xref>” section and “<xref rid="Sec28" ref-type="sec">Appendix</xref>”.</p>
    </notes>
    <ref-list id="Bib1">
      <title>References</title>
      <ref id="CR1">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Algunaid</surname>
              <given-names>RF</given-names>
            </name>
            <name>
              <surname>Algumaei</surname>
              <given-names>AH</given-names>
            </name>
            <name>
              <surname>Rushdi</surname>
              <given-names>MA</given-names>
            </name>
            <name>
              <surname>Yassine</surname>
              <given-names>IA</given-names>
            </name>
          </person-group>
          <article-title>Schizophrenic patient identification using graph-theoretic features of resting-state fMRI data</article-title>
          <source>Biomed Signal Process Control</source>
          <year>2018</year>
          <volume>43</volume>
          <fpage>289</fpage>
          <lpage>299</lpage>
          <pub-id pub-id-type="doi">10.1016/j.bspc.2018.02.018</pub-id>
        </element-citation>
      </ref>
      <ref id="CR2">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Allen</surname>
              <given-names>EA</given-names>
            </name>
            <name>
              <surname>Erhardt</surname>
              <given-names>EB</given-names>
            </name>
            <name>
              <surname>Wei</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Eichele</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
          </person-group>
          <article-title>Capturing inter-subject variability with group independent component analysis of fMRI data: a simulation study</article-title>
          <source>Neuroimage</source>
          <year>2012</year>
          <volume>59</volume>
          <issue>4</issue>
          <fpage>4141</fpage>
          <lpage>4159</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.010</pub-id>
          <pub-id pub-id-type="pmid">22019879</pub-id>
        </element-citation>
      </ref>
      <ref id="CR3">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anderson</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Cohen</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Decreased small-world functional network connectivity and clustering across resting state networks in schizophrenia: an fMRI classification tutorial</article-title>
          <source>Front Hum Neurosci</source>
          <year>2013</year>
          <volume>7</volume>
          <fpage>520</fpage>
          <pub-id pub-id-type="pmid">24032010</pub-id>
        </element-citation>
      </ref>
      <ref id="CR4">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anderson</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Dinov</surname>
              <given-names>ID</given-names>
            </name>
            <name>
              <surname>Sherin</surname>
              <given-names>JE</given-names>
            </name>
            <name>
              <surname>Quintana</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Yuille</surname>
              <given-names>AL</given-names>
            </name>
            <name>
              <surname>Cohen</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Classification of spatially unaligned fMRI scans</article-title>
          <source>Neuroimage</source>
          <year>2010</year>
          <volume>49</volume>
          <issue>3</issue>
          <fpage>2509</fpage>
          <lpage>2519</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.08.036</pub-id>
          <pub-id pub-id-type="pmid">19712744</pub-id>
        </element-citation>
      </ref>
      <ref id="CR5">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Baumgartner</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Ryner</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Richter</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Summers</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Jarmasz</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Somorjai</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Comparison of two exploratory data analysis methods for fMRI: fuzzy clustering vs. principal component analysis</article-title>
          <source>Magn Reson Imaging</source>
          <year>2000</year>
          <volume>18</volume>
          <issue>1</issue>
          <fpage>89</fpage>
          <lpage>94</lpage>
          <pub-id pub-id-type="doi">10.1016/S0730-725X(99)00102-2</pub-id>
          <pub-id pub-id-type="pmid">10642106</pub-id>
        </element-citation>
      </ref>
      <ref id="CR6">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
          </person-group>
          <article-title>Probabilistic independent component analysis for functional magnetic resonance imaging</article-title>
          <source>IEEE Trans Med Imaging</source>
          <year>2004</year>
          <volume>23</volume>
          <issue>2</issue>
          <fpage>137</fpage>
          <lpage>152</lpage>
          <pub-id pub-id-type="doi">10.1109/TMI.2003.822821</pub-id>
          <pub-id pub-id-type="pmid">14964560</pub-id>
        </element-citation>
      </ref>
      <ref id="CR7">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
          </person-group>
          <article-title>Tensorial extensions of independent component analysis for multisubject fMRI analysis</article-title>
          <source>Neuroimage</source>
          <year>2005</year>
          <volume>25</volume>
          <issue>1</issue>
          <fpage>294</fpage>
          <lpage>311</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.10.043</pub-id>
          <pub-id pub-id-type="pmid">15734364</pub-id>
        </element-citation>
      </ref>
      <ref id="CR8">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
            <name>
              <surname>DeLuca</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Devlin</surname>
              <given-names>JT</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
          </person-group>
          <article-title>Investigations into resting-state connectivity using independent component analysis</article-title>
          <source>Philos Trans R Soc B Biol Sci</source>
          <year>2005</year>
          <volume>360</volume>
          <issue>1457</issue>
          <fpage>1001</fpage>
          <lpage>1013</lpage>
          <pub-id pub-id-type="doi">10.1098/rstb.2005.1634</pub-id>
        </element-citation>
      </ref>
      <ref id="CR9">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Belkin</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Niyogi</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Laplacian eigenmaps for dimensionality reduction and data representation</article-title>
          <source>Neural Comput</source>
          <year>2003</year>
          <volume>15</volume>
          <issue>6</issue>
          <fpage>1373</fpage>
          <lpage>1396</lpage>
          <pub-id pub-id-type="doi">10.1162/089976603321780317</pub-id>
        </element-citation>
      </ref>
      <ref id="CR10">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Benjaminsson</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Fransson</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Lansner</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>A novel model-free data analysis technique based on clustering in a mutual information space: application to resting-state fMRI</article-title>
          <source>Front Syst Neurosci</source>
          <year>2010</year>
          <volume>4</volume>
          <fpage>34</fpage>
          <pub-id pub-id-type="pmid">20721313</pub-id>
        </element-citation>
      </ref>
      <ref id="CR11">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bullmore</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Sporns</surname>
              <given-names>O</given-names>
            </name>
          </person-group>
          <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>
          <source>Nat Rev Neurosci</source>
          <year>2009</year>
          <volume>10</volume>
          <issue>3</issue>
          <fpage>186</fpage>
          <lpage>198</lpage>
          <pub-id pub-id-type="doi">10.1038/nrn2575</pub-id>
          <pub-id pub-id-type="pmid">19190637</pub-id>
        </element-citation>
      </ref>
      <ref id="CR12">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
            <name>
              <surname>Sui</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Kiehl</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Turner</surname>
              <given-names>JA</given-names>
            </name>
            <name>
              <surname>Allen</surname>
              <given-names>EA</given-names>
            </name>
            <name>
              <surname>Pearlson</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Exploring the psychosis functional connectome: aberrant intrinsic networks in schizophrenia and bipolar disorder</article-title>
          <source>Front Psychiatry</source>
          <year>2012</year>
          <volume>2</volume>
          <fpage>75</fpage>
          <pub-id pub-id-type="doi">10.3389/fpsyt.2011.00075</pub-id>
          <pub-id pub-id-type="pmid">22291663</pub-id>
        </element-citation>
      </ref>
      <ref id="CR13">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cheng</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Newman</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Goñi</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Kent</surname>
              <given-names>JS</given-names>
            </name>
            <name>
              <surname>Howell</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Bolbecker</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Puce</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>O’Donnell</surname>
              <given-names>BF</given-names>
            </name>
            <name>
              <surname>Hetrick</surname>
              <given-names>WP</given-names>
            </name>
          </person-group>
          <article-title>Nodal centrality of functional network in the differentiation of schizophrenia</article-title>
          <source>Schizophr Res</source>
          <year>2015</year>
          <volume>168</volume>
          <issue>1–2</issue>
          <fpage>345</fpage>
          <lpage>352</lpage>
          <pub-id pub-id-type="doi">10.1016/j.schres.2015.08.011</pub-id>
          <pub-id pub-id-type="pmid">26299706</pub-id>
        </element-citation>
      </ref>
      <ref id="CR14">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Coifman</surname>
              <given-names>RR</given-names>
            </name>
            <name>
              <surname>Lafon</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Diffusion maps</article-title>
          <source>Appl Comput Harmon Anal</source>
          <year>2006</year>
          <volume>21</volume>
          <issue>1</issue>
          <fpage>5</fpage>
          <lpage>30</lpage>
          <pub-id pub-id-type="doi">10.1016/j.acha.2006.04.006</pub-id>
        </element-citation>
      </ref>
      <ref id="CR15">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cole</surname>
              <given-names>DM</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
          </person-group>
          <article-title>Advances and pitfalls in the analysis and interpretation of resting-state fMRI data</article-title>
          <source>Front Syst Neurosci</source>
          <year>2010</year>
          <volume>4</volume>
          <fpage>8</fpage>
          <pub-id pub-id-type="pmid">20407579</pub-id>
        </element-citation>
      </ref>
      <ref id="CR16">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Csardi</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Nepusz</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>The igraph software package for complex network research</article-title>
          <source>Int J Complex Syst</source>
          <year>2006</year>
          <volume>1695</volume>
          <issue>5</issue>
          <fpage>1</fpage>
          <lpage>9</lpage>
        </element-citation>
      </ref>
      <ref id="CR17">
        <mixed-citation publication-type="other">Čukić M, Stokić M, Simić S, Pokrajac D (2020) The successful discrimination of depression from EEG could be attributed to proper feature extraction and not to a particular classification method. Cogn Neurodyn 14(4):443–455. 10.1007/s11571-020-09581-x.</mixed-citation>
      </ref>
      <ref id="CR18">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>de Beeck</surname>
              <given-names>HPO</given-names>
            </name>
            <name>
              <surname>Brants</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Baeck</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Wagemans</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Distributed subordinate specificity for bodies, faces, and buildings in human ventral visual cortex</article-title>
          <source>Neuroimage</source>
          <year>2010</year>
          <volume>49</volume>
          <issue>4</issue>
          <fpage>3414</fpage>
          <lpage>3425</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.11.022</pub-id>
          <pub-id pub-id-type="pmid">19922804</pub-id>
        </element-citation>
      </ref>
      <ref id="CR19">
        <mixed-citation publication-type="other">De la Porte J, Herbst B, Hereman W, Van Der Walt S (2008) An introduction to diffusion maps. In: Proceedings of the 19th symposium of the pattern recognition association of South Africa (PRASA 2008), pp 15–25, Cape Town, South Africa</mixed-citation>
      </ref>
      <ref id="CR20">
        <mixed-citation publication-type="other">Diedrich H, Abel M, Diedrich MH (2012) Package ‘LLE’</mixed-citation>
      </ref>
      <ref id="CR21">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dijkstra</surname>
              <given-names>EW</given-names>
            </name>
          </person-group>
          <article-title>A note on two problems in connexion with graphs</article-title>
          <source>Numer Math</source>
          <year>1959</year>
          <volume>1</volume>
          <issue>1</issue>
          <fpage>269</fpage>
          <lpage>271</lpage>
          <pub-id pub-id-type="doi">10.1007/BF01386390</pub-id>
        </element-citation>
      </ref>
      <ref id="CR22">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Duncan</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Talmon</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Zaveri</surname>
              <given-names>HP</given-names>
            </name>
            <name>
              <surname>Coifman</surname>
              <given-names>RR</given-names>
            </name>
          </person-group>
          <article-title>Identifying preseizure state in intracranial EEG data using diffusion kernels</article-title>
          <source>Math Biosci Eng</source>
          <year>2013</year>
          <volume>10</volume>
          <issue>3</issue>
          <fpage>579</fpage>
          <lpage>590</lpage>
          <pub-id pub-id-type="doi">10.3934/mbe.2013.10.579</pub-id>
          <pub-id pub-id-type="pmid">23906137</pub-id>
        </element-citation>
      </ref>
      <ref id="CR23">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Etkin</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Wager</surname>
              <given-names>TD</given-names>
            </name>
          </person-group>
          <article-title>Functional neuroimaging of anxiety: a meta-analysis of emotional processing in PTSD, social anxiety disorder, and specific phobia</article-title>
          <source>Am J Psychiatry</source>
          <year>2007</year>
          <volume>164</volume>
          <issue>10</issue>
          <fpage>1476</fpage>
          <lpage>1488</lpage>
          <pub-id pub-id-type="doi">10.1176/appi.ajp.2007.07030504</pub-id>
          <pub-id pub-id-type="pmid">17898336</pub-id>
        </element-citation>
      </ref>
      <ref id="CR24">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fox</surname>
              <given-names>MD</given-names>
            </name>
            <name>
              <surname>Snyder</surname>
              <given-names>AZ</given-names>
            </name>
            <name>
              <surname>Vincent</surname>
              <given-names>JL</given-names>
            </name>
            <name>
              <surname>Corbetta</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Van Essen</surname>
              <given-names>DC</given-names>
            </name>
            <name>
              <surname>Raichle</surname>
              <given-names>ME</given-names>
            </name>
          </person-group>
          <article-title>The human brain is intrinsically organized into dynamic, anticorrelated functional networks</article-title>
          <source>Proc Natl Acad Sci</source>
          <year>2005</year>
          <volume>102</volume>
          <issue>27</issue>
          <fpage>9673</fpage>
          <lpage>9678</lpage>
          <pub-id pub-id-type="doi">10.1073/pnas.0504136102</pub-id>
          <pub-id pub-id-type="pmid">15976020</pub-id>
        </element-citation>
      </ref>
      <ref id="CR25">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>KJ</given-names>
            </name>
          </person-group>
          <article-title>Functional and effective connectivity: a review</article-title>
          <source>Brain Connect</source>
          <year>2011</year>
          <volume>1</volume>
          <issue>1</issue>
          <fpage>13</fpage>
          <lpage>36</lpage>
          <pub-id pub-id-type="doi">10.1089/brain.2011.0008</pub-id>
          <pub-id pub-id-type="pmid">22432952</pub-id>
        </element-citation>
      </ref>
      <ref id="CR26">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>KJ</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>AP</given-names>
            </name>
            <name>
              <surname>Worsley</surname>
              <given-names>KJ</given-names>
            </name>
            <name>
              <surname>Poline</surname>
              <given-names>JP</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>CD</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>RS</given-names>
            </name>
          </person-group>
          <article-title>Statistical parametric maps in functional imaging: a general linear approach</article-title>
          <source>Hum Brain Mapp</source>
          <year>1994</year>
          <volume>2</volume>
          <issue>4</issue>
          <fpage>189</fpage>
          <lpage>210</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.460020402</pub-id>
        </element-citation>
      </ref>
      <ref id="CR27">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>KJ</given-names>
            </name>
            <name>
              <surname>Frith</surname>
              <given-names>CD</given-names>
            </name>
            <name>
              <surname>Fletcher</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Liddle</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Frackowiak</surname>
              <given-names>RS</given-names>
            </name>
          </person-group>
          <article-title>Functional topography: multidimensional scaling and functional connectivity in the brain</article-title>
          <source>Cereb Cortex</source>
          <year>1996</year>
          <volume>6</volume>
          <issue>2</issue>
          <fpage>156</fpage>
          <lpage>164</lpage>
          <pub-id pub-id-type="doi">10.1093/cercor/6.2.156</pub-id>
          <pub-id pub-id-type="pmid">8670646</pub-id>
        </element-citation>
      </ref>
      <ref id="CR28">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Friston</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Holmes</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Büchel</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Worsley</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Multisubject fMRI studies and conjunction analyses</article-title>
          <source>NeuroImage</source>
          <year>1999</year>
          <volume>10</volume>
          <issue>4</issue>
          <fpage>385</fpage>
          <lpage>396</lpage>
          <pub-id pub-id-type="doi">10.1006/nimg.1999.0484</pub-id>
          <pub-id pub-id-type="pmid">10493897</pub-id>
        </element-citation>
      </ref>
      <ref id="CR29">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Garrison</surname>
              <given-names>KA</given-names>
            </name>
            <name>
              <surname>Scheinost</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Finn</surname>
              <given-names>ES</given-names>
            </name>
            <name>
              <surname>Shen</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Constable</surname>
              <given-names>RT</given-names>
            </name>
          </person-group>
          <article-title>The (in)stability of functional brain network measures across thresholds</article-title>
          <source>Neuroimage</source>
          <year>2015</year>
          <volume>118</volume>
          <fpage>651</fpage>
          <lpage>661</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.05.046</pub-id>
          <pub-id pub-id-type="pmid">26021218</pub-id>
        </element-citation>
      </ref>
      <ref id="CR30">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Goutte</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Toft</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Rostrup</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Nielsen</surname>
              <given-names>FÅ</given-names>
            </name>
            <name>
              <surname>Hansen</surname>
              <given-names>LK</given-names>
            </name>
          </person-group>
          <article-title>On clustering fMRI time series</article-title>
          <source>NeuroImage</source>
          <year>1999</year>
          <volume>9</volume>
          <issue>3</issue>
          <fpage>298</fpage>
          <lpage>310</lpage>
          <pub-id pub-id-type="doi">10.1006/nimg.1998.0391</pub-id>
          <pub-id pub-id-type="pmid">10075900</pub-id>
        </element-citation>
      </ref>
      <ref id="CR31">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Greicius</surname>
              <given-names>MD</given-names>
            </name>
            <name>
              <surname>Krasnow</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Reiss</surname>
              <given-names>AL</given-names>
            </name>
            <name>
              <surname>Menon</surname>
              <given-names>V</given-names>
            </name>
          </person-group>
          <article-title>Functional connectivity in the resting brain: a network analysis of the default mode hypothesis</article-title>
          <source>Proc Natl Acad Sci</source>
          <year>2003</year>
          <volume>100</volume>
          <issue>1</issue>
          <fpage>253</fpage>
          <lpage>258</lpage>
          <pub-id pub-id-type="doi">10.1073/pnas.0135058100</pub-id>
          <pub-id pub-id-type="pmid">12506194</pub-id>
        </element-citation>
      </ref>
      <ref id="CR32">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haak</surname>
              <given-names>KV</given-names>
            </name>
            <name>
              <surname>Marquand</surname>
              <given-names>AF</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
          </person-group>
          <article-title>Connectopic mapping with resting-state fMRI</article-title>
          <source>Neuroimage</source>
          <year>2018</year>
          <volume>170</volume>
          <fpage>83</fpage>
          <lpage>94</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.075</pub-id>
          <pub-id pub-id-type="pmid">28666880</pub-id>
        </element-citation>
      </ref>
      <ref id="CR33">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haxby</surname>
              <given-names>JV</given-names>
            </name>
            <name>
              <surname>Gobbini</surname>
              <given-names>MI</given-names>
            </name>
            <name>
              <surname>Furey</surname>
              <given-names>ML</given-names>
            </name>
            <name>
              <surname>Ishai</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Schouten</surname>
              <given-names>JL</given-names>
            </name>
            <name>
              <surname>Pietrini</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>
          <source>Science</source>
          <year>2001</year>
          <volume>293</volume>
          <issue>5539</issue>
          <fpage>2425</fpage>
          <lpage>2430</lpage>
          <pub-id pub-id-type="doi">10.1126/science.1063736</pub-id>
          <pub-id pub-id-type="pmid">11577229</pub-id>
        </element-citation>
      </ref>
      <ref id="CR34">
        <mixed-citation publication-type="other">Hecht-Nielsen R (1992) Theory of the Backpropagation Neural Network, Harcourt Brace &amp; Co., USA, p 65–93</mixed-citation>
      </ref>
      <ref id="CR35">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hervé</surname>
              <given-names>PY</given-names>
            </name>
            <name>
              <surname>Razafimandimby</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Vigneau</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Mazoyer</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Tzourio-Mazoyer</surname>
              <given-names>N</given-names>
            </name>
          </person-group>
          <article-title>Disentangling the brain networks supporting affective speech comprehension</article-title>
          <source>NeuroImage</source>
          <year>2012</year>
          <volume>61</volume>
          <issue>4</issue>
          <fpage>1255</fpage>
          <lpage>1267</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.073</pub-id>
          <pub-id pub-id-type="pmid">22507230</pub-id>
        </element-citation>
      </ref>
      <ref id="CR36">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Himberg</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Hyvärinen</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Esposito</surname>
              <given-names>F</given-names>
            </name>
          </person-group>
          <article-title>Validating the independent components of neuroimaging time series via clustering and visualization</article-title>
          <source>Neuroimage</source>
          <year>2004</year>
          <volume>22</volume>
          <issue>3</issue>
          <fpage>1214</fpage>
          <lpage>1222</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.03.027</pub-id>
          <pub-id pub-id-type="pmid">15219593</pub-id>
        </element-citation>
      </ref>
      <ref id="CR37">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Huang</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Zhu</surname>
              <given-names>Q</given-names>
            </name>
            <name>
              <surname>Hao</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Shi</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Gao</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Identifying resting-state multifrequency biomarkers via tree-guided group sparse learning for schizophrenia classification</article-title>
          <source>IEEE J Biomed Health Inform</source>
          <year>2018</year>
          <volume>23</volume>
          <issue>1</issue>
          <fpage>342</fpage>
          <lpage>350</lpage>
          <pub-id pub-id-type="doi">10.1109/JBHI.2018.2796588</pub-id>
          <pub-id pub-id-type="pmid">29994431</pub-id>
        </element-citation>
      </ref>
      <ref id="CR38">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hyde</surname>
              <given-names>JS</given-names>
            </name>
            <name>
              <surname>Jesmanowicz</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Cross-correlation: an fMRI signal-processing strategy</article-title>
          <source>NeuroImage</source>
          <year>2012</year>
          <volume>62</volume>
          <issue>2</issue>
          <fpage>848</fpage>
          <lpage>851</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.064</pub-id>
          <pub-id pub-id-type="pmid">22051223</pub-id>
        </element-citation>
      </ref>
      <ref id="CR39">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hyvärinen</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Oja</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Independent component analysis: algorithms and applications</article-title>
          <source>Neural Netw</source>
          <year>2000</year>
          <volume>13</volume>
          <issue>4–5</issue>
          <fpage>411</fpage>
          <lpage>430</lpage>
          <pub-id pub-id-type="doi">10.1016/S0893-6080(00)00026-5</pub-id>
          <pub-id pub-id-type="pmid">10946390</pub-id>
        </element-citation>
      </ref>
      <ref id="CR40">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Iraji</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
            <name>
              <surname>Wiseman</surname>
              <given-names>NM</given-names>
            </name>
            <name>
              <surname>Davoodi-Bojd</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Avanaki</surname>
              <given-names>MR</given-names>
            </name>
            <name>
              <surname>Haacke</surname>
              <given-names>EM</given-names>
            </name>
            <name>
              <surname>Kou</surname>
              <given-names>Z</given-names>
            </name>
          </person-group>
          <article-title>The connectivity domain: analyzing resting state fMRI data using feature-based data-driven and model-based methods</article-title>
          <source>Neuroimage</source>
          <year>2016</year>
          <volume>134</volume>
          <fpage>494</fpage>
          <lpage>507</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.04.006</pub-id>
          <pub-id pub-id-type="pmid">27079528</pub-id>
        </element-citation>
      </ref>
      <ref id="CR41">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jenkinson</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Bannister</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Brady</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>
          <source>Neuroimage</source>
          <year>2002</year>
          <volume>17</volume>
          <issue>2</issue>
          <fpage>825</fpage>
          <lpage>841</lpage>
          <pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id>
          <pub-id pub-id-type="pmid">12377157</pub-id>
        </element-citation>
      </ref>
      <ref id="CR42">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Jollife</surname>
              <given-names>I</given-names>
            </name>
          </person-group>
          <source>Principal component analysis</source>
          <year>2002</year>
          <edition>2</edition>
          <publisher-loc>Berlin</publisher-loc>
          <publisher-name>Springer</publisher-name>
        </element-citation>
      </ref>
      <ref id="CR43">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Karatzoglou</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Smola</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Hornik</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Zeileis</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Kernlab—an s4 package for kernel methods in r</article-title>
          <source>J Stat Softw</source>
          <year>2004</year>
          <volume>11</volume>
          <issue>9</issue>
          <fpage>1</fpage>
          <lpage>20</lpage>
          <pub-id pub-id-type="doi">10.18637/jss.v011.i09</pub-id>
        </element-citation>
      </ref>
      <ref id="CR44">
        <mixed-citation publication-type="other">Kayo O (2006) Locally linear embedding algorithm: extensions and applications. MS Thesis. The University of Oulu</mixed-citation>
      </ref>
      <ref id="CR45">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khajehpour</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Mohagheghian</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Ekhtiari</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Makkiabadi</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Jafari</surname>
              <given-names>AH</given-names>
            </name>
            <name>
              <surname>Eqlimi</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Harirchian</surname>
              <given-names>MH</given-names>
            </name>
          </person-group>
          <article-title>Computer-aided classifying and characterizing of methamphetamine use disorder using resting-state EEG</article-title>
          <source>Cogn Neurodyn</source>
          <year>2019</year>
          <volume>13</volume>
          <issue>6</issue>
          <fpage>519</fpage>
          <lpage>530</lpage>
          <pub-id pub-id-type="doi">10.1007/s11571-019-09550-z</pub-id>
          <pub-id pub-id-type="pmid">31741689</pub-id>
        </element-citation>
      </ref>
      <ref id="CR46">
        <mixed-citation publication-type="other">Khosla M, Jamison K, Ngo GH, Kuceyeski A, Sabuncu MR (2019) Machine learning in resting-state fMRI analysis. Magn Reson Imaging 64:101–121</mixed-citation>
      </ref>
      <ref id="CR47">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kim</surname>
              <given-names>DI</given-names>
            </name>
            <name>
              <surname>Sui</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Rachakonda</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>White</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Manoach</surname>
              <given-names>DS</given-names>
            </name>
            <name>
              <surname>Clark</surname>
              <given-names>VP</given-names>
            </name>
            <name>
              <surname>Ho</surname>
              <given-names>BC</given-names>
            </name>
            <name>
              <surname>Schulz</surname>
              <given-names>SC</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
          </person-group>
          <article-title>Identification of imaging biomarkers in schizophrenia: a coefficient-constrained independent component analysis of the mind multi-site schizophrenia study</article-title>
          <source>Neuroinformatics</source>
          <year>2010</year>
          <volume>8</volume>
          <issue>4</issue>
          <fpage>213</fpage>
          <lpage>229</lpage>
          <pub-id pub-id-type="doi">10.1007/s12021-010-9077-7</pub-id>
          <pub-id pub-id-type="pmid">20607449</pub-id>
        </element-citation>
      </ref>
      <ref id="CR48">
        <mixed-citation publication-type="other">Krogh A, Hertz JA (1992) A simple weight decay can improve generalization. In: Advances in neural information processing systems, pp 950–957</mixed-citation>
      </ref>
      <ref id="CR49">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kruskal</surname>
              <given-names>JB</given-names>
            </name>
          </person-group>
          <article-title>Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</article-title>
          <source>Psychometrika</source>
          <year>1964</year>
          <volume>29</volume>
          <issue>1</issue>
          <fpage>1</fpage>
          <lpage>27</lpage>
          <pub-id pub-id-type="doi">10.1007/BF02289565</pub-id>
        </element-citation>
      </ref>
      <ref id="CR50">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kuhn</surname>
              <given-names>M</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Building predictive models in r using the caret package</article-title>
          <source>J Stat Softw</source>
          <year>2008</year>
          <volume>28</volume>
          <issue>5</issue>
          <fpage>1</fpage>
          <lpage>26</lpage>
          <pub-id pub-id-type="doi">10.18637/jss.v028.i05</pub-id>
          <pub-id pub-id-type="pmid">27774042</pub-id>
        </element-citation>
      </ref>
      <ref id="CR51">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>YO</given-names>
            </name>
            <name>
              <surname>Adalı</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
          </person-group>
          <article-title>Estimating the number of independent components for functional magnetic resonance imaging data</article-title>
          <source>Hum Brain Mapp</source>
          <year>2007</year>
          <volume>28</volume>
          <issue>11</issue>
          <fpage>1251</fpage>
          <lpage>1266</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.20359</pub-id>
          <pub-id pub-id-type="pmid">17274023</pub-id>
        </element-citation>
      </ref>
      <ref id="CR52">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Lian</surname>
              <given-names>W</given-names>
            </name>
            <name>
              <surname>Talmon</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Zaveri</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Carin</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Coifman</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Multivariate time-series analysis and diffusion maps</article-title>
          <source>Signal Process</source>
          <year>2015</year>
          <volume>116</volume>
          <fpage>13</fpage>
          <lpage>28</lpage>
          <pub-id pub-id-type="doi">10.1016/j.sigpro.2015.04.003</pub-id>
        </element-citation>
      </ref>
      <ref id="CR53">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mannfolk</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Wirestam</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Nilsson</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Ståhlberg</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Olsrud</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Dimensionality reduction of fMRI time series data using locally linear embedding</article-title>
          <source>Magn Reson Mater Phys Biol Med</source>
          <year>2010</year>
          <volume>23</volume>
          <issue>5–6</issue>
          <fpage>327</fpage>
          <lpage>338</lpage>
          <pub-id pub-id-type="doi">10.1007/s10334-010-0204-0</pub-id>
        </element-citation>
      </ref>
      <ref id="CR54">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Margulies</surname>
              <given-names>DS</given-names>
            </name>
            <name>
              <surname>Kelly</surname>
              <given-names>AC</given-names>
            </name>
            <name>
              <surname>Uddin</surname>
              <given-names>LQ</given-names>
            </name>
            <name>
              <surname>Biswal</surname>
              <given-names>BB</given-names>
            </name>
            <name>
              <surname>Castellanos</surname>
              <given-names>FX</given-names>
            </name>
            <name>
              <surname>Milham</surname>
              <given-names>MP</given-names>
            </name>
          </person-group>
          <article-title>Mapping the functional connectivity of anterior cingulate cortex</article-title>
          <source>Neuroimage</source>
          <year>2007</year>
          <volume>37</volume>
          <issue>2</issue>
          <fpage>579</fpage>
          <lpage>588</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.05.019</pub-id>
          <pub-id pub-id-type="pmid">17604651</pub-id>
        </element-citation>
      </ref>
      <ref id="CR55">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mayer</surname>
              <given-names>AR</given-names>
            </name>
            <name>
              <surname>Ruhl</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Merideth</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Ling</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Hanlon</surname>
              <given-names>FM</given-names>
            </name>
            <name>
              <surname>Bustillo</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Cañive</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Functional imaging of the hemodynamic sensory gating response in schizophrenia</article-title>
          <source>Hum Brain Mapp</source>
          <year>2013</year>
          <volume>34</volume>
          <issue>9</issue>
          <fpage>2302</fpage>
          <lpage>2312</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.22065</pub-id>
          <pub-id pub-id-type="pmid">22461278</pub-id>
        </element-citation>
      </ref>
      <ref id="CR56">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Meszlényi</surname>
              <given-names>RJ</given-names>
            </name>
            <name>
              <surname>Hermann</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Buza</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Gál</surname>
              <given-names>V</given-names>
            </name>
            <name>
              <surname>Vidnyánszky</surname>
              <given-names>Z</given-names>
            </name>
          </person-group>
          <article-title>Resting state fMRI functional connectivity analysis using dynamic time warping</article-title>
          <source>Front Neurosci</source>
          <year>2017</year>
          <volume>11</volume>
          <fpage>75</fpage>
          <pub-id pub-id-type="doi">10.3389/fnins.2017.00075</pub-id>
          <pub-id pub-id-type="pmid">28261052</pub-id>
        </element-citation>
      </ref>
      <ref id="CR57">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Michael</surname>
              <given-names>AM</given-names>
            </name>
            <name>
              <surname>Anderson</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>RL</given-names>
            </name>
            <name>
              <surname>Adalı</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
          </person-group>
          <article-title>Preserving subject variability in group fMRI analysis: performance evaluation of GICA vs. IVA</article-title>
          <source>Front Syst Neurosci</source>
          <year>2014</year>
          <volume>8</volume>
          <fpage>106</fpage>
          <pub-id pub-id-type="doi">10.3389/fnsys.2014.00106</pub-id>
          <pub-id pub-id-type="pmid">25018704</pub-id>
        </element-citation>
      </ref>
      <ref id="CR58">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Muller</surname>
              <given-names>KR</given-names>
            </name>
            <name>
              <surname>Mika</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Ratsch</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Tsuda</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Scholkopf</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>An introduction to kernel-based learning algorithms</article-title>
          <source>IEEE Trans Neural Netw</source>
          <year>2001</year>
          <volume>12</volume>
          <issue>2</issue>
          <fpage>181</fpage>
          <lpage>201</lpage>
          <pub-id pub-id-type="doi">10.1109/72.914517</pub-id>
          <pub-id pub-id-type="pmid">18244377</pub-id>
        </element-citation>
      </ref>
      <ref id="CR59">
        <mixed-citation publication-type="other">Nadler B, Lafon S, Kevrekidis I, Coifman RR (2006) Diffusion maps, spectral clustering and eigenfunctions of Fokker–Planck operators. In: Advances in neural information processing systems, pp 955–962</mixed-citation>
      </ref>
      <ref id="CR60">
        <mixed-citation publication-type="other">Nadler B, Lafon S, Coifman R, Kevrekidis IG (2008) Diffusion maps - a proba-bilistic interpretation for spectral embedding and clustering algorithms. In:Gorban AN, Kégl B, Wunsch DC, Zinovyev AY (eds) Principal Manifolds for Data Visualization and Dimension Reduction, Springer, Berlin, Heidelberg, pp 238–260</mixed-citation>
      </ref>
      <ref id="CR61">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Oksanen</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Kindt</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Legendre</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>O’Hara</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Stevens</surname>
              <given-names>MHH</given-names>
            </name>
            <name>
              <surname>Oksanen</surname>
              <given-names>MJ</given-names>
            </name>
            <name>
              <surname>Suggests</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>The vegan package</article-title>
          <source>Commun Ecol Package</source>
          <year>2007</year>
          <volume>10</volume>
          <fpage>631</fpage>
          <lpage>637</lpage>
        </element-citation>
      </ref>
      <ref id="CR62">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>O’Toole</surname>
              <given-names>AJ</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Abdi</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Pénard</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Dunlop</surname>
              <given-names>JP</given-names>
            </name>
            <name>
              <surname>Parent</surname>
              <given-names>MA</given-names>
            </name>
          </person-group>
          <article-title>Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis of functional neuroimaging data</article-title>
          <source>J Cogn Neurosci</source>
          <year>2007</year>
          <volume>19</volume>
          <issue>11</issue>
          <fpage>1735</fpage>
          <lpage>1752</lpage>
          <pub-id pub-id-type="doi">10.1162/jocn.2007.19.11.1735</pub-id>
          <pub-id pub-id-type="pmid">17958478</pub-id>
        </element-citation>
      </ref>
      <ref id="CR63">
        <mixed-citation publication-type="other">Pamplona GS, Vieira BH, Scharnowski F, Salmon CE (2020) Personode: a toolbox for ICA map classification and individualized ROI definition. Neuroinformatics 18(3):339–349. 10.1007/s12021-019-09449-4</mixed-citation>
      </ref>
      <ref id="CR64">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Parhizi</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Daliri</surname>
              <given-names>MR</given-names>
            </name>
            <name>
              <surname>Behroozi</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Decoding the different states of visual attention using functional and effective connectivity features in fMRI data</article-title>
          <source>Cogn Neurodyn</source>
          <year>2018</year>
          <volume>12</volume>
          <issue>2</issue>
          <fpage>157</fpage>
          <lpage>170</lpage>
          <pub-id pub-id-type="doi">10.1007/s11571-017-9461-1</pub-id>
          <pub-id pub-id-type="pmid">29564025</pub-id>
        </element-citation>
      </ref>
      <ref id="CR65">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pruim</surname>
              <given-names>RH</given-names>
            </name>
            <name>
              <surname>Mennes</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>van Rooij</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Llera</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Buitelaar</surname>
              <given-names>JK</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
          </person-group>
          <article-title>ICA-aroma: a robust ICA-based strategy for removing motion artifacts from fMRI data</article-title>
          <source>Neuroimage</source>
          <year>2015</year>
          <volume>112</volume>
          <fpage>267</fpage>
          <lpage>277</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.02.064</pub-id>
          <pub-id pub-id-type="pmid">25770991</pub-id>
        </element-citation>
      </ref>
      <ref id="CR66">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Qiu</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Tan</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Chung</surname>
              <given-names>MK</given-names>
            </name>
          </person-group>
          <article-title>Manifold learning on brain functional networks in aging</article-title>
          <source>Med Image Anal</source>
          <year>2015</year>
          <volume>20</volume>
          <issue>1</issue>
          <fpage>52</fpage>
          <lpage>60</lpage>
          <pub-id pub-id-type="doi">10.1016/j.media.2014.10.006</pub-id>
          <pub-id pub-id-type="pmid">25476411</pub-id>
        </element-citation>
      </ref>
      <ref id="CR67">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Qureshi</surname>
              <given-names>MNI</given-names>
            </name>
            <name>
              <surname>Oh</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Cho</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Jo</surname>
              <given-names>HJ</given-names>
            </name>
            <name>
              <surname>Lee</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Multimodal discrimination of schizophrenia using hybrid weighted feature concatenation of brain functional connectivity and anatomical features with an extreme learning machine</article-title>
          <source>Front Neuroinform</source>
          <year>2017</year>
          <volume>11</volume>
          <fpage>59</fpage>
          <pub-id pub-id-type="doi">10.3389/fninf.2017.00059</pub-id>
          <pub-id pub-id-type="pmid">28943848</pub-id>
        </element-citation>
      </ref>
      <ref id="CR68">
        <mixed-citation publication-type="other">Richards J (2014) Diffusion map. R package version, p 1</mixed-citation>
      </ref>
      <ref id="CR69">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Richiardi</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Achard</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Bunke</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Van De Ville</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Machine learning with brain graphs: predictive modeling approaches for functional imaging in systems neuroscience</article-title>
          <source>IEEE Signal Process Mag</source>
          <year>2013</year>
          <volume>30</volume>
          <issue>3</issue>
          <fpage>58</fpage>
          <lpage>70</lpage>
          <pub-id pub-id-type="doi">10.1109/MSP.2012.2233865</pub-id>
        </element-citation>
      </ref>
      <ref id="CR70">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Ripley</surname>
              <given-names>BD</given-names>
            </name>
          </person-group>
          <source>Pattern recognition and neural networks</source>
          <year>2007</year>
          <publisher-loc>Cambridge</publisher-loc>
          <publisher-name>Cambridge University Press</publisher-name>
        </element-citation>
      </ref>
      <ref id="CR71">
        <mixed-citation publication-type="other">Ripley B, Venables W (2011) NNET: feed-forward neural networks and multinomial log-linear models. R package version, vol 7, No. 5</mixed-citation>
      </ref>
      <ref id="CR72">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Roweis</surname>
              <given-names>ST</given-names>
            </name>
            <name>
              <surname>Saul</surname>
              <given-names>LK</given-names>
            </name>
          </person-group>
          <article-title>Nonlinear dimensionality reduction by locally linear embedding</article-title>
          <source>Science</source>
          <year>2000</year>
          <volume>290</volume>
          <issue>5500</issue>
          <fpage>2323</fpage>
          <lpage>2326</lpage>
          <pub-id pub-id-type="doi">10.1126/science.290.5500.2323</pub-id>
          <pub-id pub-id-type="pmid">11125150</pub-id>
        </element-citation>
      </ref>
      <ref id="CR73">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rubinov</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Sporns</surname>
              <given-names>O</given-names>
            </name>
          </person-group>
          <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>
          <source>Neuroimage</source>
          <year>2010</year>
          <volume>52</volume>
          <issue>3</issue>
          <fpage>1059</fpage>
          <lpage>1069</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id>
          <pub-id pub-id-type="pmid">19819337</pub-id>
        </element-citation>
      </ref>
      <ref id="CR74">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Salman</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Du</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Lin</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Fu</surname>
              <given-names>Z</given-names>
            </name>
            <name>
              <surname>Fedorov</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Damaraju</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Sui</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Mayer</surname>
              <given-names>AR</given-names>
            </name>
            <name>
              <surname>Posse</surname>
              <given-names>S</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Group ICA for identifying biomarkers in schizophrenia:‘adaptive’ networks via spatially constrained ICA show more sensitivity to group differences than spatio-temporal regression</article-title>
          <source>NeuroImage Clin</source>
          <year>2019</year>
          <volume>22</volume>
          <fpage>101747</fpage>
          <pub-id pub-id-type="doi">10.1016/j.nicl.2019.101747</pub-id>
          <pub-id pub-id-type="pmid">30921608</pub-id>
        </element-citation>
      </ref>
      <ref id="CR75">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Salvador</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Suckling</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Coleman</surname>
              <given-names>MR</given-names>
            </name>
            <name>
              <surname>Pickard</surname>
              <given-names>JD</given-names>
            </name>
            <name>
              <surname>Menon</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Neurophysiological architecture of functional magnetic resonance images of human brain</article-title>
          <source>Cereb Cortex</source>
          <year>2005</year>
          <volume>15</volume>
          <issue>9</issue>
          <fpage>1332</fpage>
          <lpage>1342</lpage>
          <pub-id pub-id-type="doi">10.1093/cercor/bhi016</pub-id>
          <pub-id pub-id-type="pmid">15635061</pub-id>
        </element-citation>
      </ref>
      <ref id="CR76">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saul</surname>
              <given-names>LK</given-names>
            </name>
            <name>
              <surname>Roweis</surname>
              <given-names>ST</given-names>
            </name>
          </person-group>
          <article-title>Think globally, fit locally: unsupervised learning of low dimensional manifolds</article-title>
          <source>J Mach Learn Res</source>
          <year>2003</year>
          <volume>4</volume>
          <issue>Jun</issue>
          <fpage>119</fpage>
          <lpage>155</lpage>
        </element-citation>
      </ref>
      <ref id="CR77">
        <mixed-citation publication-type="other">Saul LK, Weinberger KQ, Ham JH, Sha F, Lee DD (2006) Spectral methods for dimensionality reduction. In: Chapelle O,  Schölkopf B and Zien A (eds) Semi-Supervised Learning, Cambridge, MA, USA, The MIT Press, pp 293–306</mixed-citation>
      </ref>
      <ref id="CR78">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Saxe</surname>
              <given-names>MD</given-names>
            </name>
            <name>
              <surname>Battaglia</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>JW</given-names>
            </name>
            <name>
              <surname>Malleret</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>David</surname>
              <given-names>DJ</given-names>
            </name>
            <name>
              <surname>Monckton</surname>
              <given-names>JE</given-names>
            </name>
            <name>
              <surname>Garcia</surname>
              <given-names>ADR</given-names>
            </name>
            <name>
              <surname>Sofroniew</surname>
              <given-names>MV</given-names>
            </name>
            <name>
              <surname>Kandel</surname>
              <given-names>ER</given-names>
            </name>
            <name>
              <surname>Santarelli</surname>
              <given-names>L</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Ablation of hippocampal neurogenesis impairs contextual fear conditioning and synaptic plasticity in the dentate gyrus</article-title>
          <source>Proc Natl Acad Sci</source>
          <year>2006</year>
          <volume>103</volume>
          <issue>46</issue>
          <fpage>17501</fpage>
          <lpage>17506</lpage>
          <pub-id pub-id-type="doi">10.1073/pnas.0607207103</pub-id>
          <pub-id pub-id-type="pmid">17088541</pub-id>
        </element-citation>
      </ref>
      <ref id="CR79">
        <mixed-citation publication-type="other">Schölkopf B, Smola A, Müller KR (1997) Kernel principal component analysis. In: International conference on artificial neural networks, pp 583–588. Springer</mixed-citation>
      </ref>
      <ref id="CR80">
        <mixed-citation publication-type="other">Shen X, Meyer FG (2005) Analysis of event-related fMRI data using diffusion maps. In: Biennial international conference on information processing in medical imaging, pp 652–663. Springer</mixed-citation>
      </ref>
      <ref id="CR81">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shen</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>L</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Discriminative analysis of resting-state functional connectivity patterns of schizophrenia using low dimensional embedding of fMRI</article-title>
          <source>Neuroimage</source>
          <year>2010</year>
          <volume>49</volume>
          <issue>4</issue>
          <fpage>3110</fpage>
          <lpage>3121</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.11.011</pub-id>
          <pub-id pub-id-type="pmid">19931396</pub-id>
        </element-citation>
      </ref>
      <ref id="CR82">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shinkareva</surname>
              <given-names>SV</given-names>
            </name>
            <name>
              <surname>Malave</surname>
              <given-names>VL</given-names>
            </name>
            <name>
              <surname>Just</surname>
              <given-names>MA</given-names>
            </name>
            <name>
              <surname>Mitchell</surname>
              <given-names>TM</given-names>
            </name>
          </person-group>
          <article-title>Exploring commonalities across participants in the neural representation of objects</article-title>
          <source>Hum Brain Mapp</source>
          <year>2012</year>
          <volume>33</volume>
          <issue>6</issue>
          <fpage>1375</fpage>
          <lpage>1383</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.21296</pub-id>
          <pub-id pub-id-type="pmid">21567662</pub-id>
        </element-citation>
      </ref>
      <ref id="CR83">
        <mixed-citation publication-type="other">Shinkareva SV, Wang J, Wedell DH (2013) Examining similarity structure: multidimensional scaling and related approaches in neuroimaging. Comput Math Methods Med 2013(2013):796183. 10.1155/2013/796183</mixed-citation>
      </ref>
      <ref id="CR84">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sidhu</surname>
              <given-names>GS</given-names>
            </name>
            <name>
              <surname>Asgarian</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Greiner</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Brown</surname>
              <given-names>MR</given-names>
            </name>
          </person-group>
          <article-title>Kernel principal component analysis for dimensionality reduction in fMRI-based diagnosis of ADHD</article-title>
          <source>Front Syst Neurosci</source>
          <year>2012</year>
          <volume>6</volume>
          <fpage>74</fpage>
          <pub-id pub-id-type="doi">10.3389/fnsys.2012.00074</pub-id>
          <pub-id pub-id-type="pmid">23162439</pub-id>
        </element-citation>
      </ref>
      <ref id="CR85">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Siettos</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Starke</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Multiscale modeling of brain dynamics: from single neurons and networks to mathematical tools</article-title>
          <source>Wiley Interdiscip Rev Syst Biol Med</source>
          <year>2016</year>
          <volume>8</volume>
          <issue>5</issue>
          <fpage>438</fpage>
          <lpage>458</lpage>
          <pub-id pub-id-type="doi">10.1002/wsbm.1348</pub-id>
          <pub-id pub-id-type="pmid">27340949</pub-id>
        </element-citation>
      </ref>
      <ref id="CR86">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Singer</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Erban</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Kevrekidis</surname>
              <given-names>IG</given-names>
            </name>
            <name>
              <surname>Coifman</surname>
              <given-names>RR</given-names>
            </name>
          </person-group>
          <article-title>Detecting intrinsic slow variables in stochastic dynamical systems by anisotropic diffusion maps</article-title>
          <source>Proc Natl Acad Sci</source>
          <year>2009</year>
          <volume>106</volume>
          <issue>38</issue>
          <fpage>16090</fpage>
          <lpage>16095</lpage>
          <pub-id pub-id-type="doi">10.1073/pnas.0905547106</pub-id>
          <pub-id pub-id-type="pmid">19706457</pub-id>
        </element-citation>
      </ref>
      <ref id="CR87">
        <mixed-citation publication-type="other">Sipola T, Cong F, Ristaniemi T, Alluri V, Toiviainen P, Brattico E, Nandi AK (2013) Diffusion map for clustering fMRI spatial maps extracted by independent component analysis. In: 2013 IEEE international workshop on machine learning for signal processing (MLSP), pp 1–6. IEEE</mixed-citation>
      </ref>
      <ref id="CR88">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
          </person-group>
          <article-title>Fast robust automated brain extraction</article-title>
          <source>Hum Brain Mapp</source>
          <year>2002</year>
          <volume>17</volume>
          <issue>3</issue>
          <fpage>143</fpage>
          <lpage>155</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.10062</pub-id>
          <pub-id pub-id-type="pmid">12391568</pub-id>
        </element-citation>
      </ref>
      <ref id="CR89">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
            <name>
              <surname>Jenkinson</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Woolrich</surname>
              <given-names>MW</given-names>
            </name>
            <name>
              <surname>Beckmann</surname>
              <given-names>CF</given-names>
            </name>
            <name>
              <surname>Behrens</surname>
              <given-names>TE</given-names>
            </name>
            <name>
              <surname>Johansen-Berg</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Bannister</surname>
              <given-names>PR</given-names>
            </name>
            <name>
              <surname>De Luca</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Drobnjak</surname>
              <given-names>I</given-names>
            </name>
            <name>
              <surname>Flitney</surname>
              <given-names>DE</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Advances in functional and structural MR image analysis and implementation as FSL</article-title>
          <source>Neuroimage</source>
          <year>2004</year>
          <volume>23</volume>
          <fpage>S208</fpage>
          <lpage>S219</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id>
          <pub-id pub-id-type="pmid">15501092</pub-id>
        </element-citation>
      </ref>
      <ref id="CR90">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Smith</surname>
              <given-names>SM</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>PT</given-names>
            </name>
            <name>
              <surname>Miller</surname>
              <given-names>KL</given-names>
            </name>
            <name>
              <surname>Glahn</surname>
              <given-names>DC</given-names>
            </name>
            <name>
              <surname>Fox</surname>
              <given-names>PM</given-names>
            </name>
            <name>
              <surname>Mackay</surname>
              <given-names>CE</given-names>
            </name>
            <name>
              <surname>Filippini</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Watkins</surname>
              <given-names>KE</given-names>
            </name>
            <name>
              <surname>Toro</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Laird</surname>
              <given-names>AR</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Correspondence of the brain’s functional architecture during activation and rest</article-title>
          <source>Proc Natl Acad Sci</source>
          <year>2009</year>
          <volume>106</volume>
          <issue>31</issue>
          <fpage>13040</fpage>
          <lpage>13045</lpage>
          <pub-id pub-id-type="doi">10.1073/pnas.0905267106</pub-id>
          <pub-id pub-id-type="pmid">19620724</pub-id>
        </element-citation>
      </ref>
      <ref id="CR91">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stam</surname>
              <given-names>CJ</given-names>
            </name>
            <name>
              <surname>Reijneveld</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>Graph theoretical analysis of complex networks in the brain</article-title>
          <source>Nonlinear Biomed Phys</source>
          <year>2007</year>
          <volume>1</volume>
          <issue>1</issue>
          <fpage>3</fpage>
          <pub-id pub-id-type="doi">10.1186/1753-4631-1-3</pub-id>
          <pub-id pub-id-type="pmid">17908336</pub-id>
        </element-citation>
      </ref>
      <ref id="CR92">
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Strange</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Zwiggelaar</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <source>Open problems in spectral dimensionality reduction</source>
          <year>2014</year>
          <publisher-loc>Berlin</publisher-loc>
          <publisher-name>Springer</publisher-name>
        </element-citation>
      </ref>
      <ref id="CR93">
        <mixed-citation publication-type="other">Team RC (2014) R: a language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria</mixed-citation>
      </ref>
      <ref id="CR94">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tenenbaum</surname>
              <given-names>JB</given-names>
            </name>
            <name>
              <surname>De Silva</surname>
              <given-names>V</given-names>
            </name>
            <name>
              <surname>Langford</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>A global geometric framework for nonlinear dimensionality reduction</article-title>
          <source>Science</source>
          <year>2000</year>
          <volume>290</volume>
          <issue>5500</issue>
          <fpage>2319</fpage>
          <lpage>2323</lpage>
          <pub-id pub-id-type="doi">10.1126/science.290.5500.2319</pub-id>
          <pub-id pub-id-type="pmid">11125149</pub-id>
        </element-citation>
      </ref>
      <ref id="CR95">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tsatsishvili</surname>
              <given-names>V</given-names>
            </name>
            <name>
              <surname>Burunat</surname>
              <given-names>I</given-names>
            </name>
            <name>
              <surname>Cong</surname>
              <given-names>F</given-names>
            </name>
            <name>
              <surname>Toiviainen</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Alluri</surname>
              <given-names>V</given-names>
            </name>
            <name>
              <surname>Ristaniemi</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>On application of kernel PCA for generating stimulus features for fMRI during continuous music listening</article-title>
          <source>J Neurosci Methods</source>
          <year>2018</year>
          <volume>303</volume>
          <fpage>1</fpage>
          <lpage>6</lpage>
          <pub-id pub-id-type="doi">10.1016/j.jneumeth.2018.03.014</pub-id>
          <pub-id pub-id-type="pmid">29596859</pub-id>
        </element-citation>
      </ref>
      <ref id="CR96">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tzagarakis</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Jerde</surname>
              <given-names>TA</given-names>
            </name>
            <name>
              <surname>Lewis</surname>
              <given-names>SM</given-names>
            </name>
            <name>
              <surname>Uğurbil</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Georgopoulos</surname>
              <given-names>AP</given-names>
            </name>
          </person-group>
          <article-title>Cerebral cortical mechanisms of copying geometrical shapes: a multidimensional scaling analysis of fMRI patterns of activation</article-title>
          <source>Exp Brain Res</source>
          <year>2009</year>
          <volume>194</volume>
          <issue>3</issue>
          <fpage>369</fpage>
          <lpage>380</lpage>
          <pub-id pub-id-type="doi">10.1007/s00221-009-1709-5</pub-id>
          <pub-id pub-id-type="pmid">19189086</pub-id>
        </element-citation>
      </ref>
      <ref id="CR97">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>van den Heuvel</surname>
              <given-names>MP</given-names>
            </name>
            <name>
              <surname>de Lange</surname>
              <given-names>SC</given-names>
            </name>
            <name>
              <surname>Zalesky</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Seguin</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Yeo</surname>
              <given-names>BT</given-names>
            </name>
            <name>
              <surname>Schmidt</surname>
              <given-names>R</given-names>
            </name>
          </person-group>
          <article-title>Proportional thresholding in resting-state fMRI functional connectivity networks and consequences for patient-control connectome studies: issues and recommendations</article-title>
          <source>NeuroImage</source>
          <year>2017</year>
          <volume>152</volume>
          <fpage>437</fpage>
          <lpage>449</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.005</pub-id>
          <pub-id pub-id-type="pmid">28167349</pub-id>
        </element-citation>
      </ref>
      <ref id="CR98">
        <mixed-citation publication-type="other">Venkataraman A, Van Dijk KR, Buckner RL, Golland P (2009) Exploring functional connectivity in fMRI via clustering. In: Proceedings of the IEEE international conference on acoustics, speech, and signal processing/sponsored by the Institute of Electrical and Electronics Engineers Signal Processing Society. ICASSP (conference), NIH public access, vol 2009, p 441</mixed-citation>
      </ref>
      <ref id="CR99">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Venkatesh</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Jaja</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Pessoa</surname>
              <given-names>L</given-names>
            </name>
          </person-group>
          <article-title>Comparing functional connectivity matrices: a geometry-aware approach applied to participant identification</article-title>
          <source>NeuroImage</source>
          <year>2020</year>
          <volume>207</volume>
          <fpage>116398</fpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116398</pub-id>
          <pub-id pub-id-type="pmid">31783117</pub-id>
        </element-citation>
      </ref>
      <ref id="CR100">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vergara</surname>
              <given-names>VM</given-names>
            </name>
            <name>
              <surname>Mayer</surname>
              <given-names>AR</given-names>
            </name>
            <name>
              <surname>Damaraju</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Hutchison</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Calhoun</surname>
              <given-names>VD</given-names>
            </name>
          </person-group>
          <article-title>The effect of preprocessing pipelines in subject classification and detection of abnormal resting state functional network connectivity using group ICA</article-title>
          <source>Neuroimage</source>
          <year>2017</year>
          <volume>145</volume>
          <fpage>365</fpage>
          <lpage>376</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.03.038</pub-id>
          <pub-id pub-id-type="pmid">27033684</pub-id>
        </element-citation>
      </ref>
      <ref id="CR101">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Viviani</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Grön</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Spitzer</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Functional principal component analysis of fMRI data</article-title>
          <source>Hum Brain Mapp</source>
          <year>2005</year>
          <volume>24</volume>
          <issue>2</issue>
          <fpage>109</fpage>
          <lpage>129</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.20074</pub-id>
          <pub-id pub-id-type="pmid">15468155</pub-id>
        </element-citation>
      </ref>
      <ref id="CR102">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Welchew</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Honey</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Sharma</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Robbins</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Multidimensional scaling of integrated neurocognitive function and schizophrenia as a disconnexion disorder</article-title>
          <source>NeuroImage</source>
          <year>2002</year>
          <volume>17</volume>
          <issue>3</issue>
          <fpage>1227</fpage>
          <lpage>1239</lpage>
          <pub-id pub-id-type="doi">10.1006/nimg.2002.1246</pub-id>
          <pub-id pub-id-type="pmid">12414263</pub-id>
        </element-citation>
      </ref>
      <ref id="CR103">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Welchew</surname>
              <given-names>DE</given-names>
            </name>
            <name>
              <surname>Ashwin</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Berkouk</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Salvador</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Suckling</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Baron-Cohen</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Bullmore</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Functional disconnectivity of the medial temporal lobe in Asperger’s syndrome</article-title>
          <source>Biol Psychiatry</source>
          <year>2005</year>
          <volume>57</volume>
          <issue>9</issue>
          <fpage>991</fpage>
          <lpage>998</lpage>
          <pub-id pub-id-type="doi">10.1016/j.biopsych.2005.01.028</pub-id>
          <pub-id pub-id-type="pmid">15860339</pub-id>
        </element-citation>
      </ref>
      <ref id="CR104">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Worsley</surname>
              <given-names>KJ</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>JI</given-names>
            </name>
            <name>
              <surname>Lerch</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Evans</surname>
              <given-names>AC</given-names>
            </name>
          </person-group>
          <article-title>Comparing functional connectivity via thresholding correlations and singular value decomposition</article-title>
          <source>Philos Trans R Soc B Biol Sci</source>
          <year>2005</year>
          <volume>360</volume>
          <issue>1457</issue>
          <fpage>913</fpage>
          <lpage>920</lpage>
          <pub-id pub-id-type="doi">10.1098/rstb.2005.1637</pub-id>
        </element-citation>
      </ref>
      <ref id="CR105">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Xiang</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Tan</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Wu</surname>
              <given-names>FX</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Schizophrenia identification using multi-view graph measures of functional brain networks</article-title>
          <source>Front Bioeng Biotechnol</source>
          <year>2020</year>
          <volume>7</volume>
          <fpage>479</fpage>
          <pub-id pub-id-type="doi">10.3389/fbioe.2019.00479</pub-id>
          <pub-id pub-id-type="pmid">32010682</pub-id>
        </element-citation>
      </ref>
      <ref id="CR106">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yang</surname>
              <given-names>Z</given-names>
            </name>
            <name>
              <surname>LaConte</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Weng</surname>
              <given-names>X</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>X</given-names>
            </name>
          </person-group>
          <article-title>Ranking and averaging independent component analysis by reproducibility (RAICAR)</article-title>
          <source>Hum Brain Mapp</source>
          <year>2008</year>
          <volume>29</volume>
          <issue>6</issue>
          <fpage>711</fpage>
          <lpage>725</lpage>
          <pub-id pub-id-type="doi">10.1002/hbm.20432</pub-id>
          <pub-id pub-id-type="pmid">17598162</pub-id>
        </element-citation>
      </ref>
      <ref id="CR107">
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhou</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Y</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Song</surname>
              <given-names>SW</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Spontaneous brain activity observed with functional magnetic resonance imaging as a potential biomarker in neuropsychiatric disorders</article-title>
          <source>Cogn Neurodyn</source>
          <year>2010</year>
          <volume>4</volume>
          <issue>4</issue>
          <fpage>275</fpage>
          <lpage>294</lpage>
          <pub-id pub-id-type="doi">10.1007/s11571-010-9126-9</pub-id>
          <pub-id pub-id-type="pmid">22132039</pub-id>
        </element-citation>
      </ref>
    </ref-list>
  </back>
</article>
