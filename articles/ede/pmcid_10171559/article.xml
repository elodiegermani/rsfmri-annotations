<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" id="hbm26289" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Hum Brain Mapp</journal-id>
      <journal-id journal-id-type="iso-abbrev">Hum Brain Mapp</journal-id>
      <journal-id journal-id-type="doi">10.1002/(ISSN)1097-0193</journal-id>
      <journal-id journal-id-type="publisher-id">HBM</journal-id>
      <journal-title-group>
        <journal-title>Human Brain Mapping</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1065-9471</issn>
      <issn pub-type="epub">1097-0193</issn>
      <publisher>
        <publisher-name>John Wiley &amp; Sons, Inc.</publisher-name>
        <publisher-loc>Hoboken, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">37070786</article-id>
      <article-id pub-id-type="pmc">10171559</article-id>
      <article-id pub-id-type="doi">10.1002/hbm.26289</article-id>
      <article-id pub-id-type="publisher-id">HBM26289</article-id>
      <article-categories>
        <subj-group subj-group-type="overline">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="heading">
          <subject>Research Articles</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Enhancing the network specific individual characteristics in <styled-content style="fixed-case" toggle="no">rs‐fMRI</styled-content> functional connectivity by dictionary learning</article-title>
        <alt-title alt-title-type="left-running-head">Jain et al.</alt-title>
      </title-group>
      <contrib-group>
        <contrib id="hbm26289-cr-0001" contrib-type="author">
          <name>
            <surname>Jain</surname>
            <given-names>Pratik</given-names>
          </name>
          <xref rid="hbm26289-aff-0001" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib id="hbm26289-cr-0002" contrib-type="author">
          <name>
            <surname>Chakraborty</surname>
            <given-names>Ankit</given-names>
          </name>
          <xref rid="hbm26289-aff-0001" ref-type="aff">
<sup>1</sup>
</xref>
        </contrib>
        <contrib id="hbm26289-cr-0003" contrib-type="author">
          <name>
            <surname>Hafiz</surname>
            <given-names>Rakibul</given-names>
          </name>
          <xref rid="hbm26289-aff-0002" ref-type="aff">
<sup>2</sup>
</xref>
        </contrib>
        <contrib id="hbm26289-cr-0004" contrib-type="author">
          <name>
            <surname>Sao</surname>
            <given-names>Anil K.</given-names>
          </name>
          <xref rid="hbm26289-aff-0003" ref-type="aff">
<sup>3</sup>
</xref>
        </contrib>
        <contrib id="hbm26289-cr-0005" contrib-type="author" corresp="yes">
          <name>
            <surname>Biswal</surname>
            <given-names>Bharat</given-names>
          </name>
          <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-3710-3500</contrib-id>
          <xref rid="hbm26289-aff-0002" ref-type="aff">
<sup>2</sup>
</xref>
          <address>
            <email>bbiswal@gmail.com</email>
          </address>
        </contrib>
      </contrib-group>
      <aff id="hbm26289-aff-0001">
<label>
<sup>1</sup>
</label>
<named-content content-type="organisation-division">School of Computing and Electrical Engineering</named-content>
<institution>Indian Institute of Technology Mandi</institution>
<city>Mandi</city>
<country country="IN">India</country>
</aff>
      <aff id="hbm26289-aff-0002">
<label>
<sup>2</sup>
</label>
<named-content content-type="organisation-division">Department of Biomedical Engineering</named-content>
<institution>New Jersey Institute of Technology</institution>
<city>Newark</city>
<named-content content-type="country-part">New Jersey</named-content>
<postal-code>07102</postal-code>
<country country="US">USA</country>
</aff>
      <aff id="hbm26289-aff-0003">
<label>
<sup>3</sup>
</label>
<named-content content-type="organisation-division">Department of Electrical Engineering and Computer Science</named-content>
<institution>Indian Institute of Technology Bhilai</institution>
<city>Bhilai</city>
<country country="IN">India</country>
</aff>
      <author-notes>
        <corresp id="correspondenceTo">
<label>*</label>
<bold>Correspondence</bold>
<break/>
Bharat Biswal, Department of Biomedical Engineering, New Jersey Institute of Technology, 607 Fenster Hall, University Height, Newark, NJ 07102, USA.<break/>
Email: <email>bbiswal@gmail.com</email>
<break/>
</corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>18</day>
        <month>4</month>
        <year>2023</year>
      </pub-date>
      <pub-date pub-type="collection">
        <day>1</day>
        <month>6</month>
        <year>2023</year>
      </pub-date>
      <volume>44</volume>
      <issue seq="350">8</issue>
      <issue-id pub-id-type="doi">10.1002/hbm.v44.8</issue-id>
      <fpage>3410</fpage>
      <lpage>3432</lpage>
      <history>
<date date-type="rev-recd"><day>03</day><month>3</month><year>2023</year></date>
<date date-type="received"><day>25</day><month>10</month><year>2022</year></date>
<date date-type="accepted"><day>13</day><month>3</month><year>2023</year></date>
</history>
      <permissions>
        <!--&#x000a9; 2023 Wiley Periodicals LLC.-->
        <copyright-statement content-type="article-copyright">© 2023 The Authors. <italic toggle="yes">Human Brain Mapping</italic> published by Wiley Periodicals LLC.</copyright-statement>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p>
        </license>
      </permissions>
      <self-uri content-type="pdf" xlink:href="file:HBM-44-3410.pdf"/>
      <abstract>
        <title>Abstract</title>
        <p>Most fMRI inferences are based on analyzing the scans of a cohort. Thus, the individual variability of a subject is often overlooked in these studies. Recently, there has been a growing interest in individual differences in brain connectivity also known as individual connectome. Various studies have demonstrated the individual specific component of functional connectivity (FC), which has enormous potential to identify participants across consecutive testing sessions. Many machine learning and dictionary learning‐based approaches have been used to extract these subject‐specific components either from the blood oxygen level dependent (BOLD) signal or from the FC. In addition, several studies have reported that some resting‐state networks have more individual‐specific information than others. This study compares four different dictionary‐learning algorithms that compute the individual variability from the network‐specific FC computed from resting‐state functional Magnetic Resonance Imaging (rs‐fMRI) data having 10 scans per subject. The study also compares the effect of two FC normalization techniques, namely, Fisher Z normalization and degree normalization on the extracted subject‐specific components. To quantitatively evaluate the extracted subject‐specific component, a metric named <mml:math id="jats-math-1" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> is proposed, and it is used in combination with the existing differential identifiability <mml:math id="jats-math-2" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")"><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mfenced></mml:mrow></mml:math> metric. It is based on the hypothesis that the subject‐specific FC vectors should be similar within the same subject and different across different subjects. Results indicate that Fisher Z transformed subject‐specific fronto‐parietal and default mode network extracted using Common Orthogonal Basis Extraction (COBE) dictionary learning have the best features to identify a participant.</p>
      </abstract>
      <abstract abstract-type="graphical">
        <p>The training data matrix <mml:math id="jats-math-3" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> is given as input to the PCA algorithm, which gives <bold>m</bold> principal components (PCs). First <mml:math id="jats-math-4" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> PCs are chosen, and the data are reconstructed to get the subject‐specific components. During testing, the test data <mml:math id="jats-math-5" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> are projected over the PCs computed while training, and the reconstructed matrix is the subject‐specific data matrix.<boxed-text position="anchor" content-type="graphic" id="hbm26289-blkfxd-0001"><graphic xlink:href="HBM-44-3410-g003.jpg" position="anchor" id="jats-graphic-1"/></boxed-text>
</p>
      </abstract>
      <kwd-group kwd-group-type="author-generated">
        <kwd id="hbm26289-kwd-0001">brain atlas</kwd>
        <kwd id="hbm26289-kwd-0002">degree normalization</kwd>
        <kwd id="hbm26289-kwd-0003">dictionary learning</kwd>
        <kwd id="hbm26289-kwd-0004">Fisher Z transform</kwd>
        <kwd id="hbm26289-kwd-0005">fMRI</kwd>
        <kwd id="hbm26289-kwd-0006">functional connectivity</kwd>
        <kwd id="hbm26289-kwd-0007">individual connectome</kwd>
        <kwd id="hbm26289-kwd-0008">resting‐state networks</kwd>
      </kwd-group>
      <funding-group>
        <award-group id="funding-0001">
          <funding-source>National Institute of Health</funding-source>
          <award-id>MH131335</award-id>
        </award-group>
      </funding-group>
      <counts>
        <fig-count count="15"/>
        <table-count count="1"/>
        <page-count count="23"/>
        <word-count count="15927"/>
      </counts>
      <custom-meta-group>
        <custom-meta>
          <meta-name>source-schema-version-number</meta-name>
          <meta-value>2.0</meta-value>
        </custom-meta>
        <custom-meta>
          <meta-name>cover-date</meta-name>
          <meta-value>June 1, 2023</meta-value>
        </custom-meta>
        <custom-meta>
          <meta-name>details-of-publishers-convertor</meta-name>
          <meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:6.2.8 mode:remove_FC converted:10.05.2023</meta-value>
        </custom-meta>
      </custom-meta-group>
    </article-meta>
    <notes>
      <p content-type="self-citation">
<mixed-citation publication-type="journal" id="hbm26289-cit-9001">
<string-name>
<surname>Jain</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Chakraborty</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Hafiz</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Sao</surname>, <given-names>A. K.</given-names>
</string-name>, &amp; <string-name>
<surname>Biswal</surname>, <given-names>B.</given-names>
</string-name> (<year>2023</year>). <article-title>Enhancing the network specific individual characteristics in <styled-content style="fixed-case" toggle="no">rs‐fMRI</styled-content> functional connectivity by dictionary learning</article-title>. <source>Human Brain Mapping</source>, <volume>44</volume>(<issue>8</issue>), <fpage>3410</fpage>–<lpage>3432</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.26289</pub-id>
</mixed-citation>
</p>
    </notes>
  </front>
  <body id="hbm26289-body-0001">
    <sec id="hbm26289-sec-0001">
      <label>1</label>
      <title>INTRODUCTION</title>
      <p>Functional magnetic resonance imaging (fMRI) is a popular noninvasive neuroimaging technique that accommodates high spatial and temporal resolution to perform systems‐level neuroscience in human and animal models. Currently, most fMRI studies use the Blood oxygenation level‐dependent (BOLD) contrast mechanism first proposed by Ogawa et al. (<xref rid="hbm26289-bib-0049" ref-type="bibr">1990</xref>). Ogawa and colleagues showed that changes in blood oxygen levels in the brain (oxygenated blood) can be reflective of the neuronal response during some cognitive or mental task. Since fMRI signals are “dependent” and sensitive to these changes, they are called “Blood Oxygenation Level Dependent” (BOLD) signals. Generally, for task activation studies, subjects are presented with a stimulus for a short period (10–20 s), alternating with about the same period of a control condition. Although task‐fMRI has been widely used to identify brain regions corresponding to specific tasks, it is still not clear which stimulus or task could be appropriate for finding out the unique characteristics of the individual which make every person different. In addition, certain populations such as infants, Alzheimer's patients, and patients with other debilitating clinical disorders may not be able to perform certain tasks required from them.</p>
      <p>Resting‐state fMRI (rs‐fMRI) has emerged as an alternative to task‐fMRI to map brain functions by observing brain signals during rest. This method was first demonstrated in 1995, where it was shown that brain activations in the resting‐state could exhibit similar correlations between brain regions as activations in the task‐state (Biswal et al., <xref rid="hbm26289-bib-0005" ref-type="bibr">1995</xref>). rs‐fMRI primarily focuses on measuring the spontaneous activity in BOLD signals, which is measured in a resting state wherein subjects do not perform specific tasks that may alter brain activity. These rs‐fMRI signals possess very low amplitude fluctuations, resting primarily within the 0.01–0.1 Hz range (van den Heuvel &amp; Hulshoff Pol, <xref rid="hbm26289-bib-0065" ref-type="bibr">2010</xref>). It was shown that rs‐fMRI signals in the sensorimotor and its associated cortex had a significant temporal correlation within the cortex but not with other brain regions. Similar observations were also made in other functional regions, including the visual cortex (Lowe et al., <xref rid="hbm26289-bib-0044" ref-type="bibr">1998</xref>).</p>
      <p>Friston et al. (<xref rid="hbm26289-bib-0030" ref-type="bibr">1993</xref>) first defined functional connectivity (FC) in neuroimaging as temporal correlations between spatially remote neurophysiological events. Because we observed temporal correlation between functionally related regions during resting state, specifically, a high temporal correlation between the fMRI time series between the left and right primary motor network, we used the term resting state functional connectivity (RSFC). These left and right hemispheric regions are spatially distributed but seem to be functionally connected and share information with each other. Various studies have demonstrated similar significant correlations in the other known networks including visual network, auditory network, and other cognitive networks (Biswal et al., <xref rid="hbm26289-bib-0006" ref-type="bibr">1997</xref>; Cordes et al., <xref rid="hbm26289-bib-0015" ref-type="bibr">2000</xref>, <xref rid="hbm26289-bib-0014" ref-type="bibr">2002</xref>; Damoiseaux et al., <xref rid="hbm26289-bib-0016" ref-type="bibr">2006</xref>; De Luca et al., <xref rid="hbm26289-bib-0017" ref-type="bibr">2005</xref>; Fox &amp; Raichle, <xref rid="hbm26289-bib-0029" ref-type="bibr">2007</xref>; Greicius et al., <xref rid="hbm26289-bib-0033" ref-type="bibr">2003</xref>; Lowe et al., <xref rid="hbm26289-bib-0043" ref-type="bibr">2000</xref>; van den Heuvel et al., <xref rid="hbm26289-bib-0064" ref-type="bibr">2008</xref>; Xiong et al., <xref rid="hbm26289-bib-0072" ref-type="bibr">1999</xref>).</p>
      <p>In general, FC from rs‐fMRI can be computed using two widely used methods. The first is data‐driven approaches such as independent component analysis (ICA) that decomposes the fMRI data into spatially segregated components based on how well the voxels within a component are temporally synchronized. The other method is the seed‐based correlation method. It performs the temporal correlation between fMRI time series voxels. The seed‐based method needs prior knowledge of the brain regions of interest (ROIs). Pairwise correlation can then be performed between all ROI's time series to generate a functional brain network.</p>
      <p>Rs‐fMRI possesses several advantages over task‐based fMRI. For one, it is a simpler paradigm that does not require stimuli to be presented to a subject, nor does it require the subject to respond to stimuli. It is also easier for certain patient groups, such as the very young or elderly, to undergo imaging as they do not need to perform actions they may have difficulty with (Maknojia et al., <xref rid="hbm26289-bib-0047" ref-type="bibr">2019</xref>). Additionally, it has been found that rs‐fMRI can pick up on trends in the brain that task‐based fMRI cannot pick up on as well. For example, one study has used rs‐fMRI to classify the social and neurocognitive performance in individuals based on connectivity in sensorimotor networks. Task‐based fMRI was also used for this study but was less sensitive to detecting connectivity in the brain, and its findings did not replicate well across another independent test sample, whereas rs‐fMRI did (Viviano et al., <xref rid="hbm26289-bib-0069" ref-type="bibr">2019</xref>). Besides, Finn et al. (<xref rid="hbm26289-bib-0024" ref-type="bibr">2017</xref>) compared the unique individual characteristics from the Human Connectome Project (HCP) dataset, which contains two resting‐state and seven different task‐based fMRI scans for each subject. The study correlated the FC computed from every pair of fMRI scans for the same subject. It found out that the correlation between the FCs of the two resting‐state scans was higher than the other rest–task or task–task pairs. However, the rest–rest correlation decreased when they reduced the number of time points while calculating the FC, suggesting that more time points are essential for computing the FC.</p>
      <p>Recently, there has been a growing interest in individual differences in Brain Connectivity also known as Individual Connectome. Unlike structural MRI, which is widely used in clinical applications to describe the physical structure of individual brains, fMRI, and RSFC have faced a lot of challenges in extracting the individual‐specific information limiting its clinical use (Gordon et al., <xref rid="hbm26289-bib-0032" ref-type="bibr">2017</xref>). Individual Connectome can help us understand and predict the behavior right from the RSFC as demonstrated by Finn et al. (<xref rid="hbm26289-bib-0025" ref-type="bibr">2015</xref>) which further helps in creating biomarkers or fingerprints that can identify an individual from a cohort. This can also be used as a brain‐based measure on an individual brain.</p>
      <p>One aspect of quantifying the individual differences has been to predict the behavioral scores from the resting state brain scans. Earlier, the neural correlates of individual differences in general fluid intelligence (Gf) have been found to be associated with variations in brain size and connections (Deary, <xref rid="hbm26289-bib-0018" ref-type="bibr">2012</xref>; Jaeggi et al., <xref rid="hbm26289-bib-0037" ref-type="bibr">2008</xref>). Recently, the information flow among certain areas associated with Gf has been quantified by FC. These results suggest that the variation in the correlation between specific brain regions is related to specific behavioral factors that may contribute to individual differences (Haier, <xref rid="hbm26289-bib-0034" ref-type="bibr">2009</xref>; Penke et al., <xref rid="hbm26289-bib-0051" ref-type="bibr">2012</xref>; Song et al., <xref rid="hbm26289-bib-0063" ref-type="bibr">2008</xref>). The whole‐brain FC measure may provide a more holistic sight to determine an individual's Gf rather than global brain size. A recent study Li et al. (<xref rid="hbm26289-bib-0042" ref-type="bibr">2020</xref>) used, a general linear model to predict the Gf scores from healthy participants (<italic toggle="yes">N</italic> = 326) using their FCNs. Moreover, the results of the model were validated by a leave‐one‐out cross‐validation approach, and its performance was measured by computing Pearson's correlation between the predicted and actual Gf scores. The model found FCs in the superior longitudinal fasciculus, deep frontal regions, and ventral fronto‐parietal important for Gf prediction. This result demonstrates that FCs can be used as a predictor of Gf and can potentially be used to predict other phenotypic traits. Furthermore, researchers have reported that the individual connectome can improve prediction performance (Cai et al., <xref rid="hbm26289-bib-0008" ref-type="bibr">2019</xref>; Kashyap et al., <xref rid="hbm26289-bib-0038" ref-type="bibr">2019</xref>; Qin et al., <xref rid="hbm26289-bib-0054" ref-type="bibr">2019</xref>). Thus, studies on extracting the subject‐specific FC have come into prominence.</p>
      <p>Measuring and validating the subject‐specific components can be subjective. Generally, the validation of the subject‐specific components is based on the assumption that the connectivity profiles should be more similar between visits of the same subjects than between different subjects. Finn et al. (<xref rid="hbm26289-bib-0024" ref-type="bibr">2017</xref>) have attempted to explain this assumption using a thought experiment considering Human faces and used the term identifiability as a metric to evaluate the subject‐specific component. They argue that there can be two ways to enhance the identifiability: first by exaggerating the most prominent features of each individual, which make individuals look more different from each other, and second by removing the irrelevant or redundant features while retaining and enriching relevant ones. Moreover, Amico and Goñi (<xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>) uses PCA to remove the redundant features and demonstrates that this can significantly enhance the identifiability. They defined the term differential identifiability <mml:math id="jats-math-6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math>, which quantifies the difference between the average within‐subject FCs similarity and the average between subjects FCs similarity. Most of the studies try to predict the behavioral scores of an individual from the subject‐specific information computed from the FC of the same individual.</p>
      <p>Several studies have attempted to predict the behavioral scores from RSFC using different machine‐learning techniques. Kashyap et al. (<xref rid="hbm26289-bib-0038" ref-type="bibr">2019</xref>) showed how the prediction of behavioral scores could be enhanced by first removing the common components in the RSFC using Common Orthogonal Basis Extraction (COBE) method. Recent work has used more complex methods such as Multi‐Task Learning‐based sparse Convex Alternating Structure Optimization (MTL‐sCASO; Wang et al., <xref rid="hbm26289-bib-0070" ref-type="bibr">2021</xref>) to construct the RSFC in a regularized learning framework. The MTL‐sCASO method defines a term to encompass the effect of the trade‐off between the similar network topology generally shared among individuals and the inter‐individual variability in estimating the brain network during rest. On the other hand, there are studies that have focused on a specific attribute such as, attention (Rosenberg et al., <xref rid="hbm26289-bib-0056" ref-type="bibr">2016</xref>), gender (Smith et al., <xref rid="hbm26289-bib-0062" ref-type="bibr">2014</xref>), procrastination (Wu et al., <xref rid="hbm26289-bib-0071" ref-type="bibr">2016</xref>), age (Geerligs et al., <xref rid="hbm26289-bib-0031" ref-type="bibr">2015</xref>), along with intelligence (Levakov et al., <xref rid="hbm26289-bib-0041" ref-type="bibr">2021</xref>) finding individual differences in bilingual individuals (Nichols et al., <xref rid="hbm26289-bib-0048" ref-type="bibr">2021</xref>), and predicting individual differences in propensity to trust (Lu et al., <xref rid="hbm26289-bib-0045" ref-type="bibr">2019</xref>).</p>
      <p>We can estimate subject‐specific components from either the fMRI BOLD signal time series or from the corresponding FC networks. Extracting the subject‐specific components from the BOLD signal during a task stimulus is preferred as all the subjects are presented with the same stimulus representing similar information of the subject's response. While during resting‐state it is highly probable that the BOLD signal of every subject is different as per their thoughts during the rs‐fMRI scan. Yet, it is shown that the RSFC networks are consistent among the subjects during the rs‐fMRI scan making FC a better choice over the BOLD signal to get the subject‐specific components. Iqbal et al. (<xref rid="hbm26289-bib-0036" ref-type="bibr">2018</xref>) demonstrated how the shared and the subject‐specific components could be extracted from the BOLD signal of each voxel in task fMRI using the shared and subject‐specific dictionary learning (ShSSDL) algorithm. The ShSSDL algorithm generates a group level as well as a set of subject‐specific voxel‐wise spatial maps by simultaneously learning multiple dictionaries about the analyzed task fMRI datasets. While the ShSSDL is performed voxel‐wise, Kashyap et al. (<xref rid="hbm26289-bib-0038" ref-type="bibr">2019</xref>) have used the COBE algorithm that uses ROI‐based time‐courses. They used 400 parcellations by Schaefer et al. (<xref rid="hbm26289-bib-0057" ref-type="bibr">2018</xref>) on (Yeo et al., <xref rid="hbm26289-bib-0073" ref-type="bibr">2011</xref>) brain atlas, which results in shared and individual time series that is further used to compute the FC from resting‐state data.</p>
      <p>Several studies have attempted to extract individual differences at the FC level. Researchers have used similarity measures such as Pearson correlation between FCs computed by two or more scans of the same subject (Finn et al., <xref rid="hbm26289-bib-0025" ref-type="bibr">2015</xref>, <xref rid="hbm26289-bib-0024" ref-type="bibr">2017</xref>; Kraus et al., <xref rid="hbm26289-bib-0040" ref-type="bibr">2021</xref>) others compute them with algorithms that either exploit the sparse nature of the FC (Wang et al., <xref rid="hbm26289-bib-0070" ref-type="bibr">2021</xref>) or use analysis techniques like representational similarity analysis (Nichols et al., <xref rid="hbm26289-bib-0048" ref-type="bibr">2021</xref>). There are other studies that use machine learning‐based methods like Amico and Goñi (<xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>) that demonstrate how principal component analysis (PCA) can enhance the individual differences and Qin et al. (<xref rid="hbm26289-bib-0054" ref-type="bibr">2019</xref>) showed how low‐rank learning algorithms like Robust PCA (RPCA) could also improve these differences. Moreover, K‐SVD, a well‐known algorithm in machine learning, was used by Cai et al. (<xref rid="hbm26289-bib-0008" ref-type="bibr">2019</xref>) which shows encouraging results. On the other hand, Pallarés et al. (<xref rid="hbm26289-bib-0050" ref-type="bibr">2018</xref>) have attempted to bring out the individual differences from effective connectivity (EC), which uses causality to compute the connectivity matrix, unlike FC, which uses Pearson correlation.</p>
      <p>A vital requirement for estimation of FC is to choose a suitable Brain Atlas from the many available in the literature. Finn et al. (<xref rid="hbm26289-bib-0025" ref-type="bibr">2015</xref>) initially demonstrated results with the functional atlas developed by Shen et al. (<xref rid="hbm26289-bib-0060" ref-type="bibr">2013</xref>) having 268 ROIs and also compared it with Free Surfer atlas (Fischl et al., <xref rid="hbm26289-bib-0027" ref-type="bibr">2004</xref>) having 68 ROIs, concluding higher resolution atlas boosts identification rate within the subjects. Wang et al. (<xref rid="hbm26289-bib-0070" ref-type="bibr">2021</xref>) have also compared different parcellation schemes and have emphasized on using Whole Brain atlas including the subcortical regions. Cai et al. (<xref rid="hbm26289-bib-0009" ref-type="bibr">2020</xref>), Lu et al. (<xref rid="hbm26289-bib-0045" ref-type="bibr">2019</xref>), Rosenberg et al. (<xref rid="hbm26289-bib-0056" ref-type="bibr">2016</xref>), and Shen et al. (<xref rid="hbm26289-bib-0059" ref-type="bibr">2017</xref>) have also used the Shen 268 node atlas, while studies like Qin et al. (<xref rid="hbm26289-bib-0054" ref-type="bibr">2019</xref>) have used the Dosenbach 160 node (Dosenbach et al., <xref rid="hbm26289-bib-0021" ref-type="bibr">2010</xref>) atlas, and other studies Kashyap et al. (<xref rid="hbm26289-bib-0038" ref-type="bibr">2019</xref>), Levakov et al. (<xref rid="hbm26289-bib-0041" ref-type="bibr">2021</xref>), and Pessoa et al. (<xref rid="hbm26289-bib-0052" ref-type="bibr">2021</xref>) have used the Schaefer atlas. Recently, Kong et al. (<xref rid="hbm26289-bib-0039" ref-type="bibr">2019</xref>) proposed a multi‐session hierarchical Bayesian Model (MS‐HBM) to estimate functional network parcellations of the cerebral cortex in individual subjects. MS‐HBM model attempts to estimate individual‐specific cerebral cortex parcellations using multi‐session fMRI data. Thus, many studies have attempted to use different brain atlases throughout the literature, but very few have compared the effect of varying the atlas.</p>
      <p>Normalization of FC is something that is not very well reported in the literature, various studies like Finn et al. (<xref rid="hbm26289-bib-0024" ref-type="bibr">2017</xref>), Geerligs et al. (<xref rid="hbm26289-bib-0031" ref-type="bibr">2015</xref>), Gordon et al. (<xref rid="hbm26289-bib-0032" ref-type="bibr">2017</xref>), and Kraus et al. (<xref rid="hbm26289-bib-0040" ref-type="bibr">2021</xref>) have used the Fisher Z normalization over the FC, while other studies like Amico and Goñi (<xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>), Cai et al. (<xref rid="hbm26289-bib-0008" ref-type="bibr">2019</xref>), and Kashyap et al. (<xref rid="hbm26289-bib-0038" ref-type="bibr">2019</xref>) have directly used FC without Fisher Z normalization. However, a recent study Chiem et al. (<xref rid="hbm26289-bib-0012" ref-type="bibr">2021</xref>) reported that by using degree normalization one could improve the differential identifiability <mml:math id="jats-math-7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> score. This shows that normalization is essential, and hence in this study, we also study the effect of normalization on the subject‐specific component.</p>
      <p>In this article, we reviewed four dictionary learning (DL) methods that have been used to determine individual‐specific connectivity or components, that is, PCA, RPCA, KSVD, and COBE. We use two publicly available datasets that have multiple sessions of scanning data sets. In the first data set, the Midnight Scan Club (MSC) had scanned 10 subjects with 10 sessions per subject. For the second data set, HNU, had scanned 30 subjects with 10 sessions per subject. Each of these datasets was split into training and testing sets, the dictionaries were learned using the training set and they were further used to decompose the test set to get the subject‐specific component. This analysis was performed on the FC computed by each of the seven resting‐state networks (RSNs) given by Yeo et al. (<xref rid="hbm26289-bib-0073" ref-type="bibr">2011</xref>). We compare the different RSNs in terms of which network has the maximum subject‐specific information. We have used a grid search to determine the values of the hyper‐parameters involved in each of the DL algorithms. Further, we have checked the reproducibility and generalizability by repeating the analysis each time choosing a different set of data to train the dictionaries of the DL algorithms. We also report the effect of varying the time‐points and the effect of changing the parcellation scheme (Brain atlas) which in turn affects the FC computation. Normalization methods have also been taken into consideration by repeating the analysis first without any normalization method and then by Fisher Z and degree normalization.</p>
    </sec>
    <sec sec-type="materials-and-methods" id="hbm26289-sec-0002">
      <label>2</label>
      <title>MATERIALS AND METHODS</title>
      <sec id="hbm26289-sec-0003">
        <label>2.1</label>
        <title>Resting‐state <styled-content style="fixed-case" toggle="no">fMRI</styled-content> data</title>
        <p>This study employed two publicly available datasets: Hangzhou Normal University (HNU) and Midnight Scan Club (MSC).</p>
        <sec id="hbm26289-sec-0004">
          <label>2.1.1</label>
          <title>The <styled-content style="fixed-case" toggle="no">MSC</styled-content> datasets</title>
          <p>The MSC dataset includes 10 healthy individuals (5 males, 5 females) aged between 24 and 31 years of age. The scanning protocol was approved by the local Institutional Review Board at Washington University in St. Louis. All subjects signed informed consent. Each subject was scanned for four T1 weighted images with a Siemens Trio Tim scanner with repetition time (TR) = 2400 ms, echo time (TE) = 3.74 ms, flip angle = 8°, voxel size of <mml:math id="jats-math-8" display="inline" overflow="scroll"><mml:mrow><mml:mn>0.8</mml:mn><mml:mo>×</mml:mo><mml:mn>0.8</mml:mn><mml:mo>×</mml:mo><mml:mn>0.8</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">m</mml:mi><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math> having 224 Sagittal slices. Along with this, each subject underwent 10 rs‐fMRI scans each half an hour long with TR = 2200 ms, TE = 27 ms, flip angle = 90°, and 36 axial slices with 818 volumes. Subjects were instructed to keep their eyes open while observing a plus sign. More details can be found in Gordon et al. (<xref rid="hbm26289-bib-0032" ref-type="bibr">2017</xref>).</p>
        </sec>
        <sec id="hbm26289-sec-0005">
          <label>2.1.2</label>
          <title>
<styled-content style="fixed-case" toggle="no">HNU</styled-content> dataset</title>
          <p>The HNU dataset includes 30 healthy individuals (15 males, 15 females) aged between 20 and 30 years of age. Each participant was scanned 10 times in 1 month, with each scanning occurring every 3 days. The study was approved by the local IRB and informed consent was obtained from all the subjects prior to scanning. All the data was collected using a 3T GE Scanner. The anatomical T1 weighted images were acquired using a 3D SPGR sequence with TR 8.06 ms, flip angle of 8°, voxel size of <mml:math id="jats-math-9" display="inline" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">m</mml:mi><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math> with 180 Sagittal slices. Scan parameters for the EPI sequence used to collect the rs‐fMRI data include TR = 2000 ms, TE = 30 ms, flip angle = 90°, 43 axial slices with image size <mml:math id="jats-math-10" display="inline" overflow="scroll"><mml:mrow><mml:mn>64</mml:mn><mml:mo>×</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:math>, voxel size of <mml:math id="jats-math-11" display="inline" overflow="scroll"><mml:mrow><mml:mn>3.4</mml:mn><mml:mo>×</mml:mo><mml:mn>3.4</mml:mn><mml:mo>×</mml:mo><mml:mn>3.4</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">m</mml:mi><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math>. Each resting‐state scan lasted for 10 min which resulted in 300 volumes. During the rs‐fMRI data collection, participants were asked to keep their eyes open while observing a fixation cross. More details can be found in Chen et al. (<xref rid="hbm26289-bib-0011" ref-type="bibr">2015</xref>) and Zuo et al. (<xref rid="hbm26289-bib-0075" ref-type="bibr">2014</xref>).</p>
        </sec>
      </sec>
      <sec id="hbm26289-sec-0006">
        <label>2.2</label>
        <title>Data preprocessing</title>
        <p>The data from both sites were preprocessed using the same pipeline. We preprocessed the raw rsfMRI data with the SPM12 toolbox (<ext-link xlink:href="http://www.fil.ion.ucl.ac.uk/spm/" ext-link-type="uri">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>). First, we discarded the first 10 volumes for the MSC data for T1 saturation effects. For the HNU data set, the first 50 data points were excluded to further avoid susceptibility issues. Motion correction algorithms were performed for the detection and correction of head motion‐related signal changes. Briefly, the preprocessing included five steps: slice timing correction, realignment, coregistration, normalization, and smoothing. Slice time correction corrects the differences in image acquisition time between the slices. Realignment realigns the time‐series of images acquired from the same scan using a least‐squares approach and a six parameter (rigid body) spatial transformation. Motion correction is done in this stage. The T1‐weighted anatomical image of each subject was coregistered to the corresponding functional scans. Normalization was performed to nonlinearly transform the functional data to the standard Montreal Neurological Institute (MNI) space. The spatial resolution of each voxel was resampled to isotropic <mml:math id="jats-math-12" display="inline" overflow="scroll"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">m</mml:mi><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math>. The normalized functional images were then smoothed with a Gaussian kernel of 8 mm. The time‐series signal from each voxel was then filtered in the frequency range of 0.01–0.1 Hz. Figure <xref rid="hbm26289-fig-0001" ref-type="fig">1</xref> shows the Overview of the preprocessing, Atlas parcellation, FC computation, normalization, and making the training and test matrix which will be given as input to the DL algorithms.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0001">
          <label>FIGURE 1</label>
          <caption>
            <p>Overview of preprocessing, FC computation, and the Train‐Test Split. The 4‐dimensional rs‐fMRI data are preprocessed in MATLAB 2019b using the SPM 12 toolbox, further segmented into ROIs using a predefined Brain Atlas. The BOLD time courses within an ROI are averaged to get one time course for an ROI. Moreover, the time courses belonging to each of the seven networks (Yeo et al., <xref rid="hbm26289-bib-0073" ref-type="bibr">2011</xref>) are chosen one by one, and an FC matrix specific to the rs‐network is formed using Pearson Correlation. Since this correlation matrix is symmetric, only the upper‐triangular elements are vectorized, and a data matrix is formed by concatenating the upper triangular vectors from each scan. The train‐test split is further performed by placing five sessions per subject for training and the other five for test over the data matrix, the Fisher Z transformed, and the Degree Normalized data matrix. These matrices are given as input to the dictionary learning algorithms.</p>
          </caption>
          <graphic xlink:href="HBM-44-3410-g002" position="anchor" id="jats-graphic-3"/>
        </fig>
      </sec>
      <sec id="hbm26289-sec-0007">
        <label>2.3</label>
        <title>Brain atlas</title>
        <p>Parcellation divides each cerebral hemisphere into anatomical and/or functional ROIs. To identify different functional brain regions, standard brain atlas commonly used in fMRI literature were used. For this study, Schaffer 400 atlas (Schaefer et al., <xref rid="hbm26289-bib-0057" ref-type="bibr">2018</xref>) was used. Briefly, it used both task and resting‐state fMRI to generate a gradient‐weighted Markov Random Field (gwMRF) model integrating local gradient and global similarity approaches. Applying the gwMRF model on about 1500 subjects, Schaefer and colleagues could generate atlases with different numbers of ROIs such as 100, 200, 300, up to 1000, distributed across several functional networks. The preprocessed data were parcellated using nine different predefined brain atlases of different resolutions to show the effect of the Brain atlas on the estimated individual components. Several complimentary atlases, which were publicly available and commonly used, such as Dosenbach, Brainnetome, Power, Shen, and Seitzman were also included in the study. Dosenbach atlas was created by several meta‐analyses of task‐fMRI activation studies. Brainnetome atlas was created by initially starting with an automatic surface parcellation and subcortical segmentation using free surfer's Desikan–Killiany atlas (Desikan et al., <xref rid="hbm26289-bib-0019" ref-type="bibr">2006</xref>) and modifying it with the structural information from diffusion tensor imaging (DTI) and functional information from RSFC acquired from 40 subjects. The Power atlas used a combination of task fMRI and rs‐fMRI to create 264 nodes in the brain atlas. Brain regions that reliably displayed significant activity when certain tasks such as button pressing were performed identified around 151 ROIs. Further FC mapping techniques were used from rs‐fMRI data of 40 subjects to define the other 193 ROIs. The Shen atlas was created using a Groupwise multigraph K‐way spectral clustering algorithm that jointly optimizes the group and the individual parcellation. Last, Seitzman and colleagues modified the power atlas using a winner take all partitioning technique to make the Seitzman atlas.</p>
        <p>Table <xref rid="hbm26289-tbl-0001" ref-type="table">1</xref> gives the summary of the atlases used in this study. We have also reported the average number of voxels per ROI for every atlas used in this study, which is crucial in selecting the atlas. We have included atlases such as Dosenbach (Dosenbach et al., <xref rid="hbm26289-bib-0021" ref-type="bibr">2010</xref>), Power (Power et al., <xref rid="hbm26289-bib-0053" ref-type="bibr">2011</xref>), and Seitzman atlas (Seitzman et al., <xref rid="hbm26289-bib-0058" ref-type="bibr">2020</xref>), that do not assign every voxel in the brain to a region, instead they define a spherical region around a seed voxel. Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S6</xref> shows the atlas views of all the atlases used in this study. Further, for a fair comparison of RSNs present in each of the atlases, the Yeo 7 resting‐state (RS) network atlas (Yeo et al., <xref rid="hbm26289-bib-0073" ref-type="bibr">2011</xref>) was overlaid on each of these atlases, and the nodes of the atlas were assigned a particular Yeo network by checking the extent of overlap of each of the Yeo networks with the node. The network which was maximally overlapped with the node was assigned to the node. A similar approach has been used by van Geest et al. (<xref rid="hbm26289-bib-0066" ref-type="bibr">2018</xref>).</p>
        <table-wrap position="float" id="hbm26289-tbl-0001" content-type="TABLE">
          <label>TABLE 1</label>
          <caption>
            <p>Brief details of atlases.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <thead valign="bottom">
              <tr style="border-bottom:solid 1px #000000">
                <th align="left" valign="bottom" rowspan="1" colspan="1">Atlas</th>
                <th align="left" valign="bottom" rowspan="1" colspan="1">ROIs</th>
                <th align="left" valign="bottom" rowspan="1" colspan="1">Method</th>
                <th align="left" valign="bottom" rowspan="1" colspan="1">Average number of voxels per ROI</th>
                <th align="left" valign="bottom" rowspan="1" colspan="1">References</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Dosenbach</td>
                <td align="left" valign="top" rowspan="1" colspan="1">160</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Meta‐analysis of task‐fMRI activation studies.</td>
                <td align="left" valign="top" rowspan="1" colspan="1">123</td>
                <td align="left" valign="top" rowspan="1" colspan="1">(Dosenbach et al., <xref rid="hbm26289-bib-0021" ref-type="bibr">2010</xref>)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Brainnetome</td>
                <td align="left" valign="top" rowspan="1" colspan="1">246</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Structural and functional information.</td>
                <td align="left" valign="top" rowspan="1" colspan="1">477</td>
                <td align="left" valign="top" rowspan="1" colspan="1">(Fan et al., <xref rid="hbm26289-bib-0023" ref-type="bibr">2016</xref>)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Power</td>
                <td align="left" valign="top" rowspan="1" colspan="1">264</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Used a combination of task based and rs‐fMRI data.</td>
                <td align="left" valign="top" rowspan="1" colspan="1">8</td>
                <td align="left" valign="top" rowspan="1" colspan="1">(Power et al., <xref rid="hbm26289-bib-0053" ref-type="bibr">2011</xref>)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Shen</td>
                <td align="left" valign="top" rowspan="1" colspan="1">268</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Groupwise multigraph K‐way spectral clustering algorithm.</td>
                <td align="left" valign="top" rowspan="1" colspan="1">601</td>
                <td align="left" valign="top" rowspan="1" colspan="1">(Shen et al., <xref rid="hbm26289-bib-0060" ref-type="bibr">2013</xref>)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Seitzman</td>
                <td align="left" valign="top" rowspan="1" colspan="1">300</td>
                <td align="left" valign="top" rowspan="1" colspan="1">Winner takes all partitioning technique.</td>
                <td align="left" valign="top" rowspan="1" colspan="1">58</td>
                <td align="left" valign="top" rowspan="1" colspan="1">(Seitzman et al., <xref rid="hbm26289-bib-0058" ref-type="bibr">2020</xref>)</td>
              </tr>
              <tr>
                <td align="left" valign="top" rowspan="1" colspan="1">Schaefer</td>
                <td align="left" valign="top" rowspan="1" colspan="1">100, 200, 300, 400</td>
                <td align="left" valign="top" rowspan="1" colspan="1">gwMRF.</td>
                <td align="left" valign="top" rowspan="1" colspan="1">1320, 660, 440, 330</td>
                <td align="left" valign="top" rowspan="1" colspan="1">(Schaefer et al., <xref rid="hbm26289-bib-0057" ref-type="bibr">2018</xref>)</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="hbm26289-sec-0008">
        <label>2.4</label>
        <title>
<styled-content style="fixed-case" toggle="no">FC</styled-content> computation</title>
        <p>Here, we briefly describe the FC computation done in this study. Instead of calculating the FC of the whole brain, we have calculated the network‐specific FC for each of the 7 Yeo rs‐networks. After identifying the preprocessed data with the different atlas mentioned before, the BOLD time series corresponding to each ROI were averaged, and a mean time series was formed. A pairwise correlation was performed between averaged time series from each region, which results in <mml:math id="jats-math-13" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math> correlation matrix, where <italic toggle="yes">n</italic> is the number of ROIs in the atlas corresponding to an RS network. The resultant correlation matrix is symmetric and transformed into a vector, defined as an FC vector, by considering only the upper triangular part of the FC matrix. The length of the FC vector is <mml:math id="jats-math-14" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math>. We have 10 such FC vectors for an RS‐network per subject since we have 10 sessions per subject. These correlation values are also normalized using Fisher Z transformation and degree normalization to report the effects of normalization methods. The details of Fisher Z transformation and degree normalization are given below.</p>
      </sec>
      <sec id="hbm26289-sec-0009">
        <label>2.5</label>
        <title>Normalizing the <styled-content style="fixed-case" toggle="no">FC</styled-content>
</title>
        <p>The FC matrix is the output of Pearson Correlation and hence is in the range from [−1, 1]. Since these are correlation values, we could use some well‐defined transformations like the Fisher Z transformation that works on the distribution of the correlation values. Fisher Z transforms as discussed below is a transform that works on every correlation value independent of the other. On the other hand, techniques like degree normalization treat the FC matrix as an adjacency matrix and scale every correlation value according to the values that are in its neighborhood.</p>
        <sec id="hbm26289-sec-0010">
          <label>2.5.1</label>
          <title>Fisher Z</title>
          <p>The distribution of correlation value for a given RS‐network is highly skewed (Ehtemami et al., <xref rid="hbm26289-bib-0022" ref-type="bibr">2018</xref>; Silver &amp; Dunlap, <xref rid="hbm26289-bib-0061" ref-type="bibr">1987</xref>), hence a normalizing transform developed by Fisher is used for converting the skewed distribution of the sample correlation into a normal distribution. The Fisher's Z transformation is given by,<disp-formula id="hbm26289-disp-0001">
<label>(1)</label>
<mml:math id="jats-math-15" display="block" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mn>0.5</mml:mn><mml:mspace width="0.25em"/><mml:mfenced open="[" close="]"><mml:mrow><mml:mi>ln</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">−</mml:mo><mml:mi>ln</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">−</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Here, <mml:math id="jats-math-16" display="inline" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:math> refers to the Pearson correlation value and <mml:math id="jats-math-17" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:math> refers to the corresponding Fisher Z transformation. Fisher Z transform can also be viewed as a nonlinear transformation that enhances the extremely correlated or anti‐correlated values and suppresses the values in between. The range of correlation is transformed from [−1, 1] to <mml:math id="jats-math-18" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="[" close="]" separators=","><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math>
</p>
        </sec>
        <sec id="hbm26289-sec-0011">
          <label>2.5.2</label>
          <title>Degree normalization</title>
          <p>Degree normalization, also known as adjacency matrix normalization, is a technique used in graph theory where the <mml:math id="jats-math-19" display="inline" overflow="scroll"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math> ROIs are assumed as a node of a graph and the correlation values are assumed as the weight of the edges connecting the nodes. In this method, the correlation values of a particular node are scaled by the degree of the node, that is, sum of the correlation values between the given node and all other nodes. Let the Pearson's Correlation matrix here assumed to be Adjacency matrix be denoted as <mml:math id="jats-math-20" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math>. Without loss of generality, the self‐loops (or self‐correlation) are ignored. To avoid complex values, the unsigned version of <mml:math id="jats-math-21" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow></mml:math> is considered by taking the entry‐wise absolute value of the correlation coefficients in <mml:math id="jats-math-22" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow></mml:math> denoted as <mml:math id="jats-math-23" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow></mml:math>. The normalized correlation matrix <mml:math id="jats-math-24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mtext mathvariant="bold-italic">degree</mml:mtext></mml:msub></mml:mrow></mml:math> is obtained as<disp-formula id="hbm26289-disp-0002">
<label>(2)</label>
<mml:math id="jats-math-25" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mtext mathvariant="bold-italic">degree</mml:mtext></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mn mathvariant="bold">2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mfenced open="|" close="|"><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mfenced><mml:msup><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:mn mathvariant="bold">2</mml:mn></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-26" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> is given by,<disp-formula id="hbm26289-disp-0003">
<mml:math id="jats-math-27" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="hbm26289-disp-0004">
<mml:math id="jats-math-28" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">B</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo mathvariant="bold-italic" linebreak="goodbreak">=</mml:mo><mml:mn>0</mml:mn><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math>
</disp-formula>and <mml:math id="jats-math-29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> is the degree computed as,<disp-formula id="hbm26289-disp-0005">
<mml:math id="jats-math-30" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mfenced open="|" close="|"><mml:mi>A</mml:mi></mml:mfenced><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Degree normalization modulates any excessive influence of the nodes by its corresponding weighted degree. It is worth noting that the range of values in the degree normalized matrix is from 0 to 1; however, due to the division by degree, the values tend to become relatively small. (Refer to Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S1</xref> for the flowchart of computation of the degree normalization).</p>
        </sec>
      </sec>
      <sec id="hbm26289-sec-0012">
        <label>2.6</label>
        <title>
<styled-content style="fixed-case" toggle="no">Train‐Test</styled-content> Split</title>
        <p>Of the 10 FC vectors per subject, we used five for training the DL algorithms, and the other five were used for testing. Effectively, we have a data matrix for training <mml:math id="jats-math-31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> and for testing <mml:math id="jats-math-32" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> for the <mml:math id="jats-math-33" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> subject.</p>
        <p>Further, we ran the algorithms for every possible combination of scan in train and test matrix to check the stability and reproducibility, that is, discussed in Section <xref rid="hbm26289-sec-0032" ref-type="sec">3.10</xref>.</p>
      </sec>
      <sec id="hbm26289-sec-0013">
        <label>2.7</label>
        <title>Dictionary learning algorithms</title>
        <p>DL is a technique used in machine learning and signal processing to extract a set of finite features known as atoms, that can represent the data. Based on the DL algorithm used, a linear combination of atoms can represent the data in a compact form. Using the compact or sparse representation, the common or the subject‐specific component of the data can be extracted.</p>
        <p>In general, DL algorithms aim to express a given signal <mml:math id="jats-math-34" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:math> as a linear combination of atoms. The collection of atoms is defined as a dictionary <mml:math id="jats-math-35" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mrow></mml:math> and the signal <mml:math id="jats-math-36" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:math> can be written as<disp-formula id="hbm26289-disp-0006">
<label>(3)</label>
<mml:math id="jats-math-37" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="bold-italic">Dx</mml:mi><mml:mo mathvariant="bold-italic">,</mml:mo></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-38" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:math> is the coefficient vector depicting the weights of each atom toward the construction of signal. The available dictionaries in the literature can be classified into two categories namely: analytic and data‐driven. In the first category, the dictionary is defined using mathematical expressions, such as Fourier Transform, Cosine Transform, and so on, which does not depend on the data. The second category uses the data (example signals) to derive the atoms of the dictionary. The examples here are PCA, ICA, K‐Singular Value Decomposition (KSVD), and so on. In the literature, data‐driven dictionaries are preferred over analytic dictionaries hence we focus only on the data‐driven dictionaries. For a collection of <mml:math id="jats-math-39" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math> different signals Equation (<xref rid="hbm26289-disp-0006" ref-type="disp-formula">3</xref>) can be written as<disp-formula id="hbm26289-disp-0007">
<label>(4)</label>
<mml:math id="jats-math-40" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="bold-italic">DX</mml:mi><mml:mo mathvariant="bold-italic">.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
        <p>Here <mml:math id="jats-math-41" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators=",,,,"><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi>…</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math> and <mml:math id="jats-math-42" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators=",,,"><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi>…</mml:mi></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math>. We briefly describe 4 such DL algorithms namely, PCA, RPCA, KSVD, and COBE and their application to compute the individual specific components from the given network specific FC.</p>
        <sec id="hbm26289-sec-0014">
          <label>2.7.1</label>
          <title>Principal component analysis (<styled-content style="fixed-case" toggle="no">PCA</styled-content>)</title>
          <p>PCA is a widely used method for dimensionality reduction in the area of pattern recognition. It can be considered as one of the DL approaches, where the dictionary is formed using eigenvectors (also called principal components [PCs]) of the data's covariance matrix. Which makes the data uncorrelated in the transformed space. Here, a given observation can be written as a linear combination of PCs. Amico and Goñi (<xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>) showed how to maximize the individual fingerprint in the FC domain by reconstructing the FCs by an optimal number of PCs.</p>
          <p>Here we concatenate every subject's data matrix to one global data matrix as follows,<disp-formula id="hbm26289-disp-0008">
<label>(5)</label>
<mml:math id="jats-math-43" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfenced open="[" close="]" separators=",,,,"><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi>…</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:mfenced><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mn>5</mml:mn><mml:mi>p</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Here, <mml:math id="jats-math-44" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:math> is the total number of subjects. First, the mean <mml:math id="jats-math-45" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math> is subtracted from each row <mml:math id="jats-math-46" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math> and then the eigen vectors and the eigen values are estimated from the covariance matrix of <mml:math id="jats-math-47" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math>. The mean subtracted matrix <mml:math id="jats-math-48" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math> can be decomposed as follows,<disp-formula id="hbm26289-disp-0009">
<label>(6)</label>
<mml:math id="jats-math-49" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-50" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators=",,,,"><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi>…</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msub></mml:mfenced></mml:mrow></mml:math> and <mml:math id="jats-math-51" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> are the eigen vectors. <mml:math id="jats-math-52" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub></mml:mrow></mml:math> is the corresponding coefficient matrix estimated by <mml:math id="jats-math-53" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="italic">pca</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math>. Moreover, the subject‐specific component (<mml:math id="jats-math-54" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Su</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub></mml:mrow></mml:math>) can be estimated by choosing <mml:math id="jats-math-55" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mspace width="0.25em"/><mml:mfenced open="(" close=")"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>&lt;</mml:mo><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:math> eigen vectors corresponding to the <mml:math id="jats-math-56" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> highest eigen values as follows,<disp-formula id="hbm26289-disp-0010">
<label>(7)</label>
<mml:math id="jats-math-57" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Su</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi mathvariant="italic">pca</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="italic">pca</mml:mi><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi mathvariant="italic">pca</mml:mi><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Here <mml:math id="jats-math-58" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="italic">pca</mml:mi><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msubsup><mml:mo mathvariant="bold-italic">=</mml:mo><mml:mfenced open="[" close="]" separators=",,,,"><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi>…</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msub></mml:mfenced></mml:mrow></mml:math> and <mml:math id="jats-math-59" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi mathvariant="italic">pca</mml:mi><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msubsup></mml:mrow></mml:math> is the corresponding coefficient matrix.</p>
          <p>During the testing phase, the testing data matrix <mml:math id="jats-math-60" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> is first concatenated to make a global test matrix <mml:math id="jats-math-61" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> which is then subtracted by the mean vector <mml:math id="jats-math-62" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math> found at the training phase and further projected on the eigenvectors <mml:math id="jats-math-63" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi mathvariant="italic">pca</mml:mi><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:msubsup></mml:mrow></mml:math>. Furthermore, the projected data are reconstructed back in the original space, which gives us the subject‐specific components. Figure <xref rid="hbm26289-fig-0002" ref-type="fig">2</xref> summarizes the training and the testing phase of PCA to find the individual differences.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0002">
            <label>FIGURE 2</label>
            <caption>
              <p>The Training data matrix <mml:math id="jats-math-64" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> is given as input to the PCA algorithm, which gives <bold>m</bold> principal components (PCs). First <mml:math id="jats-math-65" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> PCs are chosen, and the data are reconstructed to get the subject‐specific components. During testing, the test data <mml:math id="jats-math-66" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> are projected over the PCs computed while training, and the reconstructed matrix is the subject‐specific data matrix.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g006" position="anchor" id="jats-graphic-5"/>
          </fig>
        </sec>
        <sec id="hbm26289-sec-0015">
          <label>2.7.2</label>
          <title>Robust <styled-content style="fixed-case" toggle="no">PCA</styled-content> (<styled-content style="fixed-case" toggle="no">RPCA</styled-content>)</title>
          <p>It has been observed that PCA is sensitive to noise and corrupted observations, as PCA minimizes the squared error between the original data and the PCA reconstructed data. Candes et al. (<xref rid="hbm26289-bib-0010" ref-type="bibr">2009</xref>) addresses this issue by a method Robust PCA (RPCA), which attempts to minimize the absolute value of the error, which makes RPCA robust to noise.</p>
          <p>This approach decomposes the global FC data matrix <mml:math id="jats-math-67" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> as<disp-formula id="hbm26289-disp-0011">
<label>(8)</label>
<mml:math id="jats-math-68" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo mathvariant="bold" linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mo mathvariant="bold" linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mo mathvariant="bold-italic">,</mml:mo></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-69" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> is a low‐rank matrix and <mml:math id="jats-math-70" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> is sparse, both have the same dimensions as that of <mml:math id="jats-math-71" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math>. Further, as described by Qin et al. (<xref rid="hbm26289-bib-0054" ref-type="bibr">2019</xref>), an Online Dictionary learning (ODL) (Mairal et al., <xref rid="hbm26289-bib-0046" ref-type="bibr">2010</xref>) algorithm is trained on the sparse connectivity traits matrix <mml:math id="jats-math-72" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> after making it zero mean and unit variance, giving us the basis that can determine the traits matrix for any test scan. ODL attempts to decompose the traits matrix as follows,<disp-formula id="hbm26289-disp-0012">
<label>(9)</label>
<mml:math id="jats-math-73" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">α</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Here <mml:math id="jats-math-74" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> is the basis Dictionary, <mml:math id="jats-math-75" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> is the number of basis, and <mml:math id="jats-math-76" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">α</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> is the corresponding coefficient matrix. The <mml:math id="jats-math-77" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> matrix is stored, which can generate the trait matrix for any test scan. In this study, we have used the implementation provided by Aravkin et al. (<xref rid="hbm26289-bib-0004" ref-type="bibr">2014</xref>) for the RPCA algorithm and the SPAMS toolbox for ODL computation (Mairal et al., <xref rid="hbm26289-bib-0046" ref-type="bibr">2010</xref>). Qin et al. (<xref rid="hbm26289-bib-0054" ref-type="bibr">2019</xref>) also attempted to find the subject‐specific components in a similar manner.</p>
          <p>In the testing phase, least squares are used to get the coefficients <mml:math id="jats-math-78" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">α</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> from the stored <mml:math id="jats-math-79" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> basis for the global test matrix <mml:math id="jats-math-80" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> as described in Qin et al. (<xref rid="hbm26289-bib-0054" ref-type="bibr">2019</xref>).<disp-formula id="hbm26289-disp-0013">
<label>(10)</label>
<mml:math id="jats-math-81" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Sub</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">α</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>The overview of the training and testing phase of the RPCA algorithm is summarized in Figure <xref rid="hbm26289-fig-0003" ref-type="fig">3</xref>.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0003">
            <label>FIGURE 3</label>
            <caption>
              <p>RPCA training and testing overview. The data matrix <mml:math id="jats-math-82" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> goes through the RPCA algorithm during the training phase, which decomposes <mml:math id="jats-math-83" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> into a low‐rank matrix <mml:math id="jats-math-84" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> and a sparse matrix <mml:math id="jats-math-85" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math>. <mml:math id="jats-math-86" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> having the individual differences is further decomposed by Online Dictionary Learning (ODL) which finds out the basis <mml:math id="jats-math-87" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> whose linear combination can construct the individual components to any data matrix. This gives the subject‐specific components for training. During the test, least squares are used to get the coefficients <mml:math id="jats-math-88" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">α</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mtext mathvariant="italic">rpca</mml:mtext></mml:msub></mml:mrow></mml:math> for the test matrix <mml:math id="jats-math-89" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> which on reconstruction gives the subject‐specific component.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g007" position="anchor" id="jats-graphic-7"/>
          </fig>
        </sec>
        <sec id="hbm26289-sec-0016">
          <label>2.7.3</label>
          <title>K‐SVD</title>
          <p>K‐SVD is a well‐known DL algorithm for obtaining sparse codes over a dictionary to reconstruct the data matrix. It is an iterative method that alternates between sparse coding of the examples based on the current dictionary and then updating the dictionaries using Singular value decomposition (SVD) to fit the data (Aharon et al., <xref rid="hbm26289-bib-0002" ref-type="bibr">2006</xref>). Recently, Cai et al. (<xref rid="hbm26289-bib-0008" ref-type="bibr">2019</xref>) demonstrated that subtracting the data matrix <mml:math id="jats-math-90" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> from its approximate matrix using KSVD, brings out the individual components in the FC vectors.</p>
          <p>K‐SVD is performed on the global data matrix formed by concatenating all the subject's data matrix (refer Equation <xref rid="hbm26289-disp-0008" ref-type="disp-formula">5</xref>). K‐SVD decomposes the global data matrix <mml:math id="jats-math-91" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> as follows,<disp-formula id="hbm26289-disp-0014">
<label>(11)</label>
<mml:math id="jats-math-92" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub></mml:mrow></mml:math>
</disp-formula>where <mml:math id="jats-math-93" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> denotes the dictionary consisting of <mml:math id="jats-math-94" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> dictionary atoms and <mml:math id="jats-math-95" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>×</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>5</mml:mn><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:math> denotes the corresponding sparse codes learnt by the K‐SVD algorithm. The dictionaries are initialized randomly, and the sparse codes with sparsity <mml:math id="jats-math-96" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> are learned by Orthogonal Matching Pursuit (OMP). Further, the <italic toggle="yes">k</italic>‐dictionary atoms are updated one by one using SVD. Least squares are used to get the coefficient matrix <mml:math id="jats-math-97" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub></mml:mrow></mml:math> for the global testing data matrix <mml:math id="jats-math-98" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> using the dictionaries <mml:math id="jats-math-99" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub></mml:mrow></mml:math>. We used the implementation provided by Aharon and Elad (<xref rid="hbm26289-bib-0001" ref-type="bibr">2008</xref>) for OMP. The individual components for the test are computed by subtracting the reconstructed data matrix from the test data matrix as follows,<disp-formula id="hbm26289-disp-0015">
<label>(12)</label>
<mml:math id="jats-math-100" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Su</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:mo mathvariant="bold" linebreak="goodbreak">=</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo mathvariant="bold" linebreak="goodbreak">−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:mo mathvariant="bold-italic">.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Figure <xref rid="hbm26289-fig-0004" ref-type="fig">4</xref> shows the Block diagram summarizing the training and testing phase of K‐SVD.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0004">
            <label>FIGURE 4</label>
            <caption>
              <p>K‐SVD training and testing overview. K‐SVD algorithm decomposes the data matrix <mml:math id="jats-math-101" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> into a dictionary <mml:math id="jats-math-102" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub></mml:mrow></mml:math> and sparse coefficients <mml:math id="jats-math-103" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow></mml:math>. The product <mml:math id="jats-math-104" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">ksvd</mml:mtext></mml:msub></mml:mrow></mml:math> represents the common or shared information. This, when subtracted with the data matrix <mml:math id="jats-math-105" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> gives the subject‐specific component. During testing, least squares are used to find the coefficients for the Dictionary obtained during the test. This, when subtracted from the Test data matrix <mml:math id="jats-math-106" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math>, gives us the Subject‐specific matrix for the test.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g012" position="anchor" id="jats-graphic-9"/>
          </fig>
        </sec>
        <sec id="hbm26289-sec-0017">
          <label>2.7.4</label>
          <title>Common orthogonal basis extraction</title>
          <p>COBE was first described by Zhou et al. (<xref rid="hbm26289-bib-0074" ref-type="bibr">2016</xref>). It works on multiblock data where data are a collection of matrices. COBE tries to find an orthogonal basis that is shared by all the matrices in the data. Kashyap et al. (<xref rid="hbm26289-bib-0038" ref-type="bibr">2019</xref>) demonstrated how the algorithm could be applied to rs‐fMRI data. They have demonstrated the efficacy of the COBE algorithm on the averaged BOLD signal using a combination of Schaefer 400 nodes Atlas and 19 subcortical regions (Fischl et al., <xref rid="hbm26289-bib-0026" ref-type="bibr">2002</xref>), while in this study, we use it on the FC vectors. In this approach, individual matrix is decomposed as,<disp-formula id="hbm26289-disp-0016">
<label>(13)</label>
<mml:math id="jats-math-107" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:mo linebreak="goodbreak">+</mml:mo><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:msub><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Here, <mml:math id="jats-math-108" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> is the shared dictionary containing <mml:math id="jats-math-109" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> atoms common to all subjects and <mml:math id="jats-math-110" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math> is the subject‐specific dictionary containing <mml:math id="jats-math-111" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> atoms for the <mml:math id="jats-math-112" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> subject. <mml:math id="jats-math-113" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> and <mml:math id="jats-math-114" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> are the corresponding coefficients of the shared and subject‐specific dictionaries. However, the COBE algorithm focuses on getting the shared dictionary <mml:math id="jats-math-115" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub></mml:mrow></mml:math> and its coefficients <mml:math id="jats-math-116" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math>. The subject‐specific component <mml:math id="jats-math-117" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:msub><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub></mml:mrow></mml:math> is later found by subtracting the shared component from the data matrix <mml:math id="jats-math-118" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> as follows,<disp-formula id="hbm26289-disp-0017">
<label>(14)</label>
<mml:math id="jats-math-119" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:msub><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msup><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak">−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>The shared dictionary <mml:math id="jats-math-120" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub></mml:mrow></mml:math> is stored in memory to get the individual differences in the test scans.</p>
          <p>An important point that distinguishes the COBE algorithm from the algorithms discussed before is that here the subject data matrix <mml:math id="jats-math-121" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> containing the five sessions of the subject is given and not the global matrix <mml:math id="jats-math-122" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math>, which makes COBE a supervised algorithm.</p>
          <p>In the testing phase, least squares are used to acquire the coefficients <mml:math id="jats-math-123" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math> corresponding to the shared dictionary <mml:math id="jats-math-124" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub></mml:mrow></mml:math> for the global test data matrix <mml:math id="jats-math-125" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math>. After which we subtract the reconstructed shared information from the original data matrix to obtain the subject‐specific information as follows,<disp-formula id="hbm26289-disp-0018">
<label>(15)</label>
<mml:math id="jats-math-126" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Su</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo mathvariant="bold" linebreak="goodbreak">−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:mo mathvariant="bold-italic">.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>Figure <xref rid="hbm26289-fig-0005" ref-type="fig">5</xref> shows the flowchart describing the training and testing phase of the COBE algorithm to find the subject‐specific component.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0005">
            <label>FIGURE 5</label>
            <caption>
              <p>COBE training and testing overview. Here instead of the Global data matrix <mml:math id="jats-math-127" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math> the subject data matrix <mml:math id="jats-math-128" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> is given individually to the COBE algorithm which decomposes the matrix into a dictionary <mml:math id="jats-math-129" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub></mml:mrow></mml:math> and coefficients matrix <mml:math id="jats-math-130" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math> for every subject. The product <mml:math id="jats-math-131" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub><mml:msubsup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math> is subtracted from <mml:math id="jats-math-132" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> for every subject which gives the subject‐specific components. During test, the least‐squares algorithm is used to get the coefficients for the dictionary <mml:math id="jats-math-133" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mtext mathvariant="italic">cobe</mml:mtext></mml:msub></mml:mrow></mml:math> obtained during training. Finally, the subject‐wise subtraction of the reconstructed matrix with the test data matrix <mml:math id="jats-math-134" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> gives the subject‐specific matrix during test.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g014" position="anchor" id="jats-graphic-11"/>
          </fig>
        </sec>
      </sec>
      <sec id="hbm26289-sec-0018">
        <label>2.8</label>
        <title>Metrics for evaluating the subject‐specific components</title>
        <p>This section discusses the metrics used to evaluate the subject‐specific components computed by the DL algorithms.</p>
        <sec id="hbm26289-sec-0019">
          <label>2.8.1</label>
          <title>Differential identifiability quality function <mml:math id="jats-math-135" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")"><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mtext mathvariant="bold-italic">diff</mml:mtext></mml:msub></mml:mfenced></mml:mrow></mml:math>
</title>
          <p>This metric is taken from Amico and Goñi (<xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>), it is calculated as follows. Considering <mml:math id="jats-math-136" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:math> number of subjects and <mml:math id="jats-math-137" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math> number of sessions per subject, the sessions of every subject are arranged together such that we get <mml:math id="jats-math-138" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math> different matrices each consisting of the <mml:math id="jats-math-139" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> session (<mml:math id="jats-math-140" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math>) of every subject. The size of these matrices is <mml:math id="jats-math-141" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math>. Considering two matrix at a time we will have <mml:math id="jats-math-142" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi><mml:mspace width="0.25em"/></mml:mrow><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math> different combinations. For each combination, let <mml:math id="jats-math-143" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math>, <mml:math id="jats-math-144" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math> be the “identifiability matrix,” which is computed by talking a correlation of the two matrices containing <mml:math id="jats-math-145" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> and the <mml:math id="jats-math-146" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> sessions of every subject. The dimension of <mml:math id="jats-math-147" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> is <mml:math id="jats-math-148" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math> (see Figure <xref rid="hbm26289-fig-0006" ref-type="fig">6a</xref>), where <mml:math id="jats-math-149" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:math> is the number of subjects in the database. Let <mml:math id="jats-math-150" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math> represents the average of the main diagonal elements of <mml:math id="jats-math-151" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math>, which consist of the Pearson correlation values between visits of the same subjects. Similarly, let <mml:math id="jats-math-152" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">others</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math> defines the average of the off‐diagonal elements of matrix <mml:math id="jats-math-153" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> that is, the correlation between visits of different subjects. Then the differential identifiability (<mml:math id="jats-math-154" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math>) is defined as the difference between both terms as,<disp-formula id="hbm26289-disp-0019">
<label>(16)</label>
<mml:math id="jats-math-155" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo linebreak="goodbreak">−</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">others</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo linebreak="goodbreak">×</mml:mo><mml:mn>100</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:math>
</disp-formula>
</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0006">
            <label>FIGURE 6</label>
            <caption>
              <p>(a) <mml:math id="jats-math-156" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> computation: The subject‐specific data matrix consisting of <mml:math id="jats-math-157" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> and the <mml:math id="jats-math-158" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>j</mml:mi><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> sessions of all the subjects. Further <mml:math id="jats-math-159" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> is computed by taking Pearson correlation. <mml:math id="jats-math-160" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext></mml:msub></mml:mrow></mml:math> is the mean of diagonal elements and <mml:math id="jats-math-161" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">others</mml:mtext></mml:msub></mml:mrow></mml:math> is the mean of non‐diagonal elements of the correlation matrix obtained in b. <mml:math id="jats-math-162" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math> is computed using Equation (<xref rid="hbm26289-disp-0019" ref-type="disp-formula">16</xref>). Finally, <mml:math id="jats-math-163" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> is computed as mean of the <mml:math id="jats-math-164" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> values computed taking every <mml:math id="jats-math-165" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mi mathvariant="italic">th</mml:mi></mml:msup></mml:mrow></mml:math> pair. (b) <mml:math id="jats-math-166" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> computation: A Pearson correlation matrix is computed from the subject‐specific data matrix. This correlation matrix was partitioned into <mml:math id="jats-math-167" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math> sub‐matrices each of size <mml:math id="jats-math-168" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi><mml:mo>×</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math>, then the histogram of the diagonal blocks would represent within‐subject similarity (WSS) values and the histogram of non‐diagonal blocks would represent between‐subject similarity (BSS) values. Using these histograms, a threshold is computed such that any value above the threshold is considered within‐subject and below the threshold is considered between‐subject. The threshold that minimizes the error is taken and stored in memory during the training phase. During the testing phase, the threshold computed during training is used. The total number of values in error is called <mml:math id="jats-math-169" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. (c) Ratio of <mml:math id="jats-math-170" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-171" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>: Plot shows the variation of the ratio to with the variation of <mml:math id="jats-math-172" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> and <mml:math id="jats-math-173" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g011" position="anchor" id="jats-graphic-13"/>
          </fig>
          <p>We get <mml:math id="jats-math-174" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> such <mml:math id="jats-math-175" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math> scores. The mean of these scores over all <mml:math id="jats-math-176" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> pairs is the <mml:math id="jats-math-177" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> score.<disp-formula id="hbm26289-disp-0020">
<mml:math id="jats-math-178" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mfrac><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math>
</disp-formula>
</p>
          <p>It should be noted that a greater <mml:math id="jats-math-179" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> score, signifies better estimate of individual components. Ideally <mml:math id="jats-math-180" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> should be 100.</p>
        </sec>
        <sec id="hbm26289-sec-0020">
          <label>2.8.2</label>
          <title>Overlap</title>
          <p>Assuming <mml:math id="jats-math-181" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:math> subjects and <mml:math id="jats-math-182" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math> sessions per subject, there are <mml:math id="jats-math-183" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math> individual FC vectors in all. The hypothesis is that the individual‐specific FC vectors should be similar within the same subject and different across different subjects. The Pearson correlation of the estimated individual‐specific FC vectors between every scan of every subject can be computed and obtain a <mml:math id="jats-math-184" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")"><mml:mi mathvariant="italic">ps</mml:mi></mml:mfenced><mml:mo>×</mml:mo><mml:mfenced open="(" close=")"><mml:mi mathvariant="italic">ps</mml:mi></mml:mfenced></mml:mrow></mml:math> matrix. If this correlation matrix is partitioned into <mml:math id="jats-math-185" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math>, <mml:math id="jats-math-186" display="inline" overflow="scroll"><mml:mrow><mml:mi>s</mml:mi><mml:mo>×</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math> matrices, the diagonal blocks represent the within‐subject correlation values, and the other blocks represent the between‐subject correlation values (see Figure <xref rid="hbm26289-fig-0006" ref-type="fig">6b</xref>). From this, a histogram of the between subject's correlation value and within subject's correlation value can be computed. Using the histogram, a threshold can be found, which separates the within and between‐subject distributions. This threshold can help identify whether a test scan belongs to the same subject or not. After thresholding, the total number of correlations that are misclassified or, in other words, the overlap between the within‐subject and the between‐subject distributions is used to determine how good the subject‐specific component is. The less the <mml:math id="jats-math-187" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>, the better the individuality in the subject‐specific component. The optimal threshold that minimizes the <mml:math id="jats-math-188" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> is saved for each DL algorithm during the training phase. This threshold is then used during the testing phase to determine the overlap during the test. A less value of <mml:math id="jats-math-189" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> is desirable. Ideally <mml:math id="jats-math-190" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> should be <mml:math id="jats-math-191" display="inline" overflow="scroll"><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:math>.</p>
        </sec>
        <sec id="hbm26289-sec-0021">
          <label>2.8.3</label>
          <title>Ratio of <mml:math id="jats-math-192" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mtext mathvariant="bold-italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-193" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="bold-italic">Overlap</mml:mtext></mml:mrow></mml:math>
</title>
          <p>
<mml:math id="jats-math-194" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> looks at the mean of within and between subjects' correlation value, hence for <mml:math id="jats-math-195" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to be high, the means of within‐subject correlation and the between‐subject correlation should be far apart. Since <mml:math id="jats-math-196" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> only accounts for the mean and not the variance, it is possible to have a reasonably good <mml:math id="jats-math-197" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math>, but a high value of <mml:math id="jats-math-198" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. For example, consider <mml:math id="jats-math-199" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">others</mml:mtext></mml:msub></mml:mrow></mml:math> = 0.3 and the between‐subject distribution to have a large variance, due to this there is a good chance that some of the between‐subject correlations are close to 1. Similarly, say <mml:math id="jats-math-200" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext></mml:msub></mml:mrow></mml:math> = 0.7 but with a large variance of within‐subject correlation there can be quite a few values that are close to 0; Although, in this case, the means of both the distribution are far, resulting in a good <mml:math id="jats-math-201" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> (40 in this case), <mml:math id="jats-math-202" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> can be high and thus it is a better metric as it shows the actual error one can get while identifying within or between subject correlations. On the other hand, <mml:math id="jats-math-203" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> explains the separation between the means of within‐subject and between‐subject distribution while <mml:math id="jats-math-204" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">overlap</mml:mtext></mml:mrow></mml:math> does not. We not only want to minimize the <mml:math id="jats-math-205" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">overlap</mml:mtext></mml:mrow></mml:math> of the two distributions, but also want the distributions to be far apart, as, the more they are apart in training, it is probable that they will be apart during testing. So, if for two cases the <mml:math id="jats-math-206" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">overlap</mml:mtext></mml:mrow></mml:math> is the same, we want to give a higher score to the case having the means of the two distributions farther which can be done using <mml:math id="jats-math-207" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math>. Both cases are essential. The former says there should be one threshold that can differentiate the within and between subjects with minimum error, while the latter says the means of the within‐subject, and the between‐subject correlations should be far apart for better repeatability. To account for both, we take the ratio of <mml:math id="jats-math-208" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-209" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>, which must be maximized. Both the extent of separation of the means of <mml:math id="jats-math-210" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext></mml:msub></mml:mrow></mml:math> and <mml:math id="jats-math-211" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">others</mml:mtext></mml:msub></mml:mrow></mml:math> and the classification error of within and between‐subject correlations are taken into consideration here. The ratio will have a higher value if there are less misclassifications (lower <mml:math id="jats-math-212" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>) and the separation between the means of within and between subjects' distribution is large (higher <mml:math id="jats-math-213" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math>). See Figure <xref rid="hbm26289-fig-0006" ref-type="fig">6c</xref> which shows the variation of the ratio as <mml:math id="jats-math-214" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> and <mml:math id="jats-math-215" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> are varied.</p>
        </sec>
      </sec>
    </sec>
    <sec sec-type="results" id="hbm26289-sec-0022">
      <label>3</label>
      <title>RESULTS</title>
      <p>One subject from the HNU dataset and one from the MSC dataset was excluded as they had motion displacements greater than 3 mm. For this study, we used the Schaefer atlas to determine 400 ROIs. For each ROI, the number of voxels time courses was averaged to find a representative time course corresponding to the ROI. This was done for all the 400 ROIs.</p>
      <sec id="hbm26289-sec-0023">
        <label>3.1</label>
        <title>
<mml:math id="jats-math-216" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math>, <mml:math id="jats-math-217" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>, ratio of <mml:math id="jats-math-218" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-219" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> before applying any algorithm</title>
        <p>The <mml:math id="jats-math-220" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> and <mml:math id="jats-math-221" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> for the Fisher Z transformed raw correlation values of the fronto‐parietal network (FPN) and Somato Motor network (SMN) were 32 and 26, 262, and 432, respectively (refer to Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S2</xref>). The greater <mml:math id="jats-math-222" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> for FPN suggests that the difference between the mean value of self‐individuality (<mml:math id="jats-math-223" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext></mml:msub></mml:mrow></mml:math>) (similar to mean within‐subject correlation) and <mml:math id="jats-math-224" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">other</mml:mtext></mml:msub></mml:mrow></mml:math> (similar to mean between‐subject correlations) for FPN is greater than SMN. The <mml:math id="jats-math-225" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> values suggest that FPN is better able to classify the within and between‐subject correlations with fewer errors as compared to the SMN. Ideally, a high value of <mml:math id="jats-math-226" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> signifies that the means of <mml:math id="jats-math-227" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">self</mml:mtext></mml:msub></mml:mrow></mml:math> and <mml:math id="jats-math-228" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">other</mml:mtext></mml:msub></mml:mrow></mml:math> are as far as possible and on the other hand, an <mml:math id="jats-math-229" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> of 0, would mean that no within or between subject correlations are misclassified.</p>
        <p>For FPN and SMN, the ratio of <mml:math id="jats-math-230" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-231" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> with Fisher Z normalization was 0.12 and 0.06, respectively. This suggests that FPN is better as compared to SMN in finding the subject‐specific information.</p>
        <p>Based on the above‐mentioned analysis we found that the FPN for degree normalization had the highest value of the ratio of <mml:math id="jats-math-232" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-233" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> (0.2) among the 7 Yeo networks followed by default mode network (DMN) with a value of 0.16 and dorsal attention network (DAN) with a value of 0.35. Limbic network (LN), visual network (VN), SMN, and ventral attention network (VAN) had relatively lower values of the ratio.</p>
      </sec>
      <sec id="hbm26289-sec-0024">
        <label>3.2</label>
        <title>Parameter search</title>
        <p>Here we discuss how the parameters for the different dictionary algorithms effect the ratio of <mml:math id="jats-math-234" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-235" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>.</p>
        <sec id="hbm26289-sec-0025">
          <label>3.2.1</label>
          <title>PCA</title>
          <p>PCA has only one parameter that we can tune to maximize the ratio of <mml:math id="jats-math-236" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-237" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> which is the number of PCs used to reconstruct the train data matrix <mml:math id="jats-math-238" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math>. Figure <xref rid="hbm26289-fig-0007" ref-type="fig">7</xref> shows the variation of the ratio of <mml:math id="jats-math-239" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-240" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> with respect to the change in number of PC used for reconstruction. The number of PCs was varied from 1 to 189 for every RSN and with different normalization methods. Referring to Figure <xref rid="hbm26289-fig-0007" ref-type="fig">7</xref>, the ratio initially increased as the number of PC were increased, it reached a peak around 50 components and then decreased as the number of PC were increased. DMN was observed to be a better network as it gave the highest value for the ratio due to its low value for overlap (around 100 and <mml:math id="jats-math-241" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> around 35 with no normalization and Fisher Z), but FPN was observed to be better if degree normalization is considered as it achieved a higher <mml:math id="jats-math-242" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> value of 40. The LN, however, achieved the lowest value of the ratio as compared to any other Yeo rs‐networks as it had the maximum <mml:math id="jats-math-243" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> value (around 700) across all normalization methods and a lowest <mml:math id="jats-math-244" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> (about 28) with no normalization and Fisher Z normalization and around 25 with degree normalization.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0007">
            <label>FIGURE 7</label>
            <caption>
              <p>Number of Principle components (PC) used versus the ratio of <mml:math id="jats-math-245" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-246" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. Plots show how the ratio changes as we change the number of PCs used to reconstruct the train data matrix <mml:math id="jats-math-247" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math>. The number of PCs varied from 1 to 189 in steps of 5. (a–c) The effect of the different normalization methods on the ratio.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g009" position="anchor" id="jats-graphic-15"/>
          </fig>
          <p>We also looked at the percentage of variance explained by each PC. We observed the first 50 PCs explained about 93% of variance for the LN when no normalization or Fisher Z normalization was used but with degree normalization, only 86% of variance was explained. However, with the DMN the first 50 components explained 86% variance using no normalization or Fisher Z normalization, and with degree normalization that fell to 79%. FPN also gave results similar to the DMN. The other networks had a lesser percentage of variance explained by the first 50 components compared with the LN but greater than the DMN (refer to Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S3</xref>).</p>
        </sec>
        <sec id="hbm26289-sec-0026">
          <label>3.2.2</label>
          <title>R‐PCA</title>
          <p>Although R‐PCA does not have any parameters that can be tweaked, the ODL algorithm applied on the sparse connectivity matrix obtained from R‐PCA had two parameters that are, (1) <mml:math id="jats-math-248" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math>: number of atoms in the dictionary and (2) <mml:math id="jats-math-249" display="inline" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math> parameter. The number of dictionary atoms <mml:math id="jats-math-250" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> were varied from 25 to 70 in steps of 5, and we observed from Figure <xref rid="hbm26289-fig-0008" ref-type="fig">8</xref> that <mml:math id="jats-math-251" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> in between 35 and 50, irrespective of <mml:math id="jats-math-252" display="inline" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math>, acquired a relatively high value of the ratio of <mml:math id="jats-math-253" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-254" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. Especially when <mml:math id="jats-math-255" display="inline" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math> is in between 0.3 and 0.5, the ratio is at its peak. The DMN and the FPN achieve a value around 0.7 when 40 dictionary atoms are used with degree normalization. The value of the ratio for DAN is around 0.5 using 40 dictionaries. For the other networks, the value of the ratio is less than 0.2 when using degree normalization. However, with Fisher Z transform all networks, except for VAN and the SMN, do not perform as well as they perform with degree normalization.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0008">
            <label>FIGURE 8</label>
            <caption>
              <p>Effect of changing the number of atoms (<mml:math id="jats-math-256" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math>) and the <mml:math id="jats-math-257" display="inline" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math> parameter of the dictionary computed by the Online dictionary learning algorithm on the Sparse connectivity Traits matrix obtained by the R‐PCA algorithm on the training data matrix <mml:math id="jats-math-258" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math>. The number of dictionary atoms k is varied from 25 to 70 in steps of 5, and the <mml:math id="jats-math-259" display="inline" overflow="scroll"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:math> parameter is varied from 0.1 to 0.5 in steps of 0.05.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g001" position="anchor" id="jats-graphic-17"/>
          </fig>
        </sec>
        <sec id="hbm26289-sec-0027">
          <label>3.2.3</label>
          <title>K‐SVD</title>
          <p>The number of atoms in the K‐SVD dictionary <mml:math id="jats-math-260" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> and the corresponding Sparsity parameter <mml:math id="jats-math-261" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> are the two parameters that had to be tuned to maximize the ratio of <mml:math id="jats-math-262" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-263" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. Both <mml:math id="jats-math-264" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-265" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> were varied from 2 to 8 as shown in Figure <xref rid="hbm26289-fig-0009" ref-type="fig">9</xref>. K‐SVD enhances the ratio to about 0.7 in FPN with <mml:math id="jats-math-266" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> value around 44 and <mml:math id="jats-math-267" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> of 64 using two dictionary atoms and about 0.8 for the DMN (<mml:math id="jats-math-268" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> = 42, <mml:math id="jats-math-269" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> = 52) using 3 or 4 dictionary atoms with the Fisher Z normalization. DAN is at the third place with the ratio being 0.5 (<mml:math id="jats-math-270" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> = 44 and <mml:math id="jats-math-271" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> = 86) when two dictionary atoms were used with Fisher Z transform. LN was observed to have a value of ratio less than 0.1, because of a very high <mml:math id="jats-math-272" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> which was greater than 500 across all Normalization methods as well as all values of <mml:math id="jats-math-273" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-274" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>, and a low <mml:math id="jats-math-275" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> as well. Using no normalization DMN achieved a value of ratio around 0.5 using 6 dictionary atoms. FPN with no normalization achieved a value around 0.35 (<mml:math id="jats-math-276" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> = 41 and <mml:math id="jats-math-277" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> = 116) with 3 or 4 dictionary atoms and DAN achieved a ratio of 0.25 (<mml:math id="jats-math-278" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> = 40 and <mml:math id="jats-math-279" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> = 168) using 2 dictionary atoms. Otherwise, the values of the ratio for networks other than DMN, FPN, and DAN were mostly less than 0.2 because of a high overlap that was greater than 200 when no normalization was used. Degree normalization was observed to have higher values of the ratio in FPN, and DAN networks as compared with no normalization with DAN achieving a value around 0.3 (<mml:math id="jats-math-280" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> = 41 and <mml:math id="jats-math-281" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> = 138) and FPN achieving a value around 0.45 (<mml:math id="jats-math-282" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> = 43 and <mml:math id="jats-math-283" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> = 98) using two dictionary atoms.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0009">
            <label>FIGURE 9</label>
            <caption>
              <p>Variation of number of atoms (<mml:math id="jats-math-284" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math>) in the K‐SVD dictionary and the sparsity (<mml:math id="jats-math-285" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math>) in the corresponding coefficient matrix. <mml:math id="jats-math-286" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math> and <mml:math id="jats-math-287" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math> is varied from 2 to 8, across all the rs‐networks and normalization methods.</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g005" position="anchor" id="jats-graphic-19"/>
          </fig>
        </sec>
        <sec id="hbm26289-sec-0028">
          <label>3.2.4</label>
          <title>COBE</title>
          <p>COBE had only one parameter, that is the number of common components <mml:math id="jats-math-288" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math>, which could be tuned to maximize the ratio of <mml:math id="jats-math-289" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-290" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> (refer Figure <xref rid="hbm26289-fig-0010" ref-type="fig">10</xref>). We varied the number of common components from 2 to 5 and checked the value of the ratio. Results show an increasing trend as the number of common components <mml:math id="jats-math-291" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> was increased for all networks except the LN, which is almost constant. However, for the DMN, FPN, and the DAN networks, <mml:math id="jats-math-292" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> increased more rapidly compared to others. DMN and FPN achieved the highest value of the ratio which is a little greater than 1.5 with the Fisher Z transformation. Taking <mml:math id="jats-math-293" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> as 5 gave the best results across all networks as well as normalization methods.</p>
          <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0010">
            <label>FIGURE 10</label>
            <caption>
              <p>Variation of number of common components <mml:math id="jats-math-294" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:math> in COBE algorithm. We can observe the change in the ratio of <mml:math id="jats-math-295" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-296" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> with respect to the number of common components chosen in the COBE algorithm. The number of common components was varied from 2 to 5 for all networks across all normalization methods (a–c).</p>
            </caption>
            <graphic xlink:href="HBM-44-3410-g015" position="anchor" id="jats-graphic-21"/>
          </fig>
        </sec>
      </sec>
      <sec id="hbm26289-sec-0029">
        <label>3.3</label>
        <title>Comparison between the DL algorithms</title>
        <p>Here we compare the results obtained after choosing the best parameters that maximize the ratio of <mml:math id="jats-math-297" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-298" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. Referring to Figure <xref rid="hbm26289-fig-0011" ref-type="fig">11a–f</xref>, it is observed that the COBE algorithm with the Fisher Z transformation gave the best results with DMN during the training and testing phase by achieving the value of the ratio as high as 1.6 and 0.8, respectively. On the other hand, the LN, VN, and SMN seemed to have poor performance both during testing and training. The ratio for the LN remained unchanged, irrespective of the DL algorithms used. PCA, being computationally the simplest algorithm relative to the others mentioned here performed slightly better than the original raw correlations when none of the DL algorithms were used. RPCA performed exceptionally well when degree normalization was used. RPCA achieved a value of the ratio of around 0.7 for the DMN and FPN networks during training which is better than KSVD which achieved a value around 0.5. Using no normalization or Fisher Z normalization KSVD performs better than RPCA.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0011">
          <label>FIGURE 11</label>
          <caption>
            <p>(a–c) Comparison between the dictionary learning algorithms during training. Following parameter check, we choose the parameters which maximize the ratio of <mml:math id="jats-math-299" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-300" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> and present the results here. (d–f) Comparison between the dictionary learning algorithms during test. Using the parameters and the thresholds for <mml:math id="jats-math-301" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> computation during training, these are the results obtained during the testing phase. Results were obtained using the Schaefer 400 atlas.</p>
          </caption>
          <graphic xlink:href="HBM-44-3410-g013" position="anchor" id="jats-graphic-23"/>
        </fig>
      </sec>
      <sec id="hbm26289-sec-0030">
        <label>3.4</label>
        <title>Variation with scan length</title>
        <p>Figure <xref rid="hbm26289-fig-0012" ref-type="fig">12</xref> shows the effect of variation of BOLD time points on the ratio of <mml:math id="jats-math-302" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-303" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> computed using the original FC and the subject‐specific FC extracted from the 4 DL algorithms during the training phase (Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S5</xref> shows the results obtained during the testing phase). We observed that during both training and testing phases the ratio increased as the number of time points increased, suggesting that FC computed using more time points give better subject‐specific components. However, LN does not show much variation as the time scan length increased. Referring to Figure <xref rid="hbm26289-fig-0012" ref-type="fig">12</xref>, the ratio remained constant at around 0.05 for LN. The ratio for DMN, FPN, and the DAN networks increased as more and more time points are used to compute the FC, suggesting more potential in these networks to enhance the individual components, with the exception of the RPCA algorithm where the DMN network saturated after 7 min to value of 0.4, 0.7, and 0.7 with no normalization, Fisher Z normalization, and degree normalizations, respectively. DMN along with Fisher Z transform acquired the maximum value of the ratio among other networks. Before using the DL algorithms with fisher Z normalization DMN achieved a value of 0.2, with PCA the value increased to 0.5, RPCA and KSVD had similar values around 0.7, and with COBE the value was maximum at 1.6. In comparison, the values of DMN with no normalization were lower with COBE achieving the maximum at just 0.75. Fisher Z transformed FC extracted the best Individual components as compared to no normalized and degree normalized FC.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0012">
          <label>FIGURE 12</label>
          <caption>
            <p>Effect of varying the number of time points in the BOLD signal on the ratio of <mml:math id="jats-math-304" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-305" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> computed using the (a) the original functional connectivity (b) the subject‐specific functional connectivity extracted by DL algorithms during the training phase. The time points were varied as 1, 3, 5, 7, and 8.5 min. Results were obtained using the Schaefer 400 atlas.</p>
          </caption>
          <graphic xlink:href="HBM-44-3410-g008" position="anchor" id="jats-graphic-25"/>
        </fig>
      </sec>
      <sec id="hbm26289-sec-0031">
        <label>3.5</label>
        <title>Variation with atlas</title>
        <p>Looking at Figure <xref rid="hbm26289-fig-0013" ref-type="fig">13</xref> we observed the effect of varying the brain atlas on the ratio of <mml:math id="jats-math-306" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-307" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> computed using the original FC and the subject‐specific FC extracted from the 4 DL algorithms during the training phase (refer Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S6</xref> for the results obtained during the testing phase). The Brain atlases are arranged in decreasing order of average number of voxels per ROI, with Schaefer 100 having the largest average number of voxels per ROI and power having the least (refer Table <xref rid="hbm26289-tbl-0001" ref-type="table">1</xref>). Considering results obtained during the training and testing phases we observed that the less the average number of voxels per ROI in the brain atlas, the higher the ratio <mml:math id="jats-math-308" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub><mml:mo>/</mml:mo><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math>. We also observed a dip at the Dosenbach atlas in both the training and testing phases across all the DL algorithms. Dosenbach atlas, although having a low average number of voxels per ROI, has only 164 ROI, which is very less as compared to the ones in its neighbor (Seitzman having 300 ROIs, and Schaefer 400 having 400 ROIs). This suggested that less Average number of voxels per ROI and a greater total number of ROIs are desirable.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0013">
          <label>FIGURE 13</label>
          <caption>
            <p>Effect of variation of brain atlas on the ratio of <mml:math id="jats-math-309" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-310" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> during the training phase. On the x‐axis brain atlas are arranged in decreasing order of average number of voxels per ROI.</p>
          </caption>
          <graphic xlink:href="HBM-44-3410-g010" position="anchor" id="jats-graphic-27"/>
        </fig>
      </sec>
      <sec id="hbm26289-sec-0032">
        <label>3.6</label>
        <title>Stability</title>
        <p>The algorithms were repeated 252 <mml:math id="jats-math-311" display="inline" overflow="scroll"><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:msup><mml:mrow/><mml:mn>10</mml:mn></mml:msup><mml:msub><mml:mi>C</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math> times (by choosing 5 scans out of the available 10 scans for training), each time picking a different combination of scans for training and testing to check the Algorithm's stability. Figure <xref rid="hbm26289-fig-0014" ref-type="fig">14</xref> shows the standard deviation of the ratio of <mml:math id="jats-math-312" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-313" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> found at each iteration across the networks and the normalization methods. Overall, the maximum standard deviation was around 0.3 for the DMN and FPN with Fisher Z transformation using the COBE algorithm, while others were primarily below 0.15 during training. After COBE, RPCA had the second‐largest standard deviation (around 0.15), especially with the degree normalization with DMN and FPN. DMN and FPN were observed to have a larger standard deviation as compared to the other networks. LN showed the least standard deviation across all the DL algorithms as well as the Normalization methods. KSVD had a lower standard deviation as compared to RPCA and COBE. Moreover, PCA results were the most stable with the least standard deviation, especially with the degree normalization. The more the standard deviation the less the stability as more standard deviation suggests that the results are dependent on which combination of subjects are used as training and testing. Ideally, the results should only be dependent on the DL algorithm, normalization method and the brain atlases used. Looking at Figure <xref rid="hbm26289-fig-0014" ref-type="fig">14</xref> we observed that despite COBE having a high standard deviation (especially for DMN and FPN using the Fisher Z normalization), the minimum value of the ratio of <mml:math id="jats-math-314" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-315" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> (which is 0.9 for DMN) is still higher than the maximum value of KSVD (which is 0.8 for DMN). Making COBE a better choice over KSVD. An important point to note is that the stability results were very similar between training and test which showed that all the algorithms have a good generalization.</p>
        <fig position="float" fig-type="FIGURE" id="hbm26289-fig-0014">
          <label>FIGURE 14</label>
          <caption>
            <p>Results were repeated 252 <mml:math id="jats-math-316" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msup><mml:mrow/><mml:mn>10</mml:mn></mml:msup><mml:msub><mml:mi>C</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math>) times, each time taking a different set of training and testing data for the different dictionary learning algorithms. (a–c) The standard deviation of the ratio computed at each iteration across the different networks and the different normalization methods during training. (d–f) The results during the test.</p>
          </caption>
          <graphic xlink:href="HBM-44-3410-g004" position="anchor" id="jats-graphic-29"/>
        </fig>
      </sec>
      <sec id="hbm26289-sec-0033">
        <label>3.7</label>
        <title>Time taken by each algorithm</title>
        <p>We also recorded the time taken by the algorithm to compute the subject‐specific FC to compare their performance with respect to the amount of time they take. These results were recorded on a Linux mint machine with an intel core i7 processor and 16 GB RAM. Further, the MATLAB 2019b was used to compute all the results of this study. Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S4</xref> shows the time taken by the algorithms across Normalization methods as well as across networks using Schaefer 300 nodes atlas. PCA took the least amount of time, being the simplest algorithm among the others. Comparatively, RPCA is computationally more costly, as it first had to run the RPCA algorithm and then the ODL DL algorithm. Thus, it took the most amount of time. COBE and K‐SVD took almost a similar amount of time. Since the time taken by the algorithms depended on the dimensionality of the data matrix, which is the number of elements in the FC upper triangular vector (<mml:math id="jats-math-317" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math>), we observed that the different rs‐networks took different time. Default mode had maximum number of nodes and hence had the largest <mml:math id="jats-math-318" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>n</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math> thus it took the most amount of time across all the DL algorithms and normalization methods.</p>
      </sec>
    </sec>
    <sec sec-type="discussion" id="hbm26289-sec-0034">
      <label>4</label>
      <title>DISCUSSION</title>
      <p>In this study, we compared four dictionary algorithms, PCA, RPCA, KSVD, and COBE based on how accurately and efficiently they can identify individual components from the FC of 7 large‐scale RSNs. We observed the COBE algorithm to work better than the other DL algorithms when the Fisher Z transform was used. DMN and FPN networks performed better than the other networks. The FC computation is largely dependent on the Brain Atlas. The spatial extent of each ROI used for seed location as well as the total number of ROIs affects the FC. In this study, we have considered both these aspects. We observe the variation of the ratio of <mml:math id="jats-math-319" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-320" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> across 10 different atlas having nodes varying from 100 to 400. We also highlighted the average number of voxels per ROI which tells us about the average ROI size in these atlases. Our results indicate that the more granular ROIs, that is, lesser the average number of voxels contained per ROI, the better the ratio of <mml:math id="jats-math-321" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-322" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> and hence the more accurate extraction of Subject‐Specific components. We average the time series of the voxels in an ROI to get one single time series for that ROI. If there are more voxels per ROI, then we may lose information as the mean time series may not be a good representation of the region. However, if we look at Figure <xref rid="hbm26289-fig-0013" ref-type="fig">13</xref> a dip in the ratio can be observed for the Dosenbach atlas. Dosenbach Atlas has a relatively low number of average voxels per ROI and a significantly lower total number of ROIs (164), which may be responsible for the dip. This dip suggests that averaging a lower number of voxels per ROI and a greater number of ROIs is desirable for obtaining a more accurate estimate of the subject‐specific FC. An ideal case would be to do the analyses at the voxel level, where each voxel would be considered a node. However, computing the FC, in this case, would significantly increase the computational complexity as the voxels in the brain are in the order of <mml:math id="jats-math-323" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mn>5</mml:mn></mml:msup></mml:mrow></mml:math>. After calculating the FC, the order may go up to <mml:math id="jats-math-324" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mn>10</mml:mn></mml:msup></mml:mrow></mml:math>, which would make it very difficult and time‐consuming for the DL algorithms to learn the Dictionaries. Furthermore, to deal with such high dimensional data, we would also require more subjects, the number of subjects used should be comparable to the dimensions for the DL algorithm to work. Also, massively univariate approaches like these make a very strong assumption about independence between voxels, which is in direct contradiction to the ubiquitous regional homogeneity among brain regions. If the multiplicity issue is not addressed properly, we may wrongly model a true effect.</p>
      <p>Large‐scale RSNs are generally associated with specific cognitive functions as pointed out by Hausman et al. (<xref rid="hbm26289-bib-0035" ref-type="bibr">2020</xref>), such as attention (Fox et al., <xref rid="hbm26289-bib-0028" ref-type="bibr">2006</xref>), memory (Vincent et al., <xref rid="hbm26289-bib-0068" ref-type="bibr">2006</xref>), cognitive control (Cole et al., <xref rid="hbm26289-bib-0013" ref-type="bibr">2012</xref>; Dosenbach et al., <xref rid="hbm26289-bib-0020" ref-type="bibr">2007</xref>; Vincent et al., <xref rid="hbm26289-bib-0067" ref-type="bibr">2008</xref>), default mode (Buckner et al., <xref rid="hbm26289-bib-0007" ref-type="bibr">2008</xref>; Raichle et al., <xref rid="hbm26289-bib-0055" ref-type="bibr">2001</xref>), motor (Biswal et al., <xref rid="hbm26289-bib-0005" ref-type="bibr">1995</xref>), and sensory systems (Damoiseaux et al., <xref rid="hbm26289-bib-0016" ref-type="bibr">2006</xref>; De Luca et al., <xref rid="hbm26289-bib-0017" ref-type="bibr">2005</xref>). By incorporating a set of DL algorithms, this study focuses on determining which of the RSNs from Yeo et al. (<xref rid="hbm26289-bib-0073" ref-type="bibr">2011</xref>) can be used to estimate the individual variability in a subject. Our results show that DMN and FPN networks demonstrate higher individual variability in FC compared to other RSNs. However, it is essential to note that in this study the atlases used for the computation of the RSFC have more nodes in DMN than FPN, which affects the performance of the DL algorithm. Yet, FPN does equally good as DMN in most cases. Studies in literature have pointed out that the FPN is potentially a better candidate to extract the subject‐specific component (Amico &amp; Goñi, <xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>; Cai et al., <xref rid="hbm26289-bib-0009" ref-type="bibr">2020</xref>). On the other hand, LN has performed poorly across all DL algorithms and atlases. There may be three reasons for this (1) LN may not have a significant subject‐specific component, (2) As limbic nodes are physically below the other networks, the signal from the limbic region could be noisy, or (3) The number of nodes in LN is lesser as compared to the other networks, which have a great influence on the learned dictionaries. VN and SMN also performed poorly, which is expected, as, in resting‐state, all the subjects lie still in the scanner without doing any motor or visual activity. It would be interesting to recheck the results of these networks with a task comprising of a visual or motor activity.</p>
      <p>Duration of the fMRI scan can be a critical contributing factor, given the fact that being in the MRI scanner for an extended period can be difficult for patients. Thus, we also looked at the effect of varying the time points on the ratio of <mml:math id="jats-math-325" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-326" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> (refer Figure <xref rid="hbm26289-fig-0012" ref-type="fig">12</xref> and Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S5</xref>). Results suggest that a longer duration can efficiently bring out better Individual connectome only in specific RSNs such as default mode, fronto‐parietal, and dorsal attention. However, other networks tend to saturate after at most 5 min of scan length, except the default mode network enhanced by the RPCA algorithm. Studies like Amico and Goñi (<xref rid="hbm26289-bib-0003" ref-type="bibr">2018</xref>) have also pointed out similar results but considering the whole brain and not the RSNs.</p>
      <p>In this study, we compared four dictionary algorithms, (i) PCA, (ii) RPCA, (iii) KSVD, and (iv) COBE algorithms, respectively. COBE algorithm has achieved the best performance in all the results mentioned in this study; however, it is essential to note that it is supervised. A subject matrix <mml:math id="jats-math-327" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> is given as input to the COBE algorithm during the training phase, which means the COBE algorithm knows which scans belong to the same subject. This could be the primary reason behind its improved performance. On the contrary, COBE demonstrated stability which is lesser than the other algorithms mentioned (refer to Figure <xref rid="hbm26289-fig-0014" ref-type="fig">14</xref>), suggesting that COBE may be prone to overfitting as compared to other algorithms. KSVD, on the other hand, has a better performance as compared to PCA and performs as good as RPCA. KSVD has better stability as compared to COBE and RPCA. RPCA does an excellent job with degree normalized FC, especially with the DMN, results are better than KSVD and close to COBE but on the cost of reduced stability. Also, RPCA requires a substantial amount of time because it consists of two sequentially costly algorithms—RPCA and ODL. Despite that, we only required this time during the training phase. All the algorithms may take almost the same amount of time in the testing phase, as a least‐squares solution or simple matrix multiplication must be computed from the learned dictionaries. Furthermore, PCA, the most primitive algorithm, takes the least amount of time for all the networks and is the most stable. However, its performance is just slightly better as compared to when no DL algorithm was applied and the FC was used directly, but not as good as the other algorithms as far as the ratio of <mml:math id="jats-math-328" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mtext mathvariant="italic">diff</mml:mtext></mml:msub></mml:mrow></mml:math> to <mml:math id="jats-math-329" display="inline" overflow="scroll"><mml:mrow><mml:mtext mathvariant="italic">Overlap</mml:mtext></mml:mrow></mml:math> is considered.</p>
      <p>Based on our evaluation on the type of normalization applied, choice of normalization does play a significant role in enhancing the individual‐specific components. Although Degree normalization was observed to be better as compared to the Fisher's Z transform before using any DL algorithm (refer to Figure <xref rid="hbm26289-supitem-0001" ref-type="supplementary-material">S2</xref>), Fisher's Z transform generates more accurate estimates after applying the DL algorithms, except for RPCA. Therefore, an evaluation of different normalization techniques may be necessary before using any new method, and one may then choose the best among them.</p>
    </sec>
    <sec sec-type="conclusions" id="hbm26289-sec-0035">
      <label>5</label>
      <title>CONCLUSIONS</title>
      <p>We systematically reviewed and compared four DL algorithms stating their time complexity and reproducibility using the network‐specific FC to get the individual specific components. We found that the COBE algorithm with default‐mode and fronto‐parietal networks performed comparatively better than other RSNs, while LN, VN, and SMN networks performed poorly for all DL algorithms. We also studied the effect of different normalization methods and observed Fisher Z transform to be better than the degree and no normalization. Finally, we computed the results using nine distinct Brain Atlases of different resolutions and affirmed that a greater number of ROIs per atlas and a lesser average number of voxels per ROIs achieve better results.</p>
    </sec>
    <sec sec-type="supplementary-material">
      <title>Supporting information</title>
      <supplementary-material id="hbm26289-supitem-0001" position="float" content-type="local-data">
        <caption>
          <p>
<bold>Data S1.</bold> Supporting Information.</p>
        </caption>
        <media xlink:href="HBM-44-3410-s001.docx">
          <caption>
            <p>Click here for additional data file.</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack id="hbm26289-sec-0118">
      <title>ACKNOWLEDGMENTS</title>
      <p>We thank the reviewers for their insightful comments. This work was supported by NIH R01 MH131335(BB) and internal funds from IIT (AS).</p>
    </ack>
    <sec sec-type="data-availability" id="hbm26289-sec-0037">
      <title>DATA AVAILABILITY STATEMENT</title>
      <p>The MSC dataset is publicly available at <ext-link xlink:href="https://openneuro.org/datasets/ds000224" ext-link-type="uri" specific-use="software is-supplemented-by">https://openneuro.org/datasets/ds000224</ext-link>, and the HNU dataset is publicly available at the Consortium for Reliability and Reproducibility database at <ext-link xlink:href="http://fcon_1000.projects.nitrc.org/indi/CoRR/html/hnu_1.html" ext-link-type="uri">http://fcon\_1000.projects.nitrc.org/indi/CoRR/html/hnu\_1.html</ext-link> Data were processed using publicly available software (SPM12 <ext-link xlink:href="http://www.fil.ion.ucl.ac.uk/spm/software/spm12/" ext-link-type="uri" specific-use="software is-supplemented-by">http://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link>). The Subject Specific components were extracted by code written in MATLAB. The code is available from the authors upon request.</p>
    </sec>
    <ref-list id="hbm26289-bibl-0001" content-type="cited-references">
      <title>REFERENCES</title>
      <ref id="hbm26289-bib-0001">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0001">
<string-name>
<surname>Aharon</surname>, <given-names>M.</given-names>
</string-name>, &amp; <string-name>
<surname>Elad</surname>, <given-names>M.</given-names>
</string-name> (<year>2008</year>). <article-title>Sparse and redundant modeling of image content using an image‐signature‐dictionary</article-title>. <source>SIAM Journal on Imaging Sciences</source>, <volume>1</volume>, <fpage>228</fpage>–<lpage>247</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0002">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0002">
<string-name>
<surname>Aharon</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Elad</surname>, <given-names>M.</given-names>
</string-name>, &amp; <string-name>
<surname>Bruckstein</surname>, <given-names>A.</given-names>
</string-name> (<year>2006</year>). <article-title>K‐SVD: An algorithm for designing overcomplete dictionaries for sparse representation</article-title>. <source>IEEE Transactions on Signal Processing</source>, <volume>54</volume>, <fpage>4311</fpage>–<lpage>4322</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0003">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0003">
<string-name>
<surname>Amico</surname>, <given-names>E.</given-names>
</string-name>, &amp; <string-name>
<surname>Goñi</surname>, <given-names>J.</given-names>
</string-name> (<year>2018</year>). <article-title>The quest for identifiability in human functional connectomes</article-title>. <source>Scientific Reports</source>, <volume>8</volume>, <fpage>8254</fpage>.<pub-id pub-id-type="pmid">29844466</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0004">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0004">
<string-name>
<surname>Aravkin</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Becker</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Cevher</surname>, <given-names>V.</given-names>
</string-name>, &amp; <string-name>
<surname>Olsen</surname>, <given-names>P.</given-names>
</string-name> (<year>2014</year>). <article-title>
<italic toggle="yes">A variational approach to stable principal component pursuit</italic>. Presented at Conference on Uncertainty in Artificial Intelligence (UAI)</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0005">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0005">
<string-name>
<surname>Biswal</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Zerrin Yetkin</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Haughton</surname>, <given-names>V. M.</given-names>
</string-name>, &amp; <string-name>
<surname>Hyde</surname>, <given-names>J. S.</given-names>
</string-name> (<year>1995</year>). <article-title>Functional connectivity in the motor cortex of resting human brain using echo‐planar MRI</article-title>. <source>Magnetic Resonance in Medicine</source>, <volume>34</volume>, <fpage>537</fpage>–<lpage>541</lpage>.<pub-id pub-id-type="pmid">8524021</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0006">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0006">
<string-name>
<surname>Biswal</surname>, <given-names>B. B.</given-names>
</string-name>, <string-name>
<surname>Van Kylen</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Hyde</surname>, <given-names>J. S.</given-names>
</string-name> (<year>1997</year>). <article-title>Simultaneous assessment of flow and BOLD signals in resting‐state functional connectivity maps</article-title>. <source>NMR in Biomedicine</source>, <volume>10</volume>, <fpage>165</fpage>–<lpage>170</lpage>.<pub-id pub-id-type="pmid">9430343</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0007">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0007">
<string-name>
<surname>Buckner</surname>, <given-names>R. L.</given-names>
</string-name>, <string-name>
<surname>Andrews‐Hanna</surname>, <given-names>J. R.</given-names>
</string-name>, &amp; <string-name>
<surname>Schacter</surname>, <given-names>D. L.</given-names>
</string-name> (<year>2008</year>). <article-title>The brain's default network</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1124</volume>, <fpage>1</fpage>–<lpage>38</lpage>.<pub-id pub-id-type="pmid">18400922</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0008">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0008">
<string-name>
<surname>Cai</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Hu</surname>, <given-names>W.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Zille</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Stephen</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Wilson</surname>, <given-names>T. W.</given-names>
</string-name>, <string-name>
<surname>Calhoun</surname>, <given-names>V. D.</given-names>
</string-name>, &amp; <string-name>
<surname>Wang</surname>, <given-names>Y. P.</given-names>
</string-name> (<year>2019</year>). <article-title>Refined measure of functional connectomes for improved identifiability and prediction</article-title>. <source>Human Brain Mapping</source>, <volume>40</volume>, <fpage>4843</fpage>–<lpage>4858</lpage>.<pub-id pub-id-type="pmid">31355994</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0009">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0009">
<string-name>
<surname>Cai</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Xiao</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Hu</surname>, <given-names>W.</given-names>
</string-name>, <string-name>
<surname>Stephen</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Wilson</surname>, <given-names>T. W.</given-names>
</string-name>, <string-name>
<surname>Calhoun</surname>, <given-names>V. D.</given-names>
</string-name>, &amp; <string-name>
<surname>Wang</surname>, <given-names>Y.‐P.</given-names>
</string-name> (<year>2020</year>). <article-title>Functional connectome fingerprinting: Identifying individuals and predicting cognitive function via deep learning. <italic toggle="yes">arXiv</italic> [q‐bio.NC]</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0010">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0010">
<string-name>
<surname>Candes</surname>, <given-names>E. J.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Ma</surname>, <given-names>Y.</given-names>
</string-name>, &amp; <string-name>
<surname>Wright</surname>, <given-names>J.</given-names>
</string-name> (<year>2009</year>). <article-title>Robust principal component analysis? <italic toggle="yes">arXiv</italic> [cs.IT]</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0011">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0011">
<string-name>
<surname>Chen</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Xu</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Zhou</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Wang</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Yang</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Wang</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Dong</surname>, <given-names>H. M.</given-names>
</string-name>, <string-name>
<surname>Yang</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Zang</surname>, <given-names>Y. F.</given-names>
</string-name>, <string-name>
<surname>Zuo</surname>, <given-names>X. N.</given-names>
</string-name>, &amp; <string-name>
<surname>Weng</surname>, <given-names>X. C.</given-names>
</string-name> (<year>2015</year>). <article-title>Individual variability and test‐retest reliability revealed by ten repeated resting‐state brain scans over one month</article-title>. <source>PLoS One</source>, <volume>10</volume>, <elocation-id>e0144963</elocation-id>.<pub-id pub-id-type="pmid">26714192</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0012">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0012">
<string-name>
<surname>Chiem</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Abbas</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Amico</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Duong‐Tran</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Crevecoeur</surname>, <given-names>F.</given-names>
</string-name>, &amp; <string-name>
<surname>Goni</surname>, <given-names>J.</given-names>
</string-name> (<year>2021</year>). <article-title>Improving functional connectome fingerprinting with degree‐normalization</article-title>. <source>Brain Connectivity</source>, <volume>12</volume>, <fpage>180</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">34015966</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0013">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0013">
<string-name>
<surname>Cole</surname>, <given-names>M. W.</given-names>
</string-name>, <string-name>
<surname>Yarkoni</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Repovš</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Anticevic</surname>, <given-names>A.</given-names>
</string-name>, &amp; <string-name>
<surname>Braver</surname>, <given-names>T. S.</given-names>
</string-name> (<year>2012</year>). <article-title>Global connectivity of prefrontal cortex predicts cognitive control and intelligence</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>, <fpage>8988</fpage>–<lpage>8999</lpage>.<pub-id pub-id-type="pmid">22745498</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0014">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0014">
<string-name>
<surname>Cordes</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Haughton</surname>, <given-names>V.</given-names>
</string-name>, <string-name>
<surname>Carew</surname>, <given-names>J. D.</given-names>
</string-name>, <string-name>
<surname>Arfanakis</surname>, <given-names>K.</given-names>
</string-name>, &amp; <string-name>
<surname>Maravilla</surname>, <given-names>K.</given-names>
</string-name> (<year>2002</year>). <article-title>Hierarchical clustering to measure connectivity in fMRI resting‐state data</article-title>. <source>Magnetic Resonance Imaging</source>, <volume>20</volume>, <fpage>305</fpage>–<lpage>317</lpage>.<pub-id pub-id-type="pmid">12165349</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0015">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0015">
<string-name>
<surname>Cordes</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Haughton</surname>, <given-names>V. M.</given-names>
</string-name>, <string-name>
<surname>Arfanakis</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Wendt</surname>, <given-names>G. J.</given-names>
</string-name>, <string-name>
<surname>Turski</surname>, <given-names>P. A.</given-names>
</string-name>, <string-name>
<surname>Moritz</surname>, <given-names>C. H.</given-names>
</string-name>, <string-name>
<surname>Quigley</surname>, <given-names>M. A.</given-names>
</string-name>, &amp; <string-name>
<surname>Meyerand</surname>, <given-names>M. E.</given-names>
</string-name> (<year>2000</year>). <article-title>Mapping functionally related regions of brain with functional connectivity MR imaging</article-title>. <source>AJNR. American Journal of Neuroradiology</source>, <volume>21</volume>, <fpage>1636</fpage>–<lpage>1644</lpage>.<pub-id pub-id-type="pmid">11039342</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0016">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0016">
<string-name>
<surname>Damoiseaux</surname>, <given-names>J. S.</given-names>
</string-name>, <string-name>
<surname>Rombouts</surname>, <given-names>S. A. R. B.</given-names>
</string-name>, <string-name>
<surname>Barkhof</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Scheltens</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Stam</surname>, <given-names>C. J.</given-names>
</string-name>, <string-name>
<surname>Smith</surname>, <given-names>S. M.</given-names>
</string-name>, &amp; <string-name>
<surname>Beckmann</surname>, <given-names>C. F.</given-names>
</string-name> (<year>2006</year>). <article-title>Consistent resting‐state networks across healthy subjects</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>103</volume>, <fpage>13848</fpage>–<lpage>13853</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0017">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0017">
<string-name>
<surname>De Luca</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Smith</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>De Stefano</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Federico</surname>, <given-names>A.</given-names>
</string-name>, &amp; <string-name>
<surname>Matthews</surname>, <given-names>P. M.</given-names>
</string-name> (<year>2005</year>). <article-title>Blood oxygenation level dependent contrast resting state networks are relevant to functional activity in the neocortical sensorimotor system</article-title>. <source>Experimental Brain Research</source>, <volume>167</volume>, <fpage>587</fpage>–<lpage>594</lpage>.<pub-id pub-id-type="pmid">16284751</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0018">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0018">
<string-name>
<surname>Deary</surname>, <given-names>I. J.</given-names>
</string-name> (<year>2012</year>). <article-title>Intelligence</article-title>. <source>Annual Review of Psychology</source>, <volume>63</volume>, <fpage>453</fpage>–<lpage>482</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0019">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0019">
<string-name>
<surname>Desikan</surname>, <given-names>R. S.</given-names>
</string-name>, <string-name>
<surname>Ségonne</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Fischl</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Quinn</surname>, <given-names>B. T.</given-names>
</string-name>, <string-name>
<surname>Dickerson</surname>, <given-names>B. C.</given-names>
</string-name>, <string-name>
<surname>Blacker</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Buckner</surname>, <given-names>R. L.</given-names>
</string-name>, <string-name>
<surname>Dale</surname>, <given-names>A. M.</given-names>
</string-name>, <string-name>
<surname>Maguire</surname>, <given-names>R. P.</given-names>
</string-name>, <string-name>
<surname>Hyman</surname>, <given-names>B. T.</given-names>
</string-name>, <string-name>
<surname>Albert</surname>, <given-names>M. S.</given-names>
</string-name>, &amp; <string-name>
<surname>Killiany</surname>, <given-names>R. J.</given-names>
</string-name> (<year>2006</year>). <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>NeuroImage</source>, <volume>31</volume>, <fpage>968</fpage>–<lpage>980</lpage>.<pub-id pub-id-type="pmid">16530430</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0020">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0020">
<string-name>
<surname>Dosenbach</surname>, <given-names>N. U. F.</given-names>
</string-name>, <string-name>
<surname>Fair</surname>, <given-names>D. A.</given-names>
</string-name>, <string-name>
<surname>Miezin</surname>, <given-names>F. M.</given-names>
</string-name>, <string-name>
<surname>Cohen</surname>, <given-names>A. L.</given-names>
</string-name>, <string-name>
<surname>Wenger</surname>, <given-names>K. K.</given-names>
</string-name>, <string-name>
<surname>Dosenbach</surname>, <given-names>R. A. T.</given-names>
</string-name>, <string-name>
<surname>Fox</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Snyder</surname>, <given-names>A. Z.</given-names>
</string-name>, <string-name>
<surname>Vincent</surname>, <given-names>J. L.</given-names>
</string-name>, <string-name>
<surname>Raichle</surname>, <given-names>M. E.</given-names>
</string-name>, <string-name>
<surname>Schlaggar</surname>, <given-names>B. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Petersen</surname>, <given-names>S. E.</given-names>
</string-name> (<year>2007</year>). <article-title>Distinct brain networks for adaptive and stable task control in humans</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>104</volume>, <fpage>11073</fpage>–<lpage>11078</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0021">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0021">
<string-name>
<surname>Dosenbach</surname>, <given-names>N. U. F.</given-names>
</string-name>, <string-name>
<surname>Nardos</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Cohen</surname>, <given-names>A. L.</given-names>
</string-name>, <string-name>
<surname>Fair</surname>, <given-names>D. A.</given-names>
</string-name>, <string-name>
<surname>Power</surname>, <given-names>J. D.</given-names>
</string-name>, <string-name>
<surname>Church</surname>, <given-names>J. A.</given-names>
</string-name>, <string-name>
<surname>Nelson</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Wig</surname>, <given-names>G. S.</given-names>
</string-name>, <string-name>
<surname>Vogel</surname>, <given-names>A. C.</given-names>
</string-name>, <string-name>
<surname>Lessov‐Schlaggar</surname>, <given-names>C. N.</given-names>
</string-name>, <string-name>
<surname>Barnes</surname>, <given-names>K. A.</given-names>
</string-name>, <string-name>
<surname>Dubis</surname>, <given-names>J. W.</given-names>
</string-name>, <string-name>
<surname>Feczko</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Coalson</surname>, <given-names>R. S.</given-names>
</string-name>, <string-name>
<surname>Pruett</surname>, <given-names>J. R.</given-names>, <suffix>Jr.</suffix>
</string-name>, <string-name>
<surname>Barch</surname>, <given-names>D. M.</given-names>
</string-name>, <string-name>
<surname>Petersen</surname>, <given-names>S. E.</given-names>
</string-name>, &amp; <string-name>
<surname>Schlaggar</surname>, <given-names>B. L.</given-names>
</string-name> (<year>2010</year>). <article-title>Prediction of individual brain maturity using fMRI</article-title>. <source>Science</source>, <volume>329</volume>, <fpage>1358</fpage>–<lpage>1361</lpage>.<pub-id pub-id-type="pmid">20829489</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0022">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0022">
<string-name>
<surname>Ehtemami</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Scott</surname>, <given-names>R.</given-names>
</string-name>, &amp; <string-name>
<surname>Bernadin</surname>, <given-names>S.</given-names>
</string-name> (<year>2018</year>). <article-title>A survey of FMRI data analysis methods. Presented at SoutheastCon 2018</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0023">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0023">
<string-name>
<surname>Fan</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Zhuo</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Wang</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Yang</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Chu</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Xie</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Laird</surname>, <given-names>A. R.</given-names>
</string-name>, <string-name>
<surname>Fox</surname>, <given-names>P. T.</given-names>
</string-name>, <string-name>
<surname>Eickhoff</surname>, <given-names>S. B.</given-names>
</string-name>, <string-name>
<surname>Yu</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Jiang</surname>, <given-names>T.</given-names>
</string-name> (<year>2016</year>). <article-title>The human brainnetome atlas: A new brain atlas based on connectional architecture</article-title>. <source>Cerebral Cortex</source>, <volume>26</volume>, <fpage>3508</fpage>–<lpage>3526</lpage>.<pub-id pub-id-type="pmid">27230218</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0024">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0024">
<string-name>
<surname>Finn</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Scheinost</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Finn</surname>, <given-names>D. M.</given-names>
</string-name>, <string-name>
<surname>Shen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, &amp; <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2017</year>). <article-title>Can brain state be manipulated to emphasize individual differences in functional connectivity?</article-title>
<source>NeuroImage</source>, <volume>160</volume>, <fpage>140</fpage>–<lpage>151</lpage>.<pub-id pub-id-type="pmid">28373122</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0025">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0025">
<string-name>
<surname>Finn</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Shen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Scheinost</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Rosenberg</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Huang</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Chun</surname>, <given-names>M. M.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, &amp; <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2015</year>). <article-title>Functional connectome fingerprinting: Identifying individuals using patterns of brain connectivity</article-title>. <source>Nature Neuroscience</source>, <volume>18</volume>, <fpage>1664</fpage>–<lpage>1671</lpage>.<pub-id pub-id-type="pmid">26457551</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0026">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0026">
<string-name>
<surname>Fischl</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Salat</surname>, <given-names>D. H.</given-names>
</string-name>, <string-name>
<surname>Busa</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Albert</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Dieterich</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Haselgrove</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>van der Kouwe</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Killiany</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Kennedy</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Klaveness</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Montillo</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Makris</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Rosen</surname>, <given-names>B.</given-names>
</string-name>, &amp; <string-name>
<surname>Dale</surname>, <given-names>A. M.</given-names>
</string-name> (<year>2002</year>). <article-title>Whole brain segmentation: Automated labeling of neuroanatomical structures in the human brain</article-title>. <source>Neuron</source>, <volume>33</volume>, <fpage>341</fpage>–<lpage>355</lpage>.<pub-id pub-id-type="pmid">11832223</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0027">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0027">
<string-name>
<surname>Fischl</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>van der Kouwe</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Destrieux</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Halgren</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Ségonne</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Salat</surname>, <given-names>D. H.</given-names>
</string-name>, <string-name>
<surname>Busa</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Seidman</surname>, <given-names>L. J.</given-names>
</string-name>, <string-name>
<surname>Goldstein</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Kennedy</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Caviness</surname>, <given-names>V.</given-names>
</string-name>, <string-name>
<surname>Makris</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Rosen</surname>, <given-names>B.</given-names>
</string-name>, &amp; <string-name>
<surname>Dale</surname>, <given-names>A. M.</given-names>
</string-name> (<year>2004</year>). <article-title>Automatically parcellating the human cerebral cortex</article-title>. <source>Cerebral Cortex</source>, <volume>14</volume>, <fpage>11</fpage>–<lpage>22</lpage>.<pub-id pub-id-type="pmid">14654453</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0028">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0028">
<string-name>
<surname>Fox</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Corbetta</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Snyder</surname>, <given-names>A. Z.</given-names>
</string-name>, <string-name>
<surname>Vincent</surname>, <given-names>J. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Raichle</surname>, <given-names>M. E.</given-names>
</string-name> (<year>2006</year>). <article-title>Spontaneous neuronal activity distinguishes human dorsal and ventral attention systems</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>103</volume>, <fpage>10046</fpage>–<lpage>10051</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0029">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0029">
<string-name>
<surname>Fox</surname>, <given-names>M. D.</given-names>
</string-name>, &amp; <string-name>
<surname>Raichle</surname>, <given-names>M. E.</given-names>
</string-name> (<year>2007</year>). <article-title>Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging</article-title>. <source>Nature Reviews. Neuroscience</source>, <volume>8</volume>, <fpage>700</fpage>–<lpage>711</lpage>.<pub-id pub-id-type="pmid">17704812</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0030">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0030">
<string-name>
<surname>Friston</surname>, <given-names>K. J.</given-names>
</string-name>, <string-name>
<surname>Frith</surname>, <given-names>C. D.</given-names>
</string-name>, <string-name>
<surname>Liddle</surname>, <given-names>P. F.</given-names>
</string-name>, &amp; <string-name>
<surname>Frackowiak</surname>, <given-names>R. S.</given-names>
</string-name> (<year>1993</year>). <article-title>Functional connectivity: The principal‐component analysis of large (PET) data sets</article-title>. <source>Journal of Cerebral Blood Flow and Metabolism</source>, <volume>13</volume>, <fpage>5</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">8417010</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0031">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0031">
<string-name>
<surname>Geerligs</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Rubinov</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Cam</surname>, <given-names>C. A. N.</given-names>
</string-name>, &amp; <string-name>
<surname>Henson</surname>, <given-names>R. N.</given-names>
</string-name> (<year>2015</year>). <article-title>State and trait components of functional connectivity: Individual differences vary with mental state</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>, <fpage>13949</fpage>–<lpage>13961</lpage>.<pub-id pub-id-type="pmid">26468196</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0032">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0032">
<string-name>
<surname>Gordon</surname>, <given-names>E. M.</given-names>
</string-name>, <string-name>
<surname>Laumann</surname>, <given-names>T. O.</given-names>
</string-name>, <string-name>
<surname>Gilmore</surname>, <given-names>A. W.</given-names>
</string-name>, <string-name>
<surname>Newbold</surname>, <given-names>D. J.</given-names>
</string-name>, <string-name>
<surname>Greene</surname>, <given-names>D. J.</given-names>
</string-name>, <string-name>
<surname>Berg</surname>, <given-names>J. J.</given-names>
</string-name>, <string-name>
<surname>Ortega</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Hoyt‐Drazen</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Gratton</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Sun</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Hampton</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Coalson</surname>, <given-names>R. S.</given-names>
</string-name>, <string-name>
<surname>Nguyen</surname>, <given-names>A. L.</given-names>
</string-name>, <string-name>
<surname>McDermott</surname>, <given-names>K. B.</given-names>
</string-name>, <string-name>
<surname>Shimony</surname>, <given-names>J. S.</given-names>
</string-name>, <string-name>
<surname>Snyder</surname>, <given-names>A. Z.</given-names>
</string-name>, <string-name>
<surname>Schlaggar</surname>, <given-names>B. L.</given-names>
</string-name>, <string-name>
<surname>Petersen</surname>, <given-names>S. E.</given-names>
</string-name>, <string-name>
<surname>Nelson</surname>, <given-names>S. M.</given-names>
</string-name>, &amp; <string-name>
<surname>Dosenbach</surname>, <given-names>N. U. F.</given-names>
</string-name> (<year>2017</year>). <article-title>Precision functional mapping of individual human brains</article-title>. <source>Neuron</source>, <volume>95</volume>, <fpage>791</fpage>–<lpage>807.e7</lpage>.<pub-id pub-id-type="pmid">28757305</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0033">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0033">
<string-name>
<surname>Greicius</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Krasnow</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Reiss</surname>, <given-names>A. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Menon</surname>, <given-names>V.</given-names>
</string-name> (<year>2003</year>). <article-title>Functional connectivity in the resting brain: A network analysis of the default mode hypothesis</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>100</volume>, <fpage>253</fpage>–<lpage>258</lpage>.<pub-id pub-id-type="pmid">12506194</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0034">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0034">
<string-name>
<surname>Haier</surname>, <given-names>R. J.</given-names>
</string-name> (<year>2009</year>). <article-title>What does a smart brain look like?</article-title>
<source>Scientific American</source>, <volume>23</volume>, <fpage>26</fpage>–<lpage>33</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0035">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0035">
<string-name>
<surname>Hausman</surname>, <given-names>H. K.</given-names>
</string-name>, <string-name>
<surname>O'Shea</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Kraft</surname>, <given-names>J. N.</given-names>
</string-name>, <string-name>
<surname>Boutzoukas</surname>, <given-names>E. M.</given-names>
</string-name>, <string-name>
<surname>Evangelista</surname>, <given-names>N. D.</given-names>
</string-name>, <string-name>
<surname>van Etten</surname>, <given-names>E. J.</given-names>
</string-name>, <string-name>
<surname>Bharadwaj</surname>, <given-names>P. K.</given-names>
</string-name>, <string-name>
<surname>Smith</surname>, <given-names>S. G.</given-names>
</string-name>, <string-name>
<surname>Porges</surname>, <given-names>E.</given-names>
</string-name>, <string-name>
<surname>Hishaw</surname>, <given-names>G. A.</given-names>
</string-name>, <string-name>
<surname>Wu</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>DeKosky</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Alexander</surname>, <given-names>G. E.</given-names>
</string-name>, <string-name>
<surname>Marsiske</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Cohen</surname>, <given-names>R.</given-names>
</string-name>, &amp; <string-name>
<surname>Woods</surname>, <given-names>A. J.</given-names>
</string-name> (<year>2020</year>). <article-title>The role of resting‐state network functional connectivity in cognitive aging</article-title>. <source>Frontiers in Aging Neuroscience</source>, <volume>12</volume>, <fpage>177</fpage>.<pub-id pub-id-type="pmid">32595490</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0036">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0036">
<string-name>
<surname>Iqbal</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Seghouane</surname>, <given-names>A. K.</given-names>
</string-name>, &amp; <string-name>
<surname>Adali</surname>, <given-names>T.</given-names>
</string-name> (<year>2018</year>). <article-title>Shared and subject‐specific dictionary learning (ShSSDL) algorithm for multisubject fMRI data analysis</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>, <volume>65</volume>, <fpage>2519</fpage>–<lpage>2528</lpage>.<pub-id pub-id-type="pmid">29993508</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0037">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0037">
<string-name>
<surname>Jaeggi</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Buschkuehl</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Jonides</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Perrig</surname>, <given-names>W. J.</given-names>
</string-name> (<year>2008</year>). <article-title>Improving fluid intelligence with training on working memory</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>105</volume>, <fpage>6829</fpage>–<lpage>6833</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0038">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0038">
<string-name>
<surname>Kashyap</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Kong</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Bhattacharjee</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Zhou</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Thomas Yeo</surname>, <given-names>B. T.</given-names>
</string-name> (<year>2019</year>). <article-title>Individual‐specific fMRI‐subspaces improve functional connectivity prediction of behavior</article-title>. <source>NeuroImage</source>, <volume>189</volume>, <fpage>804</fpage>–<lpage>812</lpage>.<pub-id pub-id-type="pmid">30711467</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0039">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0039">
<string-name>
<surname>Kong</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Orban</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Sabuncu</surname>, <given-names>M. R.</given-names>
</string-name>, <string-name>
<surname>Liu</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Schaefer</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Sun</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Zuo</surname>, <given-names>X. N.</given-names>
</string-name>, <string-name>
<surname>Holmes</surname>, <given-names>A. J.</given-names>
</string-name>, <string-name>
<surname>Eickhoff</surname>, <given-names>S. B.</given-names>
</string-name>, &amp; <string-name>
<surname>Yeo</surname>, <given-names>B. T. T.</given-names>
</string-name> (<year>2019</year>). <article-title>Spatial topography of individual‐specific cortical networks predicts human cognition, personality, and emotion</article-title>. <source>Cerebral Cortex</source>, <volume>29</volume>, <fpage>2533</fpage>–<lpage>2551</lpage>.<pub-id pub-id-type="pmid">29878084</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0040">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0040">
<string-name>
<surname>Kraus</surname>, <given-names>B. T.</given-names>
</string-name>, <string-name>
<surname>Perez</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Ladwig</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Seitzman</surname>, <given-names>B. A.</given-names>
</string-name>, <string-name>
<surname>Dworetsky</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Petersen</surname>, <given-names>S. E.</given-names>
</string-name>, &amp; <string-name>
<surname>Gratton</surname>, <given-names>C.</given-names>
</string-name> (<year>2021</year>). <article-title>Network variants are similar between task and rest states</article-title>. <source>NeuroImage</source>, <volume>229</volume>, <elocation-id>117743</elocation-id>.<pub-id pub-id-type="pmid">33454409</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0041">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0041">
<string-name>
<surname>Levakov</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Faskowitz</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Avidan</surname>, <given-names>G.</given-names>
</string-name>, &amp; <string-name>
<surname>Sporns</surname>, <given-names>O.</given-names>
</string-name> (<year>2021</year>). <article-title>Mapping individual differences across brain network structure to function and behavior with connectome embedding. <italic toggle="yes">bioRxiv</italic>
</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0042">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0042">
<string-name>
<surname>Li</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Biswal</surname>, <given-names>B. B.</given-names>
</string-name>, <string-name>
<surname>Meng</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Yang</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Duan</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Cui</surname>, <given-names>Q.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>H.</given-names>
</string-name>, &amp; <string-name>
<surname>Liao</surname>, <given-names>W.</given-names>
</string-name> (<year>2020</year>). <article-title>A neuromarker of individual general fluid intelligence from the white‐matter functional connectome</article-title>. <source>Translational Psychiatry</source>, <volume>10</volume>(<issue>1</issue>), <fpage>147</fpage>.<pub-id pub-id-type="pmid">32404889</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0043">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0043">
<string-name>
<surname>Lowe</surname>, <given-names>M. J.</given-names>
</string-name>, <string-name>
<surname>Dzemidzic</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Lurito</surname>, <given-names>J. T.</given-names>
</string-name>, <string-name>
<surname>Mathews</surname>, <given-names>V. P.</given-names>
</string-name>, &amp; <string-name>
<surname>Phillips</surname>, <given-names>M. D.</given-names>
</string-name> (<year>2000</year>). <article-title>Correlations in low‐frequency BOLD fluctuations reflect cortico‐cortical connections</article-title>. <source>NeuroImage</source>, <volume>12</volume>, <fpage>582</fpage>–<lpage>587</lpage>.<pub-id pub-id-type="pmid">11034865</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0044">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0044">
<string-name>
<surname>Lowe</surname>, <given-names>M. J.</given-names>
</string-name>, <string-name>
<surname>Mock</surname>, <given-names>B. J.</given-names>
</string-name>, &amp; <string-name>
<surname>Sorenson</surname>, <given-names>J. A.</given-names>
</string-name> (<year>1998</year>). <article-title>Functional connectivity in single and multislice echoplanar imaging using resting‐state fluctuations</article-title>. <source>NeuroImage</source>, <volume>7</volume>, <fpage>119</fpage>–<lpage>132</lpage>.<pub-id pub-id-type="pmid">9558644</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0045">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0045">
<string-name>
<surname>Lu</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>T.</given-names>
</string-name>, <string-name>
<surname>Xia</surname>, <given-names>Z.</given-names>
</string-name>, <string-name>
<surname>Zhu</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Wang</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Luo</surname>, <given-names>Y. J.</given-names>
</string-name>, <string-name>
<surname>Feng</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Krueger</surname>, <given-names>F.</given-names>
</string-name> (<year>2019</year>). <article-title>Connectome‐based model predicts individual differences in propensity to trust</article-title>. <source>Human Brain Mapping</source>, <volume>40</volume>, <fpage>1942</fpage>–<lpage>1954</lpage>.<pub-id pub-id-type="pmid">30633429</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0046">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0046">
<string-name>
<surname>Mairal</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Bach</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Ponce</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Sapiro</surname>, <given-names>G.</given-names>
</string-name> (<year>2010</year>). <article-title>Online learning for matrix factorization and sparse coding. <italic toggle="yes">arXiv</italic> [stat.ML]</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0047">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0047">
<string-name>
<surname>Maknojia</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Churchill</surname>, <given-names>N. W.</given-names>
</string-name>, <string-name>
<surname>Schweizer</surname>, <given-names>T. A.</given-names>
</string-name>, &amp; <string-name>
<surname>Graham</surname>, <given-names>S. J.</given-names>
</string-name> (<year>2019</year>). <article-title>Resting state fMRI: Going through the motions</article-title>. <source>Frontiers in Neuroscience</source>, <volume>13</volume>, <fpage>825</fpage>.<pub-id pub-id-type="pmid">31456656</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0048">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0048">
<string-name>
<surname>Nichols</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Gao</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Fregni</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Liu</surname>, <given-names>L.</given-names>
</string-name>, &amp; <string-name>
<surname>Joanisse</surname>, <given-names>M. F.</given-names>
</string-name> (<year>2021</year>). <article-title>Individual differences in representational similarity of first and second languages in the bilingual brain. <italic toggle="yes">bioRxiv</italic>
</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0049">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0049">
<string-name>
<surname>Ogawa</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Lee</surname>, <given-names>T. M.</given-names>
</string-name>, <string-name>
<surname>Kay</surname>, <given-names>A. R.</given-names>
</string-name>, &amp; <string-name>
<surname>Tank</surname>, <given-names>D. W.</given-names>
</string-name> (<year>1990</year>). <article-title>Brain magnetic resonance imaging with contrast dependent on blood oxygenation</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>87</volume>, <fpage>9868</fpage>–<lpage>9872</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0050">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0050">
<string-name>
<surname>Pallarés</surname>, <given-names>V.</given-names>
</string-name>, <string-name>
<surname>Insabato</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Sanjuán</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Kühn</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Mantini</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Deco</surname>, <given-names>G.</given-names>
</string-name>, &amp; <string-name>
<surname>Gilson</surname>, <given-names>M.</given-names>
</string-name> (<year>2018</year>). <article-title>Extracting orthogonal subject‐ and condition‐specific signatures from fMRI data using whole‐brain effective connectivity</article-title>. <source>NeuroImage</source>, <volume>178</volume>, <fpage>238</fpage>–<lpage>254</lpage>.<pub-id pub-id-type="pmid">29753842</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0051">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0051">
<string-name>
<surname>Penke</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Maniega</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Bastin</surname>, <given-names>M. E.</given-names>
</string-name>, <string-name>
<surname>Valdés Hernández</surname>, <given-names>M. C.</given-names>
</string-name>, <string-name>
<surname>Murray</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Royle</surname>, <given-names>N. A.</given-names>
</string-name>, <string-name>
<surname>Starr</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Wardlaw</surname>, <given-names>J. M.</given-names>
</string-name>, &amp; <string-name>
<surname>Deary</surname>, <given-names>I. J.</given-names>
</string-name> (<year>2012</year>). <article-title>Brain white matter tract integrity as a neural foundation for general intelligence</article-title>. <source>Molecular Psychiatry</source>, <volume>17</volume>, <fpage>1026</fpage>–<lpage>1030</lpage>.<pub-id pub-id-type="pmid">22614288</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0052">
        <mixed-citation publication-type="miscellaneous" id="hbm26289-cit-0052">
<string-name>
<surname>Pessoa</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Limbachia</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Misra</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Surampudi</surname>, <given-names>S. G.</given-names>
</string-name>, <string-name>
<surname>Venkatesh</surname>, <given-names>M.</given-names>
</string-name>, &amp; <string-name>
<surname>Jaja</surname>, <given-names>J.</given-names>
</string-name> (<year>2021</year>). <article-title>Learning brain dynamics for decoding and predicting individual differences. <italic toggle="yes">bioRxiv</italic>
</article-title>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0053">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0053">
<string-name>
<surname>Power</surname>, <given-names>J. D.</given-names>
</string-name>, <string-name>
<surname>Cohen</surname>, <given-names>A. L.</given-names>
</string-name>, <string-name>
<surname>Nelson</surname>, <given-names>S. M.</given-names>
</string-name>, <string-name>
<surname>Wig</surname>, <given-names>G. S.</given-names>
</string-name>, <string-name>
<surname>Barnes</surname>, <given-names>K. A.</given-names>
</string-name>, <string-name>
<surname>Church</surname>, <given-names>J. A.</given-names>
</string-name>, <string-name>
<surname>Vogel</surname>, <given-names>A. C.</given-names>
</string-name>, <string-name>
<surname>Laumann</surname>, <given-names>T. O.</given-names>
</string-name>, <string-name>
<surname>Miezin</surname>, <given-names>F. M.</given-names>
</string-name>, <string-name>
<surname>Schlaggar</surname>, <given-names>B. L.</given-names>
</string-name>, &amp; <string-name>
<surname>Petersen</surname>, <given-names>S. E.</given-names>
</string-name> (<year>2011</year>). <article-title>Functional network organization of the human brain</article-title>. <source>Neuron</source>, <volume>72</volume>, <fpage>665</fpage>–<lpage>678</lpage>.<pub-id pub-id-type="pmid">22099467</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0054">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0054">
<string-name>
<surname>Qin</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Shen</surname>, <given-names>H.</given-names>
</string-name>, <string-name>
<surname>Zeng</surname>, <given-names>L. L.</given-names>
</string-name>, <string-name>
<surname>Gao</surname>, <given-names>K.</given-names>
</string-name>, <string-name>
<surname>Luo</surname>, <given-names>Z.</given-names>
</string-name>, &amp; <string-name>
<surname>Hu</surname>, <given-names>D.</given-names>
</string-name> (<year>2019</year>). <article-title>Dissociating individual connectome traits using low‐rank learning</article-title>. <source>Brain Research</source>, <volume>1722</volume>, <elocation-id>146348</elocation-id>.<pub-id pub-id-type="pmid">31348912</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0055">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0055">
<string-name>
<surname>Raichle</surname>, <given-names>M. E.</given-names>
</string-name>, <string-name>
<surname>MacLeod</surname>, <given-names>A. M.</given-names>
</string-name>, <string-name>
<surname>Snyder</surname>, <given-names>A. Z.</given-names>
</string-name>, <string-name>
<surname>Powers</surname>, <given-names>W. J.</given-names>
</string-name>, <string-name>
<surname>Gusnard</surname>, <given-names>D. A.</given-names>
</string-name>, &amp; <string-name>
<surname>Shulman</surname>, <given-names>G. L.</given-names>
</string-name> (<year>2001</year>). <article-title>A default mode of brain function</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>98</volume>, <fpage>676</fpage>–<lpage>682</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0056">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0056">
<string-name>
<surname>Rosenberg</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Finn</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Scheinost</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Shen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name>, &amp; <string-name>
<surname>Chun</surname>, <given-names>M. M.</given-names>
</string-name> (<year>2016</year>). <article-title>A neuromarker of sustained attention from whole‐brain functional connectivity</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>, <fpage>165</fpage>–<lpage>171</lpage>.<pub-id pub-id-type="pmid">26595653</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0057">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0057">
<string-name>
<surname>Schaefer</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Kong</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Gordon</surname>, <given-names>E. M.</given-names>
</string-name>, <string-name>
<surname>Laumann</surname>, <given-names>T. O.</given-names>
</string-name>, <string-name>
<surname>Zuo</surname>, <given-names>X. N.</given-names>
</string-name>, <string-name>
<surname>Holmes</surname>, <given-names>A. J.</given-names>
</string-name>, <string-name>
<surname>Eickhoff</surname>, <given-names>S. B.</given-names>
</string-name>, &amp; <string-name>
<surname>Yeo</surname>, <given-names>B. T. T.</given-names>
</string-name> (<year>2018</year>). <article-title>Local‐global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title>. <source>Cerebral Cortex</source>, <volume>28</volume>, <fpage>3095</fpage>–<lpage>3114</lpage>.<pub-id pub-id-type="pmid">28981612</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0058">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0058">
<string-name>
<surname>Seitzman</surname>, <given-names>B. A.</given-names>
</string-name>, <string-name>
<surname>Gratton</surname>, <given-names>C.</given-names>
</string-name>, <string-name>
<surname>Marek</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Raut</surname>, <given-names>R. V.</given-names>
</string-name>, <string-name>
<surname>Dosenbach</surname>, <given-names>N. U. F.</given-names>
</string-name>, <string-name>
<surname>Schlaggar</surname>, <given-names>B. L.</given-names>
</string-name>, <string-name>
<surname>Petersen</surname>, <given-names>S. E.</given-names>
</string-name>, &amp; <string-name>
<surname>Greene</surname>, <given-names>D. J.</given-names>
</string-name> (<year>2020</year>). <article-title>A set of functionally‐defined brain regions with improved representation of the subcortex and cerebellum</article-title>. <source>NeuroImage</source>, <volume>206</volume>, <elocation-id>116290</elocation-id>.<pub-id pub-id-type="pmid">31634545</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0059">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0059">
<string-name>
<surname>Shen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Finn</surname>, <given-names>E. S.</given-names>
</string-name>, <string-name>
<surname>Scheinost</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Rosenberg</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Chun</surname>, <given-names>M. M.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, &amp; <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2017</year>). <article-title>Using connectome‐based predictive modeling to predict individual behavior from brain connectivity</article-title>. <source>Nature Protocols</source>, <volume>12</volume>, <fpage>506</fpage>–<lpage>518</lpage>.<pub-id pub-id-type="pmid">28182017</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0060">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0060">
<string-name>
<surname>Shen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Tokoglu</surname>, <given-names>F.</given-names>
</string-name>, <string-name>
<surname>Papademetris</surname>, <given-names>X.</given-names>
</string-name>, &amp; <string-name>
<surname>Constable</surname>, <given-names>R. T.</given-names>
</string-name> (<year>2013</year>). <article-title>Groupwise whole‐brain parcellation from resting‐state fMRI data for network node identification</article-title>. <source>NeuroImage</source>, <volume>82</volume>, <fpage>403</fpage>–<lpage>415</lpage>.<pub-id pub-id-type="pmid">23747961</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0061">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0061">
<string-name>
<surname>Silver</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Dunlap</surname>, <given-names>W. P.</given-names>
</string-name> (<year>1987</year>). <article-title>Averaging correlation coefficients: Should Fisher's z transformation be used?</article-title>
<source>Journal of Applied Psychology</source>, <volume>72</volume>, <fpage>146</fpage>–<lpage>148</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0062">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0062">
<string-name>
<surname>Smith</surname>, <given-names>D. V.</given-names>
</string-name>, <string-name>
<surname>Utevsky</surname>, <given-names>A. V.</given-names>
</string-name>, <string-name>
<surname>Bland</surname>, <given-names>A. R.</given-names>
</string-name>, <string-name>
<surname>Clement</surname>, <given-names>N.</given-names>
</string-name>, <string-name>
<surname>Clithero</surname>, <given-names>J. A.</given-names>
</string-name>, <string-name>
<surname>Harsch</surname>, <given-names>A. E. W.</given-names>
</string-name>, <string-name>
<surname>McKell Carter</surname>, <given-names>R.</given-names>
</string-name>, &amp; <string-name>
<surname>Huettel</surname>, <given-names>S. A.</given-names>
</string-name> (<year>2014</year>). <article-title>Characterizing individual differences in functional connectivity using dual‐regression and seed‐based approaches</article-title>. <source>NeuroImage</source>, <volume>95</volume>, <fpage>1</fpage>–<lpage>12</lpage>.<pub-id pub-id-type="pmid">24662574</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0063">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0063">
<string-name>
<surname>Song</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Zhou</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Liu</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Tian</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Yu</surname>, <given-names>C.</given-names>
</string-name>, &amp; <string-name>
<surname>Jiang</surname>, <given-names>T.</given-names>
</string-name> (<year>2008</year>). <article-title>Brain spontaneous functional connectivity and intelligence</article-title>. <source>NeuroImage</source>, <volume>41</volume>, <fpage>1168</fpage>–<lpage>1176</lpage>.<pub-id pub-id-type="pmid">18434203</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0064">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0064">
<string-name>
<surname>van den Heuvel</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Mandl</surname>, <given-names>R.</given-names>
</string-name>, <string-name>
<surname>Luigjes</surname>, <given-names>J.</given-names>
</string-name>, &amp; <string-name>
<surname>Hulshoff</surname>, <given-names>P. H.</given-names>
</string-name> (<year>2008</year>). <article-title>Microstructural organization of the cingulum tract and the level of default mode functional connectivity</article-title>. <source>The Journal of Neuroscience</source>, <volume>28</volume>, <fpage>10844</fpage>–<lpage>10851</lpage>.<pub-id pub-id-type="pmid">18945892</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0065">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0065">
<string-name>
<surname>van den Heuvel</surname>, <given-names>M. P.</given-names>
</string-name>, &amp; <string-name>
<surname>Hulshoff Pol</surname>, <given-names>H. E.</given-names>
</string-name> (<year>2010</year>). <article-title>Exploring the brain network: A review on resting‐state fMRI functional connectivity</article-title>. <source>European Neuropsychopharmacology</source>, <volume>20</volume>, <fpage>519</fpage>–<lpage>534</lpage>.<pub-id pub-id-type="pmid">20471808</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0066">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0066">
<string-name>
<surname>van Geest</surname>, <given-names>Q.</given-names>
</string-name>, <string-name>
<surname>Douw</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>van't Klooster</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>Leurs</surname>, <given-names>C. E.</given-names>
</string-name>, <string-name>
<surname>Genova</surname>, <given-names>H. M.</given-names>
</string-name>, <string-name>
<surname>Wylie</surname>, <given-names>G. R.</given-names>
</string-name>, <string-name>
<surname>Steenwijk</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Killestein</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Geurts</surname>, <given-names>J. J. G.</given-names>
</string-name>, &amp; <string-name>
<surname>Hulst</surname>, <given-names>H. E.</given-names>
</string-name> (<year>2018</year>). <article-title>Information processing speed in multiple sclerosis: Relevance of default mode network dynamics</article-title>. <source>NeuroImage: Clinical</source>, <volume>19</volume>, <fpage>507</fpage>–<lpage>515</lpage>.<pub-id pub-id-type="pmid">29984159</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0067">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0067">
<string-name>
<surname>Vincent</surname>, <given-names>J. L.</given-names>
</string-name>, <string-name>
<surname>Kahn</surname>, <given-names>I.</given-names>
</string-name>, <string-name>
<surname>Snyder</surname>, <given-names>A. Z.</given-names>
</string-name>, <string-name>
<surname>Raichle</surname>, <given-names>M. E.</given-names>
</string-name>, &amp; <string-name>
<surname>Buckner</surname>, <given-names>R. L.</given-names>
</string-name> (<year>2008</year>). <article-title>Evidence for a frontoparietal control system revealed by intrinsic functional connectivity</article-title>. <source>Journal of Neurophysiology</source>, <volume>100</volume>, <fpage>3328</fpage>–<lpage>3342</lpage>.<pub-id pub-id-type="pmid">18799601</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0068">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0068">
<string-name>
<surname>Vincent</surname>, <given-names>J. L.</given-names>
</string-name>, <string-name>
<surname>Snyder</surname>, <given-names>A. Z.</given-names>
</string-name>, <string-name>
<surname>Fox</surname>, <given-names>M. D.</given-names>
</string-name>, <string-name>
<surname>Shannon</surname>, <given-names>B. J.</given-names>
</string-name>, <string-name>
<surname>Andrews</surname>, <given-names>J. R.</given-names>
</string-name>, <string-name>
<surname>Raichle</surname>, <given-names>M. E.</given-names>
</string-name>, &amp; <string-name>
<surname>Buckner</surname>, <given-names>R. L.</given-names>
</string-name> (<year>2006</year>). <article-title>Coherent spontaneous activity identifies a hippocampal‐parietal memory network</article-title>. <source>Journal of Neurophysiology</source>, <volume>96</volume>, <fpage>3517</fpage>–<lpage>3531</lpage>.<pub-id pub-id-type="pmid">16899645</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0069">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0069">
<string-name>
<surname>Viviano</surname>, <given-names>R. P.</given-names>
</string-name>, <string-name>
<surname>Hayes</surname>, <given-names>J. M.</given-names>
</string-name>, <string-name>
<surname>Pruitt</surname>, <given-names>P. J.</given-names>
</string-name>, <string-name>
<surname>Fernandez</surname>, <given-names>Z. J.</given-names>
</string-name>, <string-name>
<surname>van Rooden</surname>, <given-names>S.</given-names>
</string-name>, <string-name>
<surname>van der Grond</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Rombouts</surname>, <given-names>S. A. R. B.</given-names>
</string-name>, &amp; <string-name>
<surname>Damoiseaux</surname>, <given-names>J. S.</given-names>
</string-name> (<year>2019</year>). <article-title>Aberrant memory system connectivity and working memory performance in subjective cognitive decline</article-title>. <source>NeuroImage</source>, <volume>185</volume>, <fpage>556</fpage>–<lpage>564</lpage>.<pub-id pub-id-type="pmid">30308246</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0070">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0070">
<string-name>
<surname>Wang</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>Q.</given-names>
</string-name>, <string-name>
<surname>Zhao</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>He</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Ma</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Fu</surname>, <given-names>Z.</given-names>
</string-name>, &amp; <string-name>
<surname>Li</surname>, <given-names>S.</given-names>
</string-name> (<year>2021</year>). <article-title>Decomposition of individual‐specific and individual‐shared components from resting‐state functional connectivity using a multi‐task machine learning method</article-title>. <source>NeuroImage</source>, <volume>238</volume>, <elocation-id>118252</elocation-id>.<pub-id pub-id-type="pmid">34116155</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0071">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0071">
<string-name>
<surname>Wu</surname>, <given-names>Y.</given-names>
</string-name>, <string-name>
<surname>Li</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Yuan</surname>, <given-names>B.</given-names>
</string-name>, &amp; <string-name>
<surname>Tian</surname>, <given-names>X.</given-names>
</string-name> (<year>2016</year>). <article-title>Individual differences in resting‐state functional connectivity predict procrastination</article-title>. <source>Personality and Individual Differences</source>, <volume>95</volume>, <fpage>62</fpage>–<lpage>67</lpage>.</mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0072">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0072">
<string-name>
<surname>Xiong</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Parsons</surname>, <given-names>L. M.</given-names>
</string-name>, <string-name>
<surname>Gao</surname>, <given-names>J. H.</given-names>
</string-name>, &amp; <string-name>
<surname>Fox</surname>, <given-names>P. T.</given-names>
</string-name> (<year>1999</year>). <article-title>Interregional connectivity to primary motor cortex revealed using MRI resting state images</article-title>. <source>Human Brain Mapping</source>, <volume>8</volume>, <fpage>151</fpage>–<lpage>156</lpage>.<pub-id pub-id-type="pmid">10524607</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0073">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0073">
<string-name>
<surname>Yeo</surname>, <given-names>B. T.</given-names>
</string-name>, <string-name>
<surname>Krienen</surname>, <given-names>F. M.</given-names>
</string-name>, <string-name>
<surname>Sepulcre</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Sabuncu</surname>, <given-names>M. R.</given-names>
</string-name>, <string-name>
<surname>Lashkari</surname>, <given-names>D.</given-names>
</string-name>, <string-name>
<surname>Hollinshead</surname>, <given-names>M.</given-names>
</string-name>, <string-name>
<surname>Roffman</surname>, <given-names>J. L.</given-names>
</string-name>, <string-name>
<surname>Smoller</surname>, <given-names>J. W.</given-names>
</string-name>, <string-name>
<surname>Zöllei</surname>, <given-names>L.</given-names>
</string-name>, <string-name>
<surname>Polimeni</surname>, <given-names>J. R.</given-names>
</string-name>, <string-name>
<surname>Fischl</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Liu</surname>, <given-names>H.</given-names>
</string-name>, &amp; <string-name>
<surname>Buckner</surname>, <given-names>R. L.</given-names>
</string-name> (<year>2011</year>). <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>Journal of Neurophysiology</source>, <volume>106</volume>, <fpage>1125</fpage>–<lpage>1165</lpage>.<pub-id pub-id-type="pmid">21653723</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0074">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0074">
<string-name>
<surname>Zhou</surname>, <given-names>G.</given-names>
</string-name>, <string-name>
<surname>Cichocki</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Zhang</surname>, <given-names>Y.</given-names>
</string-name>, &amp; <string-name>
<surname>Mandic</surname>, <given-names>D. P.</given-names>
</string-name> (<year>2016</year>). <article-title>Group component analysis for multiblock data: Common and individual feature extraction</article-title>. <source>IEEE Transactions on Neural Networks and Learning Systems</source>, <volume>27</volume>, <fpage>2426</fpage>–<lpage>2439</lpage>.<pub-id pub-id-type="pmid">26529787</pub-id></mixed-citation>
      </ref>
      <ref id="hbm26289-bib-0075">
        <mixed-citation publication-type="journal" id="hbm26289-cit-0075">
<string-name>
<surname>Zuo</surname>, <given-names>X. N.</given-names>
</string-name>, <string-name>
<surname>Anderson</surname>, <given-names>J. S.</given-names>
</string-name>, <string-name>
<surname>Bellec</surname>, <given-names>P.</given-names>
</string-name>, <string-name>
<surname>Birn</surname>, <given-names>R. M.</given-names>
</string-name>, <string-name>
<surname>Biswal</surname>, <given-names>B. B.</given-names>
</string-name>, <string-name>
<surname>Blautzik</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Breitner</surname>, <given-names>J. C. S.</given-names>
</string-name>, <string-name>
<surname>Buckner</surname>, <given-names>R. L.</given-names>
</string-name>, <string-name>
<surname>Calhoun</surname>, <given-names>V. D.</given-names>
</string-name>, <string-name>
<surname>Castellanos</surname>, <given-names>F. X.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>B.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>J.</given-names>
</string-name>, <string-name>
<surname>Chen</surname>, <given-names>X.</given-names>
</string-name>, <string-name>
<surname>Colcombe</surname>, <given-names>S. J.</given-names>
</string-name>, <string-name>
<surname>Courtney</surname>, <given-names>W.</given-names>
</string-name>, <string-name>
<surname>Craddock</surname>, <given-names>R. C.</given-names>
</string-name>, <string-name>
<surname>di Martino</surname>, <given-names>A.</given-names>
</string-name>, <string-name>
<surname>Dong</surname>, <given-names>H. M.</given-names>
</string-name>, … <string-name>
<surname>Milham</surname>, <given-names>M. P.</given-names>
</string-name> (<year>2014</year>). <article-title>An open science resource for establishing reliability and reproducibility in functional connectomics</article-title>. <source>Scientific Data</source>, <volume>1</volume>, <elocation-id>140049</elocation-id>.<pub-id pub-id-type="pmid">25977800</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
