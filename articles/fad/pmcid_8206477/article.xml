<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Hum Neurosci</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Hum Neurosci</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Hum. Neurosci.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Human Neuroscience</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1662-5161</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">34149385</article-id>
      <article-id pub-id-type="pmc">8206477</article-id>
      <article-id pub-id-type="doi">10.3389/fnhum.2021.687288</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Large-Scale Brain Functional Network Integration for Discrimination of Autism Using a 3-D Deep Learning Model</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>Ming</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="author-notes" rid="fn002">
            <sup>†</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>Menglin</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="author-notes" rid="fn002">
            <sup>†</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1275108/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Yuhao</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Yanni</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/251662/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Fan</surname>
            <given-names>Geng</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Chenxi</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Jue</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/232345/overview"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Tian</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="corresp" rid="c001">
            <sup>*</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1275111/overview"/>
        </contrib>
      </contrib-group>
      <aff id="aff1"><sup>1</sup><institution>The Key Laboratory of Biomedical Information Engineering of Ministry of Education, Institute of Health and Rehabilitation Science, School of Life Sciences and Technology, Xi’an Jiaotong University</institution>, <addr-line>Xi’an</addr-line>, <country>China</country></aff>
      <aff id="aff2"><sup>2</sup><institution>National Engineering Research Center for Healthcare Devices</institution>, <addr-line>Guangzhou</addr-line>, <country>China</country></aff>
      <aff id="aff3"><sup>3</sup><institution>The Key Laboratory of Neuro-informatics and Rehabilitation Engineering of Ministry of Civil Affairs</institution>, <addr-line>Xi’an</addr-line>, <country>China</country></aff>
      <aff id="aff4"><sup>4</sup><institution>Xi’an Children’s Hospital</institution>, <addr-line>Xi’an</addr-line>, <country>China</country></aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: Seung-Hwan Lee, Inje University Ilsan Paik Hospital, South Korea</p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: Han Zhang, University of North Carolina at Chapel Hill, United States; Heung-Il Suk, Korea University, South Korea</p>
        </fn>
        <corresp id="c001">*Correspondence: Tian Liu, <email>tianliu@xjtu.edu.cn</email></corresp>
        <fn fn-type="other" id="fn002">
          <p><sup>†</sup>These authors have contributed equally to this work and share first authorship</p>
        </fn>
        <fn fn-type="other" id="fn004">
          <p>This article was submitted to Brain Imaging and Stimulation, a section of the journal Frontiers in Human Neuroscience</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>02</day>
        <month>6</month>
        <year>2021</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2021</year>
      </pub-date>
      <volume>15</volume>
      <elocation-id>687288</elocation-id>
      <history>
        <date date-type="received">
          <day>29</day>
          <month>3</month>
          <year>2021</year>
        </date>
        <date date-type="accepted">
          <day>03</day>
          <month>5</month>
          <year>2021</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2021 Yang, Cao, Chen, Chen, Fan, Li, Wang and Liu.</copyright-statement>
        <copyright-year>2021</copyright-year>
        <copyright-holder>Yang, Cao, Chen, Chen, Fan, Li, Wang and Liu</copyright-holder>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <sec>
          <title>Goal</title>
          <p>Brain functional networks (BFNs) constructed using resting-state functional magnetic resonance imaging (fMRI) have proven to be an effective way to understand aberrant functional connectivity in autism spectrum disorder (ASD) patients. It is still challenging to utilize these features as potential biomarkers for discrimination of ASD. The purpose of this work is to classify ASD and normal controls (NCs) using BFNs derived from rs-fMRI.</p>
        </sec>
        <sec>
          <title>Methods</title>
          <p>A deep learning framework was proposed that integrated convolutional neural network (CNN) and channel-wise attention mechanism to model both intra- and inter-BFN associations simultaneously for ASD diagnosis. We investigate the effects of each BFN on performance and performed inter-network connectivity analysis between each pair of BFNs. We compared the performance of our CNN model with some state-of-the-art algorithms using functional connectivity features.</p>
        </sec>
        <sec>
          <title>Results</title>
          <p>We collected 79 ASD patients and 105 NCs from the ABIDE-I dataset. The mean accuracy of our classification algorithm was 77.74% for classification of ASD versus NCs.</p>
        </sec>
        <sec>
          <title>Conclusion</title>
          <p>The proposed model is able to integrate information from multiple BFNs to improve detection accuracy of ASD.</p>
        </sec>
        <sec>
          <title>Significance</title>
          <p>These findings suggest that large-scale BFNs is promising to serve as reliable biomarkers for diagnosis of ASD.</p>
        </sec>
      </abstract>
      <kwd-group>
        <kwd>autism spectrum disorder</kwd>
        <kwd>functional MRI</kwd>
        <kwd>convolutional neural network</kwd>
        <kwd>brain functional network</kwd>
        <kwd>classification</kwd>
      </kwd-group>
      <counts>
        <fig-count count="7"/>
        <table-count count="6"/>
        <equation-count count="7"/>
        <ref-count count="77"/>
        <page-count count="13"/>
        <word-count count="0"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <title>Introduction</title>
      <p>Autism spectrum disorder (ASD) represents a complex developmental disorder characterized by social deficits and restrictive or repetitive behaviors. Unlike other fields of medicine, psychiatry disorders lack valid physiological diagnostic criteria based on validated biomarkers (<xref rid="B6" ref-type="bibr">American Psychiatric Association, 2013</xref>). Mostly, ASD is diagnosed by subjective judgment of clinical symptoms and behaviors by clinicians. However, these methods require doctors to have high level of professional knowledge, and the diagnosis results are susceptible to doctors’ subjectivity. To find a more objective biomarker for identification of ASD, many researchers focus on deriving effective biomarkers such as genetics, epigenetics, body metabolism, and neuroimaging (<xref rid="B22" ref-type="bibr">Goldani et al., 2014</xref>). Neuroimaging is regarded as a promising non-invasive technique to uncover latent patterns of human brains. A human brain can be modeled as a complex system with various regions performing different structures and functions by using structural magnetic resonance imaging (sMRI), functional magnetic resonance imaging (fMRI), and positron emission tomography (PET) et.al. Previous neuroimaging studies have revealed alternation in both structural and functional connectivity of the brain among neurological or psychiatric disease populations (<xref rid="B45" ref-type="bibr">Mueller et al., 2013</xref>). Among all kinds of examination approaches, fMRI, especially resting state fMRI (rs-fMRI) recoding the changes of blood oxygen level-dependent (BOLD) signals, has been widely used for investigating mental disorders such as Alzheimer’s disease (<xref rid="B52" ref-type="bibr">Qureshi et al., 2019b</xref>), schizophrenia (<xref rid="B71" ref-type="bibr">Yan et al., 2019</xref>), and ASD (<xref rid="B3" ref-type="bibr">Abraham et al., 2017</xref>).</p>
      <p>Functional magnetic resonance imaging data is organized in a 4-D matrix format with high dimensionality (∼1 million) containing both spatial and temporal information. This makes it a difficult task to directly utilize the original data as input for classification algorithms. To address the high dimensionality of the data, many dimensionality reduction technologies have been proposed (<xref rid="B1" ref-type="bibr">Abdi and Williams, 2010</xref>; <xref rid="B67" ref-type="bibr">Suk et al., 2015</xref>; <xref rid="B65" ref-type="bibr">Soussia and Rekik, 2018</xref>). Instead of using original fMRI data, some have proposed brain function network analysis characterizing the “relationship” between regions of interest (ROIs). Based on the fact that the cerebral blood flow refreshes the neural activity across regions of the brain, modeling functional connectivity (FC) is helpful for understanding the neural basis of mental disorder (<xref rid="B40" ref-type="bibr">Lindquist, 2008</xref>). The most commonly used FC model is Pearson’s correlation, which can be calculated using BOLD signals between two brain regions. A brain functional network (BFN) is constructed based on the strength of the FC of all locations predefined by an atlas. BFN construction approaches explicitly reduced the dimensionality from 4-D into a 1-D vector. Many machine learning (ML) methods have been successfully employed in the automated classification of altered BFNs related to ASD (<xref rid="B70" ref-type="bibr">Uddin et al., 2013</xref>; <xref rid="B3" ref-type="bibr">Abraham et al., 2017</xref>). Some methods adopted sparse methods to implement implicit dimension reduction by adding an extra sparse regularization term [e.g., Lasso (<xref rid="B68" ref-type="bibr">Tibshirani, 1996</xref>) or the Elastic Net (<xref rid="B77" ref-type="bibr">Zou and Hastie, 2005</xref>)] to the loss function.</p>
      <p>However, the commonly used correlation for describing FC between ROIs just captures a linear relationship and is not suitable for characterizing high-order or non-linear features (<xref rid="B62" ref-type="bibr">Shojaee et al., 2019</xref>). Furthermore, collapsing the data into a feature vector (Vectorization) discards the spatial information of the brain regions (<xref rid="B33" ref-type="bibr">Kong et al., 2019</xref>). In addition, traditional classification algorithms such as support vector machine (SVM) (<xref rid="B13" ref-type="bibr">Cortes and Vapnik, 1995</xref>), Random Forest (<xref rid="B39" ref-type="bibr">Liaw and Wiener, 2002</xref>), and Naive Bayes (<xref rid="B56" ref-type="bibr">Rish, 2001</xref>) belong to a shallow model, which limits their capacity to extract the structural information hidden in BFNs.</p>
      <p>To derive BFNs with both functional connectivity and spatial information, independent component analysis (ICA) has been widely used (<xref rid="B54" ref-type="bibr">Rajapakse et al., 2006</xref>; <xref rid="B47" ref-type="bibr">Nickerson et al., 2017</xref>). ICA is a pure data-driven method, which can generate highly reproducible large-scale brain networks (<xref rid="B15" ref-type="bibr">Damoiseaux et al., 2006</xref>). However, the ICA components do not correspond exactly to meaningful brain networks. Usually, these components will be inspected by experienced clinicians or researchers to remove artifact components. Here, we use an automatic clustering algorithm (<xref rid="B8" ref-type="bibr">Beckmann et al., 2009</xref>; <xref rid="B21" ref-type="bibr">Filippini et al., 2009</xref>) to perform the selection of ICA components. The selected meaningful components can be used for deriving each subject’s subject-specific spatial maps by dual regression. Each individual spatial map captures variabilities in both the shape and amplitude of the corresponding resting state network between groups (<xref rid="B47" ref-type="bibr">Nickerson et al., 2017</xref>). This kind of feature representation in BFNs employs a 3-D functional rs-fMRI modality, which contains more information than FC coefficients.</p>
      <p>Recently, deep learning has gained much attention in various computer vision tasks (<xref rid="B55" ref-type="bibr">Redmon et al., 2016</xref>; <xref rid="B34" ref-type="bibr">Krizhevsky et al., 2017</xref>; <xref rid="B38" ref-type="bibr">Ledig et al., 2017</xref>). Deep learning has also been applied in medical image analysis, such as lesion segmentation (<xref rid="B28" ref-type="bibr">Isensee et al., 2018</xref>), MRI reconstruction (<xref rid="B59" ref-type="bibr">Schlemper et al., 2018</xref>), and registration (<xref rid="B72" ref-type="bibr">Yang et al., 2017</xref>). The deep neural network (DNN) is powerful for its capability to directly learn useful features from raw data and eliminate the need to manually design features in many other machine learning algorithms. Several studies have used stacking auto-encoders to build a DNN for classification of brain disorders such as Alzheimer’s disease (<xref rid="B67" ref-type="bibr">Suk et al., 2015</xref>), autism (<xref rid="B25" ref-type="bibr">Heinsfeld et al., 2018</xref>) and schizophrenia (<xref rid="B31" ref-type="bibr">Kim et al., 2016</xref>). In addition, recurrent neural network (RNN) and graph convolutional neural network (GCN) are also used in the early diagnosis of mental diseases. <xref rid="B20" ref-type="bibr">Dvornek et al. (2017)</xref> used long short-term memory (LSTM) to classify the time series data of resting-state fMRI, and the accuracy of cross-validation reached 68.5%. <xref rid="B71" ref-type="bibr">Yan et al. (2019)</xref> designed a multi-scale convolutional neural network-gated recurrent unit (CNN-GRU) model to learn the time series obtained from ICA and realized the classification of schizophrenia based on multi-site data. <xref rid="B35" ref-type="bibr">Ktena et al. (2017)</xref> took advantage of the spectral method of GCN to learn the similarity of brain functional connectivity networks and applied it to the early diagnosis of ASD. Unlike the methods mentioned above, 3-D convolutional neural network (3-D CNN) takes 3-D images as input rather than FC vector or time series data, capturing hierarchical features by integrating multi scales of features with different layers for spatial pattern representation and recognition (<xref rid="B37" ref-type="bibr">LeCun et al., 2015</xref>). In recent years, 3-D CNN has been successfully used in the classification of Alzheimer’s disease (<xref rid="B52" ref-type="bibr">Qureshi et al., 2019b</xref>), schizophrenia (<xref rid="B51" ref-type="bibr">Qureshi et al., 2019a</xref>), and early MCI (<xref rid="B30" ref-type="bibr">Kam et al., 2018</xref>), which achieved competitive performance of approximately 74–98% accuracy compared to traditional machine learning algorithms. Nevertheless, to date, 3-D CNN has not been used to classify large-scale BFNs in ASD, and the abnormal organization of the large-scale BFN in ASD subjects is not well understood. For these reasons, in the present study, we take the group ICA features as input and build a 3-D CNN architecture to model the differences in both “shape” (e.g., spatial activation patterns) and amplitude (e.g., the magnitude of the BOLD activity) of one or more BFNs, and we investigate both intra- and inter-BFN association changes to find a reliable and objective biomarker for diagnosis.</p>
      <p>The contributions of our work can be summarized in three aspects. (1) We used group ICA and dual regression to derive 3-D functional network spatial maps as potential biomarkers for identification of ASD. (2) We developed a variant of the VGG network, which involves channel attention mechanism, to integrate both intra- and inter-BFN association changes to find a reliable and objective biomarker for diagnosis. (3) A systematic comparison of our method with traditional machine learning framework has also been implemented. Our proposed model can improve detection accuracy of ASD.</p>
    </sec>
    <sec sec-type="materials|methods" id="S2">
      <title>Materials and Methods</title>
      <p><xref ref-type="fig" rid="F1">Figure 1</xref> illustrates the overall framework for discrimination of ASD. We first preprocessed all rs-fMRI data from the NYU site using the C-PAC pipeline. The preprocessed data were used to perform group ICA to generate 30 independent components. The good components were filtered by clustering and template matching, which would be used for further analysis (<xref ref-type="fig" rid="F1">Figure 1A</xref>). Second, we took the selected components to perform dual regression for each subject. Eight subject-specific spatial maps were generated and concatenated for each subject, which would be used as input for classification (<xref ref-type="fig" rid="F1">Figure 1B</xref>). We then randomly split all subjects into training and validation sets. The subject-specific spatial maps were fed into a 3-D CNN model. Finally, a 10-fold cross validation strategy was adopted for the classification performance evaluation (<xref ref-type="fig" rid="F1">Figure 1C</xref>).</p>
      <fig id="F1" position="float">
        <label>FIGURE 1</label>
        <caption>
          <p>Illustration of the proposed framework for ASD diagnosis. <bold>(A)</bold> All rs-fMRI data were preprocessed using the C-PAC pipeline. The independent components were derived using Group-ICA, and further inspected to identify eight well defined brain function networks (BFNs). <bold>(B)</bold> The selected BFNs were used to extract subject-specific spatial maps using dual regression. Eight subject-specific spatial maps were then concatenated together as input to the classifier. <bold>(C)</bold> The data were randomly split into training and validation sets. A total of 10-fold cross validation strategy was used for evaluating classification performance. The details of 3-D CNN model will be introduced later.</p>
        </caption>
        <graphic xlink:href="fnhum-15-687288-g001"/>
      </fig>
      <sec id="S2.SS1">
        <title>Dataset</title>
        <p>We ran our study on the Autism Brain Imaging Data Exchange (ABIDE) (<xref rid="B17" ref-type="bibr">Di Martino et al., 2014</xref>), which is a publicly available multi-site data repository. The first phase of ABIDE (ABIDE-I) compiles a dataset of 1112 individuals from 17 sites and consists of 539 individuals with ASD and 573 typical controls. Since the scan parameters vary across sites, ABIDE is a highly heterogeneous dataset. To avoid the impact of data heterogeneity, we collected raw rs-fMRI data from the whole NYU site, consisting of 79 ASD subjects and 105 normal controls (NCs). <xref rid="T1" ref-type="table">Table 1</xref> presents the complete demographic of the selected data.</p>
        <table-wrap id="T1" position="float">
          <label>TABLE 1</label>
          <caption>
            <p>Demographics characteristics of the selected subjects.</p>
          </caption>
          <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
            <thead>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="center" rowspan="1" colspan="1">Autism spectrum disorder</td>
                <td valign="top" align="center" rowspan="1" colspan="1">Normal control</td>
                <td valign="top" align="center" rowspan="1" colspan="1"><italic>p</italic>-Value</td>
              </tr>
              <tr>
                <td valign="top" align="justify" rowspan="1" colspan="1"/>
                <td valign="top" align="center" rowspan="1" colspan="1"><italic>N</italic> = 79; 11 F/68 M</td>
                <td valign="top" align="center" rowspan="1" colspan="1"><italic>N</italic> = 105; 26 F/79 M</td>
                <td rowspan="1" colspan="1"/>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Age</td>
                <td valign="top" align="center" rowspan="1" colspan="1">14.52 ± 6.97</td>
                <td valign="top" align="center" rowspan="1" colspan="1">15.81 ± 6.25</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.039</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Full IQ</td>
                <td valign="top" align="center" rowspan="1" colspan="1">107.91 ± 16.62</td>
                <td valign="top" align="center" rowspan="1" colspan="1">113.15 ± 13.12</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.022</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Verbal IQ</td>
                <td valign="top" align="center" rowspan="1" colspan="1">105.81 ± 16.13</td>
                <td valign="top" align="center" rowspan="1" colspan="1">113.13 ± 12.60</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Performance IQ</td>
                <td valign="top" align="center" rowspan="1" colspan="1">108.81 ± 17.42</td>
                <td valign="top" align="center" rowspan="1" colspan="1">110.06 ± 13.67</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.600</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ADOS total</td>
                <td valign="top" align="center" rowspan="1" colspan="1">11.30 ± 4.08</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ADOS communication score</td>
                <td valign="top" align="center" rowspan="1" colspan="1">3.54 ± 1.55</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">ADOS social score</td>
                <td valign="top" align="center" rowspan="1" colspan="1">7.76 ± 2.97</td>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1"/>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <attrib>
              <italic>ADOS, autism diagnostic observation schedule.</italic>
            </attrib>
          </table-wrap-foot>
        </table-wrap>
        <sec id="S2.SS1.SSS1">
          <title>Structural Data Acquisition</title>
          <p>All participants were scanned with a Siemens 3 Tesla Allegra scanner. An MPRAGE sequence was used with the following parameters: TR/TE/TI = 2530/3.25/1100 ms, flip angle = 7°, FoV read = 256 mm, slice thickness = 1.33 mm, voxel size = 1.3 × 1.0 × 1.3 mm, matrix = 256 × 256 × 171, bandwidth = 200 Hz/Px, and total scan time = 8:07 min.</p>
        </sec>
        <sec id="S2.SS1.SSS2">
          <title>Functional Data Acquisition</title>
          <p>Resting state functional MRI data were acquired using a 2-D echo-planar imaging (EPI) acquisition type with the following parameters: TR/TE = 2000/15 ms, flip angle = 90°, FoV read = 240 mm, slice thickness = 4 mm, voxel size = 3.0 × 3.0 × 4.0 mm, bandwidth = 3906 Hz/Px, and total scan time = 6.00 min. During the rs-fMRI scan, most participants were asked to relax with their eyes open and look at a cross-hair on a black background screen. Data were also included for some participants who were asked to keep their eyes closed.</p>
        </sec>
      </sec>
      <sec id="S2.SS2">
        <title>Pre-processing of Functional MRI Data</title>
        <p>We preprocessed the data using a widely adopted pipeline called Configurable Pipeline for the Analysis of Connectomes (C-PAC) (<xref rid="B14" ref-type="bibr">Craddock et al., 2013</xref>), which involves skull striping, slice timing correction, realignment to correct for motion, and bandpass filtering (0.01–0.1 Hz). The functional images were smoothed with a 5-mm full width half maximum (FWHM) Gaussian kernel, registered to a standard anatomical space (MNI152) and resampled to 4 mm.</p>
        <sec id="S2.SS2.SSS1">
          <title>Independent Component Analysis</title>
          <p>We used FSL Multivariate Exploratory Linear Optimized Decomposition into Independent Components (MELODIC<sup><xref ref-type="fn" rid="footnote1">1</xref></sup>) version 3.15 to perform group ICA. Preprocessed data were concatenated and entered into a group ICA to identify large-scale functional networks across the population. Usually, more than 20 components are necessary for identification of meaningful components, whereas model orders &gt;100 showed a decrease in ICA repeatability (<xref rid="B2" ref-type="bibr">Abou-Elseoud et al., 2010</xref>). The number of independent components was set to 30. Variance normalization and thresholding were further used to fit a Gaussian and 2 Gamma mixture model to the intensity histogram of the Z-transformed IC spatial maps.</p>
          <p>Finally, MELODIC yielded 30 independent component maps with the local false-discovery rate <italic>p</italic> &lt; 0.5. Among the 30 independent components, we used an automatic clustering tool, FSLNets<sup><xref ref-type="fn" rid="footnote2">2</xref></sup>, to divide these independent components into good networks and noise and/or artifacts. Second, we inspected the power spectra graph for each good independent component. The power spectrum of a typical network is in the low-frequency range, whereas an artifact power spectrum shows a multipeak pattern in the 0–0.1 Hz range. Furthermore, we used an FSL utility, <italic>fslcc</italic>, to spatially correlate all 15 good components derived by FSLNets to some set of reference networks. The reference networks we used are from the Stanford Functional Imaging in Neuropsychiatric Disorders Lab<sup><xref ref-type="fn" rid="footnote3">3</xref></sup> (<xref rid="B61" ref-type="bibr">Shirer et al., 2012</xref>). The names of reference networks are shown in <xref rid="T2" ref-type="table">Table 2</xref>. Finally, eight functional networks were filtered as the output of group ICA. <xref ref-type="fig" rid="F2">Figure 2</xref> shows all 30 components. The dendrogram contains two major branches representing good functional networks (in blue and green color) and noise and/or artifacts (in red color). All these functional networks served as templates to generate subject-specific brain function networks in the next step.</p>
          <table-wrap id="T2" position="float">
            <label>TABLE 2</label>
            <caption>
              <p>The names of reference networks.</p>
            </caption>
            <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
              <thead>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Number</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Reference network</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Anterior insula/dorsal ACC (anterior salience network)</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">2</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Auditory network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Basal ganglia network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">4</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">PCC/MPFC (dorsal default mode network)</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">5</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Higher visual network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">6</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Language network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">7</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Left DLPFC/parietal (left executive control network)</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">8</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Sensorimotor network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">9</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Posterior insula (posterior salience network)</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">10</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Precuneus network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">11</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Primary visual network</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">12</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Right DLPFC/parietal (right executive control network)</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">13</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Retrosplenial cortex/medial temporal lobe (ventral default mode network)</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">14</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Intraparietal sulcus/frontal eye fields (visuospatial network)</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
          <fig id="F2" position="float">
            <label>FIGURE 2</label>
            <caption>
              <p>Automated clustering dendrograms of the independent component-based brain functional networks acquired through Melodic ICA. The right branch depicted in red line represents noise or artifacts. The left branch contains good components that will be further inspected <italic>via</italic> power spectrum.</p>
            </caption>
            <graphic xlink:href="fnhum-15-687288-g002"/>
          </fig>
        </sec>
        <sec id="S2.SS2.SSS2">
          <title>Dual Regression</title>
          <p>To evaluate individual differences in BFNs, we applied the dual regression (<xref rid="B8" ref-type="bibr">Beckmann et al., 2009</xref>; <xref rid="B47" ref-type="bibr">Nickerson et al., 2017</xref>) approach in FSL v6.0.1<sup><xref ref-type="fn" rid="footnote4">4</xref></sup>. This method has been widely used in comparing large-scale BFNs between groups (<xref rid="B21" ref-type="bibr">Filippini et al., 2009</xref>; <xref rid="B47" ref-type="bibr">Nickerson et al., 2017</xref>). Dual regression decomposes each subject’s 4-D fMRI data into a set of spatial maps and corresponding time courses. Dual regression is an effective approach to investigate network shape and amplitude in functional connectivity analyses (<xref rid="B47" ref-type="bibr">Nickerson et al., 2017</xref>). Dual regression analysis proceeds in two steps. First, for each subject, a set of template networks is regressed into the subject’s 4-D spatial-temporal dataset. This results in a set of subject-specific time courses, corresponding to each IC template. Second, the network-specific time courses are used as predictors in a multivariable multiple linear regression into the same 4-D dataset, resulting in a set of subject-specific 3-D spatial maps. The template network can be derived using FSL’s group ICA, from an atlas, or using functional localizers. Based on these 3-D spatial maps of BFNs for each subject, we build a 3-D CNN model to learn sophisticated feature representation for classification.</p>
        </sec>
      </sec>
      <sec id="S2.SS3">
        <title>3-D CNN Architecture for Classification</title>
        <p>In the present study, we implemented stratified 10-fold cross validation to evaluate the effectiveness of our algorithm. This method of splitting data ensures that the proportion of ASDs and NCs was the same across all folds.</p>
        <sec id="S2.SS3.SSS1">
          <title>Backbone Structure</title>
          <p>A variant of VGG-net (<xref rid="B63" ref-type="bibr">Simonyan and Zisserman, 2014</xref>) was used for our task. VGG-net is a popular convolution network model that has been used in many studies (<xref rid="B51" ref-type="bibr">Qureshi et al., 2019a</xref>,<xref rid="B52" ref-type="bibr">b</xref>; <xref rid="B19" ref-type="bibr">Duc et al., 2020</xref>). Instead of using 2-D convolution in vanilla VGG, 3-D convolution was adopted in our network. Batch Normalization (<xref rid="B27" ref-type="bibr">Ioffe and Szegedy, 2015</xref>) and Leaky Rectified Linear Unit (LeakyReLU) (<xref rid="B42" ref-type="bibr">Maas et al., 2013</xref>) were used as activation functions. Because CNN is a highly non-convex function, poor initialization strategy may induce the CNN into a local sub-optimal solution, resulting in bad generalization performance. To alleviate this problem, we initiated our 3-D CNN with the initialization strategy proposed by <xref rid="B24" ref-type="bibr">He et al. (2015)</xref>. The overview of our proposed CNN is shown in <xref ref-type="fig" rid="F3">Figure 3</xref>.</p>
          <fig id="F3" position="float">
            <label>FIGURE 3</label>
            <caption>
              <p>Modified VGG-Net 3-D CNN architecture with SE module integrated.</p>
            </caption>
            <graphic xlink:href="fnhum-15-687288-g003"/>
          </fig>
        </sec>
        <sec id="S2.SS3.SSS2">
          <title>Channel Attention Module</title>
          <p>Vanilla VGG achieved good performance in image classification by stacking a series of convolution layers with the same kernel size of 3 × 3 × 3 and interleaved with non-linear activation and max-pooling layers. This kind of hierarchical architecture can capture local spatial patterns along all input channels. To model the independencies between channels, channel switching, combination (<xref rid="B75" ref-type="bibr">Zhang et al., 2017</xref>, <xref rid="B76" ref-type="bibr">2018</xref>) or using reinforcement learning to reorganize the network paths (<xref rid="B5" ref-type="bibr">Ahmed and Torresani, 2017</xref>), channel-wise attention was proposed to bias the allocation of resources to the most informative channels (<xref rid="B26" ref-type="bibr">Hu et al., 2018</xref>). The squeeze and excitation (SE) module is an efficient component that can be added to any CNN model easily. The key point of SE module is that it can calibrate the feature map and emphasize important channels by learning a channel-specific descriptor. We integrated several SE blocks into the variant VGG structure to boost classification performance.</p>
          <p>The SE module consists of two parts, <italic>squeeze</italic> and <italic>excitation.</italic> A diagram of an SE building block is depicted in <xref ref-type="fig" rid="F4">Figure 4</xref>. Let us assume that U = [u<sub>1</sub>, u<sub>2</sub>,…,u<sub>F</sub>] is an input feature map, where u<sub><italic>f</italic></sub>ϵ<italic>ℝ</italic><sup>H×W×D</sup> is a single channel with size <italic>H</italic> × <italic>W</italic> × <italic>D</italic>. <italic>H</italic>,<italic>W</italic> and <italic>D</italic> are the spatial height, width, and depth, respectively. Channel squeeze is performed <italic>via</italic> a global average pooling layer, productor vector <bold>z</bold>ϵ<italic>ℝ</italic><sup>1×1×1×<italic>F</italic></sup>, with the <italic>f-</italic>th element given by:</p>
          <fig id="F4" position="float">
            <label>FIGURE 4</label>
            <caption>
              <p>Architecture of squeeze and excitation (SE) module.</p>
            </caption>
            <graphic xlink:href="fnhum-15-687288-g004"/>
          </fig>
          <disp-formula id="S2.E1">
            <label>(1)</label>
            <mml:math id="M1">
              <mml:mrow>
                <mml:mpadded width="+3.3pt">
                  <mml:msub>
                    <mml:mtext>z</mml:mtext>
                    <mml:mrow>
                      <mml:mtext>f</mml:mtext>
                    </mml:mrow>
                  </mml:msub>
                </mml:mpadded>
                <mml:mo rspace="5.8pt">=</mml:mo>
                <mml:mrow>
                  <mml:mfrac>
                    <mml:mn>1</mml:mn>
                    <mml:mrow>
                      <mml:mpadded width="+3.3pt">
                        <mml:mtext>H</mml:mtext>
                      </mml:mpadded>
                      <mml:mo rspace="5.8pt">×</mml:mo>
                      <mml:mpadded width="+3.3pt">
                        <mml:mtext>W</mml:mtext>
                      </mml:mpadded>
                      <mml:mo rspace="5.8pt">×</mml:mo>
                      <mml:mtext>D</mml:mtext>
                    </mml:mrow>
                  </mml:mfrac>
                  <mml:mo>⁢</mml:mo>
                  <mml:mrow>
                    <mml:munderover>
                      <mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo>
                      <mml:mrow>
                        <mml:mpadded width="+3.3pt">
                          <mml:mrow>
                            <mml:mtext>h</mml:mtext>
                          </mml:mrow>
                        </mml:mpadded>
                        <mml:mo rspace="5.8pt">=</mml:mo>
                        <mml:mn>1</mml:mn>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>H</mml:mtext>
                      </mml:mrow>
                    </mml:munderover>
                    <mml:mrow>
                      <mml:munderover>
                        <mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo>
                        <mml:mrow>
                          <mml:mpadded width="+3.3pt">
                            <mml:mrow>
                              <mml:mtext>w</mml:mtext>
                            </mml:mrow>
                          </mml:mpadded>
                          <mml:mo rspace="5.8pt">=</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mtext>W</mml:mtext>
                        </mml:mrow>
                      </mml:munderover>
                      <mml:mrow>
                        <mml:munderover>
                          <mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo>
                          <mml:mrow>
                            <mml:mpadded width="+3.3pt">
                              <mml:mrow>
                                <mml:mtext>d</mml:mtext>
                              </mml:mrow>
                            </mml:mpadded>
                            <mml:mo rspace="5.8pt">=</mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mtext>D</mml:mtext>
                          </mml:mrow>
                        </mml:munderover>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mo>[</mml:mo>
                            <mml:msub>
                              <mml:mtext>u</mml:mtext>
                              <mml:mi>f</mml:mi>
                            </mml:msub>
                            <mml:mo>]</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                            <mml:mo>,</mml:mo>
                            <mml:mi>j</mml:mi>
                            <mml:mo>,</mml:mo>
                            <mml:mi>k</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mrow>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>This operation embeds the global spatial information into vector <bold>z</bold>. To make full use of the information hidden in <bold>z</bold>, an excitation operation is designed. Two fully connected layers, the ReLU (<xref rid="B46" ref-type="bibr">Nair and Hinton, 2010</xref>) function δ and a sigmoid activation function σ(⋅), are used to transform <bold>z</bold>:</p>
          <disp-formula id="S2.E2">
            <label>(2)</label>
            <mml:math id="M2">
              <mml:mrow>
                <mml:mtext mathvariant="bold">s</mml:mtext>
                <mml:mo rspace="5.8pt">=</mml:mo>
                <mml:mrow>
                  <mml:mi mathvariant="normal">σ</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mrow>
                    <mml:mo>(</mml:mo>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mtext mathvariant="bold">W</mml:mtext>
                        <mml:mn>1</mml:mn>
                      </mml:msub>
                      <mml:mo>⁢</mml:mo>
                      <mml:mi mathvariant="normal">δ</mml:mi>
                      <mml:mo>⁢</mml:mo>
                      <mml:mrow>
                        <mml:mo>(</mml:mo>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mtext>W</mml:mtext>
                            <mml:mn>2</mml:mn>
                          </mml:msub>
                          <mml:mo>⁢</mml:mo>
                          <mml:mi>z</mml:mi>
                        </mml:mrow>
                        <mml:mo>)</mml:mo>
                      </mml:mrow>
                    </mml:mrow>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <inline-formula><mml:math id="INEQ13"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">ϵ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mpadded width="+3.3pt"><mml:mfrac><mml:mi>F</mml:mi><mml:mi>r</mml:mi></mml:mfrac></mml:mpadded><mml:mo rspace="5.8pt">×</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="INEQ14"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">ϵ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mpadded width="+3.3pt"><mml:mi>F</mml:mi></mml:mpadded><mml:mo rspace="5.8pt">×</mml:mo><mml:mfrac><mml:mi>F</mml:mi><mml:mi>r</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and r is the reduction ratio to limit the model complexity and aid generalization. <bold>s</bold> encodes the channel-wise dependencies and is used to excite or recalibrate U to:</p>
          <disp-formula id="S2.E3">
            <label>(3)</label>
            <mml:math id="M3">
              <mml:mrow>
                <mml:mrow>
                  <mml:mpadded width="+3.3pt">
                    <mml:mover accent="true">
                      <mml:mi>U</mml:mi>
                      <mml:mo stretchy="false">^</mml:mo>
                    </mml:mover>
                  </mml:mpadded>
                  <mml:mo rspace="5.8pt">=</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>F</mml:mi>
                      <mml:mrow>
                        <mml:mi>s</mml:mi>
                        <mml:mo>⁢</mml:mo>
                        <mml:mi>c</mml:mi>
                        <mml:mo>⁢</mml:mo>
                        <mml:mi>a</mml:mi>
                        <mml:mo>⁢</mml:mo>
                        <mml:mi>l</mml:mi>
                        <mml:mo>⁢</mml:mo>
                        <mml:mi>e</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mo>⁢</mml:mo>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:msub>
                        <mml:mi>u</mml:mi>
                        <mml:mi>f</mml:mi>
                      </mml:msub>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi>s</mml:mi>
                        <mml:mi>f</mml:mi>
                      </mml:msub>
                      <mml:mo rspace="5.8pt">)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">=</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mi>s</mml:mi>
                      <mml:mi>f</mml:mi>
                    </mml:msub>
                    <mml:mo>⋅</mml:mo>
                    <mml:msub>
                      <mml:mi>u</mml:mi>
                      <mml:mi>f</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mrow>
                <mml:mo>,</mml:mo>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mpadded width="+2.8pt">
                      <mml:mtext>for</mml:mtext>
                    </mml:mpadded>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mtext>f</mml:mtext>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">=</mml:mo>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>,</mml:mo>
                    <mml:mn>2</mml:mn>
                    <mml:mo>,</mml:mo>
                    <mml:mi mathvariant="normal">⋯</mml:mi>
                    <mml:mo>,</mml:mo>
                    <mml:mtext>F</mml:mtext>
                  </mml:mrow>
                </mml:mrow>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <p>where <inline-formula><mml:math id="INEQ16"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>f</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for the channel-wise multiplication between the feature map u<sub><italic>f</italic></sub>ϵ<italic>ℝ</italic><sup>H×W×D</sup> and the scalar <italic>s<sub>f</sub></italic>. The importance of the <italic>i</italic>-th channel is indicated by <italic>s</italic><sub><italic>f</italic></sub> ∈ [0,1].</p>
          <p>Here, we inserted three SE blocks into the 3-D VGG net. The reduction ratio was set to 16. Details of our model are presented in <xref rid="T3" ref-type="table">Table 3</xref>.</p>
          <table-wrap id="T3" position="float">
            <label>TABLE 3</label>
            <caption>
              <p>Details of the proposed MCSE-VGG architecture.</p>
            </caption>
            <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
              <thead>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Layer</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Feature map</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Stride</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Kernel</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Activation structure</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">32</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">
                    <bold>SE block</bold>
                  </td>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" colspan="3" rowspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">32</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Max-pooling</td>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">
                    <bold>SE block</bold>
                  </td>
                  <td valign="top" align="center" rowspan="1" colspan="1">32</td>
                  <td valign="top" colspan="3" rowspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">64</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">64</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Max-pooling</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">64</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">
                    <bold>SE block</bold>
                  </td>
                  <td rowspan="1" colspan="1"/>
                  <td rowspan="1" colspan="1"/>
                  <td rowspan="1" colspan="1"/>
                  <td rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">128</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">128</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">128</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Max-pooling</td>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">256</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">256</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">156</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Max-pooling</td>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2 ×2 ×2</td>
                  <td rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">256</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">256</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">256</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">BN + LReLU + Conv</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2048</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">3 ×3 ×3</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Dropout + Conv + LReLU</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Convolution</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1024</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">1 ×1 ×1</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Dropout + Conv + LReLU</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Dense</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">2</td>
                  <td valign="top" colspan="3" rowspan="1"/>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <attrib>
                <italic>MCSE-VGG, multi channel squeeze and excitation VGG-net; LReLU, Leaky Rectified Linear Unit.</italic>
              </attrib>
            </table-wrap-foot>
          </table-wrap>
        </sec>
      </sec>
      <sec id="S2.SS4">
        <title>Performance Evaluation</title>
        <p>For performance evaluation, we adopted accuracy (ACC), precision, recall, and F1 score as quantitative metrics. TP, TN, FP, FN, PPV, and NPV denote true positive, true negative, false positive, false negative, positive predictive value, and negative predictive value, respectively. These metrics are defined as below:</p>
        <disp-formula id="S2.Ex1">
          <mml:math id="M4">
            <mml:mrow>
              <mml:mrow>
                <mml:mi>A</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>C</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mpadded width="+3.3pt">
                  <mml:mi>C</mml:mi>
                </mml:mpadded>
              </mml:mrow>
              <mml:mo rspace="5.8pt">=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>P</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>P</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>N</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>F</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>P</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>F</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="S2.Ex2">
          <mml:math id="M5">
            <mml:mrow>
              <mml:mrow>
                <mml:mi>P</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>r</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>e</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>c</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>i</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>s</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>i</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>o</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mpadded width="+3.3pt">
                  <mml:mi>n</mml:mi>
                </mml:mpadded>
              </mml:mrow>
              <mml:mo rspace="5.8pt">=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>T</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>P</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>P</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>F</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="S2.Ex3">
          <mml:math id="M6">
            <mml:mrow>
              <mml:mrow>
                <mml:mi>R</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>e</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>c</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>a</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mi>l</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mpadded width="+3.3pt">
                  <mml:mi>l</mml:mi>
                </mml:mpadded>
              </mml:mrow>
              <mml:mo rspace="5.8pt">=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>T</mml:mi>
                  <mml:mo>⁢</mml:mo>
                  <mml:mi>N</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mi>T</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>N</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>F</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>P</mml:mi>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
        <disp-formula id="S2.Ex4">
          <mml:math id="M7">
            <mml:mrow>
              <mml:mrow>
                <mml:mi>F</mml:mi>
                <mml:mo>⁢</mml:mo>
                <mml:mpadded width="+3.3pt">
                  <mml:mn>1</mml:mn>
                </mml:mpadded>
              </mml:mrow>
              <mml:mo rspace="5.8pt">=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mpadded width="+3.3pt">
                    <mml:mn>2</mml:mn>
                  </mml:mpadded>
                  <mml:mo rspace="5.8pt">×</mml:mo>
                  <mml:mpadded width="+3.3pt">
                    <mml:mtext>Precision</mml:mtext>
                  </mml:mpadded>
                  <mml:mo rspace="5.8pt">×</mml:mo>
                  <mml:mtext>Recall</mml:mtext>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mi>P</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>r</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>e</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>c</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>s</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>o</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mpadded width="+3.3pt">
                      <mml:mi>n</mml:mi>
                    </mml:mpadded>
                  </mml:mrow>
                  <mml:mo rspace="5.8pt">+</mml:mo>
                  <mml:mrow>
                    <mml:mi>R</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>e</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>c</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>a</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>l</mml:mi>
                    <mml:mo>⁢</mml:mo>
                    <mml:mi>l</mml:mi>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:math>
        </disp-formula>
      </sec>
    </sec>
    <sec id="S3">
      <title>Results</title>
      <sec id="S3.SS1">
        <title>Large-Scale Brain Functional Networks</title>
        <p>In total, eight components (<xref ref-type="fig" rid="F5">Figure 5</xref>) were identified as BFNs from group ICA. The eight selected resting state functional networks included the primary visual network (PVN), dorsal default mode network (dDMN), ventral default mode network (vDMN), precuneus network (PCUN), sensorimotor network (SMN), anterior salience network (SN), left central executive network (LCEN), and right central executive network (RCEN). They were used to perform dual regression to generate subject-specific time courses for connectivity analysis and spatial maps for classification.</p>
        <fig id="F5" position="float">
          <label>FIGURE 5</label>
          <caption>
            <p>Eight large-scale resting state brain functional networks derived using group independent component analysis (gICA): primary visual network <bold>(A)</bold>, dorsal default mode <bold>(B)</bold>, ventral default mode <bold>(C)</bold>, precuneus network <bold>(D)</bold>, sensorimotor network <bold>(E)</bold>, anterior salience <bold>(F)</bold>, left central executive <bold>(G)</bold>, right central executive <bold>(H)</bold>.</p>
          </caption>
          <graphic xlink:href="fnhum-15-687288-g005"/>
        </fig>
      </sec>
      <sec id="S3.SS2">
        <title>Network Configuration</title>
        <p>We applied PyTorch (<xref rid="B49" ref-type="bibr">Paszke et al., 2019</xref>) 1.0 framework to implement our model. Training and testing of this model used one NVIDIA RTX 2080Ti graphical processing unit (GPU). During the training phase, an ADAM (<xref rid="B32" ref-type="bibr">Kingma and Ba, 2014</xref>) optimizer was used with an initial learning rate of 0.0005. The initialization strategy proposed by <xref rid="B24" ref-type="bibr">He et al. (2015)</xref> was adopted to initiate the 3-D CNN model. The learning rate was decayed by 0.1 if the validation loss did not decrease after 10 epochs. The batch size was set to 12, and the negative slope LeakyReLU was set as 0.01. We used L2 norm regularization on the convolution kernel parameters with a weight of 1e-5. Dropout was set as 0.7. The cross-entropy loss function is applied to the output units to predict the probability of a subject belonging to the NC or ASD group. The results of the validation set of each fold will be shown in the next section.</p>
      </sec>
      <sec id="S3.SS3">
        <title>Performance Evaluation</title>
        <sec id="S3.SS3.SSS1">
          <title>Baseline</title>
          <p>First, we padded subject-specific spatial maps of each BFN into 48 × 56 × 48 and then concatenated them into a 4-D tensor of 8 × 48 × 56 × 48 for each subject. The first dimension represents the number of selected BFNs. All eight selected components are associated with high-level recognition functions, which include the primal visual network, PCUN, default mode network (DMN), SN, executive control networks and SMN. We took this 4-D tensor as input to train a vanilla VGG model as baseline.</p>
        </sec>
        <sec id="S3.SS3.SSS2">
          <title>Channel Attention Based 3-D CNN</title>
          <p>Here, we conducted two kinds of 3-D CNN integrated with the SE module. One consists of taking each BFN separately into SE-VGG to construct a single channel SE-VGG (SCSE-VGG) diagnosis model. <xref ref-type="fig" rid="F6">Figure 6</xref> shows the ability to discriminate ASD from NC based on spatial maps corresponding to each of the 8 functional networks for each subject using SE-VGG. Another option is to concatenate 8 BFNs as multi-channel input to SE-VGG (MCSE-VGG). In <xref rid="T4" ref-type="table">Table 4</xref>, we summarize the performance of our proposed method. Our experiments showed that the MCSE-VGG model outperformed other models by achieving a mean accuracy of 77.74%, which significantly boosted the performance of the baseline model by ∼8%. Compared to various SCSE-VGG models using only one BFN, the proposed MCSE-VGG improved the accuracy by ∼4–12%. The results showed that our proposed method could effectively capture the relationship within multiple BFNs. In addition, the SE block could assist the 3-D CNN learning from multiple BFNs and effectively model the channel-interdependencies information. Among all 8 SESE-VGG models, SESE-VGG with the PCUN, dDMN, and SN showed higher accuracy than those with other BFNs. This indicated that these three networks might play an important role in the development of ASD.</p>
          <fig id="F6" position="float">
            <label>FIGURE 6</label>
            <caption>
              <p>Classification accuracy for each identified brain function network (BFN). Each BFN spatial map was used as input features and fed into SCSE-VGG model for classification. The precuneus network achieved the highest accuracy at 74%.</p>
            </caption>
            <graphic xlink:href="fnhum-15-687288-g006"/>
          </fig>
          <table-wrap id="T4" position="float">
            <label>TABLE 4</label>
            <caption>
              <p>Classification results comparison of different network architectures using 10-fold cross-validation.</p>
            </caption>
            <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
              <thead>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Method</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Functional network</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">ACC (%)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Precision (%)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">Recall (%)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">F1 score</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Baseline</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">All</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">69.58</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">69.43</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">65.54</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">67.43</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">SCSE-VGG</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">PVN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">65.21</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.10</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">50.54</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">50.02</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">PCUN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">74.01</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">71.76</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">77.32</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">74.44</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">dDMN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">71.18</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">73.38</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.57</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">70.89</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">vDMN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.49</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">64.22</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">65.54</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">64.87</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">LCEN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.53</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">70.67</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">56.96</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">63.08</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">RCEN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.68</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">66.62</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">89.82</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">76.50</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">SN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">71.16</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">77.06</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">61.96</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.69</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1"/>
                  <td valign="top" align="center" rowspan="1" colspan="1">SMN</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">69.57</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">71.19</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">64.82</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">67.86</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">MCSE-VGG</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">All</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">77.74</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">76.74</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">78.57</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">75.33</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <attrib>
                <italic>The baseline and MCSE-VGG models use all the eight brain functional networks. MCSE-VGG and SCSE-VGG models are inserted with SE module. SCSE-VGG models are evaluated for each brain functional network.</italic>
              </attrib>
            </table-wrap-foot>
          </table-wrap>
        </sec>
        <sec id="S3.SS3.SSS3">
          <title>Compared Methods</title>
          <p>We compared the proposed SCSE-VGG with several state-of-the-art methods including both traditional machine learning algorithms and deep learning methods. We extracted the mean time series for ROI defined by the CC200 functional parcellation atlas of the brain. The functional connectivity was calculated by Pearson correlation between each pair of brain regions and generated a correlation matrix. The upper triangle values of the correlation matrix were vectorized as features and fed into an Autoencoder and Multilayer Perceptron (AE-MLP) model. We modified the code from <xref rid="B25" ref-type="bibr">Heinsfeld et al. (2018)</xref> and implemented three algorithms, e.g., deep neural network (<xref rid="B25" ref-type="bibr">Heinsfeld et al., 2018</xref>), SVM (<xref rid="B13" ref-type="bibr">Cortes and Vapnik, 1995</xref>) and random forest (RF) (<xref rid="B39" ref-type="bibr">Liaw and Wiener, 2002</xref>), on the NYU dataset. <xref rid="B9" ref-type="bibr">Bengs et al. (2020)</xref> used the 4-D fMRI image data and modeled the spatial-temporal information by 3-D convolutional GRU and 3-D CNN. We reported their experimental results on the NYU dataset. We show the results from these models in <xref rid="T5" ref-type="table">Table 5</xref>.</p>
          <table-wrap id="T5" position="float">
            <label>TABLE 5</label>
            <caption>
              <p>Performance comparison of the proposed and previous methods.</p>
            </caption>
            <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
              <thead>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Method</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">ACC (%)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">F1 score</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">AE-MLP</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">68.56</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">73.87</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">SVM</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">62.97</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">74.24</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Random forest</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">60.62</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">71.37</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">convGRU-CNN3D (<xref rid="B9" ref-type="bibr">Bengs et al., 2020</xref>)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">67.00</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">71.00</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">VGG (ours)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">69.58</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">67.43</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">MCSE-VGG (ours)</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">77.74</td>
                  <td valign="top" align="center" rowspan="1" colspan="1">75.33</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <attrib>
                <italic>The results of convGRU-CNN3D were reported on the paper (<xref rid="B9" ref-type="bibr">Bengs et al., 2020</xref>).</italic>
              </attrib>
            </table-wrap-foot>
          </table-wrap>
          <p>Deep learning-based classification frameworks (including AE-MLP, convGRU-CNN3D, and our proposed model) showed better performance than traditional machine learning-based frameworks (including SVM and RF). The results showed that our proposed model (MCSE-VGG) outperformed other models by achieving a mean accuracy and F1 score of 77.74 and 75.33%, respectively, which surpassed previous studies by ∼9–17 and ∼1–8%. This improvement may be due to the ability of 3-D CNN to make use of the features hidden in both inter- and intra-BFN. 3-D convolution kernel is powerful for extracting spatial information within each BFN, and the channel attention mechanism can further recalibrate the importance of spatial features extracted by convolution layers.</p>
        </sec>
      </sec>
      <sec id="S3.SS4">
        <title>Inter-Network Connectivity Analysis</title>
        <p>Although our experiments have shown good performances compared to existing methods, the deep learning framework lacks interpretability. To further validate the effectiveness of our selected BFNs to serve as reliable imaging biomarkers for ASD diagnosis, we performed an inter-network analysis on the basis of the dual regression results using the FSLNets package<sup><xref ref-type="fn" rid="footnote5">5</xref></sup>. The time courses derived by stage one of the dual regression were used as input for the modeling network. Artifactual components were regressed out over the corresponding time courses, and only the selected eight components were preserved and considered for subsequent statistical analysis. We took ridge regression partial correlation (PC) as a measure of direct connections (<xref rid="B64" ref-type="bibr">Smith et al., 2011</xref>) between each pair of components. The correlation coefficients were then transformed into <italic>Z</italic>-values <italic>via</italic> the standard Fisher’s transform. The PC matrices were used as input to the general linear model (GLM) analysis, and an unpaired nonparametric test with 5000 permutations was run to test differences in connection strength between ASD and NC.</p>
        <p>We selected the most significant network edges (<italic>p</italic> = 0.05) from the GLM output and created boxplots for the two groups as illustrated in <xref ref-type="fig" rid="F7">Figure 7</xref>. As a result, the strengths of connectivity were significantly increased between the SN and dDMN in ASD patients compared to controls. A similar result was also found between the SN and LCEN. Furthermore, a reduced connective strength was obtained between the PCUN and dDMN.</p>
        <fig id="F7" position="float">
          <label>FIGURE 7</label>
          <caption>
            <p>Box plot of the connectivity differences in ASD versus NC. Connectivity strength is shown for the brain functional networks (BFN) between <bold>(A)</bold> anterior salience network (SN) and dorsal default mode network (dDMN) and <bold>(B)</bold> SN and left central executive network (LCEN), and <bold>(C)</bold> precuneus network (PCUN) and dDMN.</p>
          </caption>
          <graphic xlink:href="fnhum-15-687288-g007"/>
        </fig>
      </sec>
    </sec>
    <sec id="S4">
      <title>Discussion</title>
      <p>In this study, we proposed a novel framework to model inter- and intra-associations of multiple large-scale BFNs derived from rs-fMRI by using a 3-D CNN deep learning architecture for ASD diagnosis. Instead of using 1-D time-series information, we used subject-specific BFN spatial maps to capture the spatial patterns <italic>via</italic> 3-D convolution. Channel attention blocks were integrated into our CNN model to fuse the deep features of multiple BFNs. We evaluated our proposed method on a public dataset and achieved the best performance compared with previous classifications (<xref rid="B25" ref-type="bibr">Heinsfeld et al., 2018</xref>; <xref rid="B9" ref-type="bibr">Bengs et al., 2020</xref>). Our proposed framework can be easily generalized to the diagnosis of other mental illnesses such as Alzheimer’s, schizophrenia and depression.</p>
      <p>Our results showed a mean test accuracy of 77.74% in a 10-fold cross validation experiment using the MCSE-VGG deep learning algorithm. In our proposed algorithm, the input data is multi-channel tensor, and each channel corresponds to one subject-specific BFN. Convolutional layers extract the most important spatial information from these BFNs in a hierarchical way with different layers. The SE module can further integrate and recalibrate these spatial features from different BFNs before they are fed into the next transformation. The introduction of the SE module improves the accuracy of the VGG model by ∼8%. <xref rid="B25" ref-type="bibr">Heinsfeld et al. (2018)</xref> proposed to use deep autoencoder network for the classification of ASD. They built a multilayer perceptron (MLP) and applied the encoder weights to the MLP. Only the last layer of MLP was adjusted to output the expected classes. They used functional connectivity features calculated by correlation between each pair of ROIs, which was different from our input features. Some works also used 3-D BFNs as features and developed a 3-D CNN for discrimination of mental illness, e.g., Alzheimer’s dementia (<xref rid="B52" ref-type="bibr">Qureshi et al., 2019b</xref>) and schizophrenia (<xref rid="B51" ref-type="bibr">Qureshi et al., 2019a</xref>). These studies treated every BFN equally and did not model the contribution of different brain networks to classification results.</p>
      <p>The ultimate goal of our proposed framework is to identify a collection of reliable biomarkers for ASD diagnosis. Although deep learning has shown great potential in classification, the lack of interpretability restricts its application in the clinic. To determine the effect of each BFN on the neural network, we used each individual BFN as input features to train a SCSE-VGG model. The results showed that dDMN, PCUN, and SN achieved better accuracies than others. These three brain networks might be the most important features that can boost the performance of MCSE-VGG significantly. <xref rid="T6" ref-type="table">Table 6</xref> lists Brodmann areas of these networks.</p>
      <table-wrap id="T6" position="float">
        <label>TABLE 6</label>
        <caption>
          <p>Anatomical labels of the identified brain functional networks.</p>
        </caption>
        <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
          <thead>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">BFN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Anatomical location of functional ROIs</td>
              <td valign="top" align="center" rowspan="1" colspan="1">Brodmann areas</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">PCC/MPFC (dDMN)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Medial prefrontal cortex, anterior cingulate cortex, orbitofrontal cortex</td>
              <td valign="top" align="center" rowspan="1" colspan="1">9, 10, 24, 32, 11</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Right superior frontal gyrus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">9</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Posterior cingulate cortex, precuneus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23, 30</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Midcingulate cortex</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Left and right angular gyrus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">39</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Left and right thalamus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">N/A</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Left and right hippocampus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">20, 36, 30</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">PCUN</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Midcingulate cortex, posterior cingulate cortex</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Precuneus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">7, 19</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Left and right angular gyrus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">7, 40</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Insula/dACC (SN)</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Left middle frontal gyrus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">9, 46</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Left and right insula</td>
              <td valign="top" align="center" rowspan="1" colspan="1">48, 47</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Anterior cingulate cortex, medial prefrontal cortex, supplementary motor area</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23, 32, 8, 6</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Right middle frontal gyrus</td>
              <td valign="top" align="center" rowspan="1" colspan="1">46, 9</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Left lobule VI, crus I</td>
              <td valign="top" align="center" rowspan="1" colspan="1">N/A</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td valign="top" align="left" rowspan="1" colspan="1">Right lobule VI, crus I</td>
              <td valign="top" align="center" rowspan="1" colspan="1">N/A</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Both dDMN and PCUN are subnetworks of the DMN comprising the posterior cingulate cortex (PCC), precuneus, medial prefrontal cortex (MPFC), temporoparietal junction (TPJ), and hippocampus (<xref rid="B53" ref-type="bibr">Raichle et al., 2001</xref>; <xref rid="B11" ref-type="bibr">Buckner et al., 2008</xref>). The DMN is engaged in a range of social cognitive processes including self-referential and autobiographical processing and mentalizing and theory of mind (<xref rid="B48" ref-type="bibr">Padmanabhan et al., 2017</xref>). In particular, the PCC and MPFC, the two most notable nodes of the DMN, are involved with social cognition (<xref rid="B57" ref-type="bibr">Schilbach et al., 2008</xref>; <xref rid="B66" ref-type="bibr">Spreng et al., 2009</xref>; <xref rid="B43" ref-type="bibr">Mars et al., 2012</xref>). The PCC is considered to be the core functional node with a high basal metabolic rate (<xref rid="B53" ref-type="bibr">Raichle et al., 2001</xref>). The PCC is mainly engaged in both self-relevant and other-relevant processing and evaluating and processing mental states of others (<xref rid="B23" ref-type="bibr">Gusnard and Raichle, 2001</xref>; <xref rid="B58" ref-type="bibr">Schiller et al., 2009</xref>; <xref rid="B66" ref-type="bibr">Spreng et al., 2009</xref>; <xref rid="B36" ref-type="bibr">Kuzmanovic et al., 2012</xref>). The MPFC is linked to monitoring of the mental state of both oneself and others (<xref rid="B23" ref-type="bibr">Gusnard and Raichle, 2001</xref>; <xref rid="B57" ref-type="bibr">Schilbach et al., 2008</xref>). There is a large amount of literature indicating that abnormal DMN organization is related to social deficits in individuals with ASD (<xref rid="B41" ref-type="bibr">Lynch et al., 2013</xref>; <xref rid="B73" ref-type="bibr">Yerys et al., 2015</xref>; <xref rid="B74" ref-type="bibr">Ypma et al., 2016</xref>). Increased within-network connectivity between the PCC and the MPFC was commonly observed in childhood ASD, while no consistent evidence was found for DMN connectivity across a whole ASD cohort (<xref rid="B18" ref-type="bibr">Doyle-Thomas et al., 2015</xref>).</p>
      <p>In addition to the DMN and PCUN, the SN has achieved higher classification accuracy at 71.16%. The SN is identified as an intrinsic network that guides behaviors to internal and environmental stimuli (<xref rid="B60" ref-type="bibr">Seeley et al., 2007</xref>). The SN exhibited hyper connectivity in children with ASD (<xref rid="B70" ref-type="bibr">Uddin et al., 2013</xref>). The anterior insula (AI) and dorsal anterior cingulate cortex (dACC) serve as the two most notable hubs of the SN. The AI is linked to emotion processing and is hypo-activated in ASD cohorts when performing a series of social cognitive tasks (<xref rid="B16" ref-type="bibr">Di Martino et al., 2009</xref>). The dACC has showed reduced cognitive control over behavior in ASD (<xref rid="B4" ref-type="bibr">Agam et al., 2010</xref>). Restrictive and repetitive behaviors in ASD may be due to the dysfunction of the salience network, which atypically allocates attention to extraneous sensory stimuli rather than relevant social stimuli (<xref rid="B70" ref-type="bibr">Uddin et al., 2013</xref>). Our experiments on each individual BFN suggest that the dDMN, PCUN, and SN are highly different between ASD and NC, which is consistent with previous studies. These three most significant brain networks have the potential to be reliable biomarkers for the identification of ASD.</p>
      <p>To further validate that our proposed method can capture the interaction between different BFNs, we also considered the relationship between BFNs. A quantitative measure of the connectivity strength value was calculated between each pair of BFNs. The results of statistical analysis suggested that there were significant differences in three pairs of BFNs (at a <italic>p</italic>-value &lt; 0.05). The SN-dDMN and SN-LCEN pairs showed increased connectivity strength in ASD, and hypo-connectivity was observed in the PCUN-dDMN pair of ASD. The SN is thought to play a role in detecting and coordinating a response to salient interoceptive and exteroceptive stimuli, including modulating the DMN and CEN as necessary (<xref rid="B44" ref-type="bibr">Menon, 2011</xref>), while aberrant interactions between these networks may lead to various mental illnesses. The enhanced connectivity between the SN and DMN and between the SN and CEN in ASD compared to NC may suggest the aberrant function of the SN, resulting in abnormal saliency mapping of internal mental events and external stimuli. Our work is consistent with the evidence implicating SN dysfunction in psychopathology in ASD (<xref rid="B69" ref-type="bibr">Uddin, 2015</xref>; <xref rid="B12" ref-type="bibr">Burrows et al., 2017</xref>). Both the PCUN and dDMN include brain regions previously regarded as being part of the DMN (<xref rid="B10" ref-type="bibr">Broyd et al., 2009</xref>). The decreased connectivity within the DMN has also been found in previous literature (<xref rid="B7" ref-type="bibr">Assaf et al., 2010</xref>). Our findings support the under-connectivity hypnosis in autism proposed by <xref rid="B29" ref-type="bibr">Just et al. (2004)</xref>. Although no significant differences were found in other pairs of BFNs, the proposed MCSE-VGG is potentially able to capture the interactions among these BFNs, which take both inter- and intra-BFN information into consideration.</p>
      <p>Our work still has a few limitations. First, a separate validation dataset is unavailable. The dataset we used is a part of the ABIDE-I dataset, which contained the largest samples with the same scan parameters. However, ABIDE-I is a highly heterogeneous dataset in which the scanning parameters, especially TR and the total scan time of each site, are different from each other. This leads to difficulty in performing group-ICA and dual regression. <xref rid="B71" ref-type="bibr">Yan et al. (2019)</xref> developed an RNN framework for discriminating schizophrenia using multi-site fMRI data. However, in their study, the scan protocols were set up by the same experts across all sites, which overcomes the heterogeneity over multi-sites. Therefore, we evaluated our framework only in the NYU dataset and showed ten-fold cross-validation results. Data augmentation has been widely used in many other computer vision tasks, but it is not suitable for neuroimaging data. We do not think synthesized data and real data have the same distribution. Second, motion effects can mimic amplitude effects and may have an impact on the results of dual regression (<xref rid="B47" ref-type="bibr">Nickerson et al., 2017</xref>). Motion effects may still remain even though we performed motion correction in the preprocessing procedures. ICA-based denoising technology was proposed to derive reproducible group-level resting state network spatial maps (<xref rid="B50" ref-type="bibr">Pruim et al., 2015</xref>), which we will consider using in the preprocessing stage. Another limitation is that deep learning-based classification framework is lacking in interpretation but is important, especially in the medical field. To overcome this issue, we statistically analyzed the differences between each pair of BFNs between ASD and NC. In the future, we will pay more attention to developing a framework integrating both structural and functional MRI data to achieve better classification accuracy, which may provide us with more insights into ASD.</p>
    </sec>
    <sec id="S5">
      <title>Conclusion</title>
      <p>In conclusion, we proposed a novel framework to model the spatial patterns of BFNs and associations between BFNs, simultaneously. We demonstrated the effectiveness of the introduction of the SE module, which is useful for modeling large-scale brain networks. Aberrant inter-network connectivity was observed in ASD, which may be related to the disorder of brain function. Our work has great application potential in the discrimination of other mental illnesses, not just ASD.</p>
    </sec>
    <sec sec-type="data-availability" id="S6">
      <title>Data Availability Statement</title>
      <p>The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s.</p>
    </sec>
    <sec id="S7">
      <title>Author Contributions</title>
      <p>MY and MC had equal contributions in data preparation, data analysis, and preparing the first draft of the manuscript. YuC and YaC interpreted the data and proofread the manuscript. GF and CL put forward some useful suggestions for the project. JW and TL conceptualized, directed the overall project, and prepared the final version. All authors contributed to the article and approved the submitted version.</p>
    </sec>
    <sec sec-type="COI-statement" id="conf1">
      <title>Conflict of Interest</title>
      <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </sec>
  </body>
  <back>
    <fn-group>
      <fn fn-type="financial-disclosure">
        <p><bold>Funding.</bold> This work has been supported by the National Natural Science Foundation of China (Grant 61503295); the Natural Science Foundation of Shaanxi Province (Grant 2018JM7080); China Postdoctoral Science Foundation (Grant No. 2018M643672); and Fundamental Research Funds for the Central Universities (Grant No. xjh012019049).</p>
      </fn>
    </fn-group>
    <fn-group>
      <fn id="footnote1">
        <label>1</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MELODIC">http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MELODIC</ext-link>
        </p>
      </fn>
      <fn id="footnote2">
        <label>2</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets</ext-link>
        </p>
      </fn>
      <fn id="footnote3">
        <label>3</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="http://findlab.stanford.edu/research">http://findlab.stanford.edu/research</ext-link>
        </p>
      </fn>
      <fn id="footnote4">
        <label>4</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/DualRegression">http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/DualRegression</ext-link>
        </p>
      </fn>
      <fn id="footnote5">
        <label>5</label>
        <p>
          <ext-link ext-link-type="uri" xlink:href="http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets">http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets</ext-link>
        </p>
      </fn>
    </fn-group>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdi</surname><given-names>H.</given-names></name><name><surname>Williams</surname><given-names>L. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Principal component analysis.</article-title>
<source><italic>WIREs Comput. Stat.</italic></source>
<volume>2</volume>
<fpage>433</fpage>–<lpage>459</lpage>. <pub-id pub-id-type="doi">10.1002/wics.101</pub-id></mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abou-Elseoud</surname><given-names>A.</given-names></name><name><surname>Starck</surname><given-names>T.</given-names></name><name><surname>Remes</surname><given-names>J.</given-names></name><name><surname>Nikkinen</surname><given-names>J.</given-names></name><name><surname>Tervonen</surname><given-names>O.</given-names></name><name><surname>Kiviniemi</surname><given-names>V.</given-names></name></person-group> (<year>2010</year>). <article-title>The effect of model order selection in group PICA.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>31</volume>
<fpage>1207</fpage>–<lpage>1216</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20929</pub-id>
<pub-id pub-id-type="pmid">20063361</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A.</given-names></name><name><surname>Milham</surname><given-names>M. P.</given-names></name><name><surname>Di Martino</surname><given-names>A.</given-names></name><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>Samaras</surname><given-names>D.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Deriving reproducible biomarkers from multi-site resting-state data: an autism-based example.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>147</volume>
<fpage>736</fpage>–<lpage>745</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.045</pub-id>
<pub-id pub-id-type="pmid">27865923</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agam</surname><given-names>Y.</given-names></name><name><surname>Joseph</surname><given-names>R. M.</given-names></name><name><surname>Barton</surname><given-names>J. J. S.</given-names></name><name><surname>Manoach</surname><given-names>D. S.</given-names></name></person-group> (<year>2010</year>). <article-title>Reduced cognitive control of response inhibition by the anterior cingulate cortex in autism spectrum disorders.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>52</volume>
<fpage>336</fpage>–<lpage>347</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.04.010</pub-id>
<pub-id pub-id-type="pmid">20394829</pub-id></mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmed</surname><given-names>K.</given-names></name><name><surname>Torresani</surname><given-names>L.</given-names></name></person-group> (<year>2017</year>). <article-title>Connectivity learning in multi-branch networks.</article-title>
<source><italic>arXiv</italic> [Preprint]</source>
<comment>arXiv:1709.09582</comment>,</mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="book"><collab>American Psychiatric Association</collab> (<year>2013</year>). <source><italic>Diagnostic and Statistical Manual of Mental Disorders (DSM-5<sup>®</sup>).</italic></source>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychiatric Pub</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Assaf</surname><given-names>M.</given-names></name><name><surname>Jagannathan</surname><given-names>K.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Miller</surname><given-names>L.</given-names></name><name><surname>Stevens</surname><given-names>M. C.</given-names></name><name><surname>Sahl</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>Abnormal functional connectivity of default mode sub-networks in autism spectrum disorder patients.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>53</volume>
<fpage>247</fpage>–<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.05.067</pub-id>
<pub-id pub-id-type="pmid">20621638</pub-id></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Mackay</surname><given-names>C. E.</given-names></name><name><surname>Filippini</surname><given-names>N.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2009</year>). <article-title>Group comparison of resting-state FMRI data using multi-subject ICA and dual regression.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>47</volume>
<fpage>S39</fpage>–<lpage>S41</lpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(09)71511-3</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengs</surname><given-names>M.</given-names></name><name><surname>Gessert</surname><given-names>N.</given-names></name><name><surname>Schlaefer</surname><given-names>A.</given-names></name></person-group> (<year>2020</year>). <article-title>4D spatio-temporal deep learning with 4d fmri data for autism spectrum disorder classification.</article-title>
<source><italic>arXiv</italic> [Preprint]</source>
<comment>arXiv:2004.10165</comment>,</mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broyd</surname><given-names>S. J.</given-names></name><name><surname>Demanuele</surname><given-names>C.</given-names></name><name><surname>Debener</surname><given-names>S.</given-names></name><name><surname>Helps</surname><given-names>S. K.</given-names></name><name><surname>James</surname><given-names>C. J.</given-names></name><name><surname>Sonuga-Barke</surname><given-names>E. J. S.</given-names></name></person-group> (<year>2009</year>). <article-title>Default-mode brain dysfunction in mental disorders: a systematic review.</article-title>
<source><italic>Neurosci. Biobehav. Rev.</italic></source>
<volume>33</volume>
<fpage>279</fpage>–<lpage>296</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2008.09.002</pub-id>
<pub-id pub-id-type="pmid">18824195</pub-id></mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>R. L.</given-names></name><name><surname>Andrews-Hanna</surname><given-names>J. R.</given-names></name><name><surname>Schacter</surname><given-names>D. L.</given-names></name></person-group> (<year>2008</year>). “<article-title>The brain’s default network: anatomy, function, and relevance to disease</article-title>,” in <source><italic>The Year in Cognitive Neuroscience 2008. Annals of the New York Academy of Sciences</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Kingstone</surname><given-names>A.</given-names></name><name><surname>Miller</surname><given-names>M. B.</given-names></name></person-group> (<publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>Blackwell Publishing</publisher-name>), <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burrows</surname><given-names>C. A.</given-names></name><name><surname>Timpano</surname><given-names>K. R.</given-names></name><name><surname>Uddin</surname><given-names>L. Q.</given-names></name></person-group> (<year>2017</year>). <article-title>Putative brain networks underlying repetitive negative thinking and comorbid internalizing problems in autism.</article-title>
<source><italic>Clin. Psychol. Sci.</italic></source>
<volume>5</volume>
<fpage>522</fpage>–<lpage>536</lpage>. <pub-id pub-id-type="doi">10.1177/2167702616683506</pub-id>
<pub-id pub-id-type="pmid">28603665</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C.</given-names></name><name><surname>Vapnik</surname><given-names>V.</given-names></name></person-group> (<year>1995</year>). <article-title>Support-vector networks.</article-title>
<source><italic>Mach. Learn.</italic></source>
<volume>20</volume>
<fpage>273</fpage>–<lpage>297</lpage>. <pub-id pub-id-type="doi">10.1007/BF00994018</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craddock</surname><given-names>C.</given-names></name><name><surname>Sikka</surname><given-names>S.</given-names></name><name><surname>Cheung</surname><given-names>B.</given-names></name><name><surname>Khanuja</surname><given-names>R.</given-names></name><name><surname>Ghosh</surname><given-names>S. S.</given-names></name><name><surname>Yan</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Towards automated analysis of connectomes: the configurable pipeline for the analysis of connectomes (c-pac).</article-title>
<source><italic>Front. Neuroinform.</italic></source>
<volume>42</volume>:<issue>10.3389</issue>. <pub-id pub-id-type="doi">10.3389/conf.fninf.2014.08.00117</pub-id></mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Damoiseaux</surname><given-names>J. S.</given-names></name><name><surname>Rombouts</surname><given-names>S. A. R. B.</given-names></name><name><surname>Barkhof</surname><given-names>F.</given-names></name><name><surname>Scheltens</surname><given-names>P.</given-names></name><name><surname>Stam</surname><given-names>C. J.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><etal/></person-group> (<year>2006</year>). <article-title>Consistent resting-state networks across healthy subjects.</article-title>
<source><italic>Proc. Natl. Acad. Sci. U.S.A.</italic></source>
<volume>103</volume>
<fpage>13848</fpage>–<lpage>13853</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0601417103</pub-id>
<pub-id pub-id-type="pmid">16945915</pub-id></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>A.</given-names></name><name><surname>Ross</surname><given-names>K.</given-names></name><name><surname>Uddin</surname><given-names>L. Q.</given-names></name><name><surname>Sklar</surname><given-names>A. B.</given-names></name><name><surname>Castellanos</surname><given-names>F. X.</given-names></name><name><surname>Milham</surname><given-names>M. P.</given-names></name></person-group> (<year>2009</year>). <article-title>Functional brain correlates of social and nonsocial processes in autism spectrum disorders: an activation likelihood estimation meta-analysis.</article-title>
<source><italic>Biol. Psychiatry</italic></source>
<volume>65</volume>
<fpage>63</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2008.09.022</pub-id>
<pub-id pub-id-type="pmid">18996505</pub-id></mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Di Martino</surname><given-names>A.</given-names></name><name><surname>Yan</surname><given-names>C.-G.</given-names></name><name><surname>Li</surname><given-names>Q.</given-names></name><name><surname>Denio</surname><given-names>E.</given-names></name><name><surname>Castellanos</surname><given-names>F. X.</given-names></name><name><surname>Alaerts</surname><given-names>K.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism.</article-title>
<source><italic>Mol. Psychiatry</italic></source>
<volume>19</volume>
<fpage>659</fpage>–<lpage>667</lpage>. <pub-id pub-id-type="doi">10.1038/mp.2013.78</pub-id>
<pub-id pub-id-type="pmid">23774715</pub-id></mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doyle-Thomas</surname><given-names>K. A. R.</given-names></name><name><surname>Lee</surname><given-names>W.</given-names></name><name><surname>Foster</surname><given-names>N. E. V.</given-names></name><name><surname>Tryfon</surname><given-names>A.</given-names></name><name><surname>Ouimet</surname><given-names>T.</given-names></name><name><surname>Hyde</surname><given-names>K. L.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Atypical functional brain connectivity during rest in autism spectrum disorders.</article-title>
<source><italic>Ann. Neurol.</italic></source>
<volume>77</volume>
<fpage>866</fpage>–<lpage>876</lpage>. <pub-id pub-id-type="doi">10.1002/ana.24391</pub-id>
<pub-id pub-id-type="pmid">25707715</pub-id></mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duc</surname><given-names>N. T.</given-names></name><name><surname>Ryu</surname><given-names>S.</given-names></name><name><surname>Qureshi</surname><given-names>M. N. I.</given-names></name><name><surname>Choi</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>K. H.</given-names></name><name><surname>Lee</surname><given-names>B.</given-names></name></person-group> (<year>2020</year>). <article-title>3D-deep learning based automatic diagnosis of Alzheimer’s disease with joint MMSE prediction using resting-state fMRI.</article-title>
<source><italic>Neuroinformatics</italic></source>
<volume>18</volume>
<fpage>71</fpage>–<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1007/s12021-019-09419-w</pub-id>
<pub-id pub-id-type="pmid">31093956</pub-id></mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dvornek</surname><given-names>N. C.</given-names></name><name><surname>Ventola</surname><given-names>P.</given-names></name><name><surname>Pelphrey</surname><given-names>K. A.</given-names></name><name><surname>Duncan</surname><given-names>J. S.</given-names></name></person-group> (<year>2017</year>). “<article-title>Identifying Autism from Resting-State fMRI Using Long Short-Term Memory Networks BT–Machine Learning in Medical Imaging</article-title>,” in <source><italic>International Workshop on Machine Learning in Medical Imaging</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Shi</surname><given-names>Y.</given-names></name><name><surname>Suk</surname><given-names>H.-I.</given-names></name><name><surname>Suzuki</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>362</fpage>–<lpage>370</lpage>.</mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filippini</surname><given-names>N.</given-names></name><name><surname>MacIntosh</surname><given-names>B. J.</given-names></name><name><surname>Hough</surname><given-names>M. G.</given-names></name><name><surname>Goodwin</surname><given-names>G. M.</given-names></name><name><surname>Frisoni</surname><given-names>G. B.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><etal/></person-group> (<year>2009</year>). <article-title>Distinct patterns of brain activity in young carriers of the APOE-ε4 allele.</article-title>
<source><italic>Proc. Natl. Acad. Sci. U.S.A.</italic></source>
<volume>106</volume>
<fpage>7209</fpage>–<lpage>7214</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0811879106</pub-id>
<pub-id pub-id-type="pmid">19357304</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldani</surname><given-names>A. A. S.</given-names></name><name><surname>Downs</surname><given-names>S. R.</given-names></name><name><surname>Widjaja</surname><given-names>F.</given-names></name><name><surname>Lawton</surname><given-names>B.</given-names></name><name><surname>Hendren</surname><given-names>R. L.</given-names></name></person-group> (<year>2014</year>). <article-title>Biomarkers in autism.</article-title>
<source><italic>Front. Psychiatry</italic></source>
<volume>5</volume>:<issue>100</issue>. <pub-id pub-id-type="doi">10.3389/fpsyt.2014.00100</pub-id>
<pub-id pub-id-type="pmid">25161627</pub-id></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gusnard</surname><given-names>D. A.</given-names></name><name><surname>Raichle</surname><given-names>M. E.</given-names></name></person-group> (<year>2001</year>). <article-title>Searching for a baseline: functional imaging and the resting human brain.</article-title>
<source><italic>Nat. Rev. Neurosci.</italic></source>
<volume>2</volume>
<fpage>685</fpage>–<lpage>694</lpage>. <pub-id pub-id-type="doi">10.1038/35094500</pub-id>
<pub-id pub-id-type="pmid">11584306</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). “<article-title>Delving deep into rectifiers: surpassing human-level performance on imagenet classification</article-title>,” in <source><italic>Proceedings of the IEEE International Conference on Computer Vision</italic></source>, <publisher-loc>Santiago, Chile</publisher-loc>, <fpage>1026</fpage>–<lpage>1034</lpage>.</mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinsfeld</surname><given-names>A. S.</given-names></name><name><surname>Franco</surname><given-names>A. R.</given-names></name><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>Buchweitz</surname><given-names>A.</given-names></name><name><surname>Meneguzzi</surname><given-names>F.</given-names></name></person-group> (<year>2018</year>). <article-title>Identification of autism spectrum disorder using deep learning and the ABIDE dataset.</article-title>
<source><italic>Neuroimage Clin.</italic></source>
<volume>17</volume>
<fpage>16</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2017.08.017</pub-id>
<pub-id pub-id-type="pmid">29034163</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Shen</surname><given-names>L.</given-names></name><name><surname>Sun</surname><given-names>G.</given-names></name></person-group> (<year>2018</year>). “<article-title>Squeeze-and-excitation networks</article-title>,” in <source><italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic></source>, <publisher-loc>Salt Lake City, UT</publisher-loc>, <fpage>7132</fpage>–<lpage>7141</lpage>.</mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ioffe</surname><given-names>S.</given-names></name><name><surname>Szegedy</surname><given-names>C.</given-names></name></person-group> (<year>2015</year>). “<article-title>Batch Normalization: accelerating Deep Network Training by Reducing Internal Covariate Shift</article-title>,” in <source><italic>Proceedings of the International Conference on Machine Learning</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Bach</surname><given-names>F.</given-names></name><name><surname>Blei</surname><given-names>D.</given-names></name></person-group> (<publisher-loc>Lille</publisher-loc>: <publisher-name>PMLR</publisher-name>), <fpage>448</fpage>–<lpage>456</lpage>.</mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Isensee</surname><given-names>F.</given-names></name><name><surname>Kickingereder</surname><given-names>P.</given-names></name><name><surname>Wick</surname><given-names>W.</given-names></name><name><surname>Bendszus</surname><given-names>M.</given-names></name><name><surname>Maier-Hein</surname><given-names>K. H.</given-names></name></person-group> (<year>2018</year>). “<article-title>Brain tumor segmentation and radiomics survival prediction: contribution to the BRATS 2017 Challenge</article-title>,” in <source><italic>International MICCAI Brainlesion Workshop</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Crimi</surname><given-names>A.</given-names></name><name><surname>Bakas</surname><given-names>S.</given-names></name><name><surname>Kuijf</surname><given-names>H.</given-names></name><name><surname>Menze</surname><given-names>B.</given-names></name><name><surname>Reyes</surname><given-names>M.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>287</fpage>–<lpage>297</lpage>.</mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Just</surname><given-names>M. A.</given-names></name><name><surname>Cherkassky</surname><given-names>V. L.</given-names></name><name><surname>Keller</surname><given-names>T. A.</given-names></name><name><surname>Minshew</surname><given-names>N. J.</given-names></name></person-group> (<year>2004</year>). <article-title>Cortical activation and synchronization during sentence comprehension in high-functioning autism: evidence of underconnectivity.</article-title>
<source><italic>Brain</italic></source>
<volume>127</volume>
<fpage>1811</fpage>–<lpage>1821</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awh199</pub-id>
<pub-id pub-id-type="pmid">15215213</pub-id></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kam</surname><given-names>T.-E.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). “<article-title>A Novel Deep Learning Framework on Brain Functional Networks for Early MCI Diagnosis</article-title>,” in <source><italic>Medical Image Computing and Computer Assisted Intervention–MICCAI 2018</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Frangi</surname><given-names>A. F.</given-names></name><name><surname>Schnabel</surname><given-names>J. A.</given-names></name><name><surname>Davatzikos</surname><given-names>C.</given-names></name><name><surname>Alberola-López</surname><given-names>C.</given-names></name><name><surname>Fichtinger</surname><given-names>G.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>293</fpage>–<lpage>301</lpage>.</mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Shim</surname><given-names>E.</given-names></name><name><surname>Lee</surname><given-names>J.-H.</given-names></name></person-group> (<year>2016</year>). <article-title>Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: evidence from whole-brain resting-state functional connectivity patterns of schizophrenia.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>124</volume>
<fpage>127</fpage>–<lpage>146</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.05.018</pub-id>
<pub-id pub-id-type="pmid">25987366</pub-id></mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D. P.</given-names></name><name><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>Adam: a method for stochastic optimization.</article-title>
<source><italic>arXiv</italic> [Preprint]</source>
<comment>arXiv:1412.6980</comment>,</mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Orban</surname><given-names>C.</given-names></name><name><surname>Sabuncu</surname><given-names>M. R.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Schaefer</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Spatial topography of individual-specific cortical networks predicts human cognition, personality, and emotion.</article-title>
<source><italic>Cereb. Cortex</italic></source>
<volume>29</volume>
<fpage>2533</fpage>–<lpage>2551</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhy123</pub-id>
<pub-id pub-id-type="pmid">29878084</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group> (<year>2017</year>). <article-title>ImageNet classification with deep convolutional neural networks.</article-title>
<source><italic>Commun. ACM</italic></source>
<volume>60</volume>
<fpage>84</fpage>–<lpage>90</lpage>. <pub-id pub-id-type="doi">10.1145/3065386</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ktena</surname><given-names>S. I.</given-names></name><name><surname>Parisot</surname><given-names>S.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Rajchl</surname><given-names>M.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Glocker</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Distance metric learning using graph convolutional networks: Application to functional brain networks</article-title>,” in <source><italic>International Conference on Medical Image Computing and Computer-Assisted Intervention</italic></source>. <publisher-loc>Cham</publisher-loc>: <publisher-name>Springer</publisher-name>, <fpage>469</fpage>–<lpage>477</lpage>.</mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuzmanovic</surname><given-names>B.</given-names></name><name><surname>Bente</surname><given-names>G.</given-names></name><name><surname>von Cramon</surname><given-names>D. Y.</given-names></name><name><surname>Schilbach</surname><given-names>L.</given-names></name><name><surname>Tittgemeyer</surname><given-names>M.</given-names></name><name><surname>Vogeley</surname><given-names>K.</given-names></name></person-group> (<year>2012</year>). <article-title>Imaging first impressions: distinct neural processing of verbal and nonverbal social information.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>60</volume>
<fpage>179</fpage>–<lpage>188</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.12.046</pub-id>
<pub-id pub-id-type="pmid">22227133</pub-id></mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2015</year>). <article-title>Deep learning.</article-title>
<source><italic>Nature</italic></source>
<volume>521</volume>
<fpage>436</fpage>–<lpage>444</lpage>. <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ledig</surname><given-names>C.</given-names></name><name><surname>Theis</surname><given-names>L.</given-names></name><name><surname>Huszár</surname><given-names>F.</given-names></name><name><surname>Caballero</surname><given-names>J.</given-names></name><name><surname>Cunningham</surname><given-names>A.</given-names></name><name><surname>Acosta</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Photo-realistic single image super-resolution using a generative adversarial network</article-title>,” in <source><italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic></source>, <publisher-loc>Hawaii</publisher-loc>, <fpage>4681</fpage>–<lpage>4690</lpage>.</mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liaw</surname><given-names>A.</given-names></name><name><surname>Wiener</surname><given-names>M.</given-names></name></person-group> (<year>2002</year>). <article-title>Classification and regression by randomForest.</article-title>
<source><italic>R News</italic></source>
<volume>2</volume>
<fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindquist</surname><given-names>M. A.</given-names></name></person-group> (<year>2008</year>). <article-title>The statistical analysis of fMRI data.</article-title>
<source><italic>Stat. Sci.</italic></source>
<volume>23</volume>
<fpage>439</fpage>–<lpage>464</lpage>. <pub-id pub-id-type="doi">10.1214/09-STS282</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lynch</surname><given-names>C. J.</given-names></name><name><surname>Uddin</surname><given-names>L. Q.</given-names></name><name><surname>Supekar</surname><given-names>K.</given-names></name><name><surname>Khouzam</surname><given-names>A.</given-names></name><name><surname>Phillips</surname><given-names>J.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name></person-group> (<year>2013</year>). <article-title>Default mode network in childhood autism: posteromedial cortex heterogeneity and relationship with social deficits.</article-title>
<source><italic>Biol. Psychiatry</italic></source>
<volume>74</volume>
<fpage>212</fpage>–<lpage>219</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2012.12.013</pub-id>
<pub-id pub-id-type="pmid">23375976</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Maas</surname><given-names>A. L.</given-names></name><name><surname>Hannun</surname><given-names>A. Y.</given-names></name><name><surname>Ng</surname><given-names>A. Y.</given-names></name></person-group> (<year>2013</year>). “<article-title>Rectifier nonlinearities improve neural network acoustic models</article-title>,” in <source><italic>Proceedings of the International Conference on Machine Learning (ICML)</italic></source>, (<publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Citeseer</publisher-name>), <fpage>3</fpage>.</mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mars</surname><given-names>R.</given-names></name><name><surname>Neubert</surname><given-names>F.-X.</given-names></name><name><surname>Noonan</surname><given-names>M.</given-names></name><name><surname>Sallet</surname><given-names>J.</given-names></name><name><surname>Toni</surname><given-names>I.</given-names></name><name><surname>Rushworth</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>On the relationship between the “default mode network” and the “social brain.”.</article-title>
<source><italic>Front. Hum. Neurosci.</italic></source>
<volume>6</volume>:<issue>189</issue>. <pub-id pub-id-type="doi">10.3389/fnhum.2012.00189</pub-id>
<pub-id pub-id-type="pmid">22737119</pub-id></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menon</surname><given-names>V.</given-names></name></person-group> (<year>2011</year>). <article-title>Large-scale brain networks and psychopathology: a unifying triple network model.</article-title>
<source><italic>Trends Cogn. Sci.</italic></source>
<volume>15</volume>
<fpage>483</fpage>–<lpage>506</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2011.08.003</pub-id>
<pub-id pub-id-type="pmid">21908230</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mueller</surname><given-names>S.</given-names></name><name><surname>Keeser</surname><given-names>D.</given-names></name><name><surname>Samson</surname><given-names>A. C.</given-names></name><name><surname>Kirsch</surname><given-names>V.</given-names></name><name><surname>Blautzik</surname><given-names>J.</given-names></name><name><surname>Grothe</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Convergent findings of altered functional and structural brain connectivity in individuals with high functioning autism: a multimodal MRI study.</article-title>
<source><italic>PLoS One</italic></source>
<volume>8</volume>:<issue>e67329</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0067329</pub-id>
<pub-id pub-id-type="pmid">23825652</pub-id></mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nair</surname><given-names>V.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group> (<year>2010</year>). “<article-title>Rectified linear units improve restricted boltzmann machines</article-title>,” in <source><italic>Proceedings of the 27th International Conference on International Conference on Machine Learning Icml</italic></source>, <publisher-loc>Haifa</publisher-loc>.</mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nickerson</surname><given-names>L. D.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Öngür</surname><given-names>D.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name></person-group> (<year>2017</year>). <article-title>Using dual regression to investigate network shape and amplitude in functional connectivity analyses.</article-title>
<source><italic>Front. Neurosci.</italic></source>
<volume>11</volume>:<issue>115</issue>. <pub-id pub-id-type="doi">10.3389/fnins.2017.00115</pub-id>
<pub-id pub-id-type="pmid">28348512</pub-id></mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Padmanabhan</surname><given-names>A.</given-names></name><name><surname>Lynch</surname><given-names>C. J.</given-names></name><name><surname>Schaer</surname><given-names>M.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name></person-group> (<year>2017</year>). <article-title>The default mode network in autism.</article-title>
<source><italic>Biol. Psychiatry Cogn. Neurosci. Neuroimaging</italic></source>
<volume>2</volume>
<fpage>476</fpage>–<lpage>486</lpage>. <pub-id pub-id-type="doi">10.1016/j.bpsc.2017.04.004</pub-id>
<pub-id pub-id-type="pmid">29034353</pub-id></mixed-citation>
      </ref>
      <ref id="B49">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Massa</surname><given-names>F.</given-names></name><name><surname>Lerer</surname><given-names>A.</given-names></name><name><surname>Bradbury</surname><given-names>J.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Pytorch: an imperative style, high-performance deep learning library.</article-title>
<source><italic>arXiv</italic> [Preprint]</source>
<comment>arXiv:1912.01703</comment>,</mixed-citation>
      </ref>
      <ref id="B50">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruim</surname><given-names>R. H. R.</given-names></name><name><surname>Mennes</surname><given-names>M.</given-names></name><name><surname>Buitelaar</surname><given-names>J. K.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name></person-group> (<year>2015</year>). <article-title>Evaluation of ICA-AROMA and alternative strategies for motion artifact removal in resting state fMRI.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>112</volume>
<fpage>278</fpage>–<lpage>287</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.02.063</pub-id>
<pub-id pub-id-type="pmid">25770990</pub-id></mixed-citation>
      </ref>
      <ref id="B51">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qureshi</surname><given-names>M. N. I.</given-names></name><name><surname>Oh</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>B.</given-names></name></person-group> (<year>2019a</year>). <article-title>3D-CNN based discrimination of schizophrenia using resting-state fMRI.</article-title>
<source><italic>Artif. Intell. Med.</italic></source>
<volume>98</volume>
<fpage>10</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1016/j.artmed.2019.06.003</pub-id>
<pub-id pub-id-type="pmid">31521248</pub-id></mixed-citation>
      </ref>
      <ref id="B52">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qureshi</surname><given-names>M. N. I.</given-names></name><name><surname>Ryu</surname><given-names>S.</given-names></name><name><surname>Song</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>K. H.</given-names></name><name><surname>Lee</surname><given-names>B.</given-names></name></person-group> (<year>2019b</year>). <article-title>Evaluation of functional decline in Alzheimer’s dementia using 3D deep learning and group ICA for rs-fMRI measurements.</article-title>
<source><italic>Front. Aging Neurosci.</italic></source>
<volume>11</volume>:<issue>8</issue>. <pub-id pub-id-type="doi">10.3389/fnagi.2019.00008</pub-id>
<pub-id pub-id-type="pmid">30804774</pub-id></mixed-citation>
      </ref>
      <ref id="B53">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>M. E.</given-names></name><name><surname>MacLeod</surname><given-names>A. M.</given-names></name><name><surname>Snyder</surname><given-names>A. Z.</given-names></name><name><surname>Powers</surname><given-names>W. J.</given-names></name><name><surname>Gusnard</surname><given-names>D. A.</given-names></name><name><surname>Shulman</surname><given-names>G. L.</given-names></name></person-group> (<year>2001</year>). <article-title>A default mode of brain function.</article-title>
<source><italic>Proc. Natl. Acad. Sci. U.S.A.</italic></source>
<volume>98</volume>
<fpage>676</fpage>–<lpage>682</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id>
<pub-id pub-id-type="pmid">11209064</pub-id></mixed-citation>
      </ref>
      <ref id="B54">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rajapakse</surname><given-names>J. C.</given-names></name><name><surname>Tan</surname><given-names>C. L.</given-names></name><name><surname>Zheng</surname><given-names>X.</given-names></name><name><surname>Mukhopadhyay</surname><given-names>S.</given-names></name><name><surname>Yang</surname><given-names>K.</given-names></name></person-group> (<year>2006</year>). <article-title>Exploratory analysis of brain connectivity with ICA.</article-title>
<source><italic>IEEE Eng. Med. Biol. Mag.</italic></source>
<volume>25</volume>
<fpage>102</fpage>–<lpage>111</lpage>. <pub-id pub-id-type="doi">10.1109/MEMB.2006.1607674</pub-id>
<pub-id pub-id-type="pmid">16568942</pub-id></mixed-citation>
      </ref>
      <ref id="B55">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Redmon</surname><given-names>J.</given-names></name><name><surname>Divvala</surname><given-names>S.</given-names></name><name><surname>Girshick</surname><given-names>R.</given-names></name><name><surname>Farhadi</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). “<article-title>You only look once: Unified, real-time object detection</article-title>,” in <source><italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic></source>, <publisher-loc>Las Vegas, NV</publisher-loc>, <fpage>779</fpage>–<lpage>788</lpage>.</mixed-citation>
      </ref>
      <ref id="B56">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rish</surname><given-names>I.</given-names></name></person-group> (<year>2001</year>). “<article-title>An empirical study of the naive Bayes classifier</article-title>,” in <source><italic>Proceedings of the IJCAI 2001 Workshop on Empirical Methods in Artificial Intelligence</italic></source>, (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>IBM</publisher-name>), <fpage>41</fpage>–<lpage>46</lpage>.</mixed-citation>
      </ref>
      <ref id="B57">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schilbach</surname><given-names>L.</given-names></name><name><surname>Eickhoff</surname><given-names>S. B.</given-names></name><name><surname>Rotarska-Jagiela</surname><given-names>A.</given-names></name><name><surname>Fink</surname><given-names>G. R.</given-names></name><name><surname>Vogeley</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Minds at rest? Social cognition as the default mode of cognizing and its putative relationship to the “default system” of the brain.</article-title>
<source><italic>Conscious. Cogn.</italic></source>
<volume>17</volume>
<fpage>457</fpage>–<lpage>467</lpage>. <pub-id pub-id-type="doi">10.1016/j.concog.2008.03.013</pub-id>
<pub-id pub-id-type="pmid">18434197</pub-id></mixed-citation>
      </ref>
      <ref id="B58">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiller</surname><given-names>D.</given-names></name><name><surname>Freeman</surname><given-names>J. B.</given-names></name><name><surname>Mitchell</surname><given-names>J. P.</given-names></name><name><surname>Uleman</surname><given-names>J. S.</given-names></name><name><surname>Phelps</surname><given-names>E. A.</given-names></name></person-group> (<year>2009</year>). <article-title>A neural mechanism of first impressions.</article-title>
<source><italic>Nat. Neurosci.</italic></source>
<volume>12</volume>:<issue>508</issue>. <pub-id pub-id-type="doi">10.1038/nn.2278</pub-id>
<pub-id pub-id-type="pmid">19270690</pub-id></mixed-citation>
      </ref>
      <ref id="B59">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlemper</surname><given-names>J.</given-names></name><name><surname>Caballero</surname><given-names>J.</given-names></name><name><surname>Hajnal</surname><given-names>J. V.</given-names></name><name><surname>Price</surname><given-names>A. N.</given-names></name><name><surname>Rueckert</surname><given-names>D.</given-names></name></person-group> (<year>2018</year>). <article-title>A deep cascade of convolutional neural networks for dynamic MR image reconstruction.</article-title>
<source><italic>IEEE Trans. Med. Imaging</italic></source>
<volume>37</volume>
<fpage>491</fpage>–<lpage>503</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2017.2760978</pub-id>
<pub-id pub-id-type="pmid">29035212</pub-id></mixed-citation>
      </ref>
      <ref id="B60">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeley</surname><given-names>W. W.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name><name><surname>Schatzberg</surname><given-names>A. F.</given-names></name><name><surname>Keller</surname><given-names>J.</given-names></name><name><surname>Glover</surname><given-names>G. H.</given-names></name><name><surname>Kenna</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>Dissociable intrinsic connectivity networks for salience processing and executive control.</article-title>
<source><italic>J. Neurosci.</italic></source>
<volume>27</volume>
<fpage>2349</fpage>–<lpage>2356</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5587-06.2007</pub-id>
<pub-id pub-id-type="pmid">17329432</pub-id></mixed-citation>
      </ref>
      <ref id="B61">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirer</surname><given-names>W. R.</given-names></name><name><surname>Ryali</surname><given-names>S.</given-names></name><name><surname>Rykhlevskaia</surname><given-names>E.</given-names></name><name><surname>Menon</surname><given-names>V.</given-names></name><name><surname>Greicius</surname><given-names>M. D.</given-names></name></person-group> (<year>2012</year>). <article-title>Decoding subject-driven cognitive states with whole-brain connectivity patterns.</article-title>
<source><italic>Cereb. Cortex</italic></source>
<volume>22</volume>
<fpage>158</fpage>–<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr099</pub-id>
<pub-id pub-id-type="pmid">21616982</pub-id></mixed-citation>
      </ref>
      <ref id="B62">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shojaee</surname><given-names>A.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name><name><surname>Atluri</surname><given-names>G.</given-names></name></person-group> (<year>2019</year>). “<article-title>A machine learning framework for accurate functional connectome fingerprinting and an application of a siamese network</article-title>,” in <source><italic>International Workshop on Connectomics in Neuroimaging</italic></source>, <role>eds</role>
<person-group person-group-type="editor"><name><surname>Schirmer</surname><given-names>M. D.</given-names></name><name><surname>Venkataraman</surname><given-names>A.</given-names></name><name><surname>Rekik</surname><given-names>I.</given-names></name><name><surname>Kim</surname><given-names>M.</given-names></name><name><surname>Chung</surname><given-names>A. W.</given-names></name></person-group> (<publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>83</fpage>–<lpage>94</lpage>.</mixed-citation>
      </ref>
      <ref id="B63">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simonyan</surname><given-names>K.</given-names></name><name><surname>Zisserman</surname><given-names>A.</given-names></name></person-group> (<year>2014</year>). <article-title>Very deep convolutional networks for large-scale image recognition.</article-title>
<source><italic>arXiv</italic> [Preprint]</source>
<comment>arXiv:1409.1556</comment>,</mixed-citation>
      </ref>
      <ref id="B64">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Miller</surname><given-names>K. L.</given-names></name><name><surname>Salimi-Khorshidi</surname><given-names>G.</given-names></name><name><surname>Webster</surname><given-names>M.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Nichols</surname><given-names>T. E.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Network modelling methods for FMRI.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>54</volume>
<fpage>875</fpage>–<lpage>891</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.08.063</pub-id>
<pub-id pub-id-type="pmid">20817103</pub-id></mixed-citation>
      </ref>
      <ref id="B65">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soussia</surname><given-names>M.</given-names></name><name><surname>Rekik</surname><given-names>I.</given-names></name></person-group> (<year>2018</year>). <article-title>Unsupervised manifold learning using high-order morphological brain networks derived from T1-w MRI for autism diagnosis.</article-title>
<source><italic>Front. Neuroinform.</italic></source>
<volume>12</volume>:<issue>70</issue>. <pub-id pub-id-type="doi">10.3389/fninf.2018.00070</pub-id>
<pub-id pub-id-type="pmid">30459585</pub-id></mixed-citation>
      </ref>
      <ref id="B66">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname><given-names>R. N.</given-names></name><name><surname>Mar</surname><given-names>R. A.</given-names></name><name><surname>Kim</surname><given-names>A. S. N.</given-names></name></person-group> (<year>2009</year>). <article-title>The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: a quantitative meta-analysis.</article-title>
<source><italic>J. Cogn. Neurosci.</italic></source>
<volume>21</volume>
<fpage>489</fpage>–<lpage>510</lpage>. <pub-id pub-id-type="doi">10.1162/jocn.2008.21029</pub-id>
<pub-id pub-id-type="pmid">18510452</pub-id></mixed-citation>
      </ref>
      <ref id="B67">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suk</surname><given-names>H.-I.</given-names></name><name><surname>Lee</surname><given-names>S.-W.</given-names></name><name><surname>Shen</surname><given-names>D.</given-names></name><name><surname>Initiative</surname><given-names>T. A. D. N.</given-names></name></person-group> (<year>2015</year>). <article-title>Latent feature representation with stacked auto-encoder for AD/MCI diagnosis.</article-title>
<source><italic>Brain Struct. Funct.</italic></source>
<volume>220</volume>
<fpage>841</fpage>–<lpage>859</lpage>. <pub-id pub-id-type="doi">10.1007/s00429-013-0687-3</pub-id>
<pub-id pub-id-type="pmid">24363140</pub-id></mixed-citation>
      </ref>
      <ref id="B68">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>1996</year>). <article-title>Regression shrinkage and selection via the lasso.</article-title>
<source><italic>J. R. Stat. Soc. Ser. B</italic></source>
<volume>58</volume>
<fpage>267</fpage>–<lpage>288</lpage>. <pub-id pub-id-type="doi">10.1111/j.2517-6161.1996.tb02080.x</pub-id></mixed-citation>
      </ref>
      <ref id="B69">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname><given-names>L. Q.</given-names></name></person-group> (<year>2015</year>). <article-title>Salience processing and insular cortical function and dysfunction.</article-title>
<source><italic>Nat. Rev. Neurosci.</italic></source>
<volume>16</volume>
<fpage>55</fpage>–<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1038/nrn3857</pub-id>
<pub-id pub-id-type="pmid">25406711</pub-id></mixed-citation>
      </ref>
      <ref id="B70">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname><given-names>L. Q.</given-names></name><name><surname>Supekar</surname><given-names>K.</given-names></name><name><surname>Lynch</surname><given-names>C. J.</given-names></name><name><surname>Khouzam</surname><given-names>A.</given-names></name><name><surname>Phillips</surname><given-names>J.</given-names></name><name><surname>Feinstein</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Salience network–based classification and prediction of symptom severity in children with autism.</article-title>
<source><italic>JAMA Psychiatry</italic></source>
<volume>70</volume>
<fpage>869</fpage>–<lpage>879</lpage>. <pub-id pub-id-type="doi">10.1001/jamapsychiatry.2013.104</pub-id>
<pub-id pub-id-type="pmid">23803651</pub-id></mixed-citation>
      </ref>
      <ref id="B71">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>W.</given-names></name><name><surname>Calhoun</surname><given-names>V.</given-names></name><name><surname>Song</surname><given-names>M.</given-names></name><name><surname>Cui</surname><given-names>Y.</given-names></name><name><surname>Yan</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Discriminating schizophrenia using recurrent neural network applied on time courses of multi-site FMRI data.</article-title>
<source><italic>EBioMedicine</italic></source>
<volume>47</volume>
<fpage>543</fpage>–<lpage>552</lpage>. <pub-id pub-id-type="doi">10.1016/j.ebiom.2019.08.023</pub-id>
<pub-id pub-id-type="pmid">31420302</pub-id></mixed-citation>
      </ref>
      <ref id="B72">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>X.</given-names></name><name><surname>Kwitt</surname><given-names>R.</given-names></name><name><surname>Styner</surname><given-names>M.</given-names></name><name><surname>Niethammer</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). <article-title>Quicksilver: fast predictive image registration–a deep learning approach.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>158</volume>
<fpage>378</fpage>–<lpage>396</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.07.008</pub-id>
<pub-id pub-id-type="pmid">28705497</pub-id></mixed-citation>
      </ref>
      <ref id="B73">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yerys</surname><given-names>B. E.</given-names></name><name><surname>Gordon</surname><given-names>E. M.</given-names></name><name><surname>Abrams</surname><given-names>D. N.</given-names></name><name><surname>Satterthwaite</surname><given-names>T. D.</given-names></name><name><surname>Weinblatt</surname><given-names>R.</given-names></name><name><surname>Jankowski</surname><given-names>K. F.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Default mode network segregation and social deficits in autism spectrum disorder: evidence from non-medicated children.</article-title>
<source><italic>Neuroimage Clin.</italic></source>
<volume>9</volume>
<fpage>223</fpage>–<lpage>232</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2015.07.018</pub-id>
<pub-id pub-id-type="pmid">26484047</pub-id></mixed-citation>
      </ref>
      <ref id="B74">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ypma</surname><given-names>R. J. F.</given-names></name><name><surname>Moseley</surname><given-names>R. L.</given-names></name><name><surname>Holt</surname><given-names>R. J.</given-names></name><name><surname>Rughooputh</surname><given-names>N.</given-names></name><name><surname>Floris</surname><given-names>D. L.</given-names></name><name><surname>Chura</surname><given-names>L. R.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Default mode hypoconnectivity underlies a sex-related autism spectrum.</article-title>
<source><italic>Biol. Psychiatry Cogn. Neurosci. Neuroimaging</italic></source>
<volume>1</volume>
<fpage>364</fpage>–<lpage>371</lpage>. <pub-id pub-id-type="doi">10.1016/j.bpsc.2016.04.006</pub-id>
<pub-id pub-id-type="pmid">27430030</pub-id></mixed-citation>
      </ref>
      <ref id="B75">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>T.</given-names></name><name><surname>Qi</surname><given-names>G.-J.</given-names></name><name><surname>Xiao</surname><given-names>B.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>). “<article-title>Interleaved group convolutions</article-title>,” in <source><italic>Proceedings of the IEEE International Conference on Computer Vision</italic></source>, <publisher-loc>Venice</publisher-loc>, <fpage>4373</fpage>–<lpage>4382</lpage>.</mixed-citation>
      </ref>
      <ref id="B76">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Lin</surname><given-names>M.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2018</year>). “<article-title>Shufflenet: An extremely efficient convolutional neural network for mobile devices</article-title>,” in <source><italic>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic></source>, <publisher-loc>Salt Lake City, UT</publisher-loc>, <fpage>6848</fpage>–<lpage>6856</lpage>.</mixed-citation>
      </ref>
      <ref id="B77">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>H.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). <article-title>Regularization and variable selection via the elastic net.</article-title>
<source><italic>J. R. Stat. Soc. Ser. B</italic></source>
<volume>67</volume>
<fpage>301</fpage>–<lpage>320</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
