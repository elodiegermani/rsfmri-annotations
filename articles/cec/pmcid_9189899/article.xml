<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <?properties manuscript?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-journal-id">9215515</journal-id>
      <journal-id journal-id-type="pubmed-jr-id">20498</journal-id>
      <journal-id journal-id-type="nlm-ta">Neuroimage</journal-id>
      <journal-id journal-id-type="iso-abbrev">Neuroimage</journal-id>
      <journal-title-group>
        <journal-title>NeuroImage</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1053-8119</issn>
      <issn pub-type="epub">1095-9572</issn>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">35460918</article-id>
      <article-id pub-id-type="pmc">9189899</article-id>
      <article-id pub-id-type="doi">10.1016/j.neuroimage.2022.119229</article-id>
      <article-id pub-id-type="manuscript">NIHMS1812866</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Covariance shrinkage can assess and improve functional connectomes</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Honnorat</surname>
            <given-names>Nicolas</given-names>
          </name>
          <xref rid="CR1" ref-type="corresp">*</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Habes</surname>
            <given-names>Mohamad</given-names>
          </name>
        </contrib>
        <aff id="A1">Neuroimage Analytics Laboratory and Biggs Institute Neuroimaging Core, Glenn Biggs Institute for Neurodegenerative Disorders, University of Texas Health Science Center at San Antonio, San Antonio, Texas, USA</aff>
      </contrib-group>
      <author-notes>
        <corresp id="CR1"><label>*</label>Corresponding author. <email>honnorat@uthscsa.edu</email> (N. Honnorat).</corresp>
      </author-notes>
      <pub-date pub-type="nihms-submitted">
        <day>7</day>
        <month>6</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <day>01</day>
        <month>8</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>20</day>
        <month>4</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="pmc-release">
        <day>01</day>
        <month>8</month>
        <year>2022</year>
      </pub-date>
      <volume>256</volume>
      <fpage>119229</fpage>
      <lpage>119229</lpage>
      <permissions>
        <license>
          <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
          <license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>)</license-p>
        </license>
      </permissions>
      <abstract id="ABS1">
        <p id="P1">Connectomes derived from resting-state functional MRI scans have significantly benefited from the development of dedicated fMRI motion correction and denoising algorithms. But they are based on empirical correlations that can produce unreliable results in high dimension low sample size settings. A family of statistical estimators, the covariance shrinkage methods, could mitigate this issue. Unfortunately, these methods have rarely been used to correct functional connectomes and no extensive experiment has been conducted so far to compare the shrinkage methods available for this task. In this work, we propose to fix this issue by processing a benchmark dataset made of a thousand high-resolution resting-state fMRI scans provided by the Human Connectome Project to compare the ability of five prominent covariance shrinkage methods to produce reliable functional connectomes at different spatial resolutions and scans duration: the pioneer linear covariance shrinkage method introduced by Ledoit and Wolf, the Oracle Approximating Shrinkage, the QuEST method, the NERCOME method, and a recent analytical approximation of the QuEST approach. Our experiments establish that all covariance shrinkage methods significantly improve functional connectomes derived from short fMRI scans. The Oracle Approximating Shrinkage and the QuEST method produced the best results. Lastly, we present shrinkage intensity charts that can be used for designing and analyzing fMRI studies. These charts indicate that sparse connectomes are difficult to estimate from short fMRI scans, and they describe a range of settings where dynamic functional connectivity should not be computed.</p>
      </abstract>
      <kwd-group>
        <kwd>Resting-state fmri</kwd>
        <kwd>Covariance shrinkage</kwd>
        <kwd>Dynamic connectivity</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="S1">
      <label>1.</label>
      <title>Introduction</title>
      <p id="P2">Resting-state functional MRI (rs-fMRI) offers a precious insight into brain function by measuring at the scale of the entire brain a Blood-Oxygen-Level-Dependent (BOLD) signal reflecting brain activity over long periods of rest (<xref rid="R17" ref-type="bibr">Fox and Raichle, 2007</xref>). Over the past three decades, multiple measures were proposed to estimate information transfers between brain regions from BOLD time series. To name a few, partial correlations were computed to estimate the effective brain connectivity obtained after removing indirect connections from BOLD signals correlations (<xref rid="R52" ref-type="bibr">Varoquaux et al., 2010</xref>), wavelet coherence was used to capture rs-fMRI synchronicity over different ranges of time frequencies (<xref rid="R8" ref-type="bibr">Chang and Glover, 2010</xref>), and causality was used to capture the amplitude and the direction of information transfers in the brain (<xref rid="R50" ref-type="bibr">Stokes and Purdon, 2017</xref>). The Pearson correlations between BOLD signals measured at different brain locations were among the first measures to be computed (<xref rid="R46" ref-type="bibr">Smith et al., 2011</xref>). These correlations are straightforward to estimate empirically from fMRI data, by calculating ratios of BOLD time series empirical covariances (<xref rid="R46" ref-type="bibr">Smith et al., 2011</xref>). In addition, they are easy to interpret and they rank among the most robust and reproducible functional connectivity measures (<xref rid="R46" ref-type="bibr">Smith et al., 2011</xref>). For these reasons, empirical Pearson correlations between BOLD time series have become the standard measure of functional connectivity. Their quality is crucial for subsequent analysis, such as the definition of binary connectomes and the extraction of graph-theoretical features (<xref rid="R7" ref-type="bibr">Bullmore and Sporns, 2009</xref>; <xref rid="R43" ref-type="bibr">Rubinov and Sporns, 2010</xref>).</p>
      <p id="P3">However, statisticians noted that empirical covariances and empirical Pearson correlations are not the best possible statistical estimators of the “real” covariances and Pearson correlations that would be measured if an infinite number of measurements were performed. When few measures are available to estimate many covariances or many correlations at the same time, their amplitude tends to be overestimated (<xref rid="R48" ref-type="bibr">Stein, 1975</xref>, <xref rid="R49" ref-type="bibr">1986</xref>). Unfortunately, this setting corresponds to most rs-fMRI scans: while a few hundred brain volumes are usually recorded during a rs-fMRI scan, the brain presents thousands of interesting locations where investigating functional connectivity would provide useful information about the evolution of brain disorders, healthy neurodevelopment, or brain aging.</p>
      <p id="P4">Several statistical procedures were proposed to correct empirical covariances. Because all these procedures have the effect of reducing the variability of covariances around their average, they were called <italic toggle="yes">covariance shrinkage methods</italic>. The first covariance shrinkage methods were proposed by Stein in the seventies (<xref rid="R48" ref-type="bibr">Stein, 1975</xref>, <xref rid="R49" ref-type="bibr">1986</xref>) and a large part of modern approaches rely on his pioneering approach (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>; <xref rid="R24" ref-type="bibr">Ledoit and Wolf, 2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>, <xref rid="R29" ref-type="bibr">2020</xref>; <xref rid="R44" ref-type="bibr">Schäfer and Strimmer, 2005</xref>). Unfortunately, this first approach suffers from severe practical implementation issues, despite the introduction of ad hoc fixes such as the isotonization procedure (<xref rid="R12" ref-type="bibr">Daniels and Kass, 2001</xref>; <xref rid="R25" ref-type="bibr">Ledoit and Wolf, 2004</xref>; <xref rid="R41" ref-type="bibr">Rajaratnam and Vincenzi, 2016</xref>). The linear covariance shrinkage methods emerged when new approaches were explored during the first decade of the new millennium to overcome these issues (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>; <xref rid="R24" ref-type="bibr">Ledoit and Wolf, 2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>; <xref rid="R44" ref-type="bibr">Schäfer and Strimmer, 2005</xref>). The first linear shrinkage method, proposed by <xref rid="R24" ref-type="bibr">Ledoit and Wolf (2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>), was first extended to use different shrinkage targets (<xref rid="R44" ref-type="bibr">Schäfer and Strimmer, 2005</xref>), and then further improved in the specific setting where covariances are calculated for random data following a Gaussian distribution (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>). All these linear shrinkage methods benefit from simple implementations and great computational efficiency (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>; <xref rid="R24" ref-type="bibr">Ledoit and Wolf, 2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>; <xref rid="R44" ref-type="bibr">Schäfer and Strimmer, 2005</xref>). In recent years, several non-linear covariance shrinkage methods were proposed with the hope that more subtle shrinkage schemes could produce better results (<xref rid="R1" ref-type="bibr">Abadir et al., 2014</xref>; <xref rid="R26" ref-type="bibr">Ledoit and Wolf, 2012</xref>) and, in particular, the NERCOME method that relies on the combination of covariance matrices estimated after random sample splits (<xref rid="R23" ref-type="bibr">Lam, 2016</xref>), the QuEST method based on the numerical inversion of a set of equations predicting empirical covariance matrix eigenvalues from their unbiased theoretical counterparts (<xref rid="R27" ref-type="bibr">Ledoit and Wolf, 2015</xref>) and a recent analytical approximation (<xref rid="R29" ref-type="bibr">Ledoit and Wolf, 2020</xref>). By adapting the shrinkage intensity to the amplitude of the covariance matrix eigenvalues, these more flexible methods can achieve better performances. But this advantage comes, for most methods, at the cost of a larger computational burden (<xref rid="R29" ref-type="bibr">Ledoit and Wolf, 2020</xref>).</p>
      <p id="P5">Linear shrinkage methods have been successfully used in the past to improve functional connectomes (<xref rid="R13" ref-type="bibr">Deligianni et al., 2014</xref>; <xref rid="R18" ref-type="bibr">Fritsch et al., 2012</xref>; <xref rid="R35" ref-type="bibr">Ng et al., 2011</xref>, <xref rid="R36" ref-type="bibr">2012</xref>, <xref rid="R37" ref-type="bibr">2013</xref>; <xref rid="R40" ref-type="bibr">Rahim et al., 2019</xref>), but nonlinear shrinkage methods have never been used in that setting, and no detailed comparison between shrinkage methods has been carried out so far. All the covariance shrinkage methods could potentially produce more accurate functional connectomes. However, while the linear shrinkage methods mentioned above are mathematically guaranteed to produce correlation matrices when applied to correlation matrices (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>; <xref rid="R24" ref-type="bibr">Ledoit and Wolf, 2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>; <xref rid="R44" ref-type="bibr">Schäfer and Strimmer, 2005</xref>), the nonlinear shrinkage methods are not guaranteed to preserve the diagonal of the correlation matrices and not guaranteed to produce values between −1 and 1 when applied to correlation matrices. The output of these shrinkage methods would, therefore, need to be rescaled or projected to produce correlations, and the effect of these operations might partially reduce the benefits introduced by the non-linear methods. Moreover, the mathematical validity of most shrinkage methods has only been established under asymptotic conditions, such as matrix dimensions increasing to infinity. Experimental validation is still required to establish whether the connectomes extracted from rs-fMRI scans would be large enough for the covariance shrinkage methods to be effective in practice.</p>
      <p id="P6">The present work addresses these issues by reporting detailed comparisons between five prominent covariance shrinkage methods. A large benchmark dataset of a thousand high-resolution scans was selected in the Human Connectome Project (HCP) database (<xref rid="R15" ref-type="bibr">Essen et al., 2013</xref>) for the experiments, and the ability of the shrinkage methods to capture four prominent functional networks at different spatial resolutions were compared for a broad range of scan duration. In addition, two important applications were considered: the definition of binary connectomes and the analysis of heterogeneous sets of scans acquired using different fMRI protocols. For this last experiment, an additional large rs-fMRI data set known for its heterogeneity was processed: the ABIDE data set (Craddock et al., 2013a).</p>
    </sec>
    <sec id="S2">
      <label>2.</label>
      <title>Materials and methods</title>
      <sec id="S3">
        <label>2.1.</label>
        <title>HCP Dataset</title>
        <p id="P7">A thousand high-resolution resting-state fMRI scans were extracted from the Human Connectome Project (HCP) HCP_1200 release (<xref rid="R15" ref-type="bibr">Essen et al., 2013</xref>) by selecting the first 250 HCP participants with a complete set of four rsfMRI scans. All these scans were acquired on the same customized Siemens 3T Connectome Skyra housed at Washington University in St. Louis, set for a gradient-echo EPI sequence with a repetition time of 720 milliseconds (TR), an echo time of 33.1 milliseconds (TE), a flip angle of 52 degrees, FOV 208×180 mm (RO × PE), Matrix 104×90 (RO × PE). 72 slices of 2.0 mm thickness were acquired to obtain 2.0 mm isotropic voxels using a multiband factor of 8, an echo spacing of 0.58 milliseconds, and a bandwidth (BW) of 2290 Hz/Px (<xref rid="R53" ref-type="bibr">WU-Minn HCP 1200 Subjects Data Release, 2018</xref>). In total, rs-fMRI scans were 14 minutes and 33 seconds long and 1200 time points were acquired, which corresponds to an average time point duration of 727.5 milliseconds. For each rsfMRI scan, the file storing the grayordinates time series denoised using the ICA-FIX method and registered using the MSMAll approach were downloaded from the HCP website (<xref rid="R20" ref-type="bibr">Glasser et al., 2013</xref>). Cortical time series were extracted from the files, temporally detrended, and bandpass filtered using a temporal Butterworth filter of order 2 to retain the BOLD signal between 0.01 Hz and 0.1 Hz (<xref rid="R46" ref-type="bibr">Smith et al., 2011</xref>). The first two hundred time points of each scan were dropped to alleviate bandpass filtering border condition effects. Lastly, time series were normalized to a zero temporal mean and an L2 norm equal to one. These three preprocessing steps, detrending, bandpass filtering, and normalization, were implemented in Python (scipy.signal library, version 1.4.1). The brain parcellation (<xref rid="R19" ref-type="bibr">Glasser et al., 2016</xref>) derived from the HCP data was used as a brain map. This parcellation defines 180 parcels per hemisphere that are matched between hemispheres and can be grouped into 22 large regions to investigate functional connectivity at a larger scale.</p>
      </sec>
      <sec id="S4">
        <label>2.2.</label>
        <title>Shrinkage methods</title>
        <p id="P8">Five prominent covariance shrinkage methods were included in the benchmark: (1) the original linear covariance shrinkage method introduced by <xref rid="R25" ref-type="bibr">Ledoit and Wolf (2004)</xref>, (2) an improvement of this original approach coined the Oracle Approximating Shrinkage method (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>), (3) the nonlinear covariance shrinkage method NERCOME (<xref rid="R23" ref-type="bibr">Lam, 2016</xref>) that achieves the best performances among sample-splitting algorithms (<xref rid="R29" ref-type="bibr">Ledoit and Wolf, 2020</xref>), (4) the nonlinear shrinkage method QuEST (<xref rid="R27" ref-type="bibr">Ledoit and Wolf, 2015</xref>) that was shown to achieve the best performances so far but required a separate publication covering its difficult implementation (<xref rid="R28" ref-type="bibr">Ledoit and Wolf, 2017</xref>), and (5) a recent non-linear method easy to implement and able to handle large covariance matrices that was introduced as an approximation of QuEST (<xref rid="R29" ref-type="bibr">Ledoit and Wolf, 2020</xref>).</p>
        <sec id="S5">
          <label>2.2.1.</label>
          <title>Original linear shrinkage</title>
          <p id="P9">The linear shrinkage method introduced by <xref rid="R24" ref-type="bibr">Ledoit and Wolf (2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>) was included at first in the benchmark. Let <inline-formula><mml:math id="M1" display="inline"><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> denote a time series containing <italic toggle="yes">n</italic> measures of a p-dimensional random variable with zero mean, and let S denote the empirical covariance of this sample:
<disp-formula id="FD1">
<label>(1)</label>
<mml:math id="M2" display="block"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math>
</disp-formula></p>
          <p id="P10">The shrinkage introduced by Ledoit and Wolf replaces the empirical covariance matrix <italic toggle="yes">S</italic> by a matrix Σ that is closer than <italic toggle="yes">S</italic> to the covariance matrix that would be obtained with an infinite set of observations, according to the standard squared <italic toggle="yes">L</italic><sub>2</sub> norm. The corrected covariance matrix Σ is obtained via the following linear combination:
<disp-formula id="FD2">
<label>(2)</label>
<mml:math id="M3" display="block"><mml:mrow><mml:mi>Σ</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>F</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math>
</disp-formula>
where the target matrix <italic toggle="yes">F</italic> is an isotropic diagonal matrix with the same trace as S and the shrinkage intensity <italic toggle="yes">λ</italic> is calculated as follows (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>; <xref rid="R24" ref-type="bibr">Ledoit and Wolf, 2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>), where <italic toggle="yes">T r</italic> (.) denotes the trace of a matrix and <italic toggle="yes">I</italic> the identity matrix:
<disp-formula id="FD3">
<label>(3)</label>
<mml:math id="M4" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:mfrac><mml:mi>I</mml:mi></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD4">
<label>(4)</label>
<mml:math id="M5" display="block"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mstyle><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow></mml:math>
</disp-formula>
where ⌈<italic toggle="yes">x</italic>⌉<sup>1</sup> denotes <italic toggle="yes">min</italic> (<italic toggle="yes">x,</italic> 1) and ensures that the shrinkage intensity is always smaller than one, even when computation errors happen. When <italic toggle="yes">S</italic> is a correlation matrix, where the diagonal is equal to 1, the formula simplifies to the convex combination:
<disp-formula id="FD5">
<label>(5)</label>
<mml:math id="M6" display="block"><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msup><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD6">
<label>(6)</label>
<mml:math id="M7" display="block"><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mstyle><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow></mml:math>
</disp-formula>
The identity matrix is a correlation matrix and the convex combination of correlation matrices is a correlation matrix. So, the linear shrinkage introduced by Ledoit and Wolf is guaranteed to generate correlation matrices when applied to correlation matrices. This property has already been exploited to improve the estimation of functional connectomes (<xref rid="R13" ref-type="bibr">Deligianni et al., 2014</xref>). The need for a correlation shrinkage and, in particular, when the sample size <italic toggle="yes">n</italic> is small and the <inline-formula><mml:math id="M8" display="inline"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> vary around their mean <italic toggle="yes">S</italic>, indicates that correlations’ amplitudes tend to be overestimated.</p>
        </sec>
        <sec id="S6">
          <label>2.2.2.</label>
          <title>Oracle approximating shrinkage</title>
          <p id="P12">The Oracle Approximating Shrinkage (OAS) is known to achieve better performances than the original Ledoit-Wolf method (<xref rid="R9" ref-type="bibr">Chen et al., 2010</xref>). It relies on the same setting but, under the assumption that the sample was drawn for a Gaussian distribution, computes a modified shrinkage intensity that achieves improved performances in practice:
<disp-formula id="FD7">
<label>(7)</label>
<mml:math id="M9" display="block"><mml:mrow><mml:mi>Σ</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>F</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD8">
<label>(8)</label>
<mml:math id="M10" display="block"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow></mml:math>
</disp-formula>
When <italic toggle="yes">S</italic> is a correlation matrix, where the diagonal is equal to 1, the formula boils down to the convex combination:
<disp-formula id="FD9">
<label>(9)</label>
<mml:math id="M11" display="block"><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD10">
<label>(10)</label>
<mml:math id="M12" display="block"><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msup></mml:mrow></mml:math>
</disp-formula></p>
          <p id="P13">Like the original linear shrinkage proposed by Ledoit and Wolf, the OAS of a correlation matrix is mathematically guaranteed to be a correlation matrix. OAS has already been used to improve functional connectomes (<xref rid="R18" ref-type="bibr">Fritsch et al., 2012</xref>; <xref rid="R35" ref-type="bibr">Ng et al., 2011</xref>, <xref rid="R36" ref-type="bibr">2012</xref>, <xref rid="R37" ref-type="bibr">2013</xref>).</p>
        </sec>
        <sec id="S7">
          <label>2.2.3.</label>
          <title>NERCOME</title>
          <p id="P14">NERCOME (<xref rid="R23" ref-type="bibr">Lam, 2016</xref>) is based on a sample-splitting scheme. More specifically, time series are randomly split in two, <italic toggle="yes">m</italic> times. For each split <italic toggle="yes">i</italic>, the eigenvectors of the empirical covariance matrix <inline-formula><mml:math id="M13" display="inline"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> obtained for the first part are computed and stored in a matrix <inline-formula><mml:math id="M14" display="inline"><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, for instance, by Singular Value Decomposition (SVD). The empirical covariance matrix of the second part of the sample, <inline-formula><mml:math id="M15" display="inline"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, is then projected onto these eigenvectors to obtain a regularized covariance matrix. The average of the <italic toggle="yes">m</italic> regularized covariance matrices constitutes the output of the NERCOME method:
<disp-formula id="FD11">
<label>(11)</label>
<mml:math id="M16" display="block"><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mspace width="1pt"/><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mtext mathvariant="italic">diag</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:msubsup></mml:mrow></mml:math>
</disp-formula></p>
        </sec>
        <sec id="S8">
          <label>2.2.4.</label>
          <title>QuEST</title>
          <p id="P15">The QuEST method produces a new covariance matrix by numerically solving a set of complex equations derived from Random Matrix Theory (<xref rid="R27" ref-type="bibr">Ledoit and Wolf, 2015</xref>, <xref rid="R29" ref-type="bibr">2020</xref>). More specifically, the authors define a Quantized Eigenvalues Sampling Transform (QuEST) that maps the eigenvalues of the covariance matrix that would be obtained for an infinite sample size to the eigenvalues of an empirical covariance matrix observed for a limited sample size, in large dimensional asymptotic (i.e. when the dimension of the covariance matrices tends to the infinity). The numerical inversion of this QuEST function produces then an estimation of the ideal covariance eigenvalues from their empirical counterparts, under the assumption that the matrix dimension is large enough for the QuEST function to be accurate.</p>
        </sec>
        <sec id="S9">
          <label>2.2.5.</label>
          <title>Analytical nonlinear shrinkage</title>
          <p id="P16">NERCOME and QuEST produced promising results, but these methods rely on time-consuming numerical schemes that are unable to accommodate large covariance matrices (<xref rid="R27" ref-type="bibr">Ledoit and Wolf, 2015</xref>, <xref rid="R29" ref-type="bibr">2020</xref>). The analytical method recently proposed by <xref rid="R29" ref-type="bibr">Ledoit and Wolf (2020)</xref> addresses this issue by providing a set of transformations that can be directly applied to the eigenvalues of a covariance matrix to approximate its nonlinear shrinkage. This set of transformations was carefully selected so that they could be expressed in simple closed-form solutions easy to implement. As a result, the approach benefits from a great computational efficiency offering the possibility to process very large correlation matrices (<xref rid="R29" ref-type="bibr">Ledoit and Wolf, 2020</xref>). More specifically, a modified eigenvalue <italic toggle="yes">σ</italic><sub><italic toggle="yes">i</italic></sub> is obtained for each non-zero eigenvalue <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub> of the covariance matrix as follows when the number of time points <italic toggle="yes">n</italic> is larger than the dimension <italic toggle="yes">p</italic>:
<disp-formula id="FD12">
<label>(12)</label>
<mml:math id="M17" display="block"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mfrac><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mi>π</mml:mi><mml:mfrac><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:mfrac><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula>
where
<disp-formula id="FD13">
<label>(13)</label>
<mml:math id="M18" display="block"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mspace linebreak="newline"/><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mspace linebreak="newline"/><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mi>y</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace linebreak="newline"/><mml:msub><mml:mi>F</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mn>5</mml:mn></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mspace linebreak="newline"/><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>10</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mspace linebreak="newline"/><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:mi>π</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mn>5</mml:mn></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="1pt"/><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>≠</mml:mo><mml:mn>5</mml:mn><mml:mspace linebreak="newline"/><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace linebreak="newline"/><mml:mtext mathvariant="italic">otherwise</mml:mtext><mml:mspace linebreak="newline"/><mml:msub><mml:mi>H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>
</disp-formula></p>
          <p id="P17">If <italic toggle="yes">U</italic> denotes the eigenvectors, the final covariance matrix is obtained as:
<disp-formula id="FD14">
<label>(14)</label>
<mml:math id="M19" display="block"><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mspace width="1pt"/><mml:mtext mathvariant="italic">diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math>
</disp-formula></p>
          <p id="P18">When the number of time points <italic toggle="yes">n</italic> is smaller than the dimension, <italic toggle="yes">x</italic><sub><italic toggle="yes">i</italic>,</sub>
<italic toggle="yes">F</italic><sub><italic toggle="yes">i</italic>,</sub>
<italic toggle="yes">H</italic><sub><italic toggle="yes">i</italic></sub> are computed for the eigenvalues larger than zero as explained above, but the <italic toggle="yes">σ</italic><sub><italic toggle="yes">i</italic></sub> are now obtained as follows:
<disp-formula id="FD15">
<label>(15)</label>
<mml:math id="M20" display="block"><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mspace linebreak="newline"/><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:mn>4</mml:mn><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:mi>h</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>5</mml:mn><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mrow><mml:mn>10</mml:mn><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msqrt><mml:mn>5</mml:mn></mml:msqrt><mml:mi>h</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:mi>δ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>π</mml:mi><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mspace linebreak="newline"/><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi>π</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mi>δ</mml:mi></mml:math>
</disp-formula>
and <italic toggle="yes">δI</italic> is added to the final covariance matrix:
<disp-formula id="FD16">
<label>(16)</label>
<mml:math id="M21" display="block"><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mspace width="1pt"/><mml:mtext mathvariant="italic">diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:math>
</disp-formula></p>
          <p id="P19">The idea of computing the eigenvalues and modifying their values directly without modifying the eigenvectors of the covariance matrix bears similarities with the original method published by Stein decades ago (<xref rid="R48" ref-type="bibr">Stein, 1975</xref>, <xref rid="R49" ref-type="bibr">1986</xref>). However, the new approach alleviates the two most stringent limitations of Stein’s approach. First, Stein’s formula diverges as soon as two eigenvalues are close to each other, which happens more and more frequently as the size of the covariance matrices increases. And second, Stein’s method was not guaranteed to produce eigenvalues in the correct order of decreasing values. This second issue required the development of an ad-hoc fix called isotonization (<xref rid="R48" ref-type="bibr">Stein, 1975</xref>, <xref rid="R49" ref-type="bibr">1986</xref>) that was shown to have a significant impact on the final results (<xref rid="R41" ref-type="bibr">Rajaratnam and Vincenzi, 2016</xref>). When implementing the new analytical nonlinear shrinkage method, we noticed nonetheless that very small eigenvalues corrupted by noise could derail the computation of <italic toggle="yes">H</italic><sub>0</sub> in large dimension low sample size settings. So, we decided to set all the eigenvalues smaller than 0.1% of the largest eigenvalue to zero. This arbitrary threshold was manually selected after investigating the first connectome where the issue was noticed, but the implementation fix worked well for the rest of the data set.</p>
        </sec>
      </sec>
      <sec id="S10">
        <label>2.3.</label>
        <title>Shrinkage intensity charts</title>
        <p id="P20">Linear shrinkage methods reduce the amplitude of extra-diagonal covariances by the same scaling factor (1 − <italic toggle="yes">λ</italic>). So, when the shrinkage intensity <italic toggle="yes">λ</italic> reaches one, it means that the methods have concluded that no extra-diagonal covariance can be correctly estimated and they have taken the conservative decision of discarding them all. For correlation shrinkage, the expression of the OAS intensity is particularly elegant: the OAS intensity only depends on the number of time points <italic toggle="yes">n</italic>, the dimension of the correlation matrix <italic toggle="yes">p</italic>, and the squared <italic toggle="yes">L</italic><sub>2</sub> norm of the correlation matrix, <italic toggle="yes">Tr</italic>(<italic toggle="yes">S</italic><sup>2</sup>). This squared norm is always larger than <italic toggle="yes">p</italic>, smaller than <italic toggle="yes">p</italic><sup>2</sup>, and reflects the number of correlations with large amplitudes in the matrix. In the sequel, this quantity will be denoted <italic toggle="yes">functional connectome density</italic> and normalized between 0 and 1 as follows:
<disp-formula id="FD17">
<label>(17)</label>
<mml:math id="M22" display="block"><mml:mrow><mml:mtext>Density</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P21">Thanks to its elegant formulation, the OAS intensity can be precomputed for broad ranges of <italic toggle="yes">n</italic>, <italic toggle="yes">p</italic>, and connectome density values to create intensity charts predicting how the OAS would alter a given functional connectome. Large shrinkage intensities would flag unreliable connectomes.</p>
      </sec>
      <sec id="S11">
        <label>2.4.</label>
        <title>Alteration</title>
        <p id="P22">For nonlinear shrinkage methods, the amount of statistical correction is not related to a global intensity shrinkage defined by a specific formula. The alterations introduced in connectomes were summarized by computing the squared Frobenius distance between the empirical correlation matrix and the connectome obtained after shrinkage, a quantity that will be denoted <italic toggle="yes">alteration</italic> in the sequel:
<disp-formula id="FD18">
<label>(18)</label>
<mml:math id="M23" display="block"><mml:mrow><mml:mtext>Alteration </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mi>X</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mi>X</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math>
</disp-formula></p>
        <p id="P23">For linear shrinkage methods, alteration (A), density (D), and dimension (p) are related as follows:
<disp-formula id="FD19">
<label>(19)</label>
<mml:math id="M24" display="block"><mml:mrow><mml:mtext>A</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>D</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math>
</disp-formula>
<disp-formula id="FD20">
<label>(20)</label>
<mml:math id="M25" display="block"><mml:mrow><mml:mtext>A</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>Σ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>D</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math>
</disp-formula></p>
      </sec>
      <sec id="S12">
        <label>2.5.</label>
        <title>Spreads and bias</title>
        <p id="P24">The heterogeneity of a set of correlation matrices was measured by computing a <italic toggle="yes">Spread</italic> equal to the mean of the squared Frobenius distances between the matrices in the set and their average. When a ground truth population average was known for this set of matrices, a ground truth spread was computed as the mean of the squared Frobenius distances between the matrices in the set and this population average, and a bias was measured by computing the squared Frobenius distance between the average of the connectivity matrices in the set and the population average.</p>
      </sec>
    </sec>
    <sec id="S13">
      <label>3.</label>
      <title>Experiments</title>
      <sec id="S14">
        <label>3.1.</label>
        <title>Implementation</title>
        <p id="P25">The QuEST method is very difficult to implement (<xref rid="R27" ref-type="bibr">Ledoit and Wolf, 2015</xref>, <xref rid="R28" ref-type="bibr">2017</xref>), so an existing library developed for R (version 3.6.3) was used in this work, the nlshrink library (version 1.0.1). The covariances estimated by the two different solvers implemented in this library (nlminb and nloptr) were compared (<italic toggle="yes">QuEST</italic><sub>1</sub> and <italic toggle="yes">QuEST</italic><sub>2</sub>). The implementation of the original linear shrinkage (<xref rid="R24" ref-type="bibr">Ledoit and Wolf, 2003</xref>, <xref rid="R25" ref-type="bibr">2004</xref>) provided by this library was also used. All the other methods, NERCOME, OAS, and the analytical nonlinear shrinkage were re-implemented in Python (version 3.7.4). For all the methods, the same sets of rs-fMRI BOLD time series normalized to zero mean and unit variance were used. The covariance matrices produced by the nonlinear shrinkage methods were projected by replacing the diagonal of the matrices with a diagonal equal to one, setting all the values in the matrices lower than −1 to −1, and all the values larger than 1 to 1. Lastly, to prevent instability during the calculations, the eigenvalues passed to the nonlinear analytical shrinkage method were modified as follows. When the number of time points was strictly inferior to the dimension of the matrix, spurious eigenvalues were removed by discarding all the pairs of eigenvector and eigenvalue corresponding to eigenvalues smaller than 10<sup>−6</sup> times the largest eigenvalue. When the number of time points was equal or larger than the dimension of the correlation matrix, the random fluctuations of the smaller eigenvalues were fixed by setting all the eigenvalues smaller than 10<sup>−3</sup> times the largest eigenvalue to that threshold. NERCOME was tested for an average of 100 matrices, and five parameter values were compared: retaining half of the time series when computing the matrices <inline-formula><mml:math id="M26" display="inline"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mspace width="1pt"/><mml:mtext mathvariant="italic">ERCOM</mml:mtext><mml:mspace width="1pt"/><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mn>50</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, retaining 75% of the time series (<italic toggle="yes">N ERCOM E</italic><sub>75</sub>), 90% (<italic toggle="yes">N ERCOM E</italic><sub>90</sub>), 95% (<italic toggle="yes">N ERCOM E</italic><sub>95</sub>), or 99% (<italic toggle="yes">N ERCOM E</italic><sub>99</sub>). As a result, during the experiments, baseline empirical Pearson correlations were compared to their improved counterparts generated by ten different shrinkage methods: the original Ledoit-Wolf approach (LW), the Oracle Approximating Shrinkage (OAS), the nonlinear analytical shrinkage (NAS), the two QuEST implementations (<italic toggle="yes">QuEST</italic><sub>1</sub> and <italic toggle="yes">QuEST</italic><sub>2</sub>), and the five NERCOME variants.</p>
      </sec>
      <sec id="S15">
        <label>3.2.</label>
        <title>Intensity charts and functional networks</title>
        <p id="P26">Shrinkage intensity charts were first derived for a broad range of dimensions, sample sizes, and densities. More specifically, for each dimension <italic toggle="yes">p</italic> in (10, 25, 50, 100, 250, 500, 1000, 10000) the OAS intensity was computed for a regular logarithmic grid of 501 time points <italic toggle="yes">n</italic> between 10 and 5000, and 501 values of density between 0.005 and 1. The standard <italic toggle="yes">contour</italic> function of the matplotlib python library (version 3.3.4) was then used to display the level sets corresponding to shrinkage intensities (0.002,0.005,0.01,0.025,0.05,0.1,0.25,0.5,0.9).</p>
        <p id="P27">Then, the HCP benchmark data set prepared for this work was used to estimate typical connectome densities. Four bilateral connectomes were considered: (1) the connectome obtained for the entire HCP parcellation (180 parcels per hemisphere, 360 parcels in total), (2) the connectome obtained for the large HCP regions (22 regions per hemisphere, 44 regions in total), (3) the connectome obtained for the 13 parcels of the dorsolateral prefrontal cortex in the HCP parcellation (DLPFC, 26 parcels in total), and (4) the connectome of the Default Mode Network (DMN, 76 parcels in total) (<xref rid="R6" ref-type="bibr">Buckner et al., 2008</xref>). The parcels part of the DMN were selected by averaging over both hemispheres and over the scans of all the 250 HCP participants the correlations between parcel BOLD signals and the average of the BOLD signals of the 14 HCP parcels in the Posterior Cingulate Cortex (PCC), and selecting all parcels with a correlation larger than 0.2 with the PCC (38 parcels passed that threshold). The density of these connectomes were measured repeatedly and for different random scan durations as follows. For each HCP participant, the four processed rs-fMRI scans were concatenated to create time series with 4000 time points. Then, ten times per HCP participant, the time points were shuffled at random and the first <italic toggle="yes">m</italic> time points were used to compute the connectomes, with <italic toggle="yes">m</italic> uniformly selected at random among the OAS intensity chart grid points corresponding to less than 4000 time points. The densities of these 2500 connectomes were computed and reported on the OAS intensity charts corresponding to the dimensions of the connectomes (360 for the high-resolution HCP parcellation, 44 for the low-resolution HCP, 26 for the DLPFC and 76 for the DMN).</p>
      </sec>
      <sec id="S16">
        <label>3.3.</label>
        <title>Methods comparison</title>
        <p id="P28">For the four functional networks separately (high-resolution HCP parcellation, low-resolution HCP parcellation, DMN, and DLPFC), the methods were compared as follows. First, fifty-one numbers of time points were selected to cover the logarithmic scale between 15 and 1000 time points. Then, for each of these scan duration, twenty-five times in a row, an HCP study participant was selected at random, the normalized BOLD time series of his four scans were concatenated, shuffled at random, cropped to the scan duration, normalized to zero mean and unit squared <italic toggle="yes">L</italic><sub>2</sub> norm, the correlation matrix was computed and corrected using the ten shrinkage methods compared in this study. The squared Frobenius distances between these eleven correlation matrices and the correlation matrix obtained for the 4000 time points of the concatenated scans were reported as a measure of <italic toggle="yes">error</italic>, that was plotted as a function of the scan duration. Lastly, the results were refined by subtracting the error measured for the OAS to the errors measured for each other approach, measuring the mean and the median of these error differences, and checking their significance using a Wilcoxon signed-rank test.</p>
      </sec>
      <sec id="S17">
        <label>3.4.</label>
        <title>Methods agreement</title>
        <p id="P29">The agreement between shrinkage methods was calculated by comparing the shrinkage alterations they induce. More specifically, for all the matrices generated at the previous step, the shrinkage alteration measured for the OAS was compared to the alterations measured for the other methods, and the Spearman correlation between these alterations was computed.</p>
      </sec>
      <sec id="S18">
        <label>3.5.</label>
        <title>Thresholded connectomes</title>
        <p id="P30">The second set of experiments was carried out to study the impact of correlation shrinkage on thresholded connectomes. During these experiments, eleven different scans duration were considered: 25, 50, 75, 100, 125, 150, 200, 250, 300, 400, and 500 time points. For each scan duration, BOLD time series were extracted at random as explained above (by concatenating all study participant normalized data, shuffling, cropping the time series, and normalizing them again). Their correlation matrices, with and without OAS, were used to define connectivity matrices, and three binary connectomes were obtained for each connectivity matrix by thresholding the correlations at the values 0.3, 0.4, and 0.5. Three measures were then derived to compare these random connectomes with the ground truth binary connectomes obtained by thresholding the correlation matrices derived from all the data available for the study participant: a precision measuring the proportion of connections in both connectomes among the connections retained in the random connectomes; an accuracy equal to the sum of the numbers of connections in both connectomes and in none of the connectomes divided by the total number of possible connections; and a Jaccard index equal to the number of connections selected in both connectomes divided by the number of connections selected in at least one of them.</p>
      </sec>
      <sec id="S19">
        <label>3.6.</label>
        <title>Heterogeneous datasets</title>
        <p id="P31">The effects of correlation shrinkage on a heterogeneous set of connectivity matrices derived from fMRI scans acquired using different protocols were simulated by randomly splitting the data available for a study participant into short time series, and using these time series to derive connectivity matrices with or without shrinkage. More specifically, after concatenation and shuffling, the time series available for each of the 250 study participants and each functional network were split in 50 different time series of random duration longer than 30 time points. The spread of these connectivity matrices, their spread around the ground truth connectivity matrix obtained when considering all the data at once, and the bias between that ground truth and the average of the connectivity matrices derived from short time series were measured.</p>
        <p id="P32">Lastly, the pre-processed fMRI scans of an additional dataset known for its heterogeneity, the ABIDE dataset (Craddock et al., 2013a; <xref rid="R31" ref-type="bibr">Martino et al., 2014</xref>), were used to test whether OAS could reinforce the associations observed between functional connectivity changes and brain disorders. More specifically, for each of the 766 ABIDE participants with pre-processed data and each available set of time series, a correlation matrix was calculated and improved via OAS. Then, for each pair of time series, a T-test was conducted on the functional connectivity to detect a group difference between ABIDE control participants and ABIDE participants with Autism Spectrum Disorder (ASD). These T-tests were conducted at first using the original correlations before shrinkage and then using the correlations produced by OAS. The analysis was replicated for the seven sets of time series available. These time series were derived from the following brain parcellations: the Automated Anatomical Labeling (aal, 116 parcels), the Eickhoff-Zilles parcellation (ez, 116 parcels), the Harvard-Oxford parcellation (ho, 111 parcels), the Talaraich and Tournoux parcellation (tt, 97 parcels), the Dosenbach 160 parcellation (do160, 161 parcels), the Craddock 200 parcellation (CC200, 200 parcels), and the Craddock 400 parcellation (CC400, 392 parcels) (Craddock et al., 2013b). ABIDE scans were collected in 17 different locations using different scanners and various protocols.</p>
      </sec>
      <sec id="S20">
        <title>Ethics Statement</title>
        <p id="P33">The data used in this study are all public/shared data provided by the HCP consortium (<ext-link xlink:href="https://www.humanconnectome.org/" ext-link-type="uri">https://www.humanconnectome.org</ext-link>) and the ABIDE consortium (<ext-link xlink:href="http://preprocessed-connectomes-project.org/abide/index.html" ext-link-type="uri">http://preprocessed-connectomes-project.org/abide/index.html</ext-link>).</p>
        <p id="P34">The original ABIDE ethics statement (<xref rid="R31" ref-type="bibr">Martino et al., 2014</xref>) reads as follows: All contributions were based on studies approved by local IRBs, and data were fully anonymized (removing all 18 HIPAA protected health information identifiers, and face information from structural images). All data distributed were visually inspected prior to release.</p>
        <p id="P35">HCP’s original publication (<xref rid="R15" ref-type="bibr">Essen et al., 2013</xref>) indicates: To aid in the protection of participants’ privacy, the HCP has adopted a two-tiered data access strategy (<ext-link xlink:href="http://www.humanconnectome.org/data/data-use-terms/" ext-link-type="uri">http://www.humanconnectome.org/data/data-use-terms/</ext-link>). Every investigator must agree to FieldTrip Toolbox. An additional set of Restricted Data Use Terms applies to an important subset of the non-imaging data and is essential for preventing any inappropriate disclosure of subject identity. The released HCP data are not considered de-identified, insofar as certain combinations of HCP Restricted Data (available through a separate process) might allow identification of individuals as discussed below. It is accordingly important that all investigators who agree to Open Access Data Use Terms consult with their local IRB or Ethics Committee to determine whether the research needs to be approved or declared exempt. If needed and upon request, the HCP will provide a certificate stating that an investigator has accepted the HCP Open Access Data Use Terms.</p>
        <p id="P36">No HCP Restricted Data was used in the present study.</p>
      </sec>
    </sec>
    <sec id="S21">
      <label>4.</label>
      <title>Results</title>
      <sec id="S22">
        <label>4.1.</label>
        <title>Shrinkage intensity charts</title>
        <p id="P37"><xref rid="F1" ref-type="fig">Fig. 1</xref> presents the OAS intensity charts. Surprisingly, shrinkage intensity is very stable with respect to the dimension <italic toggle="yes">p</italic>: the chart obtained for a dimension of ten thousand is almost the same as the chart obtained for a dimension of one hundred. On the other hand, shrinkage intensity strongly depends on connectome density and the number of time points <italic toggle="yes">n</italic>. High densities corresponding to connectomes with multiple strong correlations and anti-correlations are judged more reliable by the OAS. These charts indicate that it is impossible to estimate reliable sparse connectomes from a limited number of time points.</p>
      </sec>
      <sec id="S23">
        <label>4.2.</label>
        <title>Functional networks</title>
        <p id="P38">Thirty eight regions were selected to form the DMN connectome: CVT, RSC, POS1, POS2, PCV, 7m, 23d, v23ab, d23ab, 31pv, 31pd, 31a in the Posterior Cingulate Cortex region; a24, d32, p32, 10r, 9m, 10v, s32 in the Anterior Cingulate and Medial Prefrontal Cortex region; 8Av, 8Ad, 9p, i6–8, in the DorsoLateral Prefrontal Cortex region; 10d and p10p in the Orbital and Polar Frontal Cortex region; PreS, PeEc, PHA1, PHA2, PHA3 in the Medial Temporal Cortex region; PGp, IP1, PGi, PGs, 7Pm in the Superior Parietal Cortex region; and STSva in the Auditory Association Cortex and TE1m and TE1a in the Lateral Temporal Cortex (<xref rid="R19" ref-type="bibr">Glasser et al., 2016</xref>). The functional networks and their spatial support are shown in <xref rid="F2" ref-type="fig">Fig. 2</xref>.</p>
      </sec>
      <sec id="S24">
        <label>4.3.</label>
        <title>Functional networks OAS intensity</title>
        <p id="P39"><xref rid="F3" ref-type="fig">Fig. 3</xref> displays the OAS intensities obtained for all the HCP, DMN, and DLFPC connectomes. With a density between 0.1 and 0.2, the DLPFC is the connectome with the largest density, and therefore the one that can be estimated with the lowest number of time points: for 200 time points, the OAS intensity ranges between 0.05 an d 0.1, which indicates that the connectomes are reliable. On the other hand, the entire HCP connectome is moderately sparse (density close to 0.05) and would need to be shrunk by up to 0.25 when only 100 time points are available. This duration corresponds to 72.75 seconds of scanning time using the high-resolution HCP acquisition protocol but would correspond to more than 3 minutes for a standard fMRI acquisition protocol with a TR of 2 seconds (<xref rid="R51" ref-type="bibr">Tremblay-Mercier et al., 2021</xref>). The Default Mode Network and the low-resolution HCP connectomes present intermediary densities.</p>
      </sec>
      <sec id="S25">
        <label>4.4.</label>
        <title>Methods performances</title>
        <p id="P40"><xref rid="F4" ref-type="fig">Fig. 4</xref> shows that, except the last variant of NERCOME, all the methods improved functional connectomes when the number of time points was smaller than the dimension of the connectivity matrix and produced connectomes converging to the baseline connectome for large numbers of time points. The two QuEST variants produced very similar results, which suggests that the choice of the QuEST solver had a minor impact on the functional connectome shrinkage. Despite its improved implementation, the nonlinear analytical shrinkage generated wrong connectivity matrices when the number of time points was close to the dimension of the correlation matrices and, in particular, for the full resolution HCP parcellation. This issue suggests that the NAS method would require further implementation fixes to be fully effective in practice.</p>
        <p id="P41">One-to-one methods comparisons were then conducted with the OAS shrinkage as a reference by computing, for each correlation matrix, the difference between the error measured for the empirical correlation matrices or the matrices obtained after shrinkage and the error measured after OAS shrinkage. The mean and the median of these differences were computed to estimate what method was producing the smallest error during each comparison (OAS or the alternative approach), and a Wilcoxon sign-rank test was conducted to derive a p-value indicating the significance of these differences. A subset of the one-to-one comparisons conducted for the correlation matrices corresponding to the high-resolution HCP parcellation are presented in <xref rid="F5" ref-type="fig">Fig. 5</xref> and indicate that OAS significantly improves correlation matrices and significantly outperforms Ledoit-Wolf’s original approach. The complete results presented in <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref> indicate that OAS outperforms all NERCOME variants. For the DMN, shown in <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref>, NAS and both QuEST variants produce significantly better results than OAS. For the full resolution HCP parcellation, the improvements observed for the QuEST variants are the only one significant (NAS improvements do not reach significance level 0.05). By contrast, OAS was the best method for the low-resolution HCP parcellation and the DLPFC shown in <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref>. These results suggest that OAS and QuEST are the best methods, <italic toggle="yes">QuEST</italic><sub>2</sub> generating slightly better results than <italic toggle="yes">QuEST</italic><sub>1.</sub> A direct comparison between <italic toggle="yes">QuEST</italic><sub>1</sub> and <italic toggle="yes">QuEST</italic><sub>2</sub> confirms that <italic toggle="yes">QuEST</italic><sub>2</sub> produces lower errors, on average by 0.297 for the high-resolution HCP network, by 0.111 for the low-resolution HCP network, 0.022 for DMN, and 0.037 for DLPFC. These improvements were significant at level 0.05, except for the high-resolution HCP parcellation (Wilcoxon signed-rank test W 494447, p-value 0.34).</p>
      </sec>
      <sec id="S26">
        <label>4.5.</label>
        <title>Computational time</title>
        <p id="P42">NERCOME was the most time-consuming method, even when running for a single parameter value. NERCOME is straightforward to implement but requires multiple time-consuming matrix multiplications and additions. In addition, the method depends on a parameter, the proportion of samples retained to compute <italic toggle="yes">S</italic><sub>2</sub> during each split, which can only be selected by conducting an experimental replication or a cross-validation. This extra step of parameter selection further increases NERCOME computational cost. As a result, the computational burden was significantly larger for NERCOME than the other methods tested. The second slowest approach was QuEST, because of the cost required for the numerical inversion of the equations defined by the method. The other methods, the OAS, NAS, and the original LW method, exhibited a similar, significantly faster speed and would scale to large matrices, as noted by <xref rid="R29" ref-type="bibr">Ledoit and Wolf (2020)</xref>.</p>
      </sec>
      <sec id="S27">
        <label>4.6.</label>
        <title>Shrinkage alterations</title>
        <p id="P43">The agreement between OAS and the other methods shown in <xref rid="F6" ref-type="fig">Fig. 6</xref> for the high-resolution HCP parcellation and in <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref> for the other networks are always larger than 0.9, the largest values been obtained with the original Ledoit-Wolf linear shrinkage and QuEST. These large Spearman correlations suggest that OAS alterations are a reliable indicator of the alterations that would be introduced by the other methods. In other words, when OAS flags connectomes as less reliable and corrects them more substantially, other shrinkage methods would introduce stronger corrections as well.</p>
      </sec>
      <sec id="S28">
        <label>4.7.</label>
        <title>Thresholded connectomes</title>
        <p id="P44"><xref rid="F7" ref-type="fig">Figs. 7</xref> and <xref rid="SD1" ref-type="supplementary-material">supplemental Figure 11</xref> show that OAS has the effect of maintaining a good precision for thresholded connectomes derived from short scans. By focusing on a reduced set of reliable correlations, OAS is able to prune a significant part of the spurious connections that gradually appear in thresholded connectomes derived from empirical correlations as the number of time points is reduced. This benefit is sometimes associated with a moderate accuracy improvement, such as the one observed for the high-resolution HCP parcellation. However, it systematically comes at the cost of a reduced Jaccard Index, the shrinkage reducing the overlap between random and ground truth connectomes by strongly restricting the number of connections in random connectomes. The results obtained for the higher thresholds shown in <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref> indicate that these effects are stronger when the threshold is set to larger values selecting fewer connections, as long as OAS does not discard all the correlations. This issue happened once during the experiments, for connectomes estimated from 25 time points, for the high-resolution HCP parcellation, and the largest threshold tested <italic toggle="yes">τ</italic> = 0. 5. Interestingly, for the high-resolution HCP parcellation and the largest threshold <italic toggle="yes">τ</italic>, the precision improvements induced by OAS were still fairly strong for the longest time series tested: for the time series of five hundred time points, corresponding to six minutes scans acquired using the HCP protocol, the baseline precision of 0.89 was boosted by the OAS to 0.96. This corresponds to a threefold reduction of the fraction of spurious connections in the connectomes (4% versus 11%).</p>
      </sec>
      <sec id="S29">
        <label>4.8.</label>
        <title>Heterogeneous datasets</title>
        <p id="P45"><xref rid="F8" ref-type="fig">Fig. 8</xref> demonstrates that, for the synthetic data generated in this experiment, OAS reduces connectome heterogeneity and produces connectomes that are not only closer to each other but also closer to the ground truth they are attempting to capture. However, the fact that all the connectomes are shrunk towards the identity matrix shifts their mean and introduces bias. This issue could perhaps be addressed in the future by developing new shrinkage methods using the population average correlation matrix as a shrinkage target (<xref rid="R40" ref-type="bibr">Rahim et al., 2019</xref>; <xref rid="R44" ref-type="bibr">Schäfer and Strimmer, 2005</xref>).</p>
        <p id="P145"><xref rid="F9" ref-type="fig">Fig. 9</xref> presents the ABIDE dataset, the OAS intensity, and the proportion of pairwise functional connections strongly associated with ASD that are reinforced after OAS. These results point the variability between the 17 ABIDE acquisition sites. Most shrinkage intensities, close to 0.1 or larger, are not negligible. As a result, OAS had a noticeable impact on the results. By reinforcing the most significant associations while reducing the significance of spurious associations (see <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref>), OAS had a beneficial impact similar to a denoising procedure. The parcellation associated with the smallest shrinkage intensities was the Harvard-Oxford parcellation (ho, 111 parcels), followed by Eickhoff-Zilles (ez, 116 parcels), the Automated Anatomical Labeling (aal, 116 parcels), the Craddock 200 parcellation (CC200, 200 parcels), the Talaraich and Tournoux parcellation (tt, 97 parcels), and the Craddock 400 parcellation (CC400, 392 parcels). The Dosenbach 160 parcellation (do160, 161 parcels) produced the worst connectivity matrices. For all the parcellations except Dosenbach 160 the scans acquired at the Max-Mun and OHSU sites were the worst and the scans acquired at CMU, Leuven, and UM the bests. Please refer to the <xref rid="SD1" ref-type="supplementary-material">supplementary materials</xref> for complete results.</p>
      </sec>
    </sec>
    <sec id="S30">
      <label>5.</label>
      <title>Discussion</title>
      <sec id="S31">
        <label>5.1.</label>
        <title>Summary</title>
        <p id="P46">This work examined how the most prominent covariance shrinkage methods available today could be used to improve functional connectomes. The experiments were carried out on a benchmark dataset of a thousand high-resolution fMRI scans extracted from the Human Connectome Project dataset, that were used to generate thousands of short time series to study the benefits of covariance shrinkage for various scans durations. The investigations were replicated for four functional networks presenting different topologies and spatial resolutions: the entire cortex for high-resolution and low-resolution HCP parcellations, the spatially disconnected regions part of the DMN, and the functional units inside the DLPFC.</p>
        <p id="P47">Our experimental results suggest that the connectome alterations introduced by the different methods are in agreement. When set correctly, all the methods were able to improve the connectomes derived from short fMRI time series significantly. Method comparisons suggest that NERCOME should not be used, the original Ledoit-Wolf shrinkage is obsolete compared to the OAS, and the QuEST method is the gold standard for nonlinear shrinkage approaches. The most recent approach, the nonlinear analytical method, requires additional implementation fixes. We established that shrinkage significantly improves the quality of thresholded binary connectomes (<xref rid="R7" ref-type="bibr">Bullmore and Sporns, 2009</xref>; <xref rid="R43" ref-type="bibr">Rubinov and Sporns, 2010</xref>) by pruning unreliable connections. Lastly, we found that the shrinkage intensity charts derived to investigate the effects of the OAS method are not only easy to interpret but also predictive: they delimit ranges of settings where functional connectomes cannot be correctly estimated. These charts suggest, in particular, that sparse connectomes require large numbers of time points to be distinguished from random noise. This observation is in line with the literature on sparse covariance estimation, that reports estimation errors for sparse covariance matrices slowly decreasing with the number of samples (<xref rid="R4" ref-type="bibr">Bien and Tibshirani, 2011</xref>), such as the EC2 method estimation error proportional to the square root of the inverse of the number of samples (<xref rid="R30" ref-type="bibr">Liu et al., 2014</xref>). This result is of crucial importance, as it states the impossibility of studying dynamic functional connectivity below a connectome density limit that depends on the length of the time windows considered to estimate that connectivity (<xref rid="R54" ref-type="bibr">Zhang et al., 2018</xref>). By reporting the characteristics of our functional networks on these charts, we found that typical connectomes derived from fMRI time series of a hundred to three hundred time points, while being relatively well estimated, would still significantly benefit from shrinkage. We observed that the best nonlinear method (QuEST) does not systematically outperform the best linear method (OAS). This result suggests that the superior flexibility of the nonlinear shrinkage methods might sometimes lead to a form of overfitting. So, we would suggest the simpler, most computationally efficient, and easier to interpret OAS method as a gold standard for fMRI processing.</p>
      </sec>
      <sec id="S32">
        <label>5.2.</label>
        <title>Test-retest connectome reliability</title>
        <p id="P48">Our results are in line with previous works that have established that other forms of connectivity shrinkage can successfully improve the test-retest reproducibility of correlation matrices (<xref rid="R32" ref-type="bibr">Mejia et al., 2018</xref>, <xref rid="R33" ref-type="bibr">2015</xref>). When investigating the reliability of connectomes derived from fMRI scans, the meta-analysis (<xref rid="R38" ref-type="bibr">Noble et al., 2019</xref>) concluded that test-retest reproducibility increases with the amount of fMRI data available to estimate the connectomes and with the strength of their connections. These effects are consistent with our OAS intensity charts predicting better connectivity estimates for long BOLD time series and dense connectomes. However, it is still unclear how our results could be exploited to predict the reliability of individual connections as in recent works (<xref rid="R38" ref-type="bibr">Noble et al., 2019</xref>; <xref rid="R54" ref-type="bibr">Zhang et al., 2018</xref>).</p>
      </sec>
      <sec id="S33">
        <label>5.3.</label>
        <title>Partial correlations</title>
        <p id="P49">These test-retest studies have also pointed that partial correlations are less reliable than Pearson correlations, an issue that has already been reported multiple times in the past (<xref rid="R32" ref-type="bibr">Mejia et al., 2018</xref>; <xref rid="R38" ref-type="bibr">Noble et al., 2019</xref>; <xref rid="R46" ref-type="bibr">Smith et al., 2011</xref>). In the light of our results, this fact could be explained by the lower density of the connectomes derived from partial correlations, which makes them more difficult to distinguish from noisy fluctuations (<xref rid="R52" ref-type="bibr">Varoquaux et al., 2010</xref>). But more investigations would be required to compare the different approaches that could be employed to shrink partial correlations before concluding whether partial correlations necessarily require more shrinkage than the full Pearson correlation they originate from.</p>
        <p id="P50">In any case, partial correlations estimation could also benefit from the covariance shrinkage methods presented in this work, particularly when the number of time points is smaller than the spatial dimension. In this setting, empirical covariance matrices are not invertible. By scaling null covariance matrix eigenvalues to strictly positive values, covariance shrinkage fixes the issue by producing an invertible matrix. A step of covariance shrinkage can thus be performed as a preprocessing before computing partial correlations via covariance matrix inversion (<xref rid="R52" ref-type="bibr">Varoquaux et al., 2010</xref>). By increasing the values of small noisy eigenvalues in the covariance matrix, covariance shrinkage also has the effect of reducing their influence in the precision matrices, which contributes to denoising the partial correlations (<xref rid="R22" ref-type="bibr">Honnorat and Davatzikos, 2017</xref>).</p>
      </sec>
      <sec id="S34">
        <label>5.4.</label>
        <title>Binary connectomes</title>
        <p id="P51">When binary connectomes are defined by thresholding Pearson correlations according to their amplitudes (<xref rid="R7" ref-type="bibr">Bullmore and Sporns, 2009</xref>; <xref rid="R43" ref-type="bibr">Rubinov and Sporns, 2010</xref>), the lack of data induces the apparition of spurious connections. During our experiments, the OAS was very efficient at pruning these wrong connections. For the connectomes derived from the high-resolution HCP parcellation and thresholded to focus on strong correlations larger than 0.5, this beneficial effect was still significant for time series of five hundred time points. These results demonstrate that covariance shrinkage methods have the potential to significantly improve the quality of binary graph connectomes extracted from short time series and individual fMRI scans. We hypothesize that these more reliable connectomes would exhibit more stable graph theoretical measures as well (<xref rid="R7" ref-type="bibr">Bullmore and Sporns, 2009</xref>; <xref rid="R43" ref-type="bibr">Rubinov and Sporns, 2010</xref>).</p>
      </sec>
      <sec id="S35">
        <label>5.5.</label>
        <title>Dynamic functional connectivity</title>
        <p id="P52">We think that our results bear crucial implications for dynamic functional connectivity (dFC) studies. Covariance shrinkage mitigates a form of statistical noise introduced by the limited ability of empirical Pearson correlations to capture exact Pearson correlation values when data lacks for the estimation. In dFC studies where Pearson correlations are computed for short time windows, this statistical noise will amount for a significant part of the dFC variability. As a result, all the statistics derived from dFC, such as standard deviation, ALFF, and excursion (<xref rid="R54" ref-type="bibr">Zhang et al., 2018</xref>) will be corrupted by a noise that has no biological substrate of interest. This issue calls for caution when conducting dFC studies and analyzing their results.</p>
      </sec>
      <sec id="S36">
        <label>5.6.</label>
        <title>Scan duration and target networks</title>
        <p id="P53">Lastly, we think that our OAS intensity charts could help designing fMRI experiments. Scan duration is a highly debated question in the field. Most researchers agree that longer scanning times produce more accurate results but resources are limited and the scanners could be employed to acquire other MRI modalities (<xref rid="R3" ref-type="bibr">Anderson et al., 2011</xref>; <xref rid="R5" ref-type="bibr">Birn et al., 2013</xref>; <xref rid="R14" ref-type="bibr">Dijk et al., 2010</xref>; <xref rid="R21" ref-type="bibr">Gonzalez-Castillo et al., 2014</xref>; <xref rid="R38" ref-type="bibr">Noble et al., 2019</xref>; <xref rid="R45" ref-type="bibr">Shehzad et al., 2009</xref>). While preliminary works had initially concluded that a duration of five to ten minutes was sufficient to acquire resting-state fMRI scans (<xref rid="R14" ref-type="bibr">Dijk et al., 2010</xref>; <xref rid="R45" ref-type="bibr">Shehzad et al., 2009</xref>) subsequent studies established that test-retest reproducibility is significantly better for half-hour-long scans and that the functional features derived for individual study participants known as functional fingerprints can improve up to a cumulated scan duration of four hours (<xref rid="R3" ref-type="bibr">Anderson et al., 2011</xref>; <xref rid="R5" ref-type="bibr">Birn et al., 2013</xref>; <xref rid="R21" ref-type="bibr">Gonzalez-Castillo et al., 2014</xref>). Our results indicate that the number of BOLD measurements required to achieve a target OAS shrinkage intensity depends on the density of the functional networks under investigation and its number of nodes. Once that density has been obtained, for instance, by running a pilot data acquisition, our charts could be used to select a minimal scan duration ensuring that the statistical estimates of all the functional networks investigated in the study are of sufficient quality.</p>
        <p id="P152">For instance, the charts of <xref rid="F3" ref-type="fig">Fig. 3</xref> indicate that for the low-resolution HCP connectome one hundred fifty BOLD measurements are necessary to reach an average OAS intensity close to 0.1, corresponding to an overall error on empirical Pearson correlations amplitude around 10%. For the high-resolution HCP connectome, two hundred fifty measurements are required to reach the same quality. As a result, the ADNI3 protocol, that consists in acquiring ten-minutes-long scans at TR 3 seconds and produces scans with 200 time points Alzheimer’s Disease Neuro Imaging III (ADNI3), would only be sufficient for studying the impact of aging and neurodegenerative diseases on the low-resolution HCP connectome, that describes the functional connectivity between 44 large brain regions. By contrast, concatenating the two scans acquired for each participant of the preventAD study (304 seconds per scan, TR 2 seconds) would provide enough measurements to study as well, in that cohort, the impact of Alzheimer’s Disease on the high-resolution functional connectome that captures the connectivity between 360 fine brain parcels (<xref rid="R51" ref-type="bibr">Tremblay-Mercier et al., 2021</xref>).</p>
        <p id="P153">Our results also suggest that the new scanning procedures with short TR, such as multi-band acquisitions (<xref rid="R16" ref-type="bibr">Feinberg and Setsompop, 2013</xref>; <xref rid="R34" ref-type="bibr">Moeller et al., 2010</xref>; <xref rid="R47" ref-type="bibr">Smitha et al., 2018</xref>), should improve functional connectivity estimates by providing more temporal measurements for similar scan duration. As long as the artifacts introduced during these acquisitions are maintained at a negligible level (<xref rid="R42" ref-type="bibr">Risk et al., 2021</xref>) and as long as increasing temporal resolution brings useful information for the estimation of BOLD fluctuations within the frequency range of 0.1 to 0.01 Hz commonly selected to study functional connectivity (<xref rid="R55" ref-type="bibr">Zou et al., 2008</xref>), an improved temporal resolution should, in theory, better capture the functional networks that are currently well measured and allow for the exploration of sparse networks more difficult to capture.</p>
      </sec>
      <sec id="S37">
        <label>5.7.</label>
        <title>Limitations</title>
        <p id="P54">The covariance shrinkage methods used in this work assume that the BOLD measures were statistically independent in time. This assumption might not hold in practice for time series acquired at very small repetition times. In general, the information contained in BOLD time series could be lower than expected, in the presence of repeated measurements or due to scrubbing (<xref rid="R39" ref-type="bibr">Power et al., 2014</xref>). As a result, we think that the methods studied in this work are only providing an upper bound of the connectome quality: poorly estimated connectomes flagged by shrinkage methods might be even more corrupted in practice. In the future, the use of statistical methods factoring out redundancies in BOLD time series to compress them to an effective duration better reflecting their underlying information might fix this limitation.</p>
      </sec>
    </sec>
    <sec id="S38">
      <label>6.</label>
      <title>Conclusion</title>
      <p id="P55">In this article, we used a thousand high-resolution fMRI scans from the Human Connectome Project to compare the ability of five prominent covariance shrinkage methods to improve the quality of functional connectomes. We established that OAS and QuEST were the best methods and NERCOME performed poorly, OAS intensity strongly depends on the density of the correlation matrices and the number of samples used to compute them but not so much on their dimension, OAS intensity is a reliable indicator of the amplitude of the correction that other shrinkage methods would introduce, sparse connectomes are difficult to estimate from short fMRI scans, shrinkage methods efficiently prune spurious connectivity in thresholded connectomes, and shrinkage would impact most standard fMRI scans and be of crucial importance for dynamic connectivity studies. We have shown how shrinkage can reduce the variability in datasets with heterogeneous scans duration. Lastly, by deriving OAS intensity charts, we provided a tool to estimate the reliability of functional connectomes. These charts could be of great help when designing and analyzing fMRI experiments and, in particular, when conducting dynamic connectivity studies.</p>
    </sec>
    <sec sec-type="supplementary-material" id="SM1">
      <title>Supplementary Material</title>
      <supplementary-material id="SD1" position="float" content-type="local-data">
        <label>1</label>
        <media xlink:href="NIHMS1812866-supplement-1.pdf" id="d64e2962" position="anchor"/>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack id="S40">
      <title>Acknowledgments</title>
      <p id="P57">This work has been funded in part by the National Institute of Health (NIH) grant number P30AG066546 (South Texas Alzheimer’s Disease Research Center). Data were provided by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the <ext-link xlink:href="https://doi.org/10.13039/100000135" ext-link-type="uri">NIH Blueprint for Neuroscience Research</ext-link>; and by the McDonnell Center for Systems Neuroscience at Washington University.</p>
    </ack>
    <fn-group>
      <fn fn-type="COI-statement" id="FN1">
        <p id="P58">Declaration of Competing Interest</p>
        <p id="P59">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
      </fn>
      <fn id="FN2">
        <p id="P60">Credit authorship contribution statement</p>
        <p id="P61"><bold>Nicolas Honnorat:</bold> Conceptualization, Methodology, Formal analysis, Writing – original draft, Writing – review &amp; editing. <bold>Mohamad Habes:</bold> Supervision, Writing – original draft, Writing – review &amp; editing, Funding acquisition.</p>
      </fn>
      <fn id="FN3">
        <p id="P62">Supplementary material</p>
        <p id="P63">Supplementary material associated with this article can be found, in the online version, at doi: <ext-link xlink:href="10.1016/j.neuroimage.2022.119229" ext-link-type="doi">10.1016/j.neuroimage.2022.119229</ext-link></p>
      </fn>
    </fn-group>
    <sec sec-type="data-availability" id="S39">
      <title>Data and code availability statement</title>
      <p id="P56">The data were provided by the HCP consortium (<ext-link xlink:href="https://www.humanconnectome.org/" ext-link-type="uri">https://www.humanconnectome.org</ext-link>) and the ABIDE consortium (<ext-link xlink:href="http://preprocessed-connectomes-project.org/abide/index.html" ext-link-type="uri">http://preprocessed-connectomes-project.org/abide/index.html</ext-link>). The nlshrink library (version 1.0.1, <ext-link xlink:href="https://cran.r-project.org/web/packages/nlshrink/index.html" ext-link-type="uri">https://cran.r-project.org/web/packages/nlshrink/index.html</ext-link>) was the only external covariance shrinkage method package used in this work. All the other methods were either re-implemented or specifically developed during this project. A clean copy of these methods is freely available under a MIT licence in the following GitHub repository: <ext-link xlink:href="https://github.com/UTHSCSA-NAL/shrinkage" ext-link-type="uri">https://github.com/UTHSCSA-NAL/shrinkage</ext-link>.</p>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="R1">
        <mixed-citation publication-type="journal"><name><surname>Abadir</surname><given-names>K</given-names></name>, <name><surname>Distaso</surname><given-names>W</given-names></name>, <name><surname>Žikeš</surname><given-names>F</given-names></name>, <year>2014</year>. <article-title>Design-free estimation of variance matrices</article-title>. <source>J Econom</source>
<volume>181</volume> (<issue>2</issue>), <fpage>165</fpage>–<lpage>180</lpage>.</mixed-citation>
      </ref>
      <ref id="R2">
        <mixed-citation publication-type="webpage"><source>Alzheimer’s Disease Neuro Imaging III (ADNI3) MRI Analysis User Document</source>, <year>2021</year>. <comment>Accessed</comment>
<date-in-citation>December 6, 2021</date-in-citation>. <comment><ext-link xlink:href="http://adni.loni.usc.edu/wp-content/themes/freshnews-dev-v2/documents/mri/ADNI3_MRI_Analysis_Manual_20180202.pdf" ext-link-type="uri">http://adni.loni.usc.edu/wp-content/themes/freshnews-dev-v2/documents/mri/ADNI3_MRI_Analysis_Manual_20180202.pdf</ext-link>.</comment></mixed-citation>
      </ref>
      <ref id="R3">
        <mixed-citation publication-type="journal"><name><surname>Anderson</surname><given-names>JS</given-names></name>, <name><surname>Ferguson</surname><given-names>MA</given-names></name>, <name><surname>Larson</surname><given-names>ML</given-names></name>, <name><surname>Todd</surname><given-names>DY</given-names></name>, <year>2011</year>. <article-title>Reproducibility of single–subject functional connectivity measurements</article-title>. <source>American Journal of Neuroradiology</source>
<volume>32</volume> (<issue>3</issue>), <fpage>548</fpage>–<lpage>555</lpage>.<pub-id pub-id-type="pmid">21273356</pub-id></mixed-citation>
      </ref>
      <ref id="R4">
        <mixed-citation publication-type="journal"><name><surname>Bien</surname><given-names>J</given-names></name>, <name><surname>Tibshirani</surname><given-names>R</given-names></name>, <year>2011</year>. <article-title>Sparse estimation of a covariance matrix</article-title>. <source>Biometrika</source>
<volume>98</volume> (<issue>4</issue>), <fpage>807</fpage>–<lpage>820</lpage>.<pub-id pub-id-type="pmid">23049130</pub-id></mixed-citation>
      </ref>
      <ref id="R5">
        <mixed-citation publication-type="journal"><name><surname>Birn</surname><given-names>R</given-names></name>, <name><surname>Molloy</surname><given-names>E</given-names></name>, <name><surname>Patriat</surname><given-names>R</given-names></name>, <name><surname>Parker</surname><given-names>T</given-names></name>, <name><surname>Meier</surname><given-names>T</given-names></name>, <name><surname>Kirk</surname><given-names>G</given-names></name>, <name><surname>Nair</surname><given-names>V</given-names></name>, <name><surname>Meyerand</surname><given-names>M</given-names></name>, <name><surname>Prabhakaran</surname><given-names>V</given-names></name>, <year>2013</year>. <article-title>The effect of scan length on the reliability of resting-state fMRI connectivity estimates</article-title>. <source>Neuroimage</source>
<volume>83</volume>, <fpage>550</fpage>–<lpage>558</lpage>.<pub-id pub-id-type="pmid">23747458</pub-id></mixed-citation>
      </ref>
      <ref id="R6">
        <mixed-citation publication-type="journal"><name><surname>Buckner</surname><given-names>RL</given-names></name>, <name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name>, <name><surname>Schacter</surname><given-names>DL</given-names></name>, <year>2008</year>. <article-title>The brain’s default network, anatomy, function, and relevance to disease</article-title>. <source>Ann. N. Y. Acad. Sci</source>
<fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
      </ref>
      <ref id="R7">
        <mixed-citation publication-type="journal"><name><surname>Bullmore</surname><given-names>E</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2009</year>. <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nat. Rev. Neurosci</source>
<volume>10</volume>, <fpage>186</fpage>–<lpage>198</lpage>.<pub-id pub-id-type="pmid">19190637</pub-id></mixed-citation>
      </ref>
      <ref id="R8">
        <mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>C</given-names></name>, <name><surname>Glover</surname><given-names>G</given-names></name>, <year>2010</year>. <article-title>Time-frequency dynamics of resting-state brain connectivity measured with fMRI</article-title>. <source>Neuroimage</source>
<volume>50</volume>, <fpage>81</fpage>–<lpage>98</lpage>.<pub-id pub-id-type="pmid">20006716</pub-id></mixed-citation>
      </ref>
      <ref id="R9">
        <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Wiesel</surname><given-names>A</given-names></name>, <name><surname>Eldar</surname><given-names>Y</given-names></name>, <name><surname>Hero</surname><given-names>A</given-names></name>, <year>2010</year>. <article-title>Shrinkage algorithms for mmse covariance estimation</article-title>. <source>IEEE Trans. Signal Process</source>
<volume>58</volume> (<issue>10</issue>), <fpage>5016</fpage>–<lpage>5029</lpage>.</mixed-citation>
      </ref>
      <ref id="R10">
        <mixed-citation publication-type="journal"><name><surname>Craddock</surname><given-names>C</given-names></name>, <name><surname>Benhajali</surname><given-names>Y</given-names></name>, <name><surname>Chu</surname><given-names>C</given-names></name>, <name><surname>Chouinard</surname><given-names>F</given-names></name>, <name><surname>Evans</surname><given-names>A</given-names></name>, <name><surname>Jakab</surname><given-names>A</given-names></name>, <name><surname>Khundrakpam</surname><given-names>B</given-names></name>, <name><surname>Lewis</surname><given-names>JD</given-names></name>, <name><surname>Li</surname><given-names>Q</given-names></name>, <name><surname>Milham</surname><given-names>M</given-names></name>, <name><surname>Yan</surname><given-names>C</given-names></name>, <name><surname>Bellec</surname><given-names>P</given-names></name>, <year>2013</year>. <article-title>The neuro bureau preprocessing initiative: open sharing of preprocessed neuroimaging data and derivatives</article-title>. in: <source>Neuroinformatics 2013</source>.</mixed-citation>
      </ref>
      <ref id="R11">
        <mixed-citation publication-type="journal"><name><surname>Craddock</surname><given-names>C</given-names></name>, <name><surname>Sikka</surname><given-names>S</given-names></name>, <name><surname>Cheung</surname><given-names>B</given-names></name>, <name><surname>Khanuja</surname><given-names>R</given-names></name>, <name><surname>Ghosh</surname><given-names>S</given-names></name>, <name><surname>Yan</surname><given-names>C</given-names></name>, <name><surname>Li</surname><given-names>Q</given-names></name>, <name><surname>Lurie</surname><given-names>D</given-names></name>, <name><surname>Vogelstein</surname><given-names>J</given-names></name>, <name><surname>Burns</surname><given-names>R</given-names></name>, <name><surname>Colcombe</surname><given-names>S</given-names></name>, <name><surname>Mennes</surname><given-names>M</given-names></name>, <name><surname>Kelly</surname><given-names>C</given-names></name>, <name><surname>Martino</surname><given-names>AD</given-names></name>, <name><surname>Castellanos</surname><given-names>F</given-names></name>, <name><surname>Milham</surname><given-names>M</given-names></name>, <year>2013</year>. <article-title>Towards automated analysis of connectomes: the configurable pipeline for the analysis of connectomes (C-PAC)</article-title>. <source>Front Neuroinform</source> (<volume>42</volume>).</mixed-citation>
      </ref>
      <ref id="R12">
        <mixed-citation publication-type="journal"><name><surname>Daniels</surname><given-names>M</given-names></name>, <name><surname>Kass</surname><given-names>R</given-names></name>, <year>2001</year>. <article-title>Shrinkage estimators for covariance matrices</article-title>. <source>Biometrics</source>
<volume>57</volume> (<issue>4</issue>), <fpage>1173</fpage>–<lpage>1184</lpage>.<pub-id pub-id-type="pmid">11764258</pub-id></mixed-citation>
      </ref>
      <ref id="R13">
        <mixed-citation publication-type="journal"><name><surname>Deligianni</surname><given-names>F</given-names></name>, <name><surname>Centeno</surname><given-names>M</given-names></name>, <name><surname>Carmichael</surname><given-names>D</given-names></name>, <name><surname>Clayden</surname><given-names>J</given-names></name>, <year>2014</year>. <article-title>Relating resting-state fMRI and EEG whole-brain connectomes across frequency bands</article-title>. <source>Front Neurosci</source>
<volume>8</volume>, <fpage>258</fpage>.<pub-id pub-id-type="pmid">25221467</pub-id></mixed-citation>
      </ref>
      <ref id="R14">
        <mixed-citation publication-type="journal"><name><surname>Dijk</surname><given-names>KV</given-names></name>, <name><surname>Hedden</surname><given-names>T</given-names></name>, <name><surname>Venkataraman</surname><given-names>A</given-names></name>, <name><surname>Evans</surname><given-names>K</given-names></name>, <name><surname>Lazar</surname><given-names>S</given-names></name>, <name><surname>Buckner</surname><given-names>R</given-names></name>, <year>2010</year>. <article-title>Intrinsic functional connectivity as a tool for human connectomics: theory, properties, and optimization</article-title>. <source>J. Neurophysiol</source>
<volume>103</volume>, <fpage>297</fpage>–<lpage>321</lpage>.<pub-id pub-id-type="pmid">19889849</pub-id></mixed-citation>
      </ref>
      <ref id="R15">
        <mixed-citation publication-type="journal"><name><surname>Essen</surname><given-names>DCV</given-names></name>, <name><surname>Smith</surname><given-names>S</given-names></name>, <name><surname>Barch</surname><given-names>D</given-names></name>, <name><surname>Behrens</surname><given-names>T</given-names></name>, <name><surname>Yacoub</surname><given-names>E</given-names></name>, <year>2013</year>. <article-title>K. ugurbil for the WU-Minn HCP consortium., the wu-minn human connectome project: an overview</article-title>. <source>Neuroimage</source>
<volume>80</volume>, <fpage>62</fpage>–<lpage>79</lpage>.<pub-id pub-id-type="pmid">23684880</pub-id></mixed-citation>
      </ref>
      <ref id="R16">
        <mixed-citation publication-type="journal"><name><surname>Feinberg</surname><given-names>D</given-names></name>, <name><surname>Setsompop</surname><given-names>K</given-names></name>, <year>2013</year>. <article-title>Ultra-fast mri of the human brain with simultaneous multi-slice imaging</article-title>. <source>J. Magn. Reson</source>
<volume>229</volume>, <fpage>90</fpage>–<lpage>100</lpage>.<pub-id pub-id-type="pmid">23473893</pub-id></mixed-citation>
      </ref>
      <ref id="R17">
        <mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>M</given-names></name>, <name><surname>Raichle</surname><given-names>ME</given-names></name>, <year>2007</year>. <article-title>Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging</article-title>. <source>Nat. Rev. Neurosci</source>
<volume>8</volume>, <fpage>700</fpage>–<lpage>711</lpage>.<pub-id pub-id-type="pmid">17704812</pub-id></mixed-citation>
      </ref>
      <ref id="R18">
        <mixed-citation publication-type="journal"><name><surname>Fritsch</surname><given-names>V</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Thyreau</surname><given-names>B</given-names></name>, <name><surname>Poline</surname><given-names>J</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <year>2012</year>. <article-title>Detecting outliers in high-dimensional neuroimaging datasets with robust covariance estimator</article-title>. <source>Med Image Anal</source>
<volume>16</volume>, <fpage>1359</fpage>–<lpage>1370</lpage>.<pub-id pub-id-type="pmid">22728304</pub-id></mixed-citation>
      </ref>
      <ref id="R19">
        <mixed-citation publication-type="journal"><name><surname>Glasser</surname><given-names>M</given-names></name>, <name><surname>Coalson</surname><given-names>T</given-names></name>, <name><surname>Robinson</surname><given-names>E</given-names></name>, <name><surname>Hacker</surname><given-names>C</given-names></name>, <name><surname>Harwell</surname><given-names>J</given-names></name>, <name><surname>Yacoub</surname><given-names>E</given-names></name>, <name><surname>Ugurbil</surname><given-names>K</given-names></name>, <name><surname>Andersson</surname><given-names>J</given-names></name>, <name><surname>Beckmann</surname><given-names>C</given-names></name>, <name><surname>Jenkinson</surname><given-names>M</given-names></name>, <name><surname>Smith</surname><given-names>S</given-names></name>, <name><surname>Essen</surname><given-names>DV</given-names></name>, <year>2016</year>. <article-title>A multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source>
<volume>536</volume>, <fpage>171</fpage>–<lpage>178</lpage>.<pub-id pub-id-type="pmid">27437579</pub-id></mixed-citation>
      </ref>
      <ref id="R20">
        <mixed-citation publication-type="journal"><name><surname>Glasser</surname><given-names>S</given-names></name>, <name><surname>Wilson</surname><given-names>C</given-names></name>, <name><surname>Fischl</surname><given-names>A</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Webster</surname><given-names>P</given-names></name>, <name><surname>Van Essen</surname><given-names>J</given-names></name>, <year>2013</year>. <article-title>Neuroimage</article-title>. <source>The minimal preprocessing pipelines for the Human Connectome Project</source>
<volume>80</volume>, <fpage>105</fpage>–<lpage>124</lpage>.</mixed-citation>
      </ref>
      <ref id="R21">
        <mixed-citation publication-type="journal"><name><surname>Gonzalez-Castillo</surname><given-names>J</given-names></name>, <name><surname>Handwerker</surname><given-names>DA</given-names></name>, <name><surname>Robinson</surname><given-names>ME</given-names></name>, <name><surname>Hoy</surname><given-names>CW</given-names></name>, <name><surname>Buchanan</surname><given-names>LC</given-names></name>, <name><surname>Saad</surname><given-names>ZS</given-names></name>, <name><surname>Bandettini</surname><given-names>PA</given-names></name>, <year>2014</year>. <article-title>The spatial structure of resting state connectivity stability on the scale of minutes</article-title>. <source>Front Neurosci</source>
<volume>8</volume> (<issue>138</issue>).</mixed-citation>
      </ref>
      <ref id="R22">
        <mixed-citation publication-type="journal"><name><surname>Honnorat</surname><given-names>N</given-names></name>, <name><surname>Davatzikos</surname><given-names>C</given-names></name>, <year>2017</year>. <article-title>Riccati-regularized Precision Matrices for Neuroimaging</article-title>. In: <source>Information Processing in Medical Imaging (IPMI)</source>, pp. <fpage>275</fpage>–<lpage>286</lpage>.</mixed-citation>
      </ref>
      <ref id="R23">
        <mixed-citation publication-type="journal"><name><surname>Lam</surname><given-names>C</given-names></name>, <year>2016</year>. <article-title>Nonparametric eigenvalue-regularized precision or covariance matrix estimator</article-title>. <source>The Annals of Statistics</source>
<volume>44</volume> (<issue>3</issue>), <fpage>928</fpage>–<lpage>953</lpage>.</mixed-citation>
      </ref>
      <ref id="R24">
        <mixed-citation publication-type="journal"><name><surname>Ledoit</surname><given-names>O</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>, <year>2003</year>. <article-title>Improved estimation of the covariance matrix of stock returns with an application to portfolio selection</article-title>. <source>Journal of Empirical Finance</source>
<volume>10</volume> (<issue>5</issue>), <fpage>603</fpage>–<lpage>621</lpage>.</mixed-citation>
      </ref>
      <ref id="R25">
        <mixed-citation publication-type="journal"><name><surname>Ledoit</surname><given-names>O</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>, <year>2004</year>. <article-title>A well-conditioned estimator for large-dimensional covariance matrices</article-title>. <source>J Multivar Anal</source>
<volume>88</volume> (<issue>2</issue>), <fpage>365</fpage>–<lpage>411</lpage>.</mixed-citation>
      </ref>
      <ref id="R26">
        <mixed-citation publication-type="journal"><name><surname>Ledoit</surname><given-names>O</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>, <year>2012</year>. <article-title>Nonlinear shrinkage estimation of large-dimensional covariance matrices</article-title>. <source>Ann Stat</source>
<volume>40</volume> (<issue>2</issue>), <fpage>1024</fpage>–<lpage>1060</lpage>.</mixed-citation>
      </ref>
      <ref id="R27">
        <mixed-citation publication-type="journal"><name><surname>Ledoit</surname><given-names>O</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>, <year>2015</year>. <article-title>Spectrum estimation: a unified framework for covariance matrix estimation and pca in large dimensions</article-title>. <source>J Multivar Anal</source>
<volume>139</volume> (<issue>2</issue>), <fpage>360</fpage>–<lpage>384</lpage>.</mixed-citation>
      </ref>
      <ref id="R28">
        <mixed-citation publication-type="journal"><name><surname>Ledoit</surname><given-names>O</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>, <year>2017</year>. <article-title>Numerical implementation of the quest function. Computational Statistics &amp;</article-title>
<source>Data Analysis</source>
<volume>115</volume>, <fpage>199</fpage>–<lpage>223</lpage>.</mixed-citation>
      </ref>
      <ref id="R29">
        <mixed-citation publication-type="journal"><name><surname>Ledoit</surname><given-names>O</given-names></name>, <name><surname>Wolf</surname><given-names>M</given-names></name>, <year>2020</year>. <article-title>Analytical nonlinear shrinkage of large-dimensional covariance matrices</article-title>. <source>The Annals of Statistics</source>
<volume>48</volume> (<issue>5</issue>), <fpage>3043</fpage>–<lpage>3065</lpage>.</mixed-citation>
      </ref>
      <ref id="R30">
        <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>H</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <name><surname>Zhao</surname><given-names>T</given-names></name>, <year>2014</year>. <article-title>Sparse covariance matrix estimation with eigenvalue constraints</article-title>. <source>Journal of computational and graphical statistics</source>
<volume>23</volume> (<issue>2</issue>), <fpage>439</fpage>–<lpage>459</lpage>.<pub-id pub-id-type="pmid">25620866</pub-id></mixed-citation>
      </ref>
      <ref id="R31">
        <mixed-citation publication-type="journal"><name><surname>Martino</surname><given-names>AD</given-names></name>, <name><surname>Yan</surname><given-names>C</given-names></name>, <name><surname>Li</surname><given-names>Q</given-names></name>, <name><surname>Denio</surname><given-names>E</given-names></name>, <name><surname>Castellanos</surname><given-names>FX</given-names></name>, <name><surname>Alaerts</surname><given-names>K</given-names></name>, <name><surname>Anderson</surname><given-names>J</given-names></name>, <name><surname>Assaf</surname><given-names>M</given-names></name>, <name><surname>Bookheimer</surname><given-names>S</given-names></name>, <name><surname>Dapretto</surname><given-names>M</given-names></name>, <name><surname>Deen</surname><given-names>B</given-names></name>, <name><surname>Delmonte</surname><given-names>S</given-names></name>, <name><surname>Dinstein</surname><given-names>I</given-names></name>, <name><surname>Ertl-Wagner</surname><given-names>B</given-names></name>, <name><surname>Fair</surname><given-names>D</given-names></name>, <name><surname>Gallagher</surname><given-names>L</given-names></name>, <name><surname>Kennedy</surname><given-names>DP</given-names></name>, <name><surname>Keown</surname><given-names>CL</given-names></name>, <name><surname>Keysers</surname><given-names>C</given-names></name>, <name><surname>Lainhart</surname><given-names>J</given-names></name>, <name><surname>Lord</surname><given-names>C</given-names></name>, <name><surname>Luna</surname><given-names>B</given-names></name>, <name><surname>Menon</surname><given-names>V</given-names></name>, <name><surname>Minshew</surname><given-names>N</given-names></name>, <name><surname>Monk</surname><given-names>C</given-names></name>, <name><surname>Mueller</surname><given-names>S</given-names></name>, <name><surname>Müller</surname><given-names>R-A</given-names></name>, <name><surname>Nebel</surname><given-names>M</given-names></name>, <name><surname>Nigg</surname><given-names>J</given-names></name>, <name><surname>O’Hearn</surname><given-names>K</given-names></name>, <name><surname>Pelphrey</surname><given-names>K</given-names></name>, <name><surname>Peltier</surname><given-names>S</given-names></name>, <name><surname>Rudie</surname><given-names>J</given-names></name>, <name><surname>Sunaert</surname><given-names>S</given-names></name>, <name><surname>Thioux</surname><given-names>M</given-names></name>, <name><surname>Tyszka</surname><given-names>J</given-names></name>, <name><surname>Uddin</surname><given-names>L</given-names></name>, <name><surname>Verhoeven</surname><given-names>J</given-names></name>, <name><surname>Wenderoth</surname><given-names>N</given-names></name>, <name><surname>Wiggins</surname><given-names>J</given-names></name>, <name><surname>Mostofsky</surname><given-names>S</given-names></name>, <name><surname>Milham</surname><given-names>M</given-names></name>, <year>2014</year>. <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>. <source>Mol. Psychiatry</source>
<volume>19</volume> (<issue>6</issue>), <fpage>659</fpage>–<lpage>667</lpage>.<pub-id pub-id-type="pmid">23774715</pub-id></mixed-citation>
      </ref>
      <ref id="R32">
        <mixed-citation publication-type="journal"><name><surname>Mejia</surname><given-names>A</given-names></name>, <name><surname>Nebel</surname><given-names>M</given-names></name>, <name><surname>Barber</surname><given-names>A</given-names></name>, <name><surname>Choe</surname><given-names>A</given-names></name>, <name><surname>Pekar</surname><given-names>B</given-names></name>, <name><surname>Caffo</surname><given-names>J.J.a.</given-names></name>, <name><surname>Lindquist</surname><given-names>M</given-names></name>, <year>2018</year>. <article-title>Improved estimation of subject-level functional connectivity using full and partial correlation with empirical bayes shrinkage</article-title>. <source>Neuroimage</source>
<fpage>478</fpage>–<lpage>491</lpage>.</mixed-citation>
      </ref>
      <ref id="R33">
        <mixed-citation publication-type="journal"><name><surname>Mejia</surname><given-names>A</given-names></name>, <name><surname>Nebel</surname><given-names>M</given-names></name>, <name><surname>Shou</surname><given-names>H</given-names></name>, <name><surname>Crainiceanu</surname><given-names>C</given-names></name>, <name><surname>Pekar</surname><given-names>J</given-names></name>, <name><surname>Mostofsky</surname><given-names>S</given-names></name>, <name><surname>Caffo</surname><given-names>B</given-names></name>, <name><surname>Lindquist</surname><given-names>M</given-names></name>, <year>2015</year>. <article-title>Improving reliability of subject-level resting-state fMRI parcellation with shrinkage estimators</article-title>. <source>Neuroimage</source> (<issue>112</issue>) <fpage>14</fpage>–<lpage>29</lpage>.</mixed-citation>
      </ref>
      <ref id="R34">
        <mixed-citation publication-type="journal"><name><surname>Moeller</surname><given-names>S</given-names></name>, <name><surname>Yacoub</surname><given-names>E</given-names></name>, <name><surname>Olman</surname><given-names>C</given-names></name>, <name><surname>Auerbach</surname><given-names>E</given-names></name>, <name><surname>Strupp</surname><given-names>J</given-names></name>, <name><surname>Harel</surname><given-names>N</given-names></name>, <name><surname>U ğurbil</surname><given-names>K</given-names></name>, <year>2010</year>. <article-title>Multiband multislice GE-EPI at 7 tesla, with 16-fold acceleration using partial parallel imaging with application to high spatial and temporal whole-brain fMRI</article-title>. <source>Magn Reson Med</source>
<volume>63</volume> (<issue>5</issue>), <fpage>1144</fpage>–<lpage>1153</lpage>.<pub-id pub-id-type="pmid">20432285</pub-id></mixed-citation>
      </ref>
      <ref id="R35">
        <mixed-citation publication-type="book"><name><surname>Ng</surname><given-names>B</given-names></name>, <name><surname>Abugharbieh</surname><given-names>R</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Poline</surname><given-names>J</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <year>2011</year>. <source>Connectivity-informed fMRI Activation Detection</source>. In: <publisher-name>Medical Image Computing and Computer-Assisted Intervention (MICCAI)</publisher-name>, pp. <fpage>285</fpage>–<lpage>292</lpage>.</mixed-citation>
      </ref>
      <ref id="R36">
        <mixed-citation publication-type="book"><name><surname>Ng</surname><given-names>B</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Poline</surname><given-names>J</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <year>2012</year>. <source>A Novel Sparse Graphical Approach for Multimodal Brain Connectivity Inference</source>. <publisher-name>Medical Image Computing and Computer-Assisted Intervention (MICCAI)</publisher-name>.</mixed-citation>
      </ref>
      <ref id="R37">
        <mixed-citation publication-type="journal"><name><surname>Ng</surname><given-names>B</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Poline</surname><given-names>J</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <year>2013</year>. <article-title>A Novel Sparse Group Gaussian Graphical Model for Functional Connectivity Estimation</article-title>. <source>Information Processing in Medical Imaging (IPMI)</source>.</mixed-citation>
      </ref>
      <ref id="R38">
        <mixed-citation publication-type="journal"><name><surname>Noble</surname><given-names>S</given-names></name>, <name><surname>Scheinost</surname><given-names>D</given-names></name>, <name><surname>Constable</surname><given-names>R</given-names></name>, <year>2019</year>. <article-title>A decade of test-retest reliability of functional connectivity: a systematic review and meta-analysis</article-title>. <source>Neuroimage</source>
<volume>203</volume>, <fpage>11615</fpage>.</mixed-citation>
      </ref>
      <ref id="R39">
        <mixed-citation publication-type="journal"><name><surname>Power</surname><given-names>J</given-names></name>, <name><surname>Mitra</surname><given-names>A</given-names></name>, <name><surname>Laumann</surname><given-names>T</given-names></name>, <name><surname>Snyder</surname><given-names>A</given-names></name>, <name><surname>Schlaggar</surname><given-names>B</given-names></name>, <name><surname>Petersen</surname><given-names>S</given-names></name>, <year>2014</year>. <article-title>Methods to detect, characterize, and remove motion artifact in resting state fMRI</article-title>. <source>Neuroimage</source>
<volume>84</volume>, <fpage>320</fpage>–<lpage>341</lpage>.<pub-id pub-id-type="pmid">23994314</pub-id></mixed-citation>
      </ref>
      <ref id="R40">
        <mixed-citation publication-type="journal"><name><surname>Rahim</surname><given-names>M</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <year>2019</year>. <article-title>Population shrinkage of covariance (posce) for better individual brain functional-connectivity estimation</article-title>. <source>Med Image Anal</source>
<volume>54</volume>, <fpage>138</fpage>–<lpage>148</lpage>.<pub-id pub-id-type="pmid">30903965</pub-id></mixed-citation>
      </ref>
      <ref id="R41">
        <mixed-citation publication-type="journal"><name><surname>Rajaratnam</surname><given-names>B</given-names></name>, <name><surname>Vincenzi</surname><given-names>D</given-names></name>, <year>2016</year>. <article-title>A theoretical study of stein’s covariance estimator</article-title>. <source>Biometrika</source>
<volume>103</volume> (<issue>3</issue>), <fpage>653</fpage>–<lpage>666</lpage>.</mixed-citation>
      </ref>
      <ref id="R42">
        <mixed-citation publication-type="journal"><name><surname>Risk</surname><given-names>B</given-names></name>, <name><surname>Murden</surname><given-names>R</given-names></name>, <name><surname>Wu</surname><given-names>J</given-names></name>, <name><surname>Nebel</surname><given-names>M</given-names></name>, <name><surname>Venkataraman</surname><given-names>A</given-names></name>, <name><surname>Zhang</surname><given-names>Z</given-names></name>, <name><surname>Qiu</surname><given-names>D</given-names></name>, <year>2021</year>. <article-title>Which multiband factor should you choose for your resting-state fMRI study?</article-title>
<source>Neuroimage</source>
<volume>234</volume>, <fpage>117965</fpage>.<pub-id pub-id-type="pmid">33744454</pub-id></mixed-citation>
      </ref>
      <ref id="R43">
        <mixed-citation publication-type="journal"><name><surname>Rubinov</surname><given-names>M</given-names></name>, <name><surname>Sporns</surname><given-names>O</given-names></name>, <year>2010</year>. <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source>
<volume>52</volume> (<issue>3</issue>), <fpage>1059</fpage>–<lpage>1069</lpage>.<pub-id pub-id-type="pmid">19819337</pub-id></mixed-citation>
      </ref>
      <ref id="R44">
        <mixed-citation publication-type="journal"><name><surname>Schäfer</surname><given-names>J</given-names></name>, <name><surname>Strimmer</surname><given-names>K</given-names></name>, <year>2005</year>. <article-title>A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics</article-title>. <source>Stat Appl Genet Mol Biol</source>
<volume>4</volume> (<issue>1</issue>), <fpage>32</fpage>.</mixed-citation>
      </ref>
      <ref id="R45">
        <mixed-citation publication-type="journal"><name><surname>Shehzad</surname><given-names>Z</given-names></name>, <name><surname>Kelly</surname><given-names>A</given-names></name>, <name><surname>Reiss</surname><given-names>P</given-names></name>, <name><surname>Gee</surname><given-names>D</given-names></name>, <name><surname>Gotimer</surname><given-names>K</given-names></name>, <name><surname>Uddin</surname><given-names>L</given-names></name>, <name><surname>Lee</surname><given-names>S</given-names></name>, <name><surname>Margulies</surname><given-names>D</given-names></name>, <name><surname>Roy</surname><given-names>A</given-names></name>, <name><surname>Biswal</surname><given-names>B</given-names></name>, <name><surname>Petkova</surname><given-names>E</given-names></name>, <name><surname>Castellanos</surname><given-names>F</given-names></name>, <name><surname>Milham</surname><given-names>M</given-names></name>, <year>2009</year>. <article-title>The resting brain: unconstrained yet reliable</article-title>. <source>Cerebral Cortex</source>
<volume>19</volume>, <fpage>2209</fpage>–<lpage>2229</lpage>.<pub-id pub-id-type="pmid">19221144</pub-id></mixed-citation>
      </ref>
      <ref id="R46">
        <mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>SM</given-names></name>, <name><surname>Miller</surname><given-names>KL</given-names></name>, <name><surname>Salimi-Khorshidi</surname><given-names>G</given-names></name>, <name><surname>Webster</surname><given-names>M</given-names></name>, <name><surname>Beckmann</surname><given-names>CF</given-names></name>, <name><surname>Nichols</surname><given-names>TE</given-names></name>, <name><surname>Ramsey</surname><given-names>JD</given-names></name>, <name><surname>Woolrich</surname><given-names>MW</given-names></name>, <year>2011</year>. <article-title>Network modelling methods for fMRI</article-title>. <source>Neuroimage</source>
<volume>54</volume>, <fpage>875</fpage>–<lpage>891</lpage>.<pub-id pub-id-type="pmid">20817103</pub-id></mixed-citation>
      </ref>
      <ref id="R47">
        <mixed-citation publication-type="journal"><name><surname>Smitha</surname><given-names>K</given-names></name>, <name><surname>Arun</surname><given-names>K</given-names></name>, <name><surname>Rajesh</surname><given-names>P</given-names></name>, <name><surname>Joel</surname><given-names>S</given-names></name>, <name><surname>Venkatesan</surname><given-names>R</given-names></name>, <name><surname>Thomas</surname><given-names>B</given-names></name>, <name><surname>Kesavadas</surname><given-names>C</given-names></name>, <year>2018</year>. <article-title>Multiband fmri as a plausible, time-saving technique for resting-state data acquisition: study on functional connectivity mapping using graph theoretical measures</article-title>. <source>Magn Reson Imaging</source>
<volume>53</volume>, <fpage>1</fpage>–<lpage>6</lpage>.<pub-id pub-id-type="pmid">29928936</pub-id></mixed-citation>
      </ref>
      <ref id="R48">
        <mixed-citation publication-type="confproc"><name><surname>Stein</surname><given-names>C</given-names></name>, <year>1975</year>. <article-title>Estimation of a Covariance Matrix, Rietz Lecture</article-title>. <conf-name>39th Annual Meeting IMS</conf-name>, <conf-loc>Atlanta, Georgia</conf-loc>.</mixed-citation>
      </ref>
      <ref id="R49">
        <mixed-citation publication-type="journal"><name><surname>Stein</surname><given-names>C</given-names></name>, <year>1986</year>. <article-title>Lectures on the theory of estimation of many parameters</article-title>. <source>Journal of Mathematical Sciences</source>
<volume>1</volume> (<issue>34</issue>), <fpage>1373</fpage>–<lpage>1403</lpage>.</mixed-citation>
      </ref>
      <ref id="R50">
        <mixed-citation publication-type="journal"><name><surname>Stokes</surname><given-names>P</given-names></name>, <name><surname>Purdon</surname><given-names>P</given-names></name>, <year>2017</year>. <article-title>A study of problems encountered in granger causality analysis from a neuroscience perspective</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America (PNAS)</source>
<volume>114</volume> (<issue>34</issue>). <fpage>E7063</fpage>–<lpage>E7072</lpage><pub-id pub-id-type="pmid">28778996</pub-id></mixed-citation>
      </ref>
      <ref id="R51">
        <mixed-citation publication-type="journal"><name><surname>Tremblay-Mercier</surname><given-names>J</given-names></name>, <name><surname>Madjar</surname><given-names>C</given-names></name>, <name><surname>Das</surname><given-names>S</given-names></name>, <name><surname>Binette</surname><given-names>AP</given-names></name>, <name><surname>Dyke</surname><given-names>S</given-names></name>, <name><surname>Étienne</surname><given-names>P</given-names></name>, <name><surname>Lafaille-Magnan</surname><given-names>M</given-names></name>, <name><surname>Remz</surname><given-names>J</given-names></name>, <name><surname>Bellec</surname><given-names>P</given-names></name>, <name><surname>Collins</surname><given-names>DL</given-names></name>, <name><surname>Rajah</surname><given-names>MN</given-names></name>, <name><surname>Bohbot</surname><given-names>V</given-names></name>, <name><surname>Leoutsakos</surname><given-names>J</given-names></name>, <name><surname>Iturria-Medina</surname><given-names>Y</given-names></name>, <name><surname>Kat</surname><given-names>J</given-names></name>, <name><surname>Hoge</surname><given-names>R</given-names></name>, <name><surname>Gauthier</surname><given-names>S</given-names></name>, <name><surname>Tardif</surname><given-names>C</given-names></name>, <name><surname>Chakravarty</surname><given-names>MM</given-names></name>, <name><surname>Poline</surname><given-names>J</given-names></name>, <name><surname>Rosa-Neto</surname><given-names>P</given-names></name>, <name><surname>Evans</surname><given-names>A</given-names></name>, <name><surname>Villeneuve</surname><given-names>S</given-names></name>, <name><surname>Poirier</surname><given-names>J</given-names></name>, <name><surname>Breitner</surname><given-names>J</given-names></name>, <year>2021</year>. <article-title>Open science datasets from prevent-ad, a longitudinal cohort of pre-symptomatic alzheimer’s disease</article-title>. <source>NeuroImage Clinical</source>
<volume>31</volume>, <fpage>102733</fpage>.<pub-id pub-id-type="pmid">34192666</pub-id></mixed-citation>
      </ref>
      <ref id="R52">
        <mixed-citation publication-type="journal"><name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Poline</surname><given-names>J</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <year>2010</year>. <article-title>Brain Covariance Selection: Better Individual Functional Connectivity Models Using Population Prior</article-title>. <source>Advances in Neural Information Processing Systems</source>.</mixed-citation>
      </ref>
      <ref id="R53">
        <mixed-citation publication-type="other"><source>WU-Minn HCP 1200 Subjects Data Release: Reference manual</source>, <comment>updated</comment>
<month>April</month>
<day>10</day>, <year>2018</year>. <comment>Accessed</comment>
<date-in-citation>July 7, 2021</date-in-citation> (<comment>March 2017</comment>).</mixed-citation>
      </ref>
      <ref id="R54">
        <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>C</given-names></name>, <name><surname>Baum</surname><given-names>S</given-names></name>, <name><surname>Adduru</surname><given-names>V</given-names></name>, <name><surname>Biswal</surname><given-names>B</given-names></name>, <name><surname>Michael</surname><given-names>A</given-names></name>, <year>2018</year>. <article-title>Test-retest reliability of dynamic functional connectivity in resting state fMRI</article-title>. <source>Neuroimage</source>
<volume>183</volume>, <fpage>907</fpage>–<lpage>918</lpage>.<pub-id pub-id-type="pmid">30120987</pub-id></mixed-citation>
      </ref>
      <ref id="R55">
        <mixed-citation publication-type="journal"><name><surname>Zou</surname><given-names>Q</given-names></name>, <name><surname>Zhu</surname><given-names>C</given-names></name>, <name><surname>Yang</surname><given-names>Y</given-names></name>, <name><surname>Zuo</surname><given-names>X-N</given-names></name>, <name><surname>Long</surname><given-names>X-Y</given-names></name>, <name><surname>Cao</surname><given-names>Q-J</given-names></name>, <name><surname>Wang</surname><given-names>Y-F</given-names></name>, <name><surname>Zang</surname><given-names>YF</given-names></name>, <year>2008</year>. <article-title>An improved approach to detection of amplitude of low-frequency fluctuation (alff) for resting-state fmri: fractional alff</article-title>. <source>J. Neurosci. Methods</source>
<volume>172</volume> (<issue>1</issue>), <fpage>137</fpage>–<lpage>141</lpage>.<pub-id pub-id-type="pmid">18501969</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
  <floats-group>
    <fig position="float" id="F1">
      <label>Fig. 1.</label>
      <caption>
        <p id="P64">Oracle Approximating Shrinkage intensity charts for increasing correlation matrix dimensions <italic toggle="yes">p</italic>. The charts obtained for different matrix dimensions are surprisingly similar. For instance, when the connectome density is equal to 0.005, the smallest density shown here, a thousand time points correspond to a shrinkage intensity of 0.25 for a matrix of dimension p = 10, while this level corresponds to 800 time points for a matrix of dimension p = 10000. By contrast, shrinkage intensity strongly depends on the connectome density and the number of time points.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0001" position="float"/>
    </fig>
    <fig position="float" id="F2">
      <label>Fig. 2.</label>
      <caption>
        <p id="P65">Functional networks considered in this work and displayed on the cortical surface of the left hemisphere. The top row presents the HCP parcellation, with different colors for the 22 regions. The middle row shows the Default Mode Network (DMN) in green. The bottom row displays the dorsolateral prefrontal cortex (DLPFC) in green. The correlation matrices obtained for the first HCP participant and both hemipsheres are shown on the right (p denoting the number of parcels included in each network; the high-resolution HCP connectivity matrix is not shown).</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0002" position="float"/>
    </fig>
    <fig position="float" id="F3">
      <label>Fig. 3.</label>
      <caption>
        <p id="P66">Oracle Approximating Shrinkage intensities computed for HCP connectomes extracted for the entire HCP parcellation (360 parcels or 44 regions), the DLPFC network (26 parcels), and the DMN (76 parcels). For each connectome, these shrinkage intensities were overlaid over the OAS intensity charts corresponding to the dimension of the network (e.g. <italic toggle="yes">p</italic> = 26 for the DLPFC). High-resolution HCP connectomes are the sparsest and would therefore either require more shrinkage for the same number of time points or longer time series to achieve the same quality as the other functional networks.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0003" position="float"/>
    </fig>
    <fig position="float" id="F4">
      <label>Fig. 4.</label>
      <caption>
        <p id="P67">Average connectome squared L2 error obtained when comparing connectomes derived from short time series randomly extracted from the data available for an HCP participant with the connectome derived using all the data for that participant; without shrinkage (baseline) or any shrinkage method tested in this work; for all the networks, and increasing number of time points. For the high-resolution HCP connectomes, the NAS method was unstable for number of time points close to the dimension of the connectome (360). When the number of time points was smaller than the dimension of the matrix, all the methods produced very similar improvements compared to the baseline. When the number of time points was significantly larger than the dimension of the connectome, all the methods except <italic toggle="yes">N ERCOM E</italic><sub>99</sub> produced estimates close to the baseline.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0004" position="float"/>
    </fig>
    <fig position="float" id="F5">
      <label>Fig. 5.</label>
      <caption>
        <p id="P68">For all the high-resolution HCP connectomes, difference between the connectome errors measured: (A) before OAS shrinkage (baseline) and after OAS, (B) after Ledoit-Wolf and after OAS, (C) after <italic toggle="yes">QuEST</italic><sub>1</sub> and OAS, (D) after <italic toggle="yes">QuEST</italic><sub>2</sub> and OAS, as a function of the OAS error. The first two error differences are significantly positive (Wilcoxon sign-rank test p-values lower than 0.001, for a positive differences median). These results indicates that OAS significantly outperforms baseline and Ledoit-Wolf shrinkage. On the other hand, QuEST methods produced significantly better connectomes (Wilcoxon sign-rank test p-values lower than 0.001, for a negative differences median).</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0005" position="float"/>
    </fig>
    <fig position="float" id="F6">
      <label>Fig. 6.</label>
      <caption>
        <p id="P69">For the high-resolution HCP network, comparison between the connectome alterations introduced by the OAS and (A) Ledoit-Wolf shrinkage (LW), (B) the nonlinear analytical shrinkage method (NAS), (C) the best NERCOME method (<italic toggle="yes">N ERCOM E</italic><sub>90</sub>), (D) QuEST implemented using the first solver (<italic toggle="yes">QuEST</italic><sub>1</sub>), and (E) QuEST implemented using the second solver (<italic toggle="yes">QuEST</italic><sub>2</sub>). In B, a few outliers were obtained when the NAS method diverged for number of time points close to the dimension of the matrix.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0006" position="float"/>
    </fig>
    <fig position="float" id="F7">
      <label>Fig. 7.</label>
      <caption>
        <p id="P70">When connectomes are thresholded at correlations larger than 0.3 (<italic toggle="yes">τ</italic> = 0. 3), precision, accuracy and Jaccard index measured with and without OAS for increasing number of time points and (A) high-resolution HCP parcellation, and (B) low-resolution HCP parcellation.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0007" position="float"/>
    </fig>
    <fig position="float" id="F8">
      <label>Fig. 8.</label>
      <caption>
        <p id="P71">Connectivity matrix spread (spread), connectivity matrix spread around the study participant connectivity matrix (ground truth spread, GT spread), and distance between average of the connectivity matrices and the study participant average connectivity matrix (bias) measured before and after Oracle Approximating Shrinkage (OAS) for all 250 HCP study participants and (A) the high-resolution HCP parcellation, (B) the low-resolution HCP parcellatioin, (C) the DMN, (D) the DLPFC.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0008" position="float"/>
    </fig>
    <fig position="float" id="F9">
      <label>Fig. 9.</label>
      <caption>
        <p id="P72">(A) the OAS intensity of the connectivity matrices derived from the AAL atlas strongly depend on the acquisition site, (B) OAS intensity also depends on the parcellation, (C) number of scans acquired at each location, (D) proportion of pairwise connections that differ more after OAS, between ASD and controls, among the most significantly different connections before shrinkage (the worst two parcellations are not shown). Shrinkage tends to reinforce strong ASD effects for all the parcellations.</p>
      </caption>
      <graphic xlink:href="nihms-1812866-f0009" position="float"/>
    </fig>
  </floats-group>
</article>
